// prh_include.h - public domain - swdayu <github.com/swdayu>
// No warranty implied, use at your own risk.
//
// REVISION HISTORY
//
// VERSION CONVENTIONS
//
// We are following https://semver.org/ as format MAJOR.MINOR.PATCH:
// - Modifying comments does not update the version.
// - PATCH is incremented in case of a bug fix or refactoring without
//   touching the API.
// - MINOR is incremented when new functions and/or types are added in a way
//   that does not break any existing user code. We want to do this in the
//   majority of the situation.
//   If we want to delete a certain function or type in favor of another one
//   we should just add the new function/type and deprecate the old one in a
//   backward compatible way and let them co-exist for a while.
// - MAJOR update should be just a periodic cleanup of the deprecated
//   functions and types without really modifying any existing functionality.
//
// LICENSE
//
// See end of the file for license information.
//
// NAMING CONVENTIONS
//
// Since Pure C does not have any namespaces, we prefix each name of the API
// with the `prh_` or `PRH_` to avoid any potential conflicts with any other
// names in your code.
//
// For the same reason, there is no way to hide implementation file scope
// names due to single-file-style library. They inevitably pollute the global
// namespace. So we choose `prh_impl_` or `PRH_IMPL_` prefix for these names.
//
// Above choices base on the fact that following identifiers are language
// reserved in C/C++:
// 1. all external identifiers that begin with an underscore.
// 2. all identifiers that begin with an underscore followed by a capital
//    letter or by another underscore (these reserved identifiers allow the
//    library to use numerous behind-the-scenes non-external macros and
//    functions).
// 3. in C++, identifiers with a double underscore anywhere are reserved
//    everywhere; in C, only the ones that begin with a double underscore
//    are reserved.
//
// In general, all exposed names are prefixed with `prh_` or `PRH_` depending
// on the case. However, the names prefixed with `prh_impl_` or `PRH_IMPL_`
// are implementation details of the library, the user should not directly
// use them.
//
// PREFIX STRIPPING
//
// The prefixed names sometimes are very annoying and make the code noisy. If
// you know that part of prh_include.h names are not conflict with your code,
// you can define PRH_XXX_STRIP_PREFIX macro to drop related name prefixes.
// For example, define PRH_ARRAY_STRIP_PREFIX can strip off `prh_` prefix
// from `prh_array_*` interfaces.
//
// Not all the names have strippable prefixes. All the redefinable names like
// `prh_realloc` and `PRH_ARRAY_INIT_ELEMS` for instance will retain their
// prefix. All basic names like `prh_i64` and `prh_inline` can not strip off
// the prefix due to they are short names anyway. But you can still #define
// your own names as you need before or after include prh_include.h. All
// implementation names `prh_impl_` and `PRH_IMPL_` are keep their original
// name untouched.
//
// The prefixes are stripped off only on the level of preprocessor. The names
// of the functions in the compiled object file will still retain the `prh_`
// prefix.
//
// If only few specific names cause conflicts for you, you can just #undef
// those names after include prh_include.h since they are macros anyway.
#ifndef PRH_IMPL_INCLUDE_H
#define PRH_IMPL_INCLUDE_H
#ifdef __cplusplus
extern "C" {
#endif

// architecture
#ifndef prh_arch_bits
#if defined(__LP64__) || defined(_WIN64) || (defined(__x86_64__) && !defined(__ILP32__)) || defined(_M_X64) || defined(__ia64) || defined (_M_IA64) || defined(__aarch64__) || defined(_M_ARM64) || defined(__powerpc64__)
    #if defined(__x86_64__) || defined(_M_X64)
        #define prh_arch_x64 1
    #elif defined(__aarch64__) || defined(_M_ARM64)
        #define prh_arch_a64 1
    #else
        #error "architecture unsupported!!!"
    #endif
    #define prh_arch_bits 64
    #define prh_arch_32 0
    #define prh_arch_64 1
#else
    #if defined(__i386) || defined(_M_IX86)
        #define prh_arch_x86 1
    #elif defined(__arm__) || defined(_M_ARM)
        #define prh_arch_arm 1
    #else
        #error "architecture unsupported!!!"
    #endif
    #define prh_arch_bits 32
    #define prh_arch_32 1
    #define prh_arch_64 0
#endif
#endif // prh_arch_bits

// byte endian
#ifndef prh_lit_endian
#if defined(prh_arch_x86) || defined(prh_arch_x64) || defined(prh_arch_arm) || defined(prh_arch_a64)
    #define prh_lit_endian 1
    #define prh_big_endian 0
#endif
#ifndef prh_lit_endian
    #define prh_lit_endian 1
    #define prh_big_endian 0
#endif
#endif // prh_lit_endian

// Visual Studio version                _MSC_VER
// Visual Studio 6.0                    1200
// Visual Studio .NET 2002 (7.0)        1300
// Visual Studio .NET 2003 (7.1)        1310
// Visual Studio 2005 (8.0)             1400
// Visual Studio 2008 (9.0)             1500
// Visual Studio 2010 (10.0)            1600
// Visual Studio 2012 (11.0)            1700
// Visual Studio 2013 (12.0)            1800
// Visual Studio 2015 (14.0)            1900
// Visual Studio 2017 RTW (15.0)        1910
// Visual Studio 2017 version 15.3      1911
// Visual Studio 2017 version 15.5      1912
// Visual Studio 2017 version 15.6      1913
// Visual Studio 2017 version 15.7      1914
// Visual Studio 2017 version 15.8      1915
// Visual Studio 2017 version 15.9      1916
// Visual Studio 2019 RTW 16.0          1920
// Visual Studio 2019 version 16.1      1921
// Visual Studio 2019 version 16.2      1922
// Visual Studio 2019 version 16.3      1923
// Visual Studio 2019 version 16.4      1924
// Visual Studio 2019 version 16.5      1925
// Visual Studio 2019 version 16.6      1926
// Visual Studio 2019 version 16.7      1927
// Visual Studio 2019 version 16.8      1928
// Visual Studio 2019 version 16.10     1929
// Visual Studio 2022 RTW 17.0          1930
// Visual Studio 2022 version 17.1      1931
// Visual Studio 2022 version 17.2      1932
// Visual Studio 2022 version 17.3      1933
// Visual Studio 2022 version 17.4      1934
// Visual Studio 2022 version 17.5      1935
// Visual Studio 2022 version 17.6      1936
// Visual Studio 2022 version 17.7      1937
// Visual Studio 2022 version 17.8      1938
// Visual Studio 2022 version 17.9      1939
// Visual Studio 2022 version 17.10     1940
// Visual Studio 2022 version 17.11     1941
// Visual Studio 2022 version 17.12     1942
// Visual Studio 2022 version 17.13     1943
// Visual Studio 2022 version 17.14     1944
//
// __GNUC__ __GNUC_MINOR__ __GNUC_PATCHLEVEL__
// /* Test for GCC > 3.2.0 */
// #if __GNUC__ > 3 || (__GNUC__ == 3 && (__GNUC_MINOR__ > 2 ||
//      (__GNUC_MINOR__ == 2 && __GNUC_PATCHLEVEL__ > 0)))
// /* Test for GCC > 3.2.0 */
// #define GCC_VERSION (__GNUC__ * 10000 + __GNUC_MINOR__ * 100 +
//      __GNUC_PATCHLEVEL__)
// #if GCC_VERSION > 30200

#ifndef PRH_GCC_VERSION
#if defined(__GNUC__) && defined(__GNUC_MINOR__) && defined(__GNUC_PATCHLEVEL__)
#define PRH_GCC_VERSION (__GNUC__ * 10000 + __GNUC_MINOR__ * 100 + __GNUC_PATCHLEVEL__)
#endif
#endif

// https://clang.llvm.org/docs/LanguageExtensions.html#builtinmacros
// __clang__ defined when compiling with Clang
// __clang_major__ e.g., the 2 in 2.0.1
// __clang_minor__ e.g., the 0 in 2.0.1
// __clang_patchlevel__ e.g., the 1 in 2.0.1
// __clang_version__ version string, e.g., "1.5 (trunk 102332)"

#ifndef PRH_CLANG_VERSION
#if defined(__clang__) && defined(__clang_major__) && defined(__clang_minor__) && defined(__clang_patchlevel__)
#define PRH_CLANG_VERSION (__clang_major__ * 10000 + __clang_minor__ * 100 + __clang_patchlevel__)
#endif
#endif

// inline noinline
#ifndef prh_inline
#if defined(_MSC_VER)
    #define prh_inline static __forceinline
    #if _MSC_VER >= 1400 // noinline was introduced in Visual Studio 2005
        #define prh_noinline __declspec(noinline)
    #else
        #define prh_noinline
    #endif
#elif defined(__GNUC__)
    // I've had a bug report where GCC is emitting warnings about functions
    // possibly not being inlineable. This warning happens when the
    // __attribute__((always_inline)) attribute is defined without an "inline"
    // statement. I think therefore there must be some case where "__inline__"
    // is not always defined, thus the compiler emitting these warnings. When
    // using -std=c89 or -ansi on the command line, we cannot use the "inline"
    // keyword and instead need to use "__inline__". In an attempt to work
    // around this issue I am using "__inline__" only when we're compiling in
    // strict ANSI mode.
    #if defined(__STRICT_ANSI__)
        #define prh_impl_gnuc_inline __inline__
    #else
        #define prh_impl_gnuc_inline inline
    #endif
    #if PRH_GCC_VERSION >= 30200 || defined(__clang__)
        #define prh_inline static prh_impl_gnuc_inline __attribute__((always_inline))
        #define prh_noinline __attribute__((noinline))
    #else
        #define prh_inline static prh_impl_gnuc_inline
        #define prh_noinline __attribute__((noinline))
    #endif
#elif defined(__WATCOMC__)
    #define prh_inline static __inline
    #define prh_noinline
#else
    #define prh_inline static inline
    #define prh_noinline
#endif
#endif // prh_inline

// __cplusplus
//  199711L(until C++11)
//  201103L(C++11)
//  201402L(C++14)
//  201703L(C++17)
//  202002L(C++20)
//  202302L(C++23)
//
// __STDC_VERSION__
//  199409L (C95)
//  199901L (C99)
//  201112L (C11)
//  201710L (C17)
//  202311L (C23)

// thread_local
#ifndef prh_thread_local
#if defined(__cplusplus) && __cplusplus >= 201103L // C++11 keyword
    #define prh_thread_local thread_local
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 202311L // C23 keyword
    #define prh_thread_local thread_local
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L // C11 keyword
    #define prh_thread_local _Thread_local
#elif defined(_MSC_VER)
    #define prh_thread_local __declspec(thread)
#elif defined(__GNUC__)
    #define prh_thread_local __thread
#endif
#endif

// alignas(size) alignas(type)
// When used in a declaration, the declared object will have its alignment
// requirement set to 1) the specified size, unless it is zero; 2) the
// alignment requirement of the type; except when this would weaken the
// alignment the type would have had naturally.
// When multiple alignas specifiers appear in the same declaration, the
// strictest one is used.
// In C++, the alignas specifier may also be applied to the declarations of
// class/struct/union types and enumerations. This is not supported in C, but
// the alignment of a struct type can be controlled by using alignas in a
// member declaration.
#ifndef prh_alignas
#if defined(__cplusplus) && __cplusplus >= 201103L // C++11 keyword
    #define prh_alignas(size) alignas(size)
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 202311L // C23 keyword
    #define prh_alignas(size) alignas(size)
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L // C11 keyword
    #define prh_alignas(size) _Alignas(size)
#elif defined(_MSC_VER)
    // Before Visual Studio 2015 you could use the Microsoft-specific keywords
    // __alignof and __declspec(align) to specify an alignment greater than
    // the default. Starting in Visual Studio 2015 you should use the C++11
    // standard keywords alignof and alignas for maximum code portability.
    #define prh_alignas(size) __declspec(align(size))
#elif defined(__GNUC__)
    // The aligned attribute specifies a minimum alignment (in bytes) for
    // variables of the specified type. When specified, alignment must be a
    // power of 2. Specifying no alignment argument implies the maximum
    // alignment for the target, which is often, but by no means always,
    // 8 or 16 bytes.
    // Note that the alignment of any given struct or union type is required
    // by the ISO C standard to be at least a perfect multiple of the lowest
    // common multiple of the alignments of all of the members of the struct
    // or union in question. This means that you can effectively adjust the
    // alignment of a struct or union type by attaching an aligned attribute
    // to any one of the members of such a type. 请注意，ISO C 标准要求任何给定
    // 的结构体或联合体类型的对齐方式，至少要是该结构体或联合体中所有成员对齐方式的
    // 最小公倍数的整数倍。这意味着，你可以通过为结构体或联合体类型的任意一个成员附
    // 加 aligned 属性，来有效调整该结构体或联合体类型的对齐方式。
    #define prh_alignas(size) __attribute__ ((aligned (size)))
#endif
#endif

// alignof(type)
// Returns the alignment requirement of the type named by the type. If type
// is an array type, the result is the alignment requirement of the array
// element type. The type cannot be function type or an incomplete type.
// The result is an integer constant of type size_t.
// The operand is not evaluated (so external identifiers used in the operand
// do not have to be defined).
// The use of alignof with expressions is allowed by some C compilers as a
// non-standard extension.
#ifndef prh_alignof
#if defined(__cplusplus) && __cplusplus >= 201103L // C++11 keyword
    #define prh_alignof(type) alignof(type)
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 202311L // C23 keyword
    #define prh_alignof(type) alignof(type)
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L // C11 keyword
    #define prh_alignof(type) _Alignof(type)
#elif defined(_MSC_VER)
    // Before Visual Studio 2015 you could use the Microsoft-specific keywords
    // __alignof and __declspec(align) to specify an alignment greater than
    // the default. Starting in Visual Studio 2015 you should use the C++11
    // standard keywords alignof and alignas for maximum code portability.
    // The alignof(type) operator returns the alignment in bytes of the
    // specified type as a value of type size_t.
    #define prh_alignof(type) __alignof(type)
#elif defined(__GNUC__)
    // The keyword __alignof__ determines the alignment requirement of a
    // function, object, or a type, or the minimum alignment usually required
    // by a type. Its syntax is just like sizeof and C11 _Alignof.
    #define prh_alignof(type) __alignof__(type)
#endif
#endif

// packed struct
#ifndef prh_packed_struct
#if defined(_MSC_VER)
    // Pragma directives specify machine-specific or operating system-specific
    // compiler features. A line that starts with #pragma specifies a pragma
    // directive. The Microsoft-specific __pragma keyword enables you to code
    // pragma directives within macro definitions. The standard _Pragma
    // preprocessor operator, introduced in C99 and adopted by C++11, is
    // similar.
    //      #pragma token-string
    //      __pragma(token-string)
    //      _Pragma(string-literal)
    // pack pragma takes effect at the first struct, union, or class
    // declaration after the pragma is seen.
    //      #pragma pack(2)
    //      struct T { int i; short j; double k; };
    // The sample shows how to use the push, pop, and show syntax.
    //      #pragma pack()               // n defaults to 8; equivalent to /Zp8
    //      #pragma pack(show)           // C4810
    //      #pragma pack(4)              // n = 4
    //      #pragma pack(show)           // C4810
    //      #pragma pack(push, r1, 16)   // n = 16 pushed to stack labeled r1
    //      #pragma pack(show)           // C4810
    //      pop until r1 is removed, and set current packing alignment to n = 2
    //      it equivalent to #pragma pack(pop, r1) followed by #pragma pack(2)
    //      #pragma pack(pop, r1, 2)
    //      #pragma pack(show)
    #define prh_packed_struct __pragma(pack(push, 1)) struct
    #define prh_packing_reset() __pragma(pack(pop))
#elif defined(__GNUC__)
    // An attribute specifier list may appear as part of a struct, union or
    // enum specifier.
    // It may go either immediately after the struct, union or enum keyword,
    // or after the closing brace. The former syntax is preferred.
    // In the following example struct my_packed_struct’s members are packed
    // closely together, but the internal layout of its s member is not
    // packed — todo that, struct my_unpacked_struct needs to be packed too.
    // struct my_unpacked_struct { char c; int i; };
    // struct __attribute__ ((packed)) my_packed_struct {
    //      char c;
    //      int i;
    //      struct my_unpacked_struct s;
    // };
    // For compatibility with Microsoft Windows compilers, GCC supports a set
    // of #pragma pack directives that change the maximum alignment of members
    // of structures (other than zero-width bit-fields), unions, and classes
    // subsequently defined. The n value below specifies the new alignment in
    // bytes and may have the value 1, 2, 4, 8, and 16. A value of 0 is also
    // permitted and indicates the default alignment (as if no #pragma pack
    // were in effect) should be used.
    //      #pragma pack(n)
    //      #pragma pack()
    //      #pragma pack(push[,n])
    //      #pragma pack(pop)
    #define prh_packed_struct struct __attribute__ ((packed))
    #define prh_packing_reset()
#else
    // Implementation defined behavior is controlled by #pragma directive.
    //      #pragma pragma_params
    //      _Pragma(string-literal)
    // Non-standard pragmas #pragma pack, this family of pragmas control the
    // maximum alignment for subsequently defined structure and union members.
    //      #pragma pack(arg)
    //      #pragma pack()
    //      #pragma pack(push)
    //      #pragma pack(push, arg)
    //      #pragma pack(pop)
    #define prh_packed_struct _Pragma("pack(push, 1)") struct
    #define prh_packing_reset() _Pragma("pack(pop)")
#endif
#endif

// typeof(expr)
#ifndef prh_typeof
#if defined(__cplusplus) && __cplusplus >= 201103L // C++11 keyword
    // Note that if the name of an object is parenthesized, it is treated as
    // an ordinary lvalue expression, thus decltype(x) and decltype((x)) are
    // often different types.
    // decltype is useful when declaring types that are difficult or impossible
    // to declare using standard notation, like lambda-related types or types
    // that depend on template parameters.
    // struct A { double x; };
    // const A* a;
    // decltype(a->x) y;       // type of y is double (declared type)
    // decltype((a->x)) z = y; // type of z is const double& (lvalue expr)
    #define prh_typeof(expr) decltype(expr)
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 202311L // C23 keyword
    // typeof and typeof_unqual are collectively called the typeof operators.
    // The typeof operators cannot be applied to bit-field members. If the type
    // of the operand is a variably modified type, the operand is evaluated;
    // otherwise, the operand is not evaluated. The result of the typeof_unqual
    // operator is the non-atomic unqualified type that would result from the
    // typeof operator. The typeof operator preserves all qualifiers.
    // typeof_unqual 运算符的结果是 typeof 运算符所产生结果的非原子且无限定符的类
    // 型。typeof 运算符会保留所有限定符。
    #define prh_typeof(expr) typeof(expr)
#elif defined(_MSC_VER)
    // __typeof__ in msc requires Visual Studio 17.9 or later, or cl.exe
    // version 19.39.33428 or later. This can be meet after installing the
    // latest version of Visual Studio Community 2022.
    #define prh_typeof(expr) __typeof__(expr)
#elif defined(__GNUC__)
    #define prh_typeof(expr) __typeof__(expr)
#endif
#endif

// compiler
#ifndef prh_impl_compiler
#ifdef _MSC_VER
    #define prh_cl_msc 1
#elif defined(__GNUC__)
    #define prh_cl_gnu 1
#endif
#define prh_impl_compiler
#endif

// fastcall convension
#ifndef prh_impl_fastcall
#if defined(prh_cl_msc)
    #if defined(prh_arch_x64)
        #define prh_naked_fastcall(ret) __declspec(naked) ret
        #define prh_fastcall(ret) ret
        #define prh_fastcall_typedef(ret, name) typedef ret (*name)
    #elif defined(prh_arch_x86)
        #define prh_naked_fastcall(ret) __declspec(naked) ret __fastcall
        #define prh_fastcall(ret) ret __fastcall
        #define prh_fastcall_typedef(ret, name) typedef ret (__fastcall *name)
    #endif
    #define prh_asm_begin() __asm {
    #define prh_asm_end() }
#elif defined(prh_cl_gnu)
    #if defined(prh_arch_x64)
        #define prh_naked_fastcall(ret) __attribute__((naked)) ret
        #define prh_fastcall(ret) ret
        #define prh_fastcall_typedef(ret, name) typedef ret (*name)
    #elif defined(prh_arch_x86)
        #define prh_naked_fastcall(ret) __attribute__((naked,fastcall)) ret
        #define prh_fastcall(ret) __attribute__((fastcall)) ret
        #define prh_fastcall_typedef(ret, name) typedef ret (__attribute__((fastcall)) *name)
    #endif
    #define prh_asm_begin() __asm__ (
    #define prh_asm_end() );
#endif
#define prh_impl_fastcall
#endif

#ifndef prh_static_assert
    #define prh_static_assert(const_expr) typedef int prh_impl_static_assert[(const_expr) ? 1 : -1]
#endif

#ifndef prh_array_size
    #define prh_array_size(a) (sizeof(a)/sizeof((a)[0]))
    #define prh_array_elem(a, i) (prh_assert((i) >= 0 && (i) < prh_array_size(a))), (a)[i]
#endif

#ifndef prh_offsetof
    #define prh_offsetof(type, field) ((prh_unt)(&((type *)0)->field))
#endif

#ifndef prh_unused
    #define prh_unused(a) ((void)(a))
#endif

#ifndef prh_macro_concat_name
    #define prh_macro_concat_name(a, b) prh_impl_macro_concat_name(a, b)
    #define prh_impl_macro_concat_name(a, b) a ## b
#endif

// https://en.cppreference.com/w/cpp/error/assert
//
// The definition of the macro assert depends on another macro, NDEBUG, which
// is not defined by the standard library. If NDEBUG is defined as a macro name
// at the point in the source code where <cassert> or <assert.h> is included,
// the assertion is disabled: assert does nothing. Otherwise, the assertion is
// enabled.
//
// In one source file, you can define and undefine NDEBUG multiple times, each
// time followed by #include <cassert>, to enable or disable the assert macro
// multiple times in the same source file.
//
// https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/assert-macro-assert-wassert
//
// assert 宏通常用于在程序开发过程中识别逻辑错误。通过实现表达式参数仅在程序运行不正
// 确时评估为假，从而在出现意外条件时停止程序执行。可以通过定义宏 NDEBUG 在编译时关闭
// 断言检查。你可以通过使用 /DNDEBUG 命令行选项，在不修改源文件的情况下关闭 assert
// 宏。也可以通过在包含 <assert.h> 之前使用 #define NDEBUG 指令，在源代码中关闭
// assert 宏。
//
// 当表达式评估为假（0）时，assert 会打印一条诊断消息，并调用 abort 来停止程序执行。
// 如果表达式为真（非零），则不采取任何操作。诊断消息包括失败的表达式、源文件名以及断
// 言失败的行号。诊断消息以宽字符（wchar_t）形式打印。因此，即使表达式中包含 Unicode
// 字符，它也能按预期工作。诊断消息的目标取决于调用该例程的应用程序类型。控制台应用程
// 序通过 stderr 接收消息。在基于 Windows 的应用程序中，assert 调用 Windows 的
// MessageBox 函数来创建一个消息框以显示消息，该消息框包含三个按钮：中止（Abort）、
// 重试（Retry）和忽略（Ignore）。如果用户选择“中止”，程序将立即终止。如果用户选择
// “重试”，将调用调试器（如果启用了即时调试），用户可以调试程序。如果用户选择“忽略”，
// 程序将继续正常执行。在存在错误条件时点击“忽略”可能会导致未定义行为，因为调用代码的
// 前置条件未得到满足。要覆盖默认输出行为，无论应用程序类型如何，都可以调用
// _set_error_mode 来选择是将输出发送到 stderr 还是显示对话框。
//
// _assert 和 _wassert 函数是内部 CRT 函数。它们有助于减少对象文件中支持断言所需的
// 代码量。不建议直接调用这些函数。
//
// 当未定义 NDEBUG 时，assert 宏在 C 运行时库的发布版和调试版中都启用。当定义了
// NDEBUG 时，宏可用，但不会评估其参数，也没有任何效果。当启用时，assert 宏调用
// _wassert 来实现其功能。其他断言宏，如 _ASSERT、_ASSERTE 和 _ASSERT_EXPR 也
// 可用，但只有在定义了 _DEBUG 宏且代码链接了调试版的 C 运行时库时，才会评估传递
// 给它们的表达式。Other assertion macros, _ASSERT, _ASSERTE and _ASSERT_EXPR,
// are also available, but they only evaluate the expressions passed to them
// when the _DEBUG macro has been defined and when they are in code linked
// with the debug version of the C run-time libraries.
//
// https://learn.microsoft.com/en-us/cpp/c-runtime-library/debug
// https://learn.microsoft.com/en-us/cpp/c-runtime-library/crt-debugging-techniques
// https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/assert-asserte-assert-expr-macros
//
// The compiler defines _DEBUG when you specify the /MTd or /MDd option. These
// options specify debug versions of the C run-time library.
//
// The C runtime (CRT) library provides extensive debugging support. To use one
// of the CRT debug libraries, you must link with /DEBUG and compile with /MDd,
// /MTd, or /LDd. The main definitions and macros for CRT debugging can be
// found in the<crtdbg.h> header file.
//
// _ASSERT_EXPR、_ASSERT 和 _ASSERTE 宏为应用程序提供了一种在调试过程中检查假设的简
// 洁机制。它们非常灵活，因为不需要用 #ifdef 语句将它们包围起来，以防止它们在应用程序
// 的零售版本中被调用。这种灵活性是通过使用 _DEBUG 宏实现的。_ASSERT_EXPR、_ASSERT
// 和 _ASSERTE 只有在编译时定义了 _DEBUG 宏时才可用。如果未定义 _DEBUG 宏，则在预处
// 理期间会移除对这些宏的调用。
//
// 如果结果为假（0），它们会打印一条诊断消息，并调用 _CrtDbgReportW 来生成调试报告。
// 除非你使用 _CrtSetReportMode 和 _CrtSetReportFile 函数指定了其他方式，否则消息
// 会出现在一个弹出式对话框中，这相当于设置了：
//      _CrtSetReportMode(_CRT_ASSERT, _CRTDBG_MODE_WNDW); 将断言设置为弹窗
//
// 当目标是一个调试消息窗口且用户选择“重试”按钮时，_CrtDbgReportW 返回 1，这将导致
// _ASSERT_EXPR、_ASSERT 和 _ASSERTE 宏在启用了即时调试（JIT）的情况下启动调试器。
// _RPT 和 _RPTF 调试宏也可用于生成调试报告，但它们不评估表达式。_RPT 宏生成简单的报
// 告，而 _RPTF 宏在生成的报告中包含调用报告宏的源文件和行号。
//
// 虽然 _ASSERT_EXPR、_ASSERT 和 _ASSERTE 是宏，并且可以通过包含 <crtdbg.h> 来使
// 用，但当定义了 _DEBUG 宏时，应用程序必须链接到调试版本的 C 运行时库，因为这些宏调
// 用了其他运行时函数。
#if defined(_DEBUG)
#undef NDEBUG // 启用标准断言
#define PRH_DEBUG 1
#else
#define NDEBUG 1 // 关闭标准断言
#define PRH_DEBUG 0
#endif

#ifndef prh_real_assert
    #define prh_impl_real_assert(a, line) ((void)((a) || (prh_impl_assert(line), false)))
    #define prh_real_assert(a) prh_impl_real_assert((a), __LINE__)
    #define prh_real_unreachable() prh_abort_error(0xea)
    void prh_impl_assert(int line);
#endif

#ifndef prh_assert
#if PRH_DEBUG
    #define prh_assert(a) prh_real_assert(a)
    #define prh_assert_line(a, line) prh_impl_real_assert((a), (line))
    #define prh_unreachable() prh_real_unreachable()
#else
    #define prh_assert(a) ((void)0)
    #define prh_assert_line(a, line) ((void)0)
    #define prh_unreachable() ((void)0)
#endif
#endif

// The ‘##’ token paste operator has a special meaning when placed between a
// comma (,) and a variable argument (__VA_ARGS__). If the variable argument
// is left out when the macro is used, then the comma before the ‘##’ will be
// deleted. This does not happen if you pass an empty argument, nor does it
// happen if the token preceding ‘##’ is anything other than a comma.
// ISO C99 requires at least one argument for the "..." in a variadic macro.

#ifndef prh_defer_if
    #define prh_defer_if(cond, ...) if (cond) { __VA_ARGS__; goto label_defer; }
#endif

// 线程退出码（exit code）兼容性问题：
// linux - 退出码 >=128 可能有移植性问题，可能导致shell混乱，并且尽量不要定义成 PTHREAD_CANCELED (-1)
// windows - 退出码尽量不要定义成 STILL_ACTIVE (259)
#ifndef prh_prerr
    #define prh_preno_if(a) if (a) { prh_prerr(errno); }
    #define prh_abort_nz(a) if (a) { prh_abort_error(errno); }
    #define prh_prerr_if(error, ...) if (error) { prh_prerr(error); __VA_ARGS__; }
    #define prh_abort_if_error(error) if (error) { prh_abort_error(error); }
    #define prh_abort_errno_if(a) if (a) { prh_abort_error(errno); }
    #define prh_prerr(error) prh_impl_prerr(__LINE__, (error))
    #define prh_abort_error(error) prh_impl_abort_error(__LINE__, (error))
    #define prh_abort_if(a) if (a) { prh_impl_abort(__LINE__); }
    void prh_impl_prerr(int line, unsigned int error);
    void prh_impl_abort(int line);
    void prh_impl_abort_error(int line, unsigned int error);
    void prh_print_exit_code(int thrd_id, int exit_code);
    #define prh_real_condret(c, a) if (!((a) c)) { prh_impl_abort(__LINE__); }
    #define prh_real_numbret(n, a) if ((a) != (n)) { prh_impl_abort(__LINE__); }
    #define prh_real_zeroret(a) if ((a) != 0) { prh_impl_abort(__LINE__); }
    #define prh_real_zeroret_or_errno(a) if ((a) != 0) { prh_impl_abort_error(__LINE__, errno); }
    #define prh_real_nnegret(a) if ((a) < 0) { prh_impl_abort(__LINE__); }
    #define prh_real_boolret(a) if (!(a)) { prh_impl_abort(__LINE__); }
#if PRH_DEBUG // macro arg 'a' can only expand once
    #define prh_condret(c, a) prh_real_condret((c), (a))
    #define prh_numbret(n, a) prh_real_numbret((n), (a))
    #define prh_zeroret(a) prh_real_zeroret(a)
    #define prh_zeroret_or_errno(a) prh_real_zeroret_or_errno(a)
    #define prh_nnegret(a) prh_real_nnegret(a)
    #define prh_boolret(a) prh_real_boolret(a)
    #define prh_debug(...) __VA_ARGS__
#else
    #define prh_condret(c, a) a
    #define prh_numbret(n, a) a
    #define prh_zeroret(a) a
    #define prh_zeroret_or_errno(a) a
    #define prh_nnegret(a) a
    #define prh_boolret(a) a
    #define prh_debug(...) ((void)0)
#endif
#endif

#ifndef prh_null
    #if defined(__cplusplus)
    // The macro NULL is an implementation-defined null pointer constant.
    // In C, the macro NULL may have the type void*, but that is not
    // allowed in C++ because null pointer constants cannot have that
    // type.
    #if __cplusplus >= 201103L // C++11 keyword
        #define prh_null nullptr
    #else
        #define prh_null 0
    #endif
    #else
    // The keyword nullptr denotes a predefined null pointer constant. It
    // is a non-lvalue of type nullptr_t. nullptr can be converted to a
    // pointer types or bool, where the result is the null pointer value
    // of that type or false respectively.
    // The macro NULL is an implementation-defined null pointer constant,
    // which may be an integer constant expression with the value ​0​; an
    // integer constant expression with the value ​0​ cast to the type void*;
    // predefined constant nullptr (since C23).
    // POSIX requires NULL to be defined as an integer constant expression
    // with the value ​0​ cast to void*.
    #if __STDC_VERSION__ >= 202311L // C23 keyword
        #define prh_null nullptr
    #else
        #define prh_null ((void *)0)
    #endif
    #endif
#endif

// bool true false
#if defined(__cplusplus)
    // bool true false are C++ keywords
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 202311L // C23 keyword
    // bool true false are C23 keywords
#elif !defined(bool)
    // Note that conversion to _Bool(until C23) bool(since C23) does not work
    // the same as conversion to other integer types: (bool)0.5 evaluates to
    // true, whereas (int)0.5 evaluates to ​0​.
    #define bool _Bool
    #define true 1
    #define false 0
#endif

#ifndef prh_impl_basic_types
    #define prh_impl_basic_types
    typedef unsigned char prh_byte;
    typedef unsigned char prh_u08;
    typedef signed char prh_i08;
    typedef unsigned short prh_u16;
    typedef short prh_i16;
    typedef unsigned int prh_u32;
    typedef int prh_i32;
    typedef unsigned long long prh_u64;
    typedef long long prh_i64;
#if prh_arch_bits == 32
    typedef prh_i32 prh_int;
    typedef prh_u32 prh_unt;
    typedef prh_i32 prh_sys_int;
    typedef prh_u32 prh_sys_unt;
    #define prh_int_bits 32
    #define prh_int_32 1
    #define prh_int_64 0
#elif prh_arch_bits == 64
    #ifdef prh_32_bit_memory_range
        typedef prh_i32 prh_int;
        typedef prh_u32 prh_unt;
        #define prh_int_bits 32
        #define prh_int_32 1
        #define prh_int_64 0
    #else
        typedef prh_i64 prh_int;
        typedef prh_u64 prh_unt;
        #define prh_int_bits 64
        #define prh_int_32 0
        #define prh_int_64 1
    #endif
    typedef prh_i64 prh_sys_int;
    typedef prh_u64 prh_sys_unt;
#else
    #error unsupported architecture
#endif
    typedef prh_unt prh_ptr;
    typedef prh_sys_unt prh_sys_ptr;
    typedef float prh_f32;
    typedef double prh_f64;
    typedef prh_f32 prh_float;
    prh_static_assert(sizeof(int) == 4);
    prh_static_assert(sizeof(bool) == 1);
    prh_static_assert(sizeof(prh_byte) == 1);
    prh_static_assert(sizeof(prh_u08) == 1);
    prh_static_assert(sizeof(prh_i08) == 1);
    prh_static_assert(sizeof(prh_u16) == 2);
    prh_static_assert(sizeof(prh_i16) == 2);
    prh_static_assert(sizeof(prh_u32) == 4);
    prh_static_assert(sizeof(prh_i32) == 4);
    prh_static_assert(sizeof(prh_u64) == 8);
    prh_static_assert(sizeof(prh_i64) == 8);
    prh_static_assert(sizeof(prh_int) == sizeof(void *)); // signed pointer size type
    prh_static_assert(sizeof(prh_unt) == sizeof(void *)); // unsigned pointer size type
    prh_static_assert(sizeof(prh_ptr) == sizeof(prh_unt));
    prh_static_assert(sizeof(prh_sys_int) == prh_arch_bits / 8); // signed machine generic purpose regiter size type
    prh_static_assert(sizeof(prh_sys_unt) == prh_arch_bits / 8); // unsigned machine generic purpose register size type
    prh_static_assert(sizeof(prh_sys_ptr) == sizeof(prh_sys_unt));
    prh_static_assert(sizeof(prh_f32) == 4);
    prh_static_assert(sizeof(prh_f64) == 8);
    prh_static_assert(sizeof(prh_float) == 4);
#endif

typedef enum {
    e_success = 0,
    e_failure = 1,
    e_aborted,
    e_access,
    e_access_denied,
    e_again,
    e_already,
    e_already_assigned,
    e_already_attached,
    e_already_defined,
    e_already_enabled,
    e_already_exist,
    e_already_listening,
    e_already_locked,
    e_already_owned,
    e_already_registered,
    e_already_running,
    e_already_waiting,
    e_already_set,
    e_assert_failed,
    e_auth_required,
    e_auth_failed,
    e_bad_address,
    e_bad_argument,
    e_bad_command,
    e_bad_context,
    e_bad_dest,
    e_bad_dev_type,
    e_bad_exchange,
    e_bad_format,
    e_bad_handle,
    e_bad_key,
    e_bad_length,
    e_bad_message,
    e_bad_name,
    e_bad_request,
    e_bad_req_code,
    e_bad_response,
    e_bad_source,
    e_bad_state,
    e_bad_style,
    e_bad_object,
    e_bad_opcode,
    e_bad_path,
    e_bad_pipe,
    e_bad_slot,
    e_bad_type,
    e_bad_unit,
    e_blocked,
    e_broken,
    e_buffer,
    e_busy,
    e_network_busy,
    e_canceled,
    e_cant_access,
    e_cant_activate,
    e_cant_create,
    e_cant_complete,
    e_cant_copy,
    e_cant_execute,
    e_cant_make,
    e_cant_open,
    e_cant_read,
    e_cant_start,
    e_cant_write,
    e_changed,
    e_addr_changed,
    e_checksum,
    e_closed,
    e_local_closed,
    e_local_error,
    e_remote_closed,
    e_remote_error,
    e_closing,
    e_conflict,
    e_config_error,
    e_connected,
    e_conn_abort,
    e_conn_reset,
    e_conn_refused,
    e_corrupt,
    e_current_directory,
    e_deadlock,
    e_deleted,
    e_key_deleted,
    e_dir_not_root,
    e_dir_not_empty,
    e_disabled,
    e_discarded,
    e_disconnected,
    e_divbyzero,
    e_duplicated,
    e_dup_name,
    e_empty,
    e_eof,
    e_error,
    e_exceed,
    e_exhaust,
    e_exist,
    e_file_exist,
    e_exited,
    e_expired,
    e_failed,
    e_fatal_error,
    e_fault, // 错误地址，无效指针地址，内存越界
    e_segment_fault,
    e_file,
    e_file_type,
    e_file_format,
    e_format,
    e_full,
    e_disk_full,
    e_queue_full,
    e_halted,
    e_hostdown,
    e_hostunreach,
    e_hw_error,
    e_adap_hw_error,
    e_ignored,
    e_illegal,
    e_incompatible,
    e_incomplete,
    e_inconsistent,
    e_infected,
    e_inuse,
    e_addrinuse,
    e_invalid,
    e_invalid_access,
    e_invalid_address,
    e_invalid_category,
    e_invalid_config,
    e_invalid_data,
    e_invalid_drive,
    e_invalid_event,
    e_invalid_flag,
    e_invalid_format,
    e_invalid_handle,
    e_invalid_level,
    e_invalid_message,
    e_invalid_name,
    e_invalid_object,
    e_invalid_param,
    e_invalid_password,
    e_invalid_username,
    e_invalid_protocol,
    e_invalid_query,
    e_invalid_range,
    e_invalid_size,
    e_invalid_state,
    e_invalid_type,
    e_inprogress,
    e_insecure,
    e_insufficient,
    e_internal_error,
    e_intruppted,
    e_lock,
    e_lock_failed,
    e_locked,
    e_lost,
    e_io_error,
    e_io_incomplete,
    e_io_pending,
    e_is_directory,
    e_misalignment,
    e_mismatch,
    e_modify,
    e_more_data,
    e_netdown,
    e_network,
    e_network_error,
    e_no_bufs,
    e_no_data,
    e_no_more,
    e_no_more_files,
    e_no_more_items,
    e_no_space,
    e_no_children,
    e_no_parent,
    e_no_resource,
    e_not_accept,
    e_not_active,
    e_not_allowed,
    e_not_avail,
    e_not_attach,
    e_not_canceled,
    e_not_complete,
    e_not_connected,
    e_not_directory,
    e_not_empty,
    e_not_enable,
    e_not_exist,
    e_dev_not_exist,
    e_dir_not_exist,
    e_file_not_exist,
    e_not_found,
    e_file_not_found,
    e_name_not_found,
    e_path_not_found,
    e_not_granted,
    e_not_init,
    e_not_install,
    e_not_implemented,
    e_not_loaded,
    e_not_lock,
    e_not_listening,
    e_not_online,
    e_not_open,
    e_not_owned,
    e_not_owner,
    e_not_permitted,
    e_not_present,
    e_not_ready,
    e_not_recoverable,
    e_not_registered,
    e_not_root,
    e_not_same,
    e_not_same_device,
    e_not_safe,
    e_not_set,
    e_not_started,
    e_not_support,
    e_not_sync,
    e_not_trust,
    e_not_unique,
    e_not_used,
    e_none,
    e_null,
    e_null_pointer,
    e_object,
    e_offline,
    e_oper_abort,
    e_oper_exist,
    e_oper_failed,
    e_oper_incomplete,
    e_oper_pending,
    e_open,
    e_open_failed,
    e_outofbound,
    e_outofdomain,
    e_outofmemory,
    e_outofrange,
    e_overflow,
    e_stack_overflow,
    e_partial,
    e_partial_copy,
    e_partial_read,
    e_partial_receive,
    e_partial_write,
    e_partial_send,
    e_paused,
    e_pending,
    e_protocol,
    e_prohibited,
    e_reach_end,
    e_reach_limit,
    e_read,
    e_read_failed,
    e_read_only,
    e_receive,
    e_recv_failed,
    e_recv_closed,
    e_reseted,
    e_refused,
    e_rejected,
    e_removed,
    e_revoked,
    e_same,
    e_same_drive,
    e_seek,
    e_send,
    e_send_failed,
    e_send_closed,
    e_service,
    e_shutdown,
    e_specific_error,
    e_stopped,
    e_system,
    e_system_error,
    e_suspended,
    e_violate,
    e_wouldblock,
    e_write,
    e_write_failed,
    e_write_protect,
    e_too_large,
    e_file_too_large,
    e_too_many,
    e_too_many_cmds,
    e_too_many_levels,
    e_too_many_links,
    e_too_many_moudles,
    e_too_many_names,
    e_too_many_items,
    e_too_many_open_files,
    e_too_many_posts,
    e_too_many_refs,
    e_too_many_requests,
    e_too_many_sessions,
    e_too_many_users,
    e_too_new,
    e_too_long,
    e_message_too_long,
    e_name_too_long,
    e_path_too_long,
    e_too_old,
    e_too_short,
    e_too_small,
    e_timeout,
    e_type,
    e_wrong_type,
    e_type_error,
    e_type_mismatch,
    e_unchangeable,
    e_undefined,
    e_underflow,
    e_unlocked,
    e_uninstalled,
    e_unknown,
    e_unknown_error,
    e_unreachable,
    e_unrecognized,
    e_unused,
} prh_error_code;

// Linux 操作系统开发与调试命令
// 打印系统信息：
//      getconf -a
// 打印处理器信息：
//      lscpu
//      cat /proc/cpuinfo
// 打印当前系统中的环境变量：
//      printenv
// 查看属于某一进程的环境变量：
//      cat /proc/521/environ
// 进程虚拟内存布局是否是旧布局：
//      cat /proc/sys/vm/legacy_va_layout
// 查看虚拟内存布局中分段的随机偏移配置：
//      cat /proc/sys/kernel/randomize_va_space
// 查看进程中映射内存的位置：
//      cat /proc/521/maps
//      73e4_604b_7000-73e4_604b_9000 /usr/lib/x86_64-linux-gnu/libc-2.31.so
//      73e4_604c_2000-73e4_604c_3000 /usr/lib/x86_64-linux-gnu/libdl-2.31.so
//      73e4_6053_1000-73e4_6053_2000 /usr/lib/x86_64-linux-gnu/ld-2.31.so
// 查看进程中映射内存的空间消耗信息：
//      cat /proc/521/smaps
//      73e4_6053_1000-73e4_6053_2000 /usr/lib/x86_64-linux-gnu/ld-2.31.so
//      Size:                  4 kB
//      KernelPageSize:        4 kB
//      MMUPageSize:           4 kB
//      Rss:                   4 kB
//      Pss:                   4 kB
//      Pss_Dirty:             4 kB
//      Shared_Clean:          0 kB
//      Shared_Dirty:          0 kB
//      Private_Clean:         0 kB
//      Private_Dirty:         4 kB
//      Referenced:            4 kB
//      Anonymous:             4 kB
//      KSM:                   0 kB
//      LazyFree:              0 kB
//      AnonHugePages:         0 kB
//      ShmemPmdMapped:        0 kB
//      FilePmdMapped:         0 kB
//      Shared_Hugetlb:        0 kB
//      Private_Hugetlb:       0 kB
//      Swap:                  0 kB
//      SwapPss:               0 kB
//      Locked:                0 kB
//      THPeligible:           0
//      VmFlags: rd wr mr mw me ac sd
// 查看最大进程号编号：
//      cat /proc/sys/kernel/pid_max
// 查看进程所有的文件描述符：
//      ll /proc/520/fdinfo/
//      0
//      1
//      2
//      255
// 查看进程其中一个文件描述符的相关信息：
//      cat /proc/520/fdinfo/1
// 查看创建新进程后是否子进程先调度：
//      cat /proc/sys/kernel/sched_child_runs_first
// 查看当前配置的资源限制：
//      ulimit -a
// 解除对核心文件大小的限制：
//      ulimit -c unlimited
// 产生核心调试文件：
//      sudo gcore -o core.file 711
// 核心文件配置相关：
//      cat /proc/sys/fs/suid_dumpable    # 对应ID的进程是否能进行转储，参见 proc(5)
//      cat /proc/711/coredump_filter     # 控制各种文件内存映射的转储，参见 core(5)
//      cat /proc/sys/kernel/core_pattern # 文件命令规则，参见 core(5)
// 查看进程的主线程信息，其中包括进程对信号的处理：
//      cat /proc/521/status
// 显示进程中的所有线程信息（-L），并显示完整格式（-f）：
//      ps -Lf # 其中 LWP 表示的是线程 ID（Light Weight Process），NLWP 表示该进程线程总数
//      UID          PID    PPID     LWP  C NLWP STIME TTY          TIME CMD
//      localho+     521     520     521  0    1 Jul10 pts/0    00:00:04 -bash
//      localho+   41590     521   41590  0    1 00:48 pts/0    00:00:00 ps -Lf
// 显示所有进程：
//      ps -e   # 显示所有进程
//      ps -eLf # 显示所有进程和线程信息
// 查看线程信息：
//      cat /proc/338/task/380/status
//      Name:   gmain
//      Umask:  0022
//      State:  S (sleeping)
//      ...
//      Threads:        2
//      SigQ:   0/7579
//      SigPnd: 0000000000000000    待处理的线程定向信号
//      ShdPnd: 0000000000000000    待处理的进程定向信号
//      SigBlk: fffffffe7ffbfeff    线程阻塞的信号掩码
//      SigIgn: 0000000001001000    线程忽略的信号集合，一个进程中所有线程忽略的信号集合都相同，因为信号处置设置是属于进程的属性
//      SigCgt: 0000000180004003    线程正在捕获的（设置处理函数的）信号集合，一个进程中所有线程捕获的信号集合都相同，因为信号处置设置是属于进程的属性
//      CapInh: 0000000000000000
//      CapPrm: 000001ffffffffff
//      CapEff: 000001ffffffffff
//      CapBnd: 000001ffffffffff
//      CapAmb: 0000000000000000
// 发送信号 SIGUSR1 给进程：
//      kill -USR1 711
// 列出系统中的网络接口，其中包括 MTU 信息：
//      sudo apt install net-tools
//      netstat -i
// 临时端口的分配范围：
//      cat /proc/sys/net/ipv4/ip_local_port_range
// 本地记录的主机名或域名到IP地址之间的映射：
//      cat /etc/hosts
// 服务名称与端口号之间的映射：
//      cat /etc/services
// 网络协议（IP协议）分配的号码：
//      cat /etc/protocols
//      www.iana.org/assignments/protocol-numbers
// 域名解析配置文件：
//      cat /etc/resolv.conf
// 每个 DNS 服务器都知道的一组根域名服务器：
//      dig . ns
//      https://root-servers.org/
// 域名解析所花时间：
//      time nslookup example.com
// 目的套接字地址的排序配置（RFC 3484）：
//      cat /etc/gai.conf
// 向 inetd 守护进程发送 SIGHUP 信号：
//      killall -HUP inetd
// 列出当前运行的进行信息：
//      ps
//      ps -C program -o "pid ppid pgid sid tty command"
// 查看套接字状态：
//      ./program port=55555 &
//      netstat -a | egrep '(Address|55555)'
//          Proto   Recv-Q  Send-Q  Local Address   Foreign Address     State
//          tcp     0       0       *:55555         *:*                 LISTEN
//          tcp     0       0       localhost:32835 localhost:55555     ESTABLISHED
//          tcp     0       0       localhost:55555 localhost:32835     ESTABLISHED
// 套接字可以发送的附属数据（ancillary data）的最大大小：
//      cat /proc/sys/net/core/optmem_max
// 设置非零值开启显式拥塞通知（ECN, explicit congestion notification）功能：
//      cat /proc/sys/net/ipv4/tcp_ecn
// 显示所有套接字信息（-a），并显式扩展信息（-e）包括其用户ID：
//      netstat -a -e
// 只显示监听套接字信息（-l），并只显示 Internet 域套接字的信息（--inet -4 或 --inet6 -6）
//      netstat --inet -l
// 显示 Internet 域 TCP 套接字信息（--tcp），并显示地址和端口号、并以数字形式显示用户ID（-n）
//      netstat --tcp -a -n
// 显示 Internet 域 UDP 套接字信息（--udp），并显示进程ID以及套接字所归属程序名（-p）
//      netstat --udp -a -p
// 显示 UNIX 域套接字信息
//      netstat --unix
// 显示 TCP 套接字信息，并每秒重复刷新（-c）
//      netstat --tcp -a -c
// 显示所有ip4 ip6套接字信息：
//      netstat -4 -6 -a -e
//          Active Internet connections (servers and established)
//          Proto Recv-Q Send-Q Local Address           Foreign Address         State       User            Inode
//          tcp        0      0 127.0.0.53:domain       0.0.0.0:*               LISTEN      systemd-resolve 106370
//          udp        0      0 127.0.0.53:domain       0.0.0.0:*                           systemd-resolve 106369
//          udp        0      0 localhost:323           0.0.0.0:*                           root            1199
//          udp6       0      0 ip6-localhost:323       [::]:*                              root            1200
//      Proto 表示套接字使用的协议；
//      Recv-Q 表示套接字接收缓冲区还未被本地应用读取的字节数，对于UDP该字段不仅包含数据还包含其首部和其他元数据所占的字节；
//      Send-Q 表示套接字发送缓冲区中配对等待发送的字节数，对于UDP该字段不仅包含数据还包含其首部和其他元数据所占的字节；
//      Local Address 表示套接字绑定到的本地地址
//      Foreign Address 表示对端套接字的地址，字符串 *:* 表示没有对端地址；
//      State 表示当前套接字所处的状态，对于TCP即TCP的各种状态；
// 查看服务端套接字内核允许提前将请求的客户端连接建立起来的最大连接数量：
//      cat /proc/sys/net/core/somaxconn
//      4096
// 查看一个用户最多可以注册让epoll监控的文件描述符个数：
//      cat /proc/sys/fs/epoll/max_user_watches
//      431949

#if defined(__FreeBSD__) || defined(__FreeBSD_kernel__) || defined(__DragonFly__)
// The macro that is only defined if compiling for FreeBSD.
#define prh_plat_freebsd 1
#endif

#if (defined(linux) || defined(__linux) || defined(__linux__))
// The macro that is only defined if compiling for Linux.
// Note that Android, although ostensibly a Linux-based system, will not
// define this. It defines prh_plat_android instead.
#define prh_plat_linux 1
#endif

#if defined(ANDROID) || defined(__ANDROID__)
// The macro that is only defined if compiling for Android.
#define prh_plat_android 1
#undef prh_plat_linux
#endif

#if defined(__unix__) || defined(__unix) || defined(unix)
// The macro that is only defined if compiling for a Unix-like system.
// Other platforms, like Linux, might define this in addition to their
// primary define.
#define prh_plat_unix 1
#endif

#if defined(__EMSCRIPTEN__)
// The macro that is only defined if compiling for Emscripten.
#define prh_plat_emscripten 1
#endif

#if defined(__NetBSD__)
// The macro that is only defined if compiling for NetBSD.
#define prh_plat_netbsd 1
#endif

#if defined(__OpenBSD__)
// The macro that is only defined if compiling for OpenBSD.
#define prh_plat_openbsd 1
#endif

#if defined(__APPLE__)
// The macro that is only defined if compiling for Apple platforms.
// iOS, macOS, etc will additionally define a more specific platform macro.
// +---------------------------------------------------------------------+
// |                            TARGET_OS_MAC                            |
// | +---+ +-----------------------------------------------+ +---------+ |
// | |   | |               TARGET_OS_IPHONE                | |         | |
// | |   | | +---------------+ +----+ +-------+ +--------+ | |         | |
// | |   | | |      IOS      | |    | |       | |        | | |         | |
// | |OSX| | |+-------------+| | TV | | WATCH | | BRIDGE | | |DRIVERKIT| |
// | |   | | || MACCATALYST || |    | |       | |        | | |         | |
// | |   | | |+-------------+| |    | |       | |        | | |         | |
// | |   | | +---------------+ +----+ +-------+ +--------+ | |         | |
// | +---+ +-----------------------------------------------+ +---------+ |
// +---------------------------------------------------------------------+
// https://developer.apple.com/documentation/kernel/mach
// https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/
// https://github.com/phracker/MacOSX-SDKs/tree/master/MacOSX11.3.sdk
// https://www.manpagez.com/man/3/clock_gettime/
// https://epir.at/2019/10/30/api-availability-and-target-conditionals/
#define prh_plat_apple 1
#endif

// CYGWIN 是一个在 Windows 操作系统上模拟 Unix/Linux 环境的大型工具集，它借助一个
// 动态链接库cygwin1.dll来模拟许多类 Unix 系统调用和 POSIX API。当你在 CYGWIN 环
// 境中运行程序时，程序会调用cygwin1.dll，该库再将这些调用转换为 Windows API 调用，
// 从而实现类 Unix 环境的模拟。
//
// MINGW（Minimalist GNU for Windows）则是将 GNU 工具集移植到 Windows 平台的项目，
// 它直接生成原生的 Windows 可执行文件，不依赖模拟层。MINGW 编译的程序使用 Windows
// API，而不是模拟 Unix 系统调用，因此生成的程序可以直接在 Windows 上运行，无需额外
// 的运行时环境。A native Windows port of the GNU Compiler Collection (GCC),
// with freely distributable import libraries and header files for building
// native Windows applications; includes extensions to the MSVC runtime to
// support C99 functionality. The mingw-w64 project is a complete runtime
// environment for gcc to support binaries native to Windows 64-bit and 32-bit
// operating systems. Mingw-w64 is an advancement of the original mingw.org
// project, which was created to support the GCC compiler on Windows systems.
// It was forked in 2007 in order to provide 64-bit support and newer APIs.
// It has since then gained wide use and distribution.
//
// MSYS2（Minimal SYStem 2）是一个在 Windows 平台上提供类 Unix 环境和开发工具的软
// 件。MSYS2 提供了类似于 Unix/Linux 系统的 shell 环境，以及一系列 Unix 风格的命令
// 行工具，这使得开发者可以在 Windows 上使用熟悉的 Unix 命令和操作方式进行开发和管理
// 工作。它集成了 Pacman 包管理器，这是 Arch Linux 所使用的包管理工具。借助 Pacman，
// 你能够轻松地安装、更新和删除软件包，并且可以方便地管理软件包之间的依赖关系。通过包
// 管理器，你可以获取到大量的开源软件和开发工具，如 GCC 编译器、Python、Ruby 等。
// MSYS2 包含了一系列的开发工具，如 GCC、GDB、Make 等，这些工具是进行 C、C++ 等语言
// 开发所必需的。同时，它还支持多种编程语言的开发环境，如 Python、Ruby、Perl 等。
// 与 MinGW 相比，MSYS2 不仅提供了编译工具，还提供了完整的类 Unix 环境和丰富的开
// 发工具。MSYS2 is a collection of tools and libraries providing you with an
// easy-to-use environment for building, installing and running native Windows
// software. It consists of a command line terminal called mintty, bash,
// version control systems like git and subversion, tools like tar and awk and
// even build systems like autotools, all based on a modified version of
// Cygwin. Despite some of these central parts being based on Cygwin, the main
// focus of MSYS2 is to provide a build environment for native Windows software
// and the Cygwin-using parts are kept at a minimum. MSYS2 provides up-to-date
// native builds for GCC, mingw-w64, CPython, CMake, Meson, OpenSSL, FFmpeg,
// Rust, Ruby, just to name a few. The unixy tools in MSYS2 are directly based
// on Cygwin, so there is some overlap there. While Cygwin focuses on building
// Unix software on Windows as is, MSYS2 focuses on building native software
// built against the Windows APIs.
#if defined(_WIN32) || defined(__MINGW32__) || defined(__MINGW64__)
#define prh_plat_windows 1
#endif

#ifdef PRH_SOCK_INCLUDE
#define PRH_CONO_INCLUDE
#ifdef PRH_SOCK_IMPLEMENTATION
#define PRH_CONO_IMPLEMENTATION
#endif
#endif

#ifdef PRH_CONO_INCLUDE
#define PRH_IOCP_INCLUDE
#define PRH_CORO_INCLUDE
#ifdef PRH_CONO_IMPLEMENTATION
#define PRH_IOCP_IMPLEMENTATION
#define PRH_CORO_IMPLEMENTATION
#endif
#endif

#ifdef PRH_IOCP_INCLUDE
#define PRH_THRD_INCLUDE
#ifdef PRH_IOCP_IMPLEMENTATION
#define PRH_THRD_IMPLEMENTATION
#endif
#endif

#ifdef PRH_THRD_INCLUDE
#define PRH_ATOMIC_INCLUDE
#define PRH_TIME_INCLUDE
#ifdef PRH_THRD_IMPLEMENTATION
#define PRH_ATOMIC_IMPLEMENTATION
#define PRH_TIME_IMPLEMENTATION
#endif
#endif

#ifdef PRH_ATOMIC_INCLUDE
#define PRH_QUEUE_INCLUDE
#ifdef PRH_ATOMIC_IMPLEMENTATION
#define PRH_QUEUE_IMPLEMENTATION
#endif
#endif

#ifdef PRH_STACK_INCLUDE
#define PRH_LIST_INCLUDE
#ifdef PRH_STACK_IMPLEMENTATION
#define PRH_LIST_IMPLEMENTATION
#endif
#endif

#ifdef PRH_QUEUE_INCLUDE
#define PRH_ARRAY_INCLUDE
#define PRH_LIST_INCLUDE
#ifdef PRH_QUEUE_IMPLEMENTATION
#define PRH_ARRAY_IMPLEMENTATION
#define PRH_LIST_IMPLEMENTATION
#endif
#endif

#if defined(PRH_ARRAY_IMPLEMENTATION) || defined(PRH_LIST_IMPLEMENTATION)
#define PRH_BASE_IMPLEMENTATION
#endif

#if defined(PRH_ATOMIC_IMPLEMENTATION) || defined(PRH_THRD_IMPLEMENTATION) || \
    defined(PRH_TIME_IMPLEMENTATION) || defined(PRH_CONO_IMPLEMENTATION)
#if defined(prh_plat_windows)
    // Predefined macros:
    //      _WIN16      A 16-bit platform
    //      _WIN32      A 32-bit platform. This value is also defined by the
    //                  64-bit compiler for backward compatibility.
    //      _WIN64      A 64-bit platform. This includes both x64 and ARM64.
    //      _M_IA64     Intel Itanium platform
    //      _M_IX86     x86 platform
    //      _M_X64      x64 platform
    //      _M_ARM64    ARM64 platform
    //
    // When you use the Windows SDK, you can specify which versions of Windows
    // your code can run on. The preprocessor macros WINVER and _WIN32_WINNT
    // specify the minimum operating system version your code supports.
    //
    // The possible values are listed in the Windows header file sdkddkver.h,
    // which defines macros for each major Windows version. To build your
    // application to support a previous Windows platform, include WinSDKVer.h.
    // Then, set the WINVER and _WIN32_WINNT macros to the oldest supported
    // platform before including sdkddkver.h. Here are the lines from the
    // Windows 10 SDK version of sdkddkver.h that encode the values for each
    // major version of Windows.
    //
    //      #define _WIN32_WINNT_NT4            0x0400 // Windows NT 4.0
    //      #define _WIN32_WINNT_WIN2K          0x0500 // Windows 2000
    //      #define _WIN32_WINNT_WINXP          0x0501 // Windows XP
    //      #define _WIN32_WINNT_WS03           0x0502 // Windows Server 2003
    //      #define _WIN32_WINNT_WIN6           0x0600 // Windows Vista
    //      #define _WIN32_WINNT_VISTA          0x0600 // Windows Vista
    //      #define _WIN32_WINNT_WS08           0x0600 // Windows Server 2008
    //      #define _WIN32_WINNT_LONGHORN       0x0600 // Windows Vista
    //      #define _WIN32_WINNT_WIN7           0x0601 // Windows 7
    //      #define _WIN32_WINNT_WIN8           0x0602 // Windows 8
    //      #define _WIN32_WINNT_WINBLUE        0x0603 // Windows 8.1
    //      #define _WIN32_WINNT_WINTHRESHOLD   0x0A00 // Windows 10
    //      #define _WIN32_WINNT_WIN10          0x0A00 // Windows 10
    //
    // For a more fine-grained approach to versioning, you can use the NTDDI
    // version constants in sdkddkver.h. Here are some of the macros defined
    // by sdkddkver.h in Windows 10 SDK version 10.0.18362.0.
    //
    //      #define NTDDI_WIN4                  0x04000000
    //      #define NTDDI_WIN2K                 0x05000000
    //      #define NTDDI_WIN2KSP1              0x05000100
    //      #define NTDDI_WIN2KSP2              0x05000200
    //      #define NTDDI_WIN2KSP3              0x05000300
    //      #define NTDDI_WIN2KSP4              0x05000400
    //      #define NTDDI_WINXP                 0x05010000
    //      #define NTDDI_WINXPSP1              0x05010100
    //      #define NTDDI_WINXPSP2              0x05010200
    //      #define NTDDI_WINXPSP3              0x05010300
    //      #define NTDDI_WINXPSP4              0x05010400
    //      #define NTDDI_WS03                  0x05020000
    //      #define NTDDI_WS03SP1               0x05020100
    //      #define NTDDI_WS03SP2               0x05020200
    //      #define NTDDI_WS03SP3               0x05020300
    //      #define NTDDI_WS03SP4               0x05020400
    //      #define NTDDI_WIN6                  0x06000000
    //      #define NTDDI_WIN6SP1               0x06000100
    //      #define NTDDI_WIN6SP2               0x06000200
    //      #define NTDDI_WIN6SP3               0x06000300
    //      #define NTDDI_WIN6SP4               0x06000400
    //      #define NTDDI_VISTA                 NTDDI_WIN6
    //      #define NTDDI_VISTASP1              NTDDI_WIN6SP1
    //      #define NTDDI_VISTASP2              NTDDI_WIN6SP2
    //      #define NTDDI_VISTASP3              NTDDI_WIN6SP3
    //      #define NTDDI_VISTASP4              NTDDI_WIN6SP4
    //      #define NTDDI_LONGHORN              NTDDI_VISTA
    //      #define NTDDI_WS08                  NTDDI_WIN6SP1
    //      #define NTDDI_WS08SP2               NTDDI_WIN6SP2
    //      #define NTDDI_WS08SP3               NTDDI_WIN6SP3
    //      #define NTDDI_WS08SP4               NTDDI_WIN6SP4
    //      #define NTDDI_WIN7                  0x06010000
    //      #define NTDDI_WIN8                  0x06020000
    //      #define NTDDI_WINBLUE               0x06030000
    //      #define NTDDI_WINTHRESHOLD          0x0A000000
    //      #define NTDDI_WIN10                 0x0A000000
    //      #define NTDDI_WIN10_TH2             0x0A000001
    //      #define NTDDI_WIN10_RS1             0x0A000002
    //      #define NTDDI_WIN10_RS2             0x0A000003
    //      #define NTDDI_WIN10_RS3             0x0A000004
    //      #define NTDDI_WIN10_RS4             0x0A000005
    //      #define NTDDI_WIN10_RS5             0x0A000006
    //      #define NTDDI_WIN10_19H1            0x0A000007
    //      #define NTDDI_WIN10_VB              0x0A000008
    //      #define NTDDI_WIN10_MN              0x0A000009
    //      #define NTDDI_WIN10_FE              0x0A00000A
    //      #define NTDDI_WIN10_CO              0x0A00000B
    //      #define NTDDI_WIN10_NI              0x0A00000C
    //      #define WDK_NTDDI_VERSION           NTDDI_WIN10_NI
    //
    // The OSVER, SPVER, and SUBVER macros can be used in your code to control
    //  conditional compilation for different levels of API support.
    //
    //      #define OSVERSION_MASK      0xFFFF0000
    //      #define SPVERSION_MASK      0x0000FF00
    //      #define SUBVERSION_MASK     0x000000FF
    //      #define OSVER(Version)  ((Version) & OSVERSION_MASK)
    //      #define SPVER(Version)  (((Version) & SPVERSION_MASK) >> 8)
    //      #define SUBVER(Version) (((Version) & SUBVERSION_MASK))
    //
    // By default, new Windows projects in Visual Studio use the latest
    // Windows SDK that ships with Visual Studio. To use a newer SDK you've
    // installed separately, you'll have to set the Windows SDK explicitly
    // in your project properties. Values are not guaranteed to work if you
    // include internal MFC headers in your application. You can also define
    // this macro by using the /D compiler option.
    //
    // https://learn.microsoft.com/en-us/cpp/porting/modifying-winver-and-win32-winnt
    // https://learn.microsoft.com/en-us/windows/win32/winprog/using-the-windows-headers
    // https://learn.microsoft.com/en-us/windows/win32/winprog/header-annotations
    //
    // The header files for the Windows API enable you to create 32- and 64-bit
    // applications. They include declarations for both Unicode and ANSI
    // versions of the API. For more information, see Unicode in the Windows
    // API. They use data types that enable you to build both 32- and 64-bit
    // versions of your application from a single source code base. For more
    // information, see Getting Ready for 64-bit Windows. Additional features
    // include Header Annotations and STRICT Type Checking.
    //
    // Microsoft Visual C++ 包含了在 Visual C++ 发布时当前版本的 Windows 头文件。
    // 因此，如果你从 SDK 安装了更新的头文件，你的计算机上可能会有多个版本的 Windows
    // 头文件。如果你没有确保使用的是最新版本的 SDK 头文件，当你编译使用了在 Visual
    // C++ 发布后引入的功能的代码时，你会收到以下错误代码：error C2065: undeclared
    // identifier。
    //
    // 某些依赖于特定版本 Windows 的函数使用条件代码声明。这使得你可以利用编译器检测
    // 你的应用程序是否使用了其目标 Windows 版本不支持的函数。要编译使用这些函数的应
    // 用程序，你必须定义适当的宏。否则，你会收到 C2065 错误消息。
    //
    // The Windows header files use macros to indicate which versions of
    // Windows support many programming elements. Therefore, you must define
    // these macros to use new functionality introduced in each major
    // operating system release. (Individual header files may use different
    // macros; therefore, if compilation problems occur, check the header file
    // that contains the definition for conditional definitions.) For more
    // information, see SdkDdkVer.h.
    //
    // The table show above describes the preferred macros used in the Windows
    // header files. If you define NTDDI_VERSION, you must also define
    // _WIN32_WINNT. You can define these symbols by using the #define
    // statement in each source file, or by specifying the /D compiler option
    // supported by Visual C++. For example, to set _WIN32_WINNT in your source
    // file, use the following statement:
    //      #define _WIN32_WINNT 0x0502
    // To set _WIN32_WINNT using the /D compiler option, use the following
    //  command:
    //      cl -c /D_WIN32_WINNT=0x0502 source.cpp
    //
    // 注意，最新版本的 Windows 中引入的一些功能可能会添加到早期版本 Windows 的服务
    // 包（Service Pack, SP）中。因此，要为目标服务包定义 _WIN32_WINNT，你可能需要
    // 使用下一个主要操作系统版本的值。例如，GetDllDirectory 函数是在 Windows
    // Server 2003 中引入的，并且如果 _WIN32_WINNT 是 0x0502（Windows Server
    // 2003）或更高版本，则会定义该函数。此函数还被添加到了带有 SP1 的 Windows XP
    // 中。因此，如果你将 _WIN32_WINNT 定义为 0x0501（Windows XP），你将错过在带
    // 有 SP1 的 Windows XP 中定义的功能。
    //
    // https://devblogs.microsoft.com/oldnewthing/20070411-00/?p=27283
    // 关于 WINVER 和其他版本控制符号的起源与演变
    //
    // WINVER 符号是最古老的。它是 16 位 Windows 用于控制其头文件版本的符号，后来被
    // 延续到了 32 位头文件中，这可能是因为最初将头文件从 16 位转换为 32 位的那批人，
    // 他们习惯于使用 WINVER 符号。这个符号在那些可以追溯到 16 位 Windows 的头文件中
    // 仍然被广泛使用，例如 winuser.h、wingdi.h 和 mmsystem.h。
    //
    // 接下来出现的是 _WIN32_WINNT 符号。我不确定它从何而来，但从它的名字来看，很可
    // 能是 Windows NT 团队发明的，以便让他们能够将头文件中仅在 Windows NT 的 Win32
    // 实现中可用的部分隔离出来。别忘了在早期，还有 Win32s，这是可以在 16 位
    // Windows 3.1 上运行的 Win32 子集。单靠 WINVER 符号是不足以精确指定你想要兼容
    // 的版本的。例如，仅在 Windows NT 3.1 中可用的函数会被用 #if _WIN32_WINNT >=
    // 0x030A 保护起来，这样那些希望在 Win32s 上运行的程序就可以将 _WIN32_WINNT 设
    // 置为零，从而将该函数排除在外。同样，Windows 95 和 Windows NT 4 都标识为
    // Windows 主版本 4，所以 WINVER 符号也不足以区分它们。因此，那些存在于 Windows
    // NT 4 但不存在于 Windows 95 中的函数被用 _WIN32_WINNT 保护起来。另一方面，也
    // 有一些函数是在 Windows 95 中首次引入的，而最初的 Windows NT 4 中并不存在。
    // _WIN32_WINDOWS 符号让你可以指定你想要访问那些在 Windows 95 中新增的、并且会
    // 被移植到 Windows NT 4 和后续版本 Windows NT 的功能。
    //
    // 历史总是惊人地相似：我们在试图弄清楚为什么有些函数返回 NULL，而另一些函数返回
    // INVALID_HANDLE_VALUE 时就见过这种情况。每次有人向 Windows 添加新功能并需要
    // 添加 #ifdef 保护时，他们几乎都会随机选择使用 WINVER、_WIN32_WINDOWS 还是
    // _WIN32_WINNT。为了试图让这一切混乱变得有些条理，SDK 和 DDK 团队为 Windows
    // Vista 的头文件制定了一个新计划：sdkddkver.h。现在只有一个符号需要你定义来指
    // 定你的最低目标操作系统：NTDDI_VERSION。一旦你设置了它，所有其他符号都会自动
    // 设置为适合你的目标操作系统的值。（至于 NTDDI 这几个字母代表什么，我也不知道，
    // 尽管有一个显而易见的候选词。）但愿所有人都能统一使用 NTDDI_VERSION，这样这篇
    // 文章就会成为那些“古色古香的历史小玩意儿”，就像所有关于 16 位 Windows 的文章
    // 一样。就像“一个关于 21 世纪初疯狂日子里人们不得不做的事情的小故事。谢天谢地，
    // 我们再也不用担心这些了！”
    //
    // GetTickCount64 Windows Vista Windows Server 2008             0x0600
    // QueryInterruptTime Windows 7 Windows Server 2008 S2          0x0601
    // GetCurrentThreadStackLimits Windows 8 Windows Server 2012    0x0602
    #include <WinSDKVer.h>
    #include <sdkddkver.h>
    #if !defined(_WIN32_WINNT) || (_WIN32_WINNT < 0x0602)
    #error "target windows platform shall >= 0x0602"
    #endif
    // When you define the STRICT symbol, you enable features that require more
    // care in declaring and using types. This helps you write more portable
    // code. This extra care will also reduce your debugging time. Enabling
    // STRICT redefines certain data types so that the compiler does not permit
    // assignment from one type to another without an explicit cast. This is
    // especially helpful with Windows code. Errors in passing data types are
    // reported at compile time instead of causing fatal errors at run time.
    // With Visual C++, STRICT type checking is defined by default.
    #define STRICT 1 // #define NO_STRICT
    // https://learn.microsoft.com/en-us/windows/win32/intl/unicode-in-the-windows-api
    // https://learn.microsoft.com/en-us/windows/win32/intl/unicode
    // https://learn.microsoft.com/en-us/cpp/text/unicode-programming-summary
    // To take advantage of the MFC and C run-time support for Unicode, you
    // need to:
    //      Define the symbol _UNICODE before you build your program.
    //      Set the Entry Point symbol to wWinMainCRTStartup.
    //      Use portable run-time functions and types.
    // The run-time library provides a wide-character version of main. Use
    // wmain to make your application Unicode-aware.
    #define UNICODE 1
    #define _UNICODE 1
    // Define WIN32_LEAN_AND_MEAN to exclude APIs such as Cryptography, DDE,
    // RPC, Shell, and Windows Sockets.
    #define WIN32_LEAN_AND_MEAN 1
    // Suppress deprecation warnings for the older less secure functions.
    #define _CRT_SECURE_NO_DEPRECATE 1
    #define _CRT_SECURE_NO_WARNINGS 1
    // Define one or more of the NOapi symbols to exclude the API. For example,
    // NOCOMM excludes the serial communication API. For a list of support
    // NOapi symbols, see Windows.h. such as #define NOCOMM
    // 基本类型
    //  Data type   Size        Signed?
    //  BYTE        8 bits      Unsigned
    //  WORD        16 bits     Unsigned
    //  DWORD       32 bits     Unsigned
    //  UINT32      32 bits     Unsigned
    //  ULONG       32 bits     Unsigned
    //  INT32       32 bits     Signed
    //  LONG        32 bits     Signed
    //  INT64       64 bits     Signed
    //  LONGLONG    64 bits     Signed
    //  UINT64      64 bits     Unsigned
    //  ULONGLONG   64 bits     Unsigned
    // 指针长度的整型
    //  DWORD_PTR
    //  INT_PTR
    //  LONG_PTR
    //  ULONG_PTR
    //  UINT_PTR
    #include <windows.h>
    #define PRH_BOOLRET_OR_ABORT(a) if (!(a)) { prh_abort_error(GetLastError()); }
    #define PRH_BOOLRET_OR_ERROR(a) if (!(a)) { prh_prerr(GetLastError()); }
    // https://learn.microsoft.com/en-us/cpp/c-runtime-library/find-memory-leaks-using-the-crt-library
    // 检测内存泄漏的主要工具是 C/C++ 调试器和 CRT 调试堆函数。要启用所有调试堆函数，
    // 需要在你的 C++ 程序中按以下顺序包含下面的语句。其中 #define _CRTDBG_MAP_ALLOC
    // 将 CRT 堆函数的基本版本映射到相应的调试版本。如果省略了 #define 语句，内存泄漏
    // 信息将不够详细。包含 crtdbg.h 会将 malloc 和 free 函数映射到它们的调试版本 _malloc_dbg
    // 和 _free_dbg，这些版本会跟踪内存分配和释放。这种映射仅在具有 _DEBUG 的调试生成
    // 中发生。发布生成使用普通的 malloc 和 free 函数。
    // 通过使用前面的语句启用了调试堆函数后，在应用程序退出点之前调用 _CrtDumpMemoryLeaks()，
    // 以在应用程序退出时显示内存泄漏报告。如果你的应用程序有多个退出点，你无需手动在每
    // 个退出点放置 _CrtDumpMemoryLeaks()。为了在每个退出点自动调用 _CrtDumpMemoryLeaks()，
    // 在应用程序开头放置一个对 _CrtSetDbgFlag(_CRTDBG_ALLOC_MEM_DF | _CRTDBG_LEAK_CHECK_DF)
    // 的调用即可。
    // 默认情况下， _CrtDumpMemoryLeaks 将内存泄漏报告输出到“输出”窗口的“调试”窗格。
    // 如果你使用了库，库可能会将输出重置到另一个位置。你可以使用 _CrtSetReportMode
    // 将报告重定向到另一个位置，或者像下面这样重新定向回“输出”窗口：
    //      _CrtSetReportMode(_CRT_WARN, _CRTDBG_MODE_DEBUG);
    //
    // 内存块类型有 “normal”、“client” 和 “CRT”。普通块是由你的程序分配的普通内存。
    // “client”块是 MFC 程序用于需要析构函数的对象的特殊类型的内存块。MFC 的 new 运
    // 算符会根据被创建的对象类型创建普通块或客户端块。“CRT” 块是由 CRT 库为其自身用
    // 途分配的。CRT 库会处理这些块的释放，因此除非 CRT 库出现严重问题，否则 CRT 块
    // 不会出现在内存泄漏报告中。还有两种内存块类型永远不会出现在内存泄漏报告中。“free”
    // 块是已经释放的内存，按定义不会泄漏。“ignore” 块是你明确标记为从内存泄漏报告中
    // 排除的内存。
    //
    // 前面的技术可以识别使用标准 CRT malloc 函数分配的内存的内存泄漏。然而，如果你的
    // 程序使用 C++ 的 new 运算符分配内存，你可能只能在内存泄漏报告中看到 operator
    // new 调用 _malloc_dbg 的文件名和行号。为了创建更有用的内存泄漏报告，你可以编写
    // 一个像下面这样的宏来报告 new 分配的行，然后你可以使用 DBG_NEW 宏在代码中替换
    // new 运算符。
    // #ifdef _DEBUG
    //     #define DBG_NEW new ( _NORMAL_BLOCK , __FILE__ , __LINE__ )
    //     // Replace _NORMAL_BLOCK with _CLIENT_BLOCK if you want the
    //     // allocations to be of _CLIENT_BLOCK type
    // #else
    //     #define DBG_NEW new
    // #endif
    //
    // 内存分配编号可以告诉你泄漏的内存块是在何时分配的。例如，一个内存分配编号为 18
    // 的块是在应用程序运行期间分配的第 18 个内存块。CRT 报告会统计运行期间的所有内存
    // 块分配，包括 CRT 库和其他库（如 MFC）的分配。因此，内存分配块编号 18 可能不是
    // 你的代码分配的第 18 个内存块。你可以使用分配编号在内存分配上设置断点。
    #if PRH_DEBUG
    #define _CRTDBG_MAP_ALLOC
    #include <stdlib.h>
    #include <crtdbg.h>
    #endif
#else
    // POSIX allows an application to test at compile or run time whether
    // certain options are supported, or what the value is of certain
    // configurable constants or limits.
    // At compile time this is done by including <unistd.h> and/or <limits.h>
    // and testing the value of certain macros.
    // At run time, one can ask for numerical values using the present
    // function sysconf(). One can ask for numerical values that may depend
    // on the filesystem in which a file resides using fpathconf(3) and
    // pathconf(3). One can ask for string values using confstr(3).
    // The values obtained from these functions are system configuration
    // constants. They do not change during the lifetime of a process.
    //
    // For options, typically, there is a constant _POSIX_FOO that may be
    // defined in <unistd.h>. If it is undefined, one should ask at run time.
    // If it is defined to -1, then the option is not supported. If it is
    // defined to 0, then relevant functions and headers exist, but one has
    // to ask at run time what degree of support is available. If it is
    // defined to a value other than -1 or 0, then the option is supported.
    // Usually the value (such as 200112L) indicates the year and month of
    // the POSIX revision describing the option. glibc uses the value 1 to
    // indicate support as long as the POSIX revision has not been published
    // yet. The sysconf() argument will be _SC_FOO. For a list of options,
    // see posixoptions(7).
    // https://www.man7.org/linux/man-pages/man7/posixoptions.7.html
    //
    // For variables or limits, typically, there is a constant _FOO, maybe
    // defined in <limits.h>, or _POSIX_FOO, maybe defined in <unistd.h>.
    // The constant will not be defined if the limit is unspecified. If the
    // constant is defined, it gives a guaranteed value, and a greater value
    // might actually be supported. If an application wants to take advantage
    // of values which may change between systems, a call to sysconf() can
    // be made. The sysconf() argument will be _SC_FOO.
    #define prh_plat_posix 1
    // POSIX 可移植操作系统接口（Protable Operating System Interface），其接口分成
    // 两个部分：必须部分、可选部分。可选接口部分按功能又进一步分成40个功能分区，以下是
    // POSIX.1 可选接口分组和选项码。其中标出了如果还满足 SUS 单一UNIX规范，必须要实
    // 现的功能，其中 XSI 表示的是 X/Open 系统接口（X/Open System Interface）。
    //      选项码  SUS强制     对应宏名称                          描述
    //      ADV             _POSIX_ADVISORY_INFO                建议性信息
    //      CPT             _POSIX_CPUTIME                      进程CPU时间
    //      FSC    (*)      _POSIX_FSYNC                        文件同步
    //      IP6             _POSIX_IPV6                         IPv6接口
    //      ML              _POSIX_MEMLOCK                      进程内存加锁
    //      MLR             _POSIX_MEMLOCK_RANGE                内存区域加锁
    //      MON             _POSIX_MONOTONIC_CLOCK              单调时钟
    //      MSG             _POSIX_MESSAGE_PASSING              消息传递
    //      MX              __STDC_IEC_559__                    IEC 60559 浮点选项
    //      PIO             _POSIX_PRIORITIZED_IO               优先输入输出
    //      PS              _POSIX_PRIORITIZED_SCHEDULING       进程调度
    //      RPI             _POSIX_THREAD_ROBUST_PRIO_INHERIT   线程健壮优先权继承
    //      RPP             _POSIX_THREAD_ROBUST_PRIO_PROTECT   线程健壮优先权保护
    //      RS              _POSIX_RAW_SOCKETS                  原始套接字
    //      SHM             _POSIX_SHARED_MEMORY_OBJECTS        共享内存对象
    //      SIO             _POSIX_SYNCHRONIZED_IO              同步输入输出
    //      SPN             _POSIX_SPAWN                        创建子进程
    //      SS              _POSIX_SPROADIC_SERVER              进程阵发性服务器
    //      TCT             _POSIX_THREAD_CPUTIME               线程CPU时间
    //      TPI             _POSIX_THREAD_PRIO_INHERIT          非健壮优先权继承
    //      TPP             _POSIX_THREAD_PRIO_PROTECT          非健壮优先权保护
    //      TPS             _POSIX_THREAD_PRIORITY_SCHEDULING   线程优先级调度
    //      TSA    (*)      _POSIX_THREAD_ATTR_STACKADDR        线程栈地址属性
    //      TSH    (*)      _POSIX_THREAD_PROCESS_SHARED        线程进程共享同步
    //      TSP             _POSIX_THREAD_SPORADIC_SERVER       线程阵发性服务器
    //      TSS    (*)      _POSIX_THREAD_ATTR_STACKSIZE        线程栈长度属性
    //      TYM             _POSIX_TYPED_MEMORY_OBJECTS         类型内存对象
    //      XSI    (*)      _XOPEN_UNIX                         X/Open 扩充接口
    // SUS 单一UNIX规范（Single UNIX Specification）是 POSIX.1 标准的一个超集，它
    // 定义了一些附加接口扩展 POSIX.1 规范提供的功能。Open Group 拥有 UNIX 商标，他
    // 们使用 Single UNIX Specification 定义了一系列接口，一个系统要想称为 UNIX 系
    // 统，其实现必须支持这些接口。只有遵循 X/Open 系统接口（XSI）的实现才能称为UNIX。
    // 有些接口在遵循 XSI 的系统中是可选的，这些接口根据功能分成若干组：加密 _XOPEN_CRYPE，
    // 实时 _XOPEN_REALTIME，高级实时，实时线程 _XOPEN_REALTIME_THREADS，高级实时
    // 线程。
    // _POSIX_C_SOURCE          1               POSIX.1-1990 and ISO C (1990)
    //                          >=2             POSIX.2-1992
    //                          >=199309L       POSIX.1b (real-time extensions)
    //                          >=199506L       POSIX.1c (threads)
    //                          >=200112L       POSIX.1-2001 (excluding the XSI extension) and C99
    //                          >=200809L       POSIX.1-2008 (excluding the XSI extension)
    // _XOPEN_SOURCE            any value       POSIX.1, POSIX.2, and XPG4
    //                          >=500           SUSv2 (UNIX 98)
    //                          >=600           SUSv3 (UNIX 03, POSIX.1-2001 plus the XSI extension) and C99
    //                          >=700           SUSv4 (POSIX.1-2008 plus the XSI extension)
    // _XOPEN_SOURCE_EXTENDED   已过时，如果定义 _XOPEN_SOURCE>=500 相当于定义了该宏，XPG4v2 (SUSv1) UNIX extensions (UNIX 95)
    // 三个由各自独立的组织指定的UNIX标准：ISO C，IEEE POSIX，SUS。但是标准只是接口的
    // 规范。这些标准是如何于现实世界相关连的呢？UNIX 的各个版本和变体都起源于在 PDP-11
    // 系统上允许的 UNIX 分时系统第6版（1976）和第7版（1979），通常称为 V6 和 V7。这
    // 两个版本是在贝尔实验室以外首先得到广泛应用的 UNIX 系统。从这棵树上演进出以下三个
    // 分支：美国电话电报公司（AT&T），伯克利软件发布（BSD，Berkeley Software Distribution）
    //      1. AT&T 分支，从此引出了系统 III 和系统 V（被称为 UNIX 的商用版本）
    //      2. 加州大学伯克利分校分支，从此引出 4.xBSD 实现 => FreeBSD NetBSD OpenBSD
    //      3. 由 AT&T 贝尔实验室的计算科学研究中心不断开发的 UNIX 研究版本，从此引出
    //          UNIX 分时系统第8版、第9版、终止于1990年的第10版
    // Linux - 启发于 MINIX（Minimal UNIX）兼容 POSIX 的 UNIX 系统调用子集的微内核系统
    // Mac OS X - Mach Kernel, FreeBSD, Other framework and extention（核心操作系统称为 Darwin）
    #define _POSIX_C_SOURCE 200809L // 定义不同版本的 POSIX.1 标准
    #define _XOPEN_SOURCE 700 // 定义不同版本的 SUS 版本，其中 >=600 相当于 _POSIX_C_SOURCE>=200112L + XSI，其中 >=700 相当于 _POSIX_C_SOURCE>=200809L + XSI
    #define _ISOC11_SOURCE 1 // 相当于在编译中指定 -std=c11
    // glibc https://www.gnu.org/software/libc/
    // getconf GNU_LIBC_VERSION, ldd --version, ldd `which ls` | grep libc
    // Many features require _GNU_SOURCE on various platforms, pthread_getattr_np glibc 2.2.3, __GLIBC__ __GLIBC_MINOR__
    #define _GNU_SOURCE 1
    // _LARGEFILE64_SOURCE - 启用由 LFS（Large File Summit） 定义的 SUS “过渡扩展”
    //参见 http://opengroup.org/platform/lfs.html。该替代 API 提供了一组新对象（函
    // 数与类型），其名称均以 “64” 为后缀，例如 off64_t 对应 off_t，lseek64() 对应
    // lseek() 等。新编写的程序不应再使用此宏，应改用 _FILE_OFFSET_BITS=64 来获得大
    // 文件支持。
    // _FILE_OFFSET_BITS - 将此宏定义为 64 时，编译器会自动把所有 32 位文件 I/O 及
    // 文件系统操作相关的函数和数据类型（如 off_t、lseek、stat 等）替换为对应的 64
    // 位版本。作用：在 32 位系统 上支持大于 2 GB 的大文件；调用仅提供 64 位版本的新
    // 接口（如 copy_file_range(2)）时无需手工改写代码。只要源码本身写得符合规范，重
    // 新编译即可获得大文件能力。在 64 位系统 上，文件大小天然支持超过 2 GB，因此该宏
    // 不起作用。
    // _TIME_BITS - 将此宏定义为 64 会把 time_t 的位宽改为 64 位，从而能表示 2038
    // 年以后的时间戳。该宏与 _FILE_OFFSET_BITS 紧密相关，在某些实现中还需同时设置
    // _FILE_OFFSET_BITS=64。（glibc 2.34 起提供此宏。）
    #define _FILE_OFFSET_BITS 64
    #define _TIME_BITS 64
    #if defined(prh_plat_apple)
    #ifndef _DARWIN_C_SOURCE // Restore Darwin APIs removed by _POSIX_C_SOURCE
        #define _DARWIN_C_SOURCE 1
    #endif
    // https://epir.at/2019/10/30/api-availability-and-target-conditionals/
    #include <Availability.h>
    // https://github.com/phracker/MacOSX-SDKs/blob/master/MacOSX11.3.sdk/usr/include/AvailabilityMacros.h
    // https://github.com/phracker/MacOSX-SDKs/blob/master/MacOSX11.3.sdk/usr/include/TargetConditionals.h
    #include <AvailabilityMacros.h> // AVAILABLE_MAC_OS_X_VERSION_10_12_AND_LATER
    #ifndef __has_extension // older compilers don't support this
        #define __has_extension(x) 0
        #include <TargetConditionals.h>
        #undef __has_extension
    #else
        #include <TargetConditionals.h>
    #endif
    // Fix building with older SDKs that don't define these. More information:
    // https://stackoverflow.com/questions/12132933/preprocessor-macro-for-os-x-targets
    // TARGET_OS_MAC - Generated code will run under Mac OS X variant
    //      TARGET_OS_OSX               - Generated code will run under OS X devices
    //      TARGET_OS_IPHONE            - Generated code for firmware, devices, or simulator
    //          TARGET_OS_IOS           - Generated code will run under iOS
    //          TARGET_OS_TV            - Generated code will run under Apple TV OS
    //          TARGET_OS_WATCH         - Generated code will run under Apple Watch OS
    //          TARGET_OS_BRIDGE        - Generated code will run under Bridge devices
    //          TARGET_OS_MACCATALYST   - Generated code will run under macOS
    //      TARGET_OS_SIMULATOR         - Generated code will run under a simulator
    // TARGET_OS_EMBEDDED       - DEPRECATED: Use TARGET_OS_IPHONE and/or TARGET_OS_SIMULATOR instead
    // TARGET_IPHONE_SIMULATOR  - DEPRECATED: Same as TARGET_OS_SIMULATOR
    // TARGET_OS_NANO           - DEPRECATED: Same as TARGET_OS_WATCH
    #ifndef TARGET_OS_MACCATALYST
        #define TARGET_OS_MACCATALYST 0
    #endif
    #ifndef TARGET_OS_IOS
        #define TARGET_OS_IOS 0
    #endif
    #ifndef TARGET_OS_IPHONE
        #define TARGET_OS_IPHONE 0
    #endif
    #ifndef TARGET_OS_TV
        #define TARGET_OS_TV 0
    #endif
    #ifndef TARGET_OS_SIMULATOR
        #define TARGET_OS_SIMULATOR 0
    #endif
    #if TARGET_OS_IPHONE
        // The macro that is only defined if compiling for iOS.
        #define prh_plat_ios 1
    #else
        // The macro that is only defined if compiling for macOS.
        #define prh_plat_macos 1
        #if MAC_OS_X_VERSION_MIN_REQUIRED < 1070 // 10.12 101200
        #error Only support deploying on MAC OS 10.7 and later.
        #endif
    #endif
    #endif // prh_plat_apple
    // cc -dM -E -</dev/null
    // https://jdebp.uk/FGA/predefined-macros-compiler.html
    // https://jdebp.uk/FGA/predefined-macros-processor.html
    // https://jdebp.uk/FGA/predefined-macros-language.html
    // https://jdebp.uk/FGA/predefined-macros-platform.html
    // https://docwiki.embarcadero.com/RADStudio/Alexandria/en/Predefined_Macros
    // https://docs.freebsd.org/en/books/porters-handbook/porting-dads/#porting-versions
    // https://docs-archive.freebsd.org/doc/7.3-RELEASE/usr/share/doc/zh_CN/books/porters-handbook/porting-versions.html
    // https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/
    // https://man.freebsd.org/cgi/man.cgi/help.html
    // https://developer.apple.com/library/archive/documentation/Porting/Conceptual/PortingUnix/compiling/compiling.html
    //
    // __MACH__
    //      This macro is defined if Mach system calls are supported.
    // __APPLE__
    //      This macro is defined in any Apple computer. Note: To define a section
    //      of code to be compiled on OSX system, you should define a section using
    //      __APPLE__ with __MACH__ macros. The macro __UNIX__ is not defined in
    //      OSX.
    // __APPLE_CC__
    //      This macro is set to an integer that represents the version number of
    //      the compiler. This lets you distinguish, for example, between compilers
    //      based on the same version of GCC, but with different bug fixes or
    //      features. Larger values denote later compilers.
    // __BIG_ENDIAN__ and __LITTLE_ENDIAN__
    //      These macros tell whether the current architecture uses little endian
    //      or big endian byte ordering. For more information, see Compiling for
    //      Multiple CPU Architectures.
    //
    // 通俗的来讲，Apple现在的主要操作系统，无论是macOS、iOS还是iPadOS，甚至是HomePod和
    // Apple TV（TvOS）都是建立在Darwin的基础上。Darwin 是苹果公司开发的操作系统内核，是
    // macOS 和 iOS 的基础。它基于 Mach 微内核和 FreeBSD 的某些部分。
    //
    // __APPLE__ 宏有一个且只有一个有效的用途：在检查 BSD 系统时识别 Darwin。它仅由苹果
    // 提供的编译器和苹果分叉的编译器定义，例如 lvm-gcc、苹果旧版的 GCC 4 分叉版本以及
    // Clang。此外，一些寻求与这些编译器兼容的编译器（如 IBM 的 XLC++）也会定义这个宏。
    // 即使在这种情况下，__APPLE__ 也仅在目标平台是 Darwin 时被定义。当你需要在代码中区分
    // 不同的 Unix 系统（如 Linux、FreeBSD、OpenBSD 等）时，__APPLE__ 宏可以帮助你识别
    // Darwin 系统。如果你在其他情况下使用 __APPLE__ 宏，你可能正在做一件非常错误的事情。
    // __APPLE__ 宏并不意味着目标设备是 macOS 或 iOS。它仅表示目标平台是 Darwin。
    //
    // __APPLE__ the target platform api is "Apple-ish"                         llvm-gcc Clang
    // __MACH__ the target platform api is Mach-based (including NextSTEP and MacOS 10)     GCC Clang
    // __OpenBSD__ the target platform api is OpenBSD                           GCC Clang
    // __NetBSD__ the target platform api is NetBSD                             GCC Clang
    // __FreeBSD__ the target platform api is FreeBSD                           GCC Clang
    // __DragonFly__ the target platform api is DragonFly BSD                   GCC Clang
    // __linux__ the target platform api is Linux                               GCC
    // __unix__ the target platform api is Unix-alike (i.e. Cygwin or Linux)    GCC Clang
    // _WIN32 the target platform api is Win32                                  DigitalMars GCC Clang MSVC
    // __CYGWIN__ __CYGWIN32__ the target plaform api is Cygwin                 GCC Clang
    //
    // GCC and Clang targetting Apple's Darwin is one of the few cases where a
    // "Unix-alike" target platform doesn't have the __unix__ or __UNIX__ macros
    // defined, hence the check for __APPLE__ and __MACH__. Strictly speaking,
    // those two macros don't, either apart or in combination, mean "Unix-alike".
    // It just so happens that no Mach-based "Apple-ish" platform API will fail
    // to have a <sys/param.h> header. 严格来说，这两个宏（无论是单独还是组合）并不意
    // 味着“类 Unix”。只是碰巧没有基于 Mach 的“类苹果”平台 API 会缺少 <sys/param.h> 
    // 头文件。
    //
    // https://docs-archive.freebsd.org/doc/7.3-RELEASE/usr/share/doc/zh_CN/books/porters-handbook/porting-versions.html
    #if defined(__unix__) || defined(__UNIX__) || (defined(__APPLE__) && defined(__MACH__))
    #include <sys/param.h>
    #endif
    #include <pthread.h> // pthread_create POSIX.1-2008
    #include <unistd.h> // sysconf confstr POSIX.1-2008
    #define PRH_POSIX_ZERORET(a) if (a) { prh_abort_error(errno); }
#endif // prh_plat_posix
#endif // ATOMIC THRD TIME CONO_IMPLEMENTATION

// include basic common use C headers
#include <assert.h> // assert 如果在这之前定义了 NDEBUG 断言将失效
#include <stdlib.h> // malloc calloc realloc free abort exit
#include <string.h> // memcpy memmove memset
// void *memcpy(void *dest, const void *src, size_t count);
// void *memmove(void *dest, const void *src, size_t count);
// void *memset(void *ptr, int value, size_t count);
// if either dest or src is an invalid or null pointer { undefined behavior }
// if dest and src memory overlap for memcpy { undefined behavior }
// the count parameter can be set to zero value.
#include <stdio.h> // printf fprintf
#include <errno.h> // errno POSIX-compatible error code

#ifndef prh_malloc
#define prh_malloc(size) prh_impl_malloc((size), __LINE__)
#define prh_calloc(size) prh_impl_calloc((size), __LINE__)
#define prh_realloc(ptr, size) prh_impl_realloc((ptr), (size), __LINE__)

// void *malloc(size_t size);
// the newly allocated block of memory is not initialized, remaining with indeterminate values.
// if size == 0 { may or may not return null, but the returned pointer shall not be dereferenced }
// if fails to allocate the requested block of memory, a null pointer is returned.
prh_inline void *prh_impl_malloc(prh_unt size, int line) {
    void *p = malloc(size);
    prh_assert_line(p != prh_null, line);
    return p;
}

// void *calloc(size_t num, size_t size);
// allocates a block of memory for an array of num elements, each of them size bytes long, and
// initializes all its bits to zero. the effective result is the allocation of a zero-initialized
// memory block of (num*size) bytes.
// if size == 0 { may or may not return null, but the returned pointer shall not be dereferenced }
// if fails to allocate the requested block of memory, a null pointer is returned.
prh_inline void *prh_impl_calloc(prh_unt size, int line) {
    void *p = calloc(1, size);
    prh_assert_line(p != prh_null, line);
    return p;
}

// void *realloc(void *ptr, size_t size);
// if ptr == prh_null { return malloc(size) }
// if size == 0 { may be free(ptr) or depends on library implementation }
// if size > ptr old size { may return the new location and the newer portion is indeterminate }
// the content is preserved up to min(old and new size), even if moved to a new location.
// if fails to allocate the requested block of memory, null is returned and ptr remain unchanged.
// if ptr != NULL
//      if size != 0
//          return realloc(ptr, size)
//      else
//          **MAYBE** free(ptr) return NULL
// else
//      if size != 0
//          return malloc(size)
//      else
//          return NULL
void *prh_impl_realloc(void *ptr, prh_unt size, int line);

// void free(void *ptr);
// if ptr == prh_null { the function does nothing }
#define prh_free free
#endif // prh_malloc

// https://en.cppreference.com/w/c/memory/aligned_alloc
// https://www.man7.org/linux/man-pages/man3/posix_memalign.3.html
// https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/aligned-malloc
// https://jemalloc.net/
#ifndef prh_aligned_malloc
#if defined(prh_cl_msc)
    #include <malloc.h>
    // _aligned_malloc is based on malloc. required C header malloc.h.
    // if alignment isn't a power of 2 or size is zero, this function invokes
    // the invalid parameter handler. if execution is allowed to continue, this
    // function returns NULL and sets errno to EINVAL.
    #define prh_plat_aligned_malloc(size, alignment) _aligned_malloc((size), (alignment))
    #define prh_aligned_free(p) _aligned_free(p)
#else
    #include <stdlib.h>
    // behavior is undefined if size is not an integral multiple of alignment
    void *aligned_alloc(size_t alignment, size_t size); // glibc 2.16. C11
    #define prh_plat_aligned_malloc(size, alignment) aligned_alloc((alignment), (size))
    #define prh_aligned_free(p) free(p)
#endif
prh_inline void *prh_impl_aligned_malloc(prh_unt size, prh_unt alignment, int line) {
    void *p = prh_plat_aligned_malloc(size, alignment);
    prh_assert_line(p != prh_null, line);
    return p;
}
#define prh_aligned_malloc(size, alignment) prh_impl_aligned_malloc((size), (alignment), __LINE__)
#define prh_cache_line_aligned_malloc(size) prh_aligned_malloc((size), PRH_CACHE_LINE_SIZE)
#define prh_16_byte_aligned_malloc(size) prh_aligned_malloc((size), 16)
#endif

#ifndef PRH_GLIBC_VERSION
#if defined(__GLIBC__) && defined(__GLIBC_MINOR__)
    #define PRH_GLIBC_VERSION (__GLIBC__ * 100 + __GLIBC_MINOR__)
#endif
#endif

#ifdef prh_plat_posix
// The preferred way to tell FreeBSD versions apart are the __FreeBSD_version
// and __FreeBSD__ macros defined in sys/param.h. __FreeBSD__ is defined in all
// versions of FreeBSD as their major version number. For example, in FreeBSD
// 9.x, __FreeBSD__ is defined to be 9. __FreeBSD_version can be found in page
// https://people.freebsd.org/~olivierd/porters-handbook/versions.html. See
// https://docs.freebsd.org/en/books/porters-handbook/porting-dads/#porting-versions
//
//      #if __FreeBSD__ >= 9
//      #if __FreeBSD_version >= 901000
//      ... 9.1+ release specific code here ...
//      #endif
//      #endif
//
// __NetBSD_Version__ is defined in sys/param.h, formatted as VVRR00PP00 from
// NetBSD 2.99.9. VV is version, RR is revision, PP is patch. For example
// 3.99.8, VV is 3, RR is 99, PP is 8, __NetBSD_Version__ is 399000800.
// To distinguish between specific NetBSD versions, you should use the
// following code. See https://www.netbsd.org/docs/pkgsrc/fixes.html. Also see
// https://sourceforge.net/p/predef/wiki/OperatingSystems/
#if defined(PRH_GLIBC_VERSION) && (PRH_GLIBC_VERSION >= 206)
    // prctl - operations on a process or thread
    // int prctl(int op, ...);
    #include <linux/prctl.h> // definition of PR_* constants
    #include <sys/prctl.h>
#endif
#ifndef prh_impl_pthread_getattr
    #if defined(PRH_GLIBC_VERSION) && (PRH_GLIBC_VERSION >= 203)
        #define prh_impl_pthread_getattr_np pthread_getattr_np
    #endif
    #ifdef __NetBSD__ // __NetBSD_Version__ is defined in sys/param.h
        #include <sys/param.h>
        #if defined __NetBSD_Version__ && __NetBSD_Version__ >= 600000000 // NetBSD 6.0
        #define prh_impl_pthread_attr_get_np pthread_attr_get_np
        #endif
    #endif
    #if defined(__FreeBSD__) || defined(__OpenBSD__)
        #include <pthread_np.h> // pthread_attr_get_np pthread_set_name_np
        #define prh_impl_pthread_attr_get_np pthread_attr_get_np
    #endif
    #if defined(prh_impl_pthread_getattr_np)
        #define prh_impl_pthread_getattr prh_impl_pthread_getattr_np
    #elif defined(prh_impl_pthread_attr_get_np)
        #define prh_impl_pthread_getattr prh_impl_pthread_attr_get_np
    #endif
#endif // prh_impl_pthread_getattr
#endif // prh_plat_posix

// 高速缓存（Cache） 是一种位于 CPU 和主存之间的高速存储器，用于存储 CPU 频繁访问的数据
// 和指令。它的速度远高于主存，能够显著提升 CPU 的数据处理效率。高速缓存技术利用程序的局
// 部性原理，将程序中正在使用的部分存放在一个高速的、容量较小的缓存中，使 CPU 的访存操作
// 大多数针对缓存进行，从而提高程序的执行速度。时间局部性：如果一个存储单元被访问，那么该
// 单元很可能很快被再次访问。空间局部性：如果一个存储单元被访问，那么该单元邻近的单元也可
// 能很快被访问。
//
// 高速缓存通常被组织成一个有多个缓存组的数组，每个缓存组（Cache Set）包含若干个缓存行
// （Cache Line）。缓存行是高速缓存中的最小访问单元，用于缓存内存块数据。当 CPU 需要访
// 问主存中的数据时，高速缓存会拦截所有对内存的访问，并判断所需数据是否已经存在于高速缓存
// 中。如果缓存命中（即找到所需数据），则直接从缓存中读取数据。如果缓存未命中（即未找到所
// 需数据），则需要从主存中加载数据到缓存中。组选择（Set Selection）：根据地址中的索引位
// 找到对应的缓存组。行匹配（Line Matching）：在缓存组中，通过标记位判断是否存在匹配的缓
// 存行。字抽取（Word Extraction）：如果找到匹配的缓存行，根据偏移量提取所需的数据。
//
// 现代 CPU 通常具有多级缓存结构，包括 L1、L2 和 L3 缓存。L1 缓存：位于 CPU 芯片内部，
// 速度最快，容量最小，通常分为指令缓存和数据缓存。L2 缓存：位于 CPU 芯片内部或外部，速
// 度稍慢，容量较大。L3 缓存：位于 CPU 芯片外部，速度较慢，容量最大，通常被多个核心共享。
//
// 为了提供高速缓存效率，我们应该把只读或大部分时间只读的数据与可读可写数据分别存放，还
// 应该把差不多会在同一时间访问的数据组织在一起。并尽最大努力只让一个线程访问数据或只让
// 一个 CPU 访问数据（使用 thread affinity），这样可以完全避免并发线程引起高速缓存行失
// 效的问题。另外，让最频繁运行的代码运行得最快，要集中注意力降低核心函数和核心循环中的
// 缓存不命中率。有一项有趣的技术就是分块，它可以提高内循环的时间局部性。分块的大致思路
// 是将一个大块数据（chunk）分为块（block），使得能够将块加载到 L1 高速缓存中，并在这个
// 块中进行所需的所有读写，然后求掉这个块加载下一块，依此类推。总之，尽量访问连续的数据，
// 不要跳跃访问，从而提高程序的空间局部性；一旦从存储器中读入一块数据，就尽可能多的使用
// 它，从而提高程序中的时间局部性。
//
// 考虑一个计算机系统其内存大小为 M=2^m（M=4GB m=32），高速缓存行（Cache Line）大小为   *** 高速缓存组（Cache Set）和高速缓存行（Cache Line）
// L=2^n（L=64 n=6)，假如一个缓存组（Cache Set）包含 4096 个缓存行，那么一共有 S=2^s
// （S=16KB s=14）16384 个缓存组（4GB÷64÷4096）。也就是说整个系统内存被划分成 16384
// 个缓存组，每个缓存组包含 T=4096（t=12）个缓存行。
//
//  系统内存地址 4GB（M=4GB m=32）空间被分成 16384 个组，每组 4096 个缓存行（t=12）
//          [31 30 29 28 27 26 25 24 23 22 21 20|19 18 17 16 15 14 13 12 11 10 09 08 07 06|05 04 03 02 01 00]
//          |                                   |                                         |                 |
//          '----------- 标记（t 位）------------'---------------- 组号（s 位）-------------'- 行内偏移（6 位）-'
//
// 高速缓存的整个空间也被分成跟系统内存一样的 16384 个组，如果高速缓存大小为 8MB（C=8MB
// c=23），那么每组 8 个缓存行。也就是说 8MB 大小的高速缓存被划分成 S=16384（s=14）个
// 缓存组，每个缓存组 8 个缓存行。为了管理缓存，每个缓存行需要额外包含 1 个有效位（valid
// bit）和 t 个标记位（tag bit）。
//
//  高速缓存地址 8MB（C=8MB c=23）空间被分成 16384 个组，每组 8 个缓存行
//                                     [22 21 20|19 18 17 16 15 14 13 12 11 10 09 08 07 06|05 04 03 02 01 00]
//                                              |                                         |                 |
//                                              '---------------- 组号（s 位）-------------'- 行内偏移（6 位）-'
//                                              |
//                                              | 每组八个缓存行，每行额外包含 1 个有效位，12 个标记位
//                                              v
//      [00][31 30 29 28 27 26 25 24 23 22 21 20][7 6 5 4 3 2 1 0 ... 64-byte] 第 1 个缓存行
//      [00][31 30 29 28 27 26 25 24 23 22 21 20][7 6 5 4 3 2 1 0 ... 64-byte] 第 2 个缓存行
//      [00][31 30 29 28 27 26 25 24 23 22 21 20][7 6 5 4 3 2 1 0 ... 64-byte] 第 i 个缓存行
//      [00][31 30 29 28 27 26 25 24 23 22 21 20][7 6 5 4 3 2 1 0 ... 64-byte] 第 8 个缓存行
//      |  |                                    |                            |
//    .-'  '----------- 标记（t 位）------------' '--- 高速缓存行（64 字节）----'
//    有效位
//
// 内存（4GB）远大于缓存（8MB），内存一组 16384 行，缓存一组只有 8 行，需要通过映射将
// 内存的 16384 行映射到缓存的 8 行中，这是高速缓存的一种类型。还有其他类型，通过调整
// 高速缓存组内行数（总组数会随之改变），实现不同的映射方式。跟据每组行数，高速缓存分为
// 三类：直接映射，组相联映射，全相联映射。上述高速缓存类型即组相联类型，它的每组行数大
// 于 1，组数也大于 1。
//
// 上述高速缓存称为 8 路组相联高速缓存，每组几行即为几路组相联高速缓存。组选择：通过内存   *** 组相联高速缓存：组选择、行匹配、字选择
// 地址中的组号确定缓存行所在组。行匹配：高速缓存电路并行匹配 8 个缓存行的有效位和标记位。
// 字选择：内存地址的低位确定行内的起始偏移。组相联高速缓存的行匹配必须坚持多个行的有效
// 位和标记位，以确定所请求的字是否在缓存中。组号相同的内存地址可以随意映射到该组 8 行中
// 的其中一个，组相联必须搜索组中的每一行，寻找一个有效的并且标记匹配的行。如果 CPU 请求
// 的字不在组的任何一行中，那么就是缓存不命中，高速缓存必须从内存中读取包含这个字的行。    *** 缓存未命中取存后的替换策略：空闲行、最少访问、最久未访问
// 不过，取出一行后该怎样替换缓存中的哪行呢？当然如果有一个空行，那它就是很好的候选。但
// 如果该组中没有空行，那么我们必须从中选择一个非空的行，希望 CPU 不会很快引用这个被替换
// 的行。最简单的替换策略是随机选择要替换的行，其他更复杂的策略利用了局部性原理，以使最
// 近访问过的替换概率小。例如最少访问策略（Least-Frequently-Used, LFU）会替换在过去一    *** LFU 替换最少访问的行，但可能原来访问很少最近却进行了访问
// 时间窗口中访问次数最少的那一行，最久未访问策略（Least-Recently-Used, LRU）会替换最    *** LRU 替换最久未访问的行，只需要维护 log2N（N为组相联路数）个替换算法位
// 近一次访问时间最久远的那一行。所有这些策略都需要额外的时间和硬件，但是好的替换策略可
// 以减少不命中的概率。越往存储器层次结构的下层走，越远离 CPU，一次不命中的开销就越昂贵，
// 用更好的替换策略来减少不命中次数是值得的。
//
// 直接映射，缓存每组只有 1 行，以 1MB 的高速缓存为例，共有 16384 组，每组 1 行，组号    *** 直接映射高速缓存，相同组号的缓存冲突
// 即行号。组选择：通过内存地址中的组号确定缓存行所在的组号。行匹配：不需要匹配，组内只
// 有一行。字选择：内存地址的低位确定行内的起始偏移。根据内存地址组号直接映射到一个缓存
// 行，然后读取对应缓存行的有效位，如果无效则读取内存进行缓存，如果有效继续比较标记位，
// 如果不相等则读取内存替换该行。冲突不命中问题，缓存使用直接映射或组相联度太低，导致多    *** 冲突不命中问题（Conflict Miss），提高相联度来解决
// 个内存块映射到同一个组索引，即使缓存总容量足够也会相互替换。例如交替访问组号相同的不
// 同内存地址，即使高速缓存空间足够，这种交替访问还是会导致缓存不命中，相互交替读取内存
// 覆盖原缓存行。而对于 8 路组相联高速缓存，只有同时交替访问 8 个以上组号相同的不同内存
// 地址时，才可能出现这种冲突情况。为什么内存地址的组号放在中间而不放在高位？放在中间，    *** 组号放内存地址中间，符合空间局部性原则
// 当处理器访问很大一片内存时，高速缓存可以连续缓存整个缓存大小的空间。如果放到高位，连
// 续缓存的空间只有一个缓存行，高速缓存中相邻的缓存行都来自间隔很远的内存，破坏了空间局
// 部性原则。
//
//  系统内存地址 4GB（M=4GB m=32）空间被分成 16384 个组，每组 4096 个缓存行（t=12）
//          [31 30 29 28 27 26 25 24 23 22 21 20|19 18 17 16 15 14 13 12 11 10 09 08 07 06|05 04 03 02 01 00]
//          |                                   |                                         |                 |
//          '----------- 标记（t 位）------------'---------------- 组号（s 位）-------------'- 行内偏移（6 位）-'
//
//  高速缓存地址 1MB（C=8MB c=20）空间被分成 16384 个组，每组 1 个缓存行
//                                              [19 18 17 16 15 14 13 12 11 10 09 08 07 06|05 04 03 02 01 00]
//                                              |                                         |                 |
//                                              '---------------- 组号（s 位）-------------'- 行内偏移（6 位）-'
//                                              |
//                                              | 每组一个缓存行，每行额外包含 1 个有效位，12 个标记位
//                                              v
//      [00][31 30 29 28 27 26 25 24 23 22 21 20][7 6 5 4 3 2 1 0 ... 64-byte] 唯一缓存行
//      |  |                                    |                            |
//    .-'  '----------- 标记（t 位）------------' '--- 高速缓存行（64 字节）----'
//    有效位
//
// 全相联映射，整个高速缓存只有一个组，该组包含所有行。组选择：不需要选择，都属于同一组。  *** 全相联高速缓存，需要庞大的行匹配电路
// 行匹配：高速缓存电路并行匹配 16K 个缓存行的有效位和标记位。字选择：内存地址的低位确定
// 行内的起始偏移。因为高速缓存电路必须并行地搜索许多相匹配的标记，构造一个又大又快的相
// 联高速缓存很困难，而且很昂贵。因此全相联高速缓存只适合做小的高速缓存，例如虚拟内存中
// 的翻译备用缓存区（Translation Lookaside Buffer TLB），它缓存页表项。全相联高速缓存
// 的优点是没有组内冲突，内存可以将数据缓存到整个缓存的任何一行，其唯一的冲突来源是整个
// 高速缓存完全被塞满，即容量不命中问题。容量不命中，是程序活跃工作集大于缓存容量，无论    *** 容量不命中问题（Capacity Miss）
// 怎样映射都装不下，必须不断替换，只有增大缓存容量才能缓解。还有第三种不命中，强制不命
// 中（Compulsory Miss），也叫冷启动不命中，是第一次访问必然发生的，与容量、冲突无关。
//
//  系统内存地址 4GB（M=4GB m=32）空间被分成 1 个组，每组 64KK 个缓存行（t=26）
//          [31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06|05 04 03 02 01 00]
//          |                                                                             |                 |
//          '--------------------------------- 标记（t 位）--------------------------------'- 行内偏移（6 位）-'
//
//  高速缓存地址 1MB（C=8MB c=20）空间被分成 1 个组，每组 16K 个缓存行
//                                              [19 18 17 16 15 14 13 12 11 10 09 08 07 06|05 04 03 02 01 00]
//                                                                                        |                 |
//                                                                                        '- 行内偏移（6 位）-'
//                                    每组 16K 个缓存行，每行额外包含 1 个有效位，26 个标记位 |
//                                                                                        v
//      [00][31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06][7 6 5 4 3 2 1 0 ... 64-byte] 第 1 个缓存行
//      [00][31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06][7 6 5 4 3 2 1 0 ... 64-byte] 第 2 个缓存行
//      [00][31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06][7 6 5 4 3 2 1 0 ... 64-byte] 第 i 个缓存行
//      [00][31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06][7 6 5 4 3 2 1 0 ... 64-byte] 第16K个缓存行
//      |  |                                                                              |                            |
//    .-'  '--------------------------------- 标记（t 位）---------------------------------''--- 高速缓存行（64 字节）----'
//    有效位
//
// 关于写的问题。高速缓存关于读的操作非常简单，而写的情况就要复杂很多。假如我们要写一个
// 已经缓存命中的内存位置（write hit），当缓存更新成要写的值之后，怎么更新存储结构中下     ***  写命中                 写不命中
// 一级缓存呢？最简单的方法，称为直写（write through），就是立即更新下一层，虽然简单，          延迟写回存储器（WB）    读取存储器内容并更新缓存（写分配）
// 但直写的缺点是每次写都会引起总线流量。另一种方法是写回（write back），尽可能推迟存储         直接写入存储器（WT）    读取存储器内容不更新缓存（非写分配）
// 器的更新，只有当对应的缓存行被替换算法替换时，才更新到下一层。由于局部性，写回能显著
// 地减少总线流量，当然缺点是增加了复杂性。高速缓存必须为每个缓存行维护一个额外的脏位（
// dirty bit），表明这个缓存行被修改过但还没有更新到下一层。
//
// 另一个问题是如何处理写不命中（write miss），一种方法是写分配（write allocate），读
// 取低一层存储器中的内容，并更新到高速缓存中，写分配试图利用写的空间局部性，但缺点是每
// 次不命中都会导致一块内容从低一层存储器传送到高速缓存。另一种方法是非写分配（non write
// allocate），它直接读取下一层存储器，不更新高速缓存。直写（write through）高速缓存通
// 常使用非写分配策略，写回（write back）高速缓存通常使用写分配策略。如果回写法搭配非写
// 分配法，只要一开始行不在缓存，后面的写都会一直写主存，失去了回写法降低写主存次数的意
// 义。直写法可搭配写分配法，未缓存的行写一次后会得到缓存，但直写法下一次写还是会直接写
// 主存，同时写缓存和主存的总时间还是写主存的时间，因此直写法搭配两种方法在写操作方面其
// 实差不多。但对于后面的读，可以直接读取已经缓存好的行。
//
// 为写操作优化高速缓存是一个细致而困难的问题，细节随系统的不同而不同，而且通常是私有的，
// 文档记录不详细。对于试图编写高速缓存友好的程序的程序员来说，我们建议在心里采用一个使
// 用写回（write back）和写分配（write allocate）的高速缓存模型，这样建议有几个原因。
// 通常，由于较长的传送时间，存储器层次中较低层的缓存更可能使用写回，而不是直写。例如，
// 虚拟存储器系统（使用主存作为存储在磁盘上的块缓存）只使用写回。另外由于逻辑电路密度的
// 提高，写回的高复杂度越来越不是障碍，我们在现代系统的所有层次上都能看到写回缓存，所以
// 这种假设符合当前的趋势。假设使用写回写分配策略的另一个原因是，它与处理读的方式相对称，
// 因为写回写分配试图利用局部性。因此，我们可以在高层次上利用空间和时间局部性开发程序，
// 而不是试图为某一个存储器系统进行优化。
//
// 高速缓存不仅可以保存数据，而且可以保存指令。只保存指令的高速缓存称为 i-cache，只保存
// 数据的高速缓存称为 d-cache，既保存指令又可以保证数据的高速缓存称为统一高速缓存（unified
// cache）。现代处理器包含独立的 i-cache 和 d-cache，这样做有很多原因。有两个独立的高
// 速缓存，处理器能够同时读一个指令和一个数据。指令缓存 i-cache 通常是只读的，因此比较
// 简单。通常会针对性的优化这两个缓存，它们可以有不同的缓存行大小、组相联度、和大小。采
// 用两个缓存，也确保了数据访问不会与指令访问形成冲突不命中，反过来也一样，代价就是可能
// 会引起容量不命中增加。因为使用两个独立的高速缓存，比使用一个统一的高速缓存，每个独立
// 缓存的容量可能比较小，这样程序活跃的工作集一旦很多，就会造成容量不命中冲突。
//
// 高速缓存的性能参数。不命中率（miss rate），不命中数量 / 访问数量。命中率（hit rate）
// 等于 1 - 不命中率。命中时间（hit time），从高速缓存传送一个字到 CPU 的时间，包括组
// 选择、行确认、和字选择的时间，对于 L1 高速缓存来说，命中时间的数量级是几个时钟周期。
// 不命中处罚（miss penalty），由于不命中所需要的额外的时间，例如 L1 不命中需要从 L2
// 获取时的处罚典型是 10 个周期，从 L3 获取的处罚 40 个周期，从主存获取的处罚 100 个
// 周期。以下列出了高速缓存不同设计对性能的影响：
//  1.  高速缓存大小，一方面较大的高速缓存可能会提高命中率，但另一方面，要使大存储器运
//      行得更快总是要难一些。结果，较大的高速缓存可能会增加命中时间，对于芯片上的 L1
//      高速缓存来说这一点尤为重要，因为它的命中时间必须短。
//  2.  缓存行大小，大的缓存行也有利有弊。一方面，较大的行能利用程序中可能存在的空间局
//      部性，帮助提高命中率。不过，对于给定的高速缓存大小，行越大意味着高速缓存行数越
//      少，这会损害时间局部性比空间局部性更好的程序的命中率。较大的行对不命中处罚也越
//      大，因为越大传送时间就越长。现代系统通常会折中，通常使用 32 或 64 个字节。
//  3.  组相联度的影响，较高的相联度的优点是降低高速缓存由于冲突不命中概率，但会增加成
//      本，而且很难使之速度变快。增加组内行数，会使组数变小，最终导致每一行的标记位增
//      加。较高的相联度会增加命中时间，因为电路复杂度增加了。不命中处罚也越大，因为选
//      择替换行的复杂度也增加了。相联度的选择最终变成命中时间和不命中处罚之间的折中，
//      传统上，努力争取时钟频率的高性能系统会为 L1 高速缓存选择较低的相联度，越往存储
//      器下一层，不命中处罚比较高的层次，使用比较高的相联度。例如 Intel Core i7 系统
//      中，L2 和 L2 高速缓存是 8 路组相联，而 L3 高速缓存是 16 路组相联。
//  4.  写策略的影响，直写高速缓存比较容易实现（不需要延迟写），而且能使用独立于高速缓存
//      的写缓冲区（write buffer）用来更新存储器，解决处理器写缓存和写存储器速度不匹配   *** 写缓冲区允许写入系统内存和芯片内部缓存的写入操作被保存，
//      的问题，另外读不命中开销没这么大。另一方面，写回高速缓存的不命中处罚小（写回被延      并在某些情况下合并，以优化处理器的总线访问。
//      迟），可以节省更多到存储器的带宽做其他事（例如 I/O 设备执行 DMA 操作）。此外，
//      越往存储器下层，传送时间越长，减少传送次数将变得更加重要。一般而言，高速缓存越往
//      下层，越可能使用写回而不是直写。
//
// 存储系统被组织成一个存储设备的层次结构，较小较快的设备靠近顶部，较大较慢的设备靠近底
// 部。由于这种层次结构，程序访问存储位置的有效速率不是一个简单的数字，相反，它是一个变
// 化很大的程序局部性函数，我们称之为存储器山（Memory Mountain），即一座时间和空间局部
// 性的山，这座山的上升高度可以超过一个数量级。有良好局部性的程序会从快速的高速缓存中访
// 问它的大部分数据，明智的程序员应使程序运行在山峰而不是低谷。目标就是利用时间局部性，
// 使得频繁使用的数据从 L1 中取出；还要利用空间局部性，使得尽可能多的数据命中 L1 缓存。
//
// 一个现代处理器的高速缓存结构：
//
// Socket #0 NUMA Node #0 Processor Group #0
// 超线程处理器一个核中有两个逻辑线程，这两个线程之间切换不需要切换上下文，因为它们共享相同的高速缓存
// -----------------------------------------------------------------------------------------
// Logical Processor #0   #1    Physical Processor 0 (Hyperthreaded)
// Logical Processor #2   #3    Physical Processor 1 (Hyperthreaded)
// Logical Processor #4   #5    Physical Processor 2 (Hyperthreaded)
// Logical Processor #6   #7    Physical Processor 3 (Hyperthreaded)
// Logical Processor #8   #9    Physical Processor 4 (Hyperthreaded)
// Logical Processor #10  #11   Physical Processor 5 (Hyperthreaded)
// Logical Processor #12        Physical Processor 6
// Logical Processor #13        Physical Processor 7
// Logical Processor #14        Physical Processor 8
// Logical Processor #15        Physical Processor 9
// Logical Processor #16        Physical Processor 10
// Logical Processor #17        Physical Processor 11
// Logical Processor #18        Physical Processor 12
// Logical Processor #19        Physical Processor 13
//
//  Cache Line          64 B    相联度      数量
//  L1 i-cache          32 KB   ASSOC  8    14
//  L1 d-cache          48 KB   ASSOC 12    14
//  L2 u-cache           1 MB   ASSOC 10    8
//  L3 u-cache          24 MB   ASSOC 12    1
//
//  核0         核1    ...  核5         核6         核7         核8         核9         核10         核11        核12        核13
//  | \         | \         | \         |           |           |           |           |           |           |           |
//  P0 P1       P2 P3  ... P10 P11      P12         P13         P14        P15          P16         P17         P18         P19
//  |  |        |  |        |  |        |           |           |           |           |           |           |           |
//  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache  L1 i-cache
//  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache  L1 d-cache
//  |  |        |  |        |  |        |                                            |  |                                            |
//  L2 u-cache  L2 u-cache  L2 u-cache  '--------------- L2 u-cache -----------------'  '---------------- L2 u-cache ----------------'
//  |                                                                                                                                |
//  '----------------------------------------------------------------- L3 u-cache ---------------------------------------------------'
//
// Intel 处理器历史
//      Intel 8086/8088 16-bit Processor (1978)
//      Intel 286/386/486 Processor (1982 1985 1989)
//      Intel Pentium Processor (1993)
//      Intel P6 Family Processor (1995 ~ 1999) Pentium Pro/II/II Xeon/III/III Xeon, Celeron Processor
//      Intel Pentium 4 Processor Family (2000 ~ 2006)
//      Intel Xeon Processor (2001 ~ 2007)
//      Intel Pentium M Processor (2003 ~ 2006)
//      Intel Pentium Processor Extreme Edition (2005)
//      Intel Core Duo and Intel Core Solo Processors (2006 ~ 2007)
//      Intel Xeon Processor 5100, 5300 Series, and Intel Core 2 Processor Family (2006) 开始全面支持64位架构
//      Intel Xeon Processor 5200, 5400, 7400 Series, and Intel Core 2 Processor Family (2007)
//      Intel Atom Processor Family (2008)
//      Intel Atom Processor Family Based on Silvermont Microarchitecture (2013)
//      Intel Core i7 Processor Family (2008)
//      Intel Xeon Processor 7500 Series (2010)
//      2010 Intel Core Processor Family (2010)
//      Intel Xeon Processor 5600 Series (2010)
//      The 2nd Generation Intel Core Processor Family (2011)
//      The 3rd Generation Intel Core Processor Family (2012)
//      The 4th Generation Intel Core Processor Family (2013)
//
// Intel 64 和 IA-32 架构支持缓存（Cache）、翻译备用缓存区（TLB）以及用于指令和数据的
// 临时片上（以及外部）存储的存储缓冲区（Store Buffer）。下图展示了 Pentium 4 和 Intel
// Xeon 处理器的缓存、TLB 和存储缓冲区的布局，以及 Core i7 的缓存布局。
//
//      Pentium 4 和 Intel Xeon 处理器缓存结构
//      [物理内存]
//          ^
//          |
//          v
//      <======> 系统总线（外部）
//          ^
//          |  L3 Cache  L2 Cache  L1 D-Cache  I-TLBs   D-TLBs
//          |      ^         ^         ^        ^         ^
//          |      |         |         |        |         |   Store Buffer
//          v      v         v         v        v         v       ^
//      .--------------------------------------------------.      |
//      [总        线        接        口       单        元] <----'
//      '--------------------------------------------------'
//          |               |
//          v               v
//      [指令解码器]    [Trace Cache]
//
//      Intel Core i7 处理器缓存结构
//      [指令解码器和前端] <---> [I-TLB] <---> [L1 I-Cache]
//          |   |   |            ^                ^            <=====> 芯片组
//          v   v   v            |                |               ^
//      .----------------.       |                |               |
//      [乱   序   引   擎]       |                |               |
//      '----------------'       |                |               v
//              |                |                |             [QPI]
//              v                v                |                ^
//          [D-TLB] <---> [Share-TLB，L2 TLB]     |                |  [集成内存控制器（IMC）Integrated Memory Controller]
//              ^                                 |                |    ^
//              |                                 |                |    |
//              v                                 v                v    v
//          [L1 D-Cache] <------------------> [L2 Cache] <------> [L3 Cache]
//
//      QPI 是 Quick Path Interconnect 的缩写，这是一种由英特尔（Intel）开发的高速点
//      对点连接技术，用于连接多个处理器、芯片组和其他系统组件。QPI 主要用于多核处理器
//      和多处理器系统中，以提高系统性能和可扩展性。
//
// 下表展示了 Pentium 4、Intel Xeon、P6 家族和 Pentium 处理器缓存和缓冲区的特性。这些
// 单元的大小和特性是机器特定的，可能会在处理器的未来版本中发生变化。CPUID 指令返回执行
// 该指令的处理器上的缓存和缓冲区的大小和特性。
//
//  缓存或缓冲      处理器系列              特性
//  跟踪缓存         系列一                  未实现
//  Trace Buffer    系列二                  12 Kμops，8路组相联（其实是一种指令缓存）
//                  系列三四五六七           未实现
//
//  L1 指令缓存      系列一                 8/16KB 4路，32字节缓存行；早期 Pentium 处理器为 2 路组相联
//  L1 i-cache      系列二                  未实现
//                  系列三四五六            32KB 8路
//                  系列七                  32KB 4路
//
//  L1 数据缓存      系列一                 16KB 4路，32字节缓存行；早期 P6/Pentium 处理器为 8KB 2路
//  L1 d-cache      系列二                 16KB 8路（或8KB 4路），64字节缓存行
//                  系列四                  24K 6路，64字节缓存行
//                  系列三五六七、Xeon       32KB 8路，64字节缓存行
//
//  L2 统一缓存     系列一                  128KB ~ 512KB 或 1MB 或 2MB，4路，32字节缓存行
//  L2 u-cache     系列二                  256KB 512KB 1MB 2MB，8路，64字节缓存行，128字节扇区大小（sector size）
//                 系列三                  1MB 2MB，8路，64字节缓存行
//                 系列四                  512KB，8路，64字节缓存行
//                 Intel Core Due/Solo     2MB，8路，64字节缓存行
//                 Intel Core 2 Due, Xeon  4MB 6MB（或在四核处理器中为 4MBx2 6MBx2），16路 24路，64字节缓存行
//                 Intel Core i7、i5、i3   256KB，8路，64字节缓存行
//
//  L3 统一缓存     Intel Xeon              512KB 1MB 2MB 4MB，8路，64字节缓存行，128字节扇区大小
//  L3 u-cache     Intel Xeon 5500         8MB，16路，64字节缓存行
//                 Intel Xeon 5600 7500    12MB 24MB，64字节缓存行
//                 Intel Core i7           8MB，16路，64字节缓存行
//
//  指令TLB        系列一                   32条目，4路或全相联
//  i-TLB          系列二                  128条目，4路
//                 系列四                   32条目，全相联
//                 系列三五六               128条目，4路
//                 系列七                  每线程64条目（每核心128条目），4路
//
//  指令TLB 大页面  Pentium 处理器          使用相同的 TLB（那些用于 4KB 页面的 TLB）
//  i-large-TLB    P6 家族处理器            2条目，全相联
//                 Pentinum 4 和 Xeon      大页面被碎片化
//                 Pentium M 处理器         2条目，全相联
//                 Intel Core Duo/Solo     2条目，全相联
//                 Intel Core 2 Duo        4条目，4路
//                 Intel Core i7、i5、i3   每线程7条目，全相联
//
//  数据TLB        系列一                   64条目，4路；带有 MMX 技术的 Pentium 处理器为全相联
//  d-TLB          系列二                   64条目，全相联，与 d-large-TLB 缓存共享
//                 系列四                   每线程16条目 micro-TLB，全相联；64条目 d-TLB，4路；16条目 PDE* 缓存，全关联
//                 系列三五                 128条目，4路
//                 系列六                   d-TLB-0 16条目 d-TLB-1 256条目，4路
//                 系列七                   d-TLB-0 64条目，4路
//
//                 *PDE Cache，Page Directory Entry Cache，页目录项缓存
//
//  数据TLB 大页面  系列一                   8条目，4路，带有 MMX 技术的 Pentium 处理器使用与 4KB 页面相同的 TLB
//  d-large-TLB    系列二                   64条目，全相联，与 d-TLB 缓存共享
//                 系列四                   8条目，4路
//                 系列三五                 8条目，全相联
//                 系列六                   d-TLB-0 16条目 d-TLB-1 32条目，4路
//                 系列七                   d-TLB-0 32条目，4路
//
//  L2 u-TLB       系列七                   STLB 512条目 4路
//  4KB 页面
//
//  存储缓冲区      Pentium 处理器           2或4个缓存区，每个1条目
//  Store Buffer   P6 家族处理器            12条目
//                 系列二                   24条目
//                 系列三                   16条目
//                 系列四                   8条目，与 WC Buffer 共用
//                 系列六                   20条目
//                 系列七                   32条目
//
//  写合并缓冲区    P6 家族处理器            4条目
//  WC Buffer      系列二                  6或8条目
//                 系列四                  8条目，与 Store Buffer 共用
//                 系列三五                6条目
//                 系列六                  8条目
//
//  处理器系列一：Pentium 和 P6 家族处理器
//  处理器系列二：Pentium 4 和 Intel Xeon 处理器（基于 Intel NetBurst 微架构）
//  处理器系列三：Pentium M
//  处理器系列四：Intel Atom
//  处理器系列五：Intel Core Duo、Intel Core Solo
//  处理器系列六：Intel Core 2 Duo
//  处理器系列七：Intel Core i7、i5、i3
//
// 存储缓冲区（Store Buffer）与处理器的指令执行单元相关联。它允许写入系统内存和内部缓存   *** 存储缓存区（store buffer，wirte buffer）
// 的写入操作被保存，并在某些情况下合并，以优化处理器的总线访问。存储缓冲区在所有执行模式
// 下始终启用。根据当前生效的写入策略，写命中和写未命中都可能直接写内存，或执行内存延迟
// 写入，当写入内存的操作真正执行时，它首先被写入存储缓冲区（Store Buffer），然后当系统
// 总线可用时从存储缓冲区写入内存。
//
// 存储缓冲区（Store Buffer）。Intel 64 和 IA-32 处理器将每次对内存的写入（存储）临时
// 存储在存储缓冲区中。存储缓冲区通过允许处理器在无需等待写入内存和缓存完成的情况下继续
// 执行指令，从而提高了处理器的性能。它还允许延迟写入，以便更高效地使用内存访问的总线周
// 期。一般来说，存储缓冲区的存在对软件是透明的，即使在使用多个处理器的系统中也是如此。
// 处理器确保写入操作始终按程序顺序执行。它还确保在以下情况下，存储缓冲区的内容始终被排
// 空到内存。有关存储缓冲区操作的详细描述，参考第 10.2 节 “内存排序” 中的写入排序讨论。
//  1.  当生成异常或中断时
//  2.  （仅限 P6 及更新的处理器家族）执行序列化指令时
//  3.  执行 I/O 指令时
//  4.  执行 LOCK 操作时
//  5.  （仅限 Pentium III 及更新的处理器家族）执行 BINIT 操作时
//  6.  （仅限 Pentium 4 及更新的处理器家族）使用 SFENCE 指令对存储进行排序时
//  7.  （仅限 Pentium 4 及更新的处理器家族）使用 MFENCE 指令对存储进行排序时
//
// Intel 64 和 IA-32 处理器可能实现四种类型的缓存：跟踪缓存、一级（L1）缓存、二级（L2）
// 缓存和三级（L3）缓存。缓存可用性描述如下：
//
// Intel Core i7、i5、i3 处理器家族，和基于 Nehalem 微架构和 Westmere 微架构的 Intel
// Xeon 处理器家族。L1 缓存分为两个部分：一部分专用于缓存指令（预解码指令），另一部分
// 缓存数据。L2 缓存是一个统一的数据和指令缓存。每个处理器核心都有自己的 L1 和 L2。L3
// 缓存是一个共享的统一缓存，由物理封装内所有处理器核心共享。没有实现跟踪缓存。
//
// Intel® Core™ 2 处理器家族，和基于 Intel® Core™ 微架构的 Intel® Xeon® 处理器家族。
// L1 缓存分为两个部分：一部分专用于缓存指令（预解码指令），另一部分缓存数据。L2 缓存是
// 一个统一的数据和指令缓存，位于处理器芯片上；在双核处理器实现中，它在两个处理器核心之
// 间共享。四核处理器有两个 L2，每个由两个处理器核心共享。没有实现跟踪缓存。
//
// Intel Atom® 处理器。L1 缓存分为两个部分：一部分专用于缓存指令（预解码指令），另一部
// 分缓存数据。L2 缓存是一个统一的数据和指令缓存，位于处理器芯片上。没有实现跟踪缓存。
//
// Intel® Core™ Solo 和 Intel® Core™ Duo 处理器。L1 缓存分为两个部分：一部分专用于缓
// 存指令（预解码指令），另一部分缓存数据。L2 缓存是一个统一的数据和指令缓存，位于处理器
// 芯片上。在双核处理器实现中，它在两个处理器核心之间共享。没有实现跟踪缓存。
//
// 基于 Intel NetBurst® 微架构的 Pentium® 4 和 Intel® Xeon® 处理器。跟踪缓存缓存来自
// 指令解码器的解码指令（μops），L1 缓存包含数据。L2 和 L3 缓存是位于处理器芯片上的统一
// 缓存。双核处理器有两个 L2，每个处理器核心一个。注意，L3 缓存仅在一些 Intel Xeon 处理
// 器上实现。
//
// P6 家族处理器。L1 缓存分为两个部分：一部分专用于缓存指令（预解码指令），另一部分缓存
// 数据。L2 缓存是位于处理器芯片上的统一数据和指令缓存。P6 家族处理器不实现跟踪缓存。
//
// Pentium® 处理器。L1 缓存具有与 P6 家族处理器相同的结构。没有跟踪缓存。L2 缓存是一个
// 统一的数据和指令缓存，在早期 Pentium 处理器中位于处理器芯片外部，在后来的 Pentium
// 处理器中位于处理器芯片上。对于 L2 缓存位于处理器外部的 Pentium 处理器，通过系统总线
// 访问缓存。
//
// 对于 Intel Core i7 处理器，和基于 Intel Core、Intel Atom 和 Intel NetBurst 微架
// 构的处理器，以及 Intel Core Duo、Intel Core Solo 和 Pentium M 处理器，L1 和 L2
// 缓存以及 L3 缓存（如果支持）的缓存行宽度为 64 字节。处理器总是从系统内存中读取一个从
// 64 字节边界开始的缓存行。一个 64 字节对齐的缓存行从一个地址开始，其 6 个最低有效位清
// 零。一个缓存行可以通过 8 次传输突发事务（with 8-transfer burst transaction）从内存
// 填充。缓存不支持部分填充的缓存行，因此即使缓存一个双字也需要缓存整个行。
//
// P6 家族和 Pentium 处理器中的 L1 和 L2 缓存行为 32 字节宽，从系统内存中读取的缓存行
// 从 32 字节边界开始，内存地址的 5 个最低有效位清零。一个缓存行可以通过 4 次传输突发事
// 务从内存填充。不支持部分填充的缓存行。
//
// 基于 Intel NetBurst 微架构的处理器的跟踪缓存在所有执行模式下都可用：保护模式、系统管
// 理模式（SMM）和实地址模式。L1、L2 和 L3 缓存在所有执行模式下也都可用；然而，在 SMM
// 中使用时必须小心处理，见第 33.4.2 节 “SMRAM 缓存”。
//
// TLB 存储最近使用的页目录和页表条目。当启用分页时，它们通过减少读取存储在系统内存中的
// 页表所需的内存访问次数来加速内存访问。TLB 分为四组：4KB 页面的指令 TLB，4KB 页面的数
// 据 TLB；大页面（2MB、4MB 或 1GB 页面）指令 TLB，以及大页面数据 TLB。TLB 通常在启用
// 分页的保护模式下才处于活动状态。当分页被禁用或处理器处于实地址模式时，TLB 保持其内容，
// 直到显式或隐式刷新，见第 13.9 节 “使翻译备用缓存区（TLBs）无效”。
//
// 基于 Intel Core 微架构的处理器实现了一级指令 TLB 和两级数据 TLB。Intel Core i7 处
// 理器提供了一个第二级统一 TLB。
//
// 处理器的缓存对软件来说在很大程度上是透明的。当启用时，指令和数据流经这些缓存，无需显
// 式软件控制。然而，了解这些缓存的行为可能有助于优化软件性能。例如，了解缓存尺寸和替换
// 算法可以指示一次可以操作多大的数据结构而不会导致缓存抖动。
//
// 在多处理器系统中，缓存一致性的维护在极少数情况下可能需要系统软件的干预。对于这些罕见
// 情况，处理器提供了特权缓存控制指令，用于刷新缓存和强制内存排序。软件可以使用几条指令
// 来提高 L1、L2 和 L3 缓存的性能，包括 PREFETCHh、CLFLUSH 和 CLFLUSHOPT 指令以及非
// 时态（non-temporal）移动指令（MOVNTI、MOVNTQ、MOVNTDQ、MOVNTPS 和 MOVNTPD）。这
// 些指令的使用在第 13.5.5 节 “缓存管理指令” 中讨论。
//
// 缓存术语。IA-32 处理器（从 Pentium 处理器开始）和 Intel 64 处理器使用 MESI（修改、   *** 使用 MESI 缓存协议来维护处理器内部和其他处理器缓存的一致性
// 独占、共享、无效）缓存协议来维护与内部缓存和其他处理器缓存的一致性，见第 13.4 节 “缓
// 存控制协议”。
//
// 当处理器识别出从内存中读取的操作数是可缓存的时，处理器会将整个缓存行读取到适当的缓存
// （L1、L2、L3 或全部）中。此操作称为缓存行填充（cache line fill）。如果包含该操作数
// 的内存位置在处理器下次尝试访问时仍然被缓存，处理器可以从缓存中读取该操作数，而无需返
// 回内存。此操作称为缓存命中（cache hit）。
//
// 当处理器尝试将操作数写入可缓存的内存区域时，它首先检查该内存位置的缓存行是否存在于缓
// 存中。如果确实存在有效的缓存行，处理器（取决于当前生效的写入策略）可以将操作数写入缓
// 存，而不是将其写出到系统内存。此操作称为写入命中（write hit）。如果写入操作未命中缓
// 存（即对于正在写入的内存区域不存在有效的缓存行），处理器会执行缓存行填充和写分配。然
// 后，它将操作数写入缓存行，并且（取决于当前生效的写入策略）也可以将其写入内存。如果操
// 作数要写入内存，它首先被写入存储缓冲区（Store Buffer），然后当系统总线可用时从存储缓
// 冲区写入内存。注意，对于 Pentium 处理器，写入未命中不会导致缓存行填充；它们总是导致
// 写入内存。对于此处理器，只有读取未命中才会导致缓存行填充。
//
// 在 MP 系统中，IA-32 处理器（从 Intel486 处理器开始）和 Intel 64 处理器能够监听其他   *** 处理器会监听（snoop）其他处理器对系统内存以及对其内部缓存的访问
// 处理器对系统内存以及其内部缓存的访问。它们使用这种监听能力（snooping ability）来保持
// 其内部缓存与系统内存、以及与总线上其他处理器缓存的一致性。例如，在 Pentium 和 P6 家
// 族处理器中，如果一个处理器通过监听检测到另一个处理器打算写入一个它当前以共享状态缓存    *** 监听到其他处理器修改自己缓存的共享缓存行，监听处理器会使自己缓存的行无效
// 的内存位置，监听处理器将使缓存行无效，迫使它在下次访问同一内存位置时执行缓存行填充。
//
// 从 P6 家族处理器开始，如果一个处理器检测到（通过监听）另一个处理器正在尝试访问一个已    *** 当处理器监听到另一个处理器读取自己还未回写到内存的数据时，该处理器会通过
// 在其缓存中修改但尚未写回系统内存的内存位置，监听处理器将通过 HITM# 信号通知另一个处         隐式写回将有效数据传递给访问的处理器
// 理器该缓存行处于修改状态，并将执行修改数据的隐式回写（implicit write-back）。隐式回
// 写直接传输到最初请求的处理器，并由内存控制器监听，以确保系统内存被更新。在这里，拥有    *** 隐式回写（implicit write-back）
// 有效数据的处理器可以将数据传递给其他处理器，而实际上无需将其写入系统内存；然而，内存
// 控制器有责任监听此操作并更新内存。
//
// 可用的缓存方法。处理器允许系统内存的任何区域在 L1、L2 和 L3 缓存中被缓存。在系统内存
// 的单个页面或区域中，它允许指定缓存的类型（也称为内存类型）。目前为 Intel 64 和 IA-32
// 架构定义的内存类型如下：
//
//      内存类型和助记符    可缓存      可回写缓存  允许推测读取    内存排序模型
//      强不可缓存（UC）    否          否          否              强排序
//      不可缓存（UC-）     否          否          否              强排序，只能通过 PAT 选择，可以被 MTRRs 中的 WC 覆盖
//      写合并（WC）        否          否          是              弱排序，可通过编程 MTRRs 或通过 PAT 选择
//      直写（WT）          是          否          是              推测处理器排序（speculative processor ordering）
//      回写（WB）          是          是          是              推测处理器排序
//      写保护（WP）        读可缓存     否          是              推测处理器排序，可通过编程 MTRRs
//                         写不可缓存
//
// 下表列出了缓存方法在 Pentium、P6 家族、Pentium 4 和 Intel Xeon 处理器中的可用性。
//
//      Intel Core 2 Duo、Intel Atom、Intel Core Duo、Pentium M、Pentium 4、
//      Intel Xeon、P6 家族和 Pentium 处理器中可用的缓存方法
//      内存类型        Intel Core 2 Duo、Intel Atom、Intel Core Duo、      P6 家族处理器       Pentium 处理器
//                      Pentium M、Pentium 4 和 Intel Xeon 处理器
//      强不可缓存（UC）    是                                                  是                  是
//      不可缓存（UC-）     是                                                  是*                 否
//      写合并（WC）        是                                                  是                  否
//      直写（WT）          是                                                  是                  是
//      回写（WB）          是                                                  是                  是
//      写保护（WP）        是                                                  是                  否
//
//      *不可缓存（UC-）在 Pentium III 处理器中引入；在 Pentium Pro 或 Pentium II 处理器中不可用。
//
// 强不可缓存（UC，Strong Uncacheable）。系统内存位置不被缓存。所有读取和写入操作都会    *** 不可缓存类型：内存位置不被缓存，所有读写都
// 出现在系统总线上，并且按程序顺序执行，不会重新排序。不会进行推测性内存访问、页表遍历        直接出现在总线上，按程序顺序执行不会重排序
// 或推测分支目标的预取。这种类型的缓存控制适用于内存映射 I/O 设备。当与普通 RAM 一起使
// 用时，它会大大降低处理器性能。注意，x87 和 SIMD 指令引用内存的行为依赖实现。在某些实
// 现中，对 UC 内存的访问可能会发生多次。为了确保可预测的行为，使用通用寄存器来加载和存
// 储可能有读取或写入副作用的 UC 内存。
//
// 不可缓存（UC-，Uncacheable）。具有与强不可缓存（UC）内存类型相同的特性，除了该内存
// 类型可以通过编程 MTRRs WC 内存类型覆盖。这种内存类型从 Pentium III 处理器开始在处
// 理器家族中可用，并且只能通过页属性表（PAT，Page Attribute Table）选择。
//
// 写合并（WC，Write Combining）。系统内存位置不被缓存（与不可缓存内存一样），并且一致   *** 写合并类型：内存位置不被缓存，但写操作被缓存
// 性不由处理器的总线一致性协议强制执行，允许推测读取。写入操作可能会延迟，并在 WC 缓冲       在专门的 WC Buffer 中，直到遇到序列化指令或
// 区中合并，以减少内存访问。如果 WC 缓冲区部分填充，写入操作可能会延迟，直到出现序列化       者 WC Buffer 被塞满。
// 事件；例如 SFENCE 或 MFENCE 指令、CPUID 或其他序列化指令、对未缓存内存的读取或写入、
// 中断发生或 LOCK 指令的执行（包括带有 XACQUIRE 或 XRELEASE 前缀的指令）。此外，执行
// XEND 指令（结束事务区域）会驱逐 XBEGIN 指令（开始事务区域）之前缓冲的任何写入，然后
// 再驱逐在事务区域内执行的任何写入。
//
// 这种类型的缓存控制适用于视频帧缓冲区，其中写入的顺序不重要，只要写入更新内存，以便可
// 以在图形显示器上看到。这种内存类型在 Pentium Pro 和 Pentium II 处理器中通过编程
// MTRRs 可用；或在从 Pentium III 处理器开始的处理器家族中通过编程 MTRRs 或通过 PAT
// 选择。
//
// 直写（WT，Write Through）。对系统内存的读取和写入都会被缓存。读取操作来自缓存行上的   *** 直写类型：读操作都被缓存，写入未命中时直接写
// 缓存命中；读取未命中会导致缓存填充。允许推测读取。所有写入操作都会写入缓存行（如果可        内存（无效的缓存行永远不会被填充），写入命中
// 能）并写入系统内存。当写入内存时，无效的缓存行永远不会被填充，有效的缓存行会被填充或        时也直接写内存（有效的缓存行可能被填充或置成
// 变成无效。允许写合并。这种类型的缓存控制适用于帧缓冲区或系统总线上有访问系统内存但不        无效），它强制执行处理器和系统内存之间的一致
// 执行内存访问监听的设备。它强制执行处理器缓存和系统内存之间的一致性。                       性，适用于帧缓冲区（允许写合并）或系统总线上
//                                                                                      访问内存但不执行内存访问监听的设备
// 回写（WB，Write Back）。对系统内存的读取和写入都会被缓存。读取操作来自缓存行上的缓存
// 命中；读取未命中会导致缓存填充。允许推测读取。写入未命中会导致缓存行填充（从 P6 家族
// 处理器开始），并且写入操作尽可能完全在缓存中执行。允许写合并。回写内存类型通过消除许   *** 回写类型：写操作都被缓存，直到缓存满或缓存一致
// 多不必要的系统内存写入操作来减少总线流量。对缓存行的写入操作不会立即转发到系统内存；       性机制触发，该类型要求系统总线上所有访问内存的
// 相反，它们会在缓存中累积。修改后的缓存行会在稍后执行回写操作时写入系统内存。回写操作       设备都能够监听内存访问以确保一致性
// 在需要分配缓存行时触发，例如在缓存已满时分配新的缓存行。它们还由用于维护缓存一致性的
// 机制触发。这种类型的缓存控制提供了最佳性能，但它要求系统总线上所有访问系统内存的设备
// 都能够监听内存访问，以确保系统内存和缓存一致性。
//
// 写保护（WP，Write Protected）。读取操作尽可能来自缓存行，读取未命中会导致缓存填充。  *** 写保护类型：读操作都被缓存，写入命中总是置成无效，
// 写入操作会传播到系统总线，并导致总线上所有处理器的相应缓存行无效。允许推测读取。这种       并且写操作不会延迟，直接传播到系统总线，并导致总
// 内存类型从 P6 家族处理器开始通过编程 MTRRs 可用。                                      线上所有处理器相应缓存行无效
//
// 写合并内存位置的缓冲。对 WC 内存类型的写入不会像通常意义上的缓存那样被缓存。它们被保
// 留在一个内部写合并缓冲区（WC 缓冲区）中，该缓冲区与内部 L1、L2 和 L3 缓存以及存储缓
// 冲区分开。WC 缓冲区不会被监听，因此不提供数据一致性。对 WC 内存的写入操作进行缓冲，
// 以允许软件在一个小的时间窗口内提供更多的修改数据到 WC 缓冲区，同时尽可能对软件不产生
// 干扰。对 WC 内存的写入操作进行缓冲也会导致数据被折叠；也就是说，对同一内存位置的多次   *** 写合并类型，对同一内存位置的多次写入将保留最后写
// 写入将保留最后写入的数据，其他写入将丢失。WC 缓冲区的大小和结构在架构上没有定义。对于      入的数据，其他写入将丢失
// Intel Core 2 Duo、Intel Atom、Intel Core Duo、Pentium M、Pentium 4 和 Intel
// Xeon 处理器；WC 缓冲区由几个 64 字节 WC 缓冲区组成。对于 P6 家族处理器，WC 缓冲区由
// 几个 32 字节 WC 缓冲区组成。
//
// 当软件开始写入 WC 内存时，处理器开始逐个填充 WC 缓冲区。当一个或多个 WC 缓冲区已满时，
// 处理器可以选择将缓冲区驱逐到系统内存。驱逐 WC 缓冲区的协议依赖实现，软件不应依赖于它
// 来实现系统内存一致性。当使用 WC 内存类型时，软件必须意识到数据写入系统内存的操作被延
// 迟，并且必须在需要系统内存一致性时故意清空 WC 缓冲区。一旦处理器开始将数据从 WC 缓冲
// 区驱逐到系统内存，它将根据缓冲区包含多少有效数据做出总线事务风格决策。如果缓冲区已满
// （例如所有字节都有效），处理器将在总线上执行突发写入事务。这导致所有 32 字节（P6 家
// 族处理器）或 64 字节（Pentium 4 和更新的处理器）在单个突发事务中传输到数据总线。如果
// 一个或多个 WC 缓冲区的字节无效（例如未被软件写入），处理器将使用 “部分写入” 事务将数
// 据传输到内存（一次一个块，其中 “块” 是 8 字节）。对于一个 WC 缓冲区数据发送到内存，
// 将导致最多 4 个部分写入事务（对于P6 家族处理器）或 8 个部分写入事务（对于 Pentium 4
// 和更新的处理器）。
//
// WC 内存类型在定义上是弱排序的。一旦开始驱逐 WC 缓冲区，数据就受到其定义的弱排序语义
// 的约束。在 WC 缓冲区的连续分配和释放之间不维护排序（例如写入 WC 缓冲区 1 再写入 WC
// 缓冲区 2，可能出现在系统总线上的顺序为缓冲区 2 后跟缓冲区 1）。当 WC 缓冲区作为部分
// 写入被驱逐到内存时，连续的部分写入之间没有保证的排序（例如块 2 的部分写入可能会出现
// 在块 1 的部分写入之前或之后）。WC 传播到系统总线的唯一保证元素是那些由事务原子性提供
// 的元素。例如一个完全满的 WC 缓冲区将始终作为单个 32 位突发事务传播，使用任何块顺序。
// 在 WC 缓冲区驱逐中，如果数据将作为部分数据被驱逐，同一块中的所有数据将同时被传播。
//
// 选择内存类型。最简单的系统内存模型是不使用带有读写副作用的内存映射 I/O，不使用帧缓冲
// 区，而是对所有内存都使用回写内存类型。I/O 代理可以对回写内存执行直接内存访问（DMA），
// 缓存协议维护缓存一致性。系统可以对其他内存映射 I/O 使用强不可缓存内存，并且应始终对带
// 有读取副作用的内存映射 I/O 使用强不可缓存内存。
//
// 双端口内存（dual-ported memory）可以被视为一种写入副作用，使相对及时的写入（relatively
// prompt write）令人满意，因为这些写入在到达内存代理之前无法在其他端口观察到。系统可以
// 对包含屏幕上显示的像素值的帧缓冲区或双端口内存使用强不可缓存、不可缓存、直写或写合并
// 内存。帧缓冲区内存通常很大（几兆字节），并且通常被处理器写入的次数多于读取。对帧缓冲
// 区使用强不可缓存内存会产生非常大的总线流量，因为对整个缓冲区的操作是使用部分写入而不
// 是行写入实现的。对帧缓冲区使用直写内存可能会置换处理器 L2 和 L3 缓存以及 L1 数据缓存
// 中几乎所有其他有用的缓存行。因此，系统应尽可能对帧缓冲区使用写合并内存。
//
// 软件可以使用页面级缓存控制，当软件不会受益于回写缓存的方式访问数据结构时可分配适当的
// 有效内存类型。例如，软件可能只读取一次大型数据结构，直到另一个代理重写该结构之前不会
// 再次访问该结构。这样的大型数据结构应被标记为不可缓存，否则读取它会置换处理器将再次引
// 用的缓存行。类似的例子是仅写入数据结构（将数据导出到另一个代理），但软件从不读取该结
// 构。这样的结构可以被标记为不可缓存，因为软件从不读取它写入的值（尽管作为不可缓存内存，
// 它将使用部分写入进行写入，而作为回写内存则使用行写入进行写入，这可能不会发生直到另一
// 个代理读取结构并触发隐式回写）。
//
// 在 Pentium III、Pentium 4 和更新的处理器上，提供了新的指令，使软件能够更好地控制缓
// 存、预取和数据的回写特性。这些指令允许软件使用弱排序或处理器排序内存类型来提高处理器
// 性能，但在必要时强制对内存读写进行强排序。它们还允许软件更好地控制数据的缓存。有关这
// 些指令及其预期用途的描述，请参见第 13.5.5 节 “缓存管理指令”。
//
// 不可缓存内存中的代码获取。程序可以从不可缓存（UC）内存执行代码，但其含义与访问 UC 内
// 存中的数据不同。在执行代码获取时，处理器永远不会从可缓存代码推测性地切换到 UC 代码。
// 它也永远不会推测性地获取导致进入 UC 代码的分支目标。
//
// 处理器可能会多次获取相同的 UC 缓存行，以便解码一次指令。它可能会在缓存行中解码连续的
// UC 指令，而无需在每条指令之间获取。它还可能会从相同或连续的 4KB 页面获取额外的缓存行，
// 以便解码一条非推测性 UC 指令（即使指令完全包含在一行中也是如此）。由于上述原因，并且
// 由于缓存行大小在未来处理器中可能会发生变化，软件应避免将带有读取副作用的内存映射 I/O   *** 因为同页面和后续页面的内容可能被取指
// 放置在同一页面或用于执行 UC 代码的后续页面中。                                         令额外获取，导致不预期的读取副作用
//
// 读取副作用和写入副作用是指在访问内存或I/O设备时，除了直接的读取或写入操作外，还可能
// 产生的其他影响或行为。这些副作用通常与内存映射I/O设备有关，需要开发人员在访问这些设
// 备时特别小心，以避免意外触发这些副作用。这些副作用可能包括：触发中断，写入某些内存位
// 置可能会触发硬件中断，通知处理器发生了特定事件；修改硬件状态，写入某些内存位置可能会
// 改变硬件设备的内部状态，例如写入一个控制寄存器可能会设置或清除某些状态位；启动硬件操
// 作，写入某些内存位置可能会启动硬件设备的某些操作，例如写入一个控制寄存器可能会启动设
// 备的某种模式。例如当处理器读取地址 0x1000 时，硬件设备可能会清除其内部的中断标志位，
// 从而触发一个中断；当处理器写入地址 0x1000 时，硬件设备可能会启动一个数据传输操作，或
// 者改变其工作模式。
//
// 缓存控制协议。以下部分描述了目前为 Intel 64 和 IA-32 架构定义的缓存控制协议。在 L1
// 数据缓存和 L2/L3 统一缓存中，MESI（修改、独占、共享、无效）缓存协议保持与其他处理器
// 缓存的一致性。L1 数据缓存和 L2/L3 统一缓存每个缓存行有两个 MESI 状态标志。每行可以
// 被标记为下表定义的状态之一。通常，MESI 协议的操作对程序是透明的。P6 家族处理器中的
// L1 指令缓存仅实现 MESI 协议的 “SI” 部分，因为指令缓存不可写。指令缓存监控数据缓存的
// 更改，以在指令被修改时保持缓存之间的一致性。有关指令缓存含意的更多信息，参见第 13.6
// 节 “自修改代码”。
//
//      缓存行状态                      M（修改）      E（独占）        S（共享）                   I（无效）
//      此缓存行有效吗？                是             是              是                            否
//      内存副本…                      过时           有效             有效                          —
//      其他处理器的缓存中存在副本吗？   否             否               可能                         可能
//      对此行的写入…                  不进入系统总线   不进入系统总线   导致处理器获得该行的独占所有权  直接进入系统总线
//
// Intel 64 和 IA-32 架构提供了多种机制，用于控制数据和指令的缓存以及处理器、缓存和内存
// 之间读写操作的排序。这些机制可以分为两大类，后面部分将详细描述这两类缓存控制机制。
//
// 缓存控制寄存器和位：Intel 64 和 IA-32 架构定义了多个专用寄存器，以及控制寄存器和页表
// 或目录表条目中的各种位，用于控制 L1、L2 和 L3 缓存中系统内存位置的缓存。这些机制控制
// 虚拟内存页面和物理内存区域的缓存。
//
// 缓存控制和内存排序指令：Intel 64 和 IA-32 架构提供了几条指令，用于控制数据的缓存、
// 内存读写操作的排序以及数据的预取。这些指令允许软件控制特定数据结构的缓存，控制内存中
// 特定位置的内存一致性，并在程序的特定位置强制执行强内存排序。
//
// 缓存控制寄存器和位。下图描述了 IA-32 处理器中的缓存控制机制。除了内存地址空间，这些
// 机制在 Intel 64 处理器中也以相同的方式工作。Intel 64 和 IA-32 架构提供了以下缓存控
// 制寄存器和控制位，用于启用或限制内存中各个页面或区域的缓存。
//
//      [CR4 |...|PGE|...]
//                 '--------------> PGE 启用全局页面标志（G 标志）
//      [CR3 |...|PCD|PWT|...]
//                 '---'----------> PCD 和 PWT 控制页面目录的缓存
//      [CR0 |...|CD|NW|...]
//                 '--'-----------> CD 和 NW 控制系统内存的总体缓存机制
//      页目录或页表条目
//      [...|PAT|G|PCD|PWT|...]
//               |  '---'---------> PCD 和 PWT 控制基于页面的缓存
//               '----------------> G 控制基于页面的 TLBs 刷新（flushing）
//      [Store Buffer]  [TLBs]
//
//      物理内存
//      |               | MAXPHYADDR
//      |   ...         |
//      |               | <-------- [PAT] PAT 控制虚拟内存页的缓存
//      |   ...         |
//      |               | <----.
//      |               |      |
//      |               | <----'
//      |               |      |
//      |               | <----'--- [MTRRs] 控制物理内存选定区域的缓存
//      |               |      |
//      |               | <----'
//      |   ...         |
//      |               | 0
//
//      * TLB 翻译后边缓冲区（Translation Lookaside Buffer）
//      * G 标志（全局标志）仅在 P6 及更新的处理器家族中可用
//      * 最大物理地址大小由 MAXPHYADDR 确定，这是一个 CPUID 返回的值，指示处理器支持
//        的最大物理地址大小，它决定了系统可以寻址的物理内存的最大范围
//      * MTRR 内存类型范围寄存器（Memory Type Range Register）仅在 P6 及更新的处理
//        器家族中可用，它允许操作系统为特定的物理内存区域指定内存类型（如强不可缓存、
//        写合并等），这些寄存器提供与 Pentium 处理器中通过 KEN# 和 WB/WT# 引脚实现
//        的类似功能
//      * PAT 页面属性表（Page Attribute Table）仅在 Pentium III 及更新的处理器家族
//        中可用，PAT 允许操作系统在页面级别上指定内存类型，从而为每个虚拟内存页面提供
//        更精细的缓存控制
//      * 基于 Intel NetBurst 微架构的处理器可以通过 IA32_MISC_ENABLE MSR 禁用 L3
//        缓存，仅在基于 Intel NetBurst 微架构的处理器中支持此特性，例如 Pentium 4
//        和 Intel Xeon 处理器，在更新的处理器家族（如 Intel Core 系列）中，此特性不
//        再支持
//
// 下表描述了在不同 CD（Cache Disable）和 NW（Not Write-Back）标志设置下，处理器缓存
// 操作模式的行为。这些标志位于控制寄存器 CR0 中，用于控制缓存的启用和写入策略。
//
//      CD  NW  L1  L2/L3   缓存和读/写策略
//      0   0   --  --      正常缓存模式，最高性能缓存操作
//              Y   Y       - 读取命中访问缓存，读取未命中可能导致替换
//              Y   Y       - 写入命中更新缓存
//              Y   Y       - 只有对共享行的写入和写入未命中会更新系统内存
//              Y   Y       - 写入未命中导致缓存行填充
//              Y           - 写入命中可以在 MTRRs 控制下将共享行更改为修改状态，并伴随相关的读取无效周期
//              Y           - （仅限 Pentium 处理器）写入未命中不会导致缓存行填充
//              Y           - （仅限 Pentium 处理器）写入命中可以在 WB/WT# 控制下将共享行更改为独占状态
//              Y   Y       - 允许无效化
//              Y   Y       - 支持外部监听流量（external snoop traffic）
//      0   1   --  --      无效设置，生成一般保护异常（#GP），错误代码为 0
//      1   0   --  --      无填充缓存模式，维护内存一致性，在 Intel Atom 处理器中不支持，如果在 Intel Atom 处理器中 CD = 1，则禁用缓存
//              Y   Y       - （Pentium 4 及更新的处理器家族）电源开启或复位后的处理器状态
//              Y   Y       - 读取命中访问缓存，读取未命中不会导致替换（见上文对 Pentium 4 和 Intel Xeon 处理器的说明）
//              Y   Y       - 写入命中更新缓存
//              Y   Y       - 只有对共享行的写入和写入未命中会更新系统内存
//              Y   Y       - 写入未命中访问内存
//              Y   Y       - 写入命中可以在 MTRRs 控制下将共享行更改为独占状态，并伴随相关的读取无效化周期
//              Y           - （仅限 Pentium 处理器）写入命中可以在 WB/WT# 控制下将共享行更改为独占状态
//              Y   Y       - （仅限 P6 及更新的处理器家族）除非禁用 MTRRs 或所有内存都被引用为不可缓存，否则不强制严格的内存排序，见 7.2.4 节 “加强或削弱内存排序模型”
//              Y   Y       - 允许无效化
//              Y   Y       - 支持外部监听流量
//      1   1   --  --      不维护内存一致性
//                          Intel Atom 处理器中不支持，如果在 Intel Atom 处理器中 CD = 1，则禁用缓存
//                          Pentium 4 及更新的处理器家族不支持此模式，将 CD 和 NW 位设置为 1 会选择无填充缓存模式
//              Y   Y       - （P6 家族和 Pentium 处理器）电源开启或复位后的处理器状态
//              Y   Y       - 读取命中访问缓存，读取未命中不会导致替换
//              Y   Y       - 写入命中更新缓存并将独占行更改为修改状态
//              Y   Y       - 共享行在写入命中后保持共享状态
//              Y   Y       - 写入未命中访问内存
//              Y   Y       - 在监听时禁止无效化，但允许使用 INVD 和 WBINVD 指令进行无效化
//              N   Y       - 支持外部监听流量
//
//  1.  CD 标志，控制寄存器 CR0 的第 30 位：控制系统内存位置的缓存（见第 2.5 节 “控制
//      寄存器”）。如果 CD 标志为 0，缓存对整个系统内存启用，但可以通过其他缓存控制机制
//      限制个别页面或内存区域的缓存。当 CD 标志为 1 时，对于 P6 及更新的处理器家族，处
//      理器的缓存层次结构中的缓存被限制，而对于 Pentium 处理器，缓存被禁止（见上文表
//      格）。然而，即使设置了 CD 标志，缓存仍然会对监听流量做出响应。为了确保内存一致
//      性，应显式刷新缓存。为了获得最高的处理器性能，控制寄存器 CR0 中的 CD 和 NW 标
//      志都应被清除。上文表格展示了 CD 和 NW 标志的交互。
//
//      设置 CD 标志对 P6 家族及更新的处理器家族的影响与对 Pentium 处理器的影响有所不
//      同（见上文表格）。为了在设置 CD 标志后确保内存一致性，应显式刷新缓存（见第 13.5.3
//      节 “防止缓存”）。对于 P6 及更新的处理器家族，设置 CD 标志会修改缓存行填充和更
//      新行为。此外，除非禁用 MTRRs 或所有内存都被引用为不可缓存，否则在这些处理器上设
//      置 CD 标志不会强制严格的内存访问排序，见 10.2.5 节 “加强或削弱内存排序模型”。
//
//  2.  NW 标志，控制寄存器 CR0 的第 29 位：控制系统内存位置的写入策略，见 2.5 节 “控
//      制寄存器”。如果 NW 和 CD 标志都为 0，整个系统内存的回写被启用，但可以通过其他
//      缓存控制机制限制个别页面或内存区域的写入策略。上文表格展示了 CD 和 NW 标志的其
//      他组合对缓存的影响。
//
//      对于 Pentium 4 和 Intel Xeon 处理器，NW 标志是一个无关紧要的标志，即当 CD 标
//      志被设置时，处理器使用无填充缓存模式，不管 NW 标志的设置如何。对于 Intel Atom
//      处理器，NW 标志是一个无关紧要的标志，即当 CD 标志被设置时，处理器禁用缓存，不管
//      NW 标志的设置如何。对于 Pentium 处理器，当 L1 缓存被禁用（控制寄存器 CR0 中的
//      CD 和 NW 标志被设置）时，在双处理器系统中接受外部监听，在单处理器系统中抑制外部
//      监听。当监听被抑制时，不检查地址奇偶校验，对于错误地址不断言 APCHK#；然而，当监
//      听被接受时，检查地址奇偶校验，对于错误地址断言 APCHK#。
//
//  3.  分页结构条目中的 PCD 和 PWT 标志，控制访问分页结构和页面时使用的内存类型，
//      见第 5.9 节 “分页和内存类型”
//
//  4.  控制寄存器 CR3 中的 PCD 和 PWT 标志，访问当前分页结构层次中第一个分页结构使用
//      的内存类型，见第 5.9 节 “分页和内存类型”
//
//  5.  页目录和页表条目中的 G（全局）标志（在 P6 家族处理器中引入到 IA-32 架构），控
//      制独立页面 TLB 条目的刷新，参考第 5.10 节 “缓存翻译信息”
//
//  6.  控制寄存器 CR4 中的 PGE（页面全局启用）标志，启用对 G 标志的使用建立全局页面，
//      有关此标志的更多信息，参考第 5.10 节 “缓存翻译信息”
//
//  7.  内存类型范围寄存器（MTRRs），在 P6 家族处理器中引入，控制特定物理内存区域使用
//      的缓存类型，可以选用 “可用的缓存方法” 中描述的任何缓存类型，有关 MTRRs 的详细
//      描述，参考第 13.11 节 “内存类型范围寄存器（MTRRs）”
//
//  8.  页面属性表（PAT）MSR（在 Pentium III 处理器中引入），扩展处理器的内存类型功能，
//      允许按页面分配内存类型，见第 13.12 节 “页面属性表（PAT）”
//
//  9.  第三级缓存禁用标志，IA32_MISC_ENABLE MSR 的第 6 位（仅在基于 Intel NetBurst
//      微架构的处理器中可用），允许独立于 L1 和 L2 缓存启用和禁用 L3 缓存
//
//  10. KEN# 和 WB/WT# 引脚（Pentium 处理器），允许外部硬件控制特定内存区域的缓存方法，
//      它们在 P6 家族处理器中执行类似（但不完全相同）的功能
//
//  11. PCD 和 PWT 引脚（Pentium 处理器），这些引脚（与控制寄存器 CR3 和页目录及页表
//      条目中的 PCD 和 PWT 标志相关）允许在页面级别控制缓存到一个外部 L2 缓存，与这些
//      处理器的 L1 缓存所行使的控制一致，P6 及更新的处理器家族不提供这些引脚，因为 L2
//      缓存位于芯片封装内部
//
// 缓存控制的优先级。缓存控制标志和 MTRRs 按层次限制缓存。如果设置了 CD 标志，则全局禁
// 止缓存。如果 CD 标志为 0，则可以使用页面级别缓存控制标志和 MTRRs 来限制缓存。如果页
// 面级别和 MTRR 缓存控制有重叠，则防止缓存的机制具有优先权。例如，如果一个 MTRR 使一个
// 系统内存区域不可缓存，则不能使用页面级别缓存控制来启用该区域中页面的缓存。反之亦然，
// 如果页面级别缓存控制将一个页面指定为不可缓存，则不能使用 MTRR 使该页面可缓存。
//
// 在将回写和直写缓存策略分配给页面和内存区域时存在重叠的情况下，直写策略具有优先权。写
// 合并策略（只能通过 MTRR 或 PAT 分配）优先于直写或回写。在页面级别选择内存类型时，是
// 否使用 PAT 选择页面的内存类型会有所不同。
//
// 在基于 Intel NetBurst 微架构的处理器上，可以通过 IA32_MISC_ENABLE MSR 的第 6 位来
// 禁用第三级缓存。使用 IA32_MISC_ENABLE[bit 6] 的设置优先于 CD 标志、MTRRs 和 PAT
// 对这些处理器中的 L3 缓存的控制。也就是说，当第三级缓存禁用标志被设置（缓存被禁用）时，
// 其他缓存控制对 L3 缓存没有影响；当标志被清除（启用）时，缓存控制对 L3 缓存的影响与对
// L1 和 L2 缓存的影响相同。注意，IA32_MISC_ENABLE[bit 6] 在 Intel Core i7 处理器以
// 及基于 Intel Core 和 Intel Atom 微架构的处理器中不支持。该标志允许独立于 L1 和 L2
// 缓存启用和禁用 L3 缓存，在使用此控制禁用或启用 L3 缓存之前，软件应禁用并刷新所有处理
// 器缓存，以防止 L3 缓存中存储的信息丢失，在禁用或启用 L3 缓存后，可以恢复整个处理器的
// 缓存。
//
// 关于跨不同内存类型页面写入值。如果内存中两个相邻页面具有不同的内存类型，并且将一个字    *** 跨不同内存类型页面的写入
// 或更长的操作数写入跨越这两个页面边界的内存位置，则操作数可能会被写入内存两次。这种行
// 为对于写入实际内存不会造成问题；然而，如果一个设备被映射到页面的内存空间，则设备可能
// 会出现故障。
//
// 防止缓存。要在启用缓存并接收到缓存填充后禁用 L1、L2 和 L3 缓存，请执行以下步骤：       *** 禁用缓存和使缓存无效
//  1.  进入无填充缓存模式，将控制寄存器 CR0 中的 CD 标志设置为 1，NW 标志设置为 0
//  2.  使用 WBINVD 指令刷新所有缓存
//  3.  禁用 MTRRs 并将默认内存类型设置为不可缓存，或将所有 MTRRs 设置为不可缓存类型
//
// 必须在设置 CD 标志后刷新缓存（步骤 2），以确保系统内存一致性。如果缓存未被刷新，读取
// 操作仍会发生缓存命中，并且数据将从有效的缓存行中读取。上述三个独立步骤的意图是为了满
// 足三个不同的要求：(i) 停止新数据替换缓存中的现有数据；(ii) 确保缓存中的数据已被驱逐
// 到内存；(iii) 确保后续内存引用遵循 UC 内存类型语义。不同处理器实现的缓存控制硬件可能
// 允许这三个要求的软件实现有所不同，参考下文注释。
//
// 注释：在控制寄存器 CR0 中设置 CD 标志会修改处理器的缓存行为，但单独设置 CD 标志可能
// 不足以在所有处理器家族中强制所有物理内存的有效内存类型为 UC，也不会强制严格的内存排序，
// 因为不同处理器家族之间的硬件实现差异。为了强制所有物理内存的 UC 内存类型和严格内存排
// 序，需要将所有物理内存的 MTRRs 编程为 UC 内存类型或禁用所有 MTRRs。
//
// 对于 Pentium 4 和 Intel Xeon 处理器，在执行上述步骤序列后，WBINVD 指令结束和 MTRRs
// 实际被禁用之间的代码所在的缓存行可能还保留在缓存层次结构中。在这里，为了完全从缓存中
// 移除代码，必须在禁用 MTRRs 后执行第二个 WBINVD 指令。对于 Intel Atom 处理器，设置
// CD 标志会强制所有物理内存遵循 UC 语义（无需显式设置物理内存的内存类型）。因此，软件
// 不需要发出第二个 WBINVD，因为其他一些处理器代可能需要这样做。
//
// 使翻译后备缓冲区（TLBs）无效。处理器会透明地更新其地址翻译缓存（TLBs）。然而，存在几
// 种机制，允许软件和硬件显式地使 TLBs 无效，或者作为另一操作的副作用使 TLBs 无效。大多
// 数详细信息在内存分页第 5.10.4 节 “使 TLBs 和分页结构缓存无效” 中给出。此外，以下操作
// 会使所有 TLB 条目无效，无论 G 标志的设置如何。有关 TLBs 的更多信息，请参阅第 5.10
// 节 “缓存翻译信息”。
//  1.  断言或取消断言 FLUSH# 引脚
//  2.  （Pentium 4、Xeon 及更新处理器）写入 MTRR（使用 WRMSR 指令）
//  3.  写入控制寄存器 CR0 以修改 PG 或 PE 标志
//  4.  （Pentium 4、Xeon 及更新处理器）写入控制寄存器 CR4 以修改 PSE PGE PAE 标志
//  5.  写入控制寄存器 CR4 将 PCIDE 标志从 1 改为 0
//
// 缓存管理指令。Intel 64 和 IA-32 架构提供了几条指令，用于管理 L1、L2 和 L3 缓存。     *** 缓存管理指令
// INVD 和 WBINVD 指令是特权指令，对整个 L1、L2 和 L3 缓存进行操作。PREFETCHh、CLFLUSH
// 和 CLFLUSHOPT 指令以及非时态移动指令（MOVNTI、MOVNTQ、MOVNTDQ、MOVNTPS 和 MOVNTPD）
// 提供更细粒度的缓存控制，并且对所有特权级别都可用。
//
// INVD 和 WBINVD 指令：INVD 指令使所有内部缓存条目无效，然后生成一个特殊功能总线周期，
// 指示外部缓存也应被无效。INVD 指令应谨慎使用。它不会强制写回修改的缓存行；因此，存储
// 在缓存中且未写回系统内存的数据将丢失。除非有特定要求或好处，否则软件应使用 WBINVD 指
// 令。WBINVD 指令首先将所有内部缓存中的修改行写回，然后使 L1、L2 和 L3 缓存的内容无效。
// 它确保无论生效的写入策略如何（即直写或回写），缓存与主内存的一致性得到维护。在此操作
// 之后，WBINVD 指令生成一个（P6 家族处理器）或两个（Pentium 和 Intel486 处理器）特殊
// 功能总线周期，指示外部缓存控制器应执行修改数据的回写，然后使外部缓存无效。WBINVD 完成
// 所需的时间或周期会因不同缓存层次结构的大小和其他因素而异。因此，使用 WBINVD 指令可能
// 会影响中断/事件响应时间。
//
// CLFLUSH 和 CLFLUSHOPT 指令：允许选定的缓存行从内存中被刷新。这些指令使程序能够显式
// 地释放缓存空间，因为知道系统内存的缓存部分在不久的将来将不会被访问。
//
// 非时态移动指令（MOVNTI、MOVNTQ、MOVNTDQ、MOVNTPS 和 MOVNTPD）：允许数据从处理器的
// 寄存器直接移动到系统内存中，而不会被写入 L1、L2 和 L3 缓存。这些指令可用于仅一次修改
// 就写回系统内存的数据，防止缓存污染。这些指令对通用寄存器、MMX 和 XMM 寄存器中的数据
// 进行操作。
//
// L1 数据缓存上下文模式。L1 数据缓存上下文模式是基于支持 Intel 超线程技术的 NetBurst   *** 超线程技术中的 L1 数据缓存共享
// 微架构的处理器的一个功能。当 CPUID.01H:ECX[10] = 1 时，处理器支持使用 L1 数据缓存
// 上下文模式标志（IA32_MISC_ENABLE[bit 24]）来设置模式，可选的模式有自适应模式（默认）
// 和共享模式。BIOS 负责配置 L1 数据缓存上下文模式。
//
// 自适应模式促进了逻辑处理器之间的 L1 数据缓存共享。在自适应模式下运行时，如果满足以下
// 条件，L1 数据缓存将在同一核心中的逻辑处理器之间共享。在这种情况下，整个 L1 数据缓存
// 对每个逻辑处理器都可用（而不是竞争性共享）。如果共享 L1 数据缓存的逻辑处理器的 CR3
// 值不同，或者逻辑处理器使用不同的分页模式，处理器将竞争缓存资源，这会减少每个逻辑处理
// 器的缓存有效大小。不允许缓存别名（防止数据抖动，data thrashing）。
//  1.  共享缓存的逻辑处理器的 CR3 控制寄存器相同
//  2.  共享缓存的逻辑处理器使用相同的分页模式
//
// 在共享模式下，L1 数据缓存被逻辑处理器竞争性共享。即使逻辑处理器使用相同的 CR3 寄存器
// 和分页模式，也是如此。在共享模式下，L1 数据缓存中的线性地址可以被别名化，这意味着缓存
// 中的一个线性地址可以指向不同的物理位置，解析别名的机制可能导致抖动。因此，对于支持
// Intel 超线程技术的基于 Intel NetBurst 微架构的处理器，IA32_MISC_ENABLE[bit 24]
// 首选配置是设置为 0。
//
// 自修改代码。当写入操作作用于当前处理器缓存的代码段中的内存位置时，相关的缓存行将被无    *** 自修改代码（Self-Modifying Code）
// 效化。这一检查是基于指令的物理地址进行的。此外，P6 家族和 Pentium 处理器还会检查写入
// 代码段的操作是否会修改已被预取以供执行的指令。如果写入操作影响了预取的指令，预取队列
// 将被无效化。后者的检查是基于指令的线性地址进行的。对于 Pentium 4 和 Intel Xeon 处理
// 器，代码段中的指令的写入或监听操作，如果目标指令已经被解码并且驻留在跟踪缓存（trace
// cache，相当于 L1 i-cache）中，将使整个跟踪缓存无效。这意味着，在 Pentium 4 和 Xeon
// 处理器上运行的自修改代码的程序可能会导致性能严重下降。
//
// 实际上，基于线性地址的检查不应在 IA-32 处理器之间造成兼容性问题。包含自修改代码的应
// 用程序使用相同的线性地址来修改和获取指令。系统软件（如调试器）可能会使用与获取指令时
// 不同的线性地址来修改指令，在执行修改后的指令之前，将执行一个序列化操作（如 CPUID 指
// 令），这将自动重新同步指令缓存和预取队列。有关自修改代码的使用，请参阅第 10.1.3 节
// “处理自修改和交叉修改代码”。
//
// 对于 Intel486 处理器，对缓存中的指令的写入操作将同时修改缓存和内存中的指令，但如果在
// 写入之前已经预取了该指令，则可能会执行旧版本的指令。为了防止执行旧指令，通过在修改指
// 令的写入操作之后立即编码一条跳转指令来刷新指令预取单元。
//
// 隐式缓存（Pentium 4、Intel® Xeon® 和 P6 家族处理器）。当一个内存元素被设置为潜在可   *** 隐式缓存（Implicit Caching），由于预取、分支预测、推测性执行等技术的存在，
// 缓存时，即使该元素可能从未在正常的冯·诺依曼序列中被访问过，也会发生隐式缓存。由于积极       即使一个内存元素还未被处理，也可能隐式的提前预取到缓存
// 的预取、分支预测和 TLB 缺失处理，P6 及更新的处理器家族中会发生隐式缓存。隐式缓存是现
// 有 Intel386、Intel486 和 Pentium 处理器系统行为的扩展，因为运行在这些处理器家族上的
// 软件也无法确定性地预测指令预取的行为。
//
// 为了避免与隐式缓存相关的问题，操作系统必须在缓存一致性机制未自动处理时，显式地使缓存
// 无效。这包括对处理器的监听机制（snooping mechanism）未检测到的双端口或物理别名内存
// 板的写入，以及对内存中的页表条目的更改。
//
// 以下示例代码展示了隐式缓存对页表条目的影响。线性地址 F000H 指向物理位置 B000H（F000H
// 的页表条目包含值 B000H），F000 的页表条目为 PTE_F000。由于 P6 及更新的处理器家族中
// 的推测性执行，最后的 MOV 指令执行会将物理位置 B000H 的值放入 EBX，而不是新物理地址
// A000H 的值。通过在加载和存储之间放置 TLB 无效化操作来解决这种情况。
//
//      mov EAX, CR3; 使 TLB 无效
//      mov CR3, EAX; 通过将 CR3 复制给自己
//      mov PTE_F000, A000H; 将页表项 F000H 改为指向 A000H
//      mov EBX, [F000H]; 读取页表项的内容，由于推测性执行，该执行可能访问原来缓存的内容 B000H
//
// 显式缓存。Pentium III 处理器引入了四条新指令，即 PREFETCHh 指令，为软件提供了对数据   *** PREFETCHh 指令和显式缓存
// 缓存的显式控制。PREFETCHh 指令允许程序控制处理器从系统内存中的指定位置预取缓存行到缓
// 存层次结构中，这些指令为处理器提供了“提示”，即由 PREFETCHh 指令请求的数据应立即或
// 尽快读入缓存层次结构，以预期其使用。这些指令提供了不同的提示变体，允许选择数据被读入
// 的缓存级别。PREFETCHh 指令有助于减少通常与读取内存操作相关的长延迟，从而帮助防止处理
// 器 “停顿（stalls）”。然而，这些指令应谨慎使用，过度使用可能导致资源冲突，从而降低应
// 用程序的性能。此外，这些指令仅应用于从内存预取数据；不应用于预取指令。有关正确使用预
// 取指令的详细信息，请参阅架构优化参考手册第 9 章 “优化缓存使用”。

#ifndef PRH_CACHE_LINE_SIZE
#define PRH_CACHE_LINE_SIZE 64
#endif

#ifndef PRH_MEMORY_PAGE_SIZE
#define PRH_MEMORY_PAGE_SIZE 4096
#endif

#ifndef prh_round_ptrsize
prh_inline prh_unt prh_lower_most_bit(prh_unt n) {
    return n & (-(prh_int)n); // 0000 & 0000 -> 0000, 0001 & 1111 -> 0001, 1010 & 0110 -> 0010
}

prh_inline prh_unt prh_remove_lower_most_bit(prh_unt n) {
    return n & (n - 1);
}

prh_inline bool prh_is_power_of_2(prh_unt n) {
    return prh_remove_lower_most_bit(n) == 0; // power of 2 or zero
}

prh_inline prh_unt prh_to_power_of_2(prh_unt n) {
    if (prh_is_power_of_2(n)) return n;
    // TODO: 字节序交换然后计算lower most bit
    prh_unt m = prh_lower_most_bit(n);
    while (m < n) m <<= 1;
    return m;
}

#define prh_round_ptrsize(n) (((prh_unt)(n)+(prh_unt)(sizeof(void*)-1)) & (~(prh_unt)(sizeof(void*)-1)))
#define prh_round_cache_line_size(n) (((prh_unt)(n)+PRH_CACHE_LINE_SIZE-1) & (~(prh_unt)(PRH_CACHE_LINE_SIZE-1)))
#define prh_round_08_byte(n) (((prh_unt)(n)+7) & (~(prh_unt)7))
#define prh_round_16_byte(n) (((prh_unt)(n)+15) & (~(prh_unt)15))
#endif // prh_round_ptrsize

#ifndef prh_memory_alloc
// void *realloc(void *ptr, prh_unt size);
// if ptr != NULL
//      if size != 0
//          return realloc(ptr, size)
//      else
//          **MAYBE** free(ptr) return NULL
// else
//      if size != 0
//          return malloc(size)
//      else
//          return NULL
typedef void *(*prh_realloc_func)(void *ptr, prh_unt size);

// void *alloc_free(prh_ptr size); 至少分配指针大小的倍数，返回的地址至少对齐到指针大小
// if size & 0x02
//      return malloc(size)
// else
//      free((void *)size) return NULL
typedef void *(*prh_alloc_free)(prh_ptr size);
prh_alloc_free prh_default_alloc_free(void);

prh_inline void *prh_impl_memory_alloc(prh_alloc_free alloc, prh_unt size, int line) {
    void *p = alloc(size | 0x02);
    prh_assert_line(p != prh_null && (((prh_ptr)p) & 0x02) == 0, line);
    return p;
}

prh_inline void *prh_impl_memory_free(prh_alloc_free alloc, void *ptr, int line) {
    prh_assert_line((((prh_ptr)ptr) & 0x02) == 0, line); // 分配的内存至少对齐到指针大小
    return alloc((prh_ptr)ptr);
}

#define prh_memory_alloc(alloc, size) prh_impl_memory_alloc(alloc, size, __LINE__)
#define prh_memory_free(alloc, ptr) ((void)prh_impl_memory_free(alloc, ptr, __LINE__))
#endif // prh_memory_alloc

#ifdef PRH_BASE_IMPLEMENTATION
void prh_impl_assert(int line) {
    fprintf(stderr, "assert line %d\n", line);
    abort(); // 不能使用 exit(line)，因为退出码>=128有移植性问题，可能导致shell混乱
}

void prh_impl_prerr(int line, unsigned int error) {
    fprintf(stderr, "error %d line %d\n", error, line);
}

void prh_impl_abort(int line) {
    fprintf(stderr, "abort line %d\n", line);
    abort();
}

void prh_impl_abort_error(int line, unsigned int error) {
    fprintf(stderr, "abort %d line %d\n", error, line);
    abort();
}

void prh_print_exit_code(int thrd_id, int exit_code) {
    fprintf(stderr, "thrd %02d exit code %d\n", thrd_id, exit_code);
}

void *prh_impl_realloc(void *ptr, prh_unt size, int line) {
    if (ptr != prh_null) {
        if (size == 0) { free(ptr); return prh_null; }
        ptr = ralloc(ptr, size);
    } else {
        if (size == 0) return prh_null; // 相当于 free(prh_null)
        ptr = malloc(size);
    }
    prh_assert_line(ptr != prh_null, line);
    return ptr;
}

void *prh_impl_default_alloc_free(prh_ptr size) {
    if (size & 0x02) {
        return prh_plat_aligned_malloc(size & (~(prh_ptr)0x02), sizeof(void *));
    } else {
        prh_aligned_free((void *)size);
        return prh_null;
    }
}

prh_alloc_free prh_default_alloc_free(void) {
    return prh_impl_default_alloc_free;
}

#if defined(prh_plat_windows)
#if PRH_DEBUG
// https://learn.microsoft.com/en-us/cpp/c-runtime-library/find-memory-leaks-using-the-crt-library
void prh_impl_dump_memory_leaks(void) {
    _CrtSetReportMode(_CRT_WARN, _CRTDBG_MODE_DEBUG | _CRTDBG_MODE_FILE);
    _CrtSetReportFile(_CRT_WARN, _CRTDBG_FILE_STDERR);
    _CrtDumpMemoryLeaks();
}
#endif
#if defined(PRH_SOCK_INCLUDE) && defined(PRH_SOCK_IMPLEMENTATION)
void prh_impl_wsasocket_init(void);
#endif
#endif // WINDOWS

#if defined(PRH_THRD_INCLUDE) && defined(PRH_THRD_IMPLEMENTATION)
void prh_impl_plat_set_fault_handler(void);
#endif
#if defined(PRH_TIME_INCLUDE) && defined(PRH_TIME_IMPLEMENTATION)
void prh_impl_time_init(void);
#endif
#if defined(PRH_TEST_IMPLEMENTATION)
void prh_impl_test_code(void);
#endif

void prh_main_init(void) {
    prh_memory_alloc_init(prh_impl_default_memory_alloc, prh_impl_default_memory_free);
#if defined(prh_plat_windows)
#if PRH_DEBUG
    prh_zeroret(atexit(prh_impl_dump_memory_leaks));
#endif
#if defined(PRH_SOCK_INCLUDE) && defined(PRH_SOCK_IMPLEMENTATION)
    prh_impl_wsasocket_init();
#endif
#endif // WINDOWS
#if defined(PRH_THRD_INCLUDE) && defined(PRH_THRD_IMPLEMENTATION)
    prh_impl_plat_set_fault_handler();
#endif
#if defined(PRH_TIME_INCLUDE) && defined(PRH_TIME_IMPLEMENTATION)
    prh_impl_time_init();
#endif
#if defined(PRH_TEST_IMPLEMENTATION)
    prh_impl_test_code();
#endif
}

#if defined(prh_plat_windows)
// https://learn.microsoft.com/en-us/cpp/c-language/main-function-and-program-execution
// https://learn.microsoft.com/en-us/cpp/c-language/parsing-c-command-line-arguments
// https://learn.microsoft.com/en-us/cpp/c-language/customizing-c-command-line-processing
// https://learn.microsoft.com/en-us/windows/apps/design/globalizing/use-utf8-code-page
// https://learn.microsoft.com/en-us/windows/win32/sbscs/application-manifests
// https://learn.microsoft.com/en-us/windows/win32/api/shellapi/nf-shellapi-commandlinetoargvw
// https://devblogs.microsoft.com/oldnewthing/20100916-00/?p=12843
// https://devblogs.microsoft.com/oldnewthing/20100917-00/?p=12833
// https://alter.org.ua/en/docs/win/args/
#if defined(_CONSOLE)
// 每个 C 程序都有一个主函数，它必须命名为 main。主函数是程序执行的起点。主函数有
// 一些限制，这些限制不适用于任何其他 C 函数。主函数：不能声明为 inline；不能声明
// 为 static；不能取其地址；不能从程序中调用。main 的声明语法将如下所示：
// int main(void);
// int main(int argc, char *argv[]);
// int main(int argc, char *argv[], char *envp[]);
// 通过使用这些签名之一，主函数被隐式声明。在定义主函数时，你可以使用这些签名中的
// 任何一个。当没有返回值时，Microsoft 编译器还允许 main 的返回类型为 void。main
// 的 argv 和 envp 参数也可以定义为类型 char**。
// 在 Unicode 编程模型中，你可以定义主函数的宽字符版本。如果你想编写符合 Unicode
// 编程模型的可移植代码，请使用 wmain 而不是 main。wmain 函数也没有声明，因为它内
// 置于语言中。如果它有，wmain 的声明语法将如下所示：
// int wmain(void);
// int wmain(int argc, wchar_t *argv[]);
// int wmain(int argc, wchar_t *argv[], wchar_t *envp[]);
#if defined(_UNICODE)
extern int main(int argc, char **argv);
int wmain(int argc, wchar_t *wargv[]) {
    return main(argc, (char **)wargv); // TODO: 将 wargv 转换成 UTF-8 版本的 argv
}
#endif
#else
// 每个 Windows 程序都包含一个名为 WinMain 或 wWinMain 的入口点函数。wWinMain 的四
// 个参数如下：
// * hInstance 是实例句柄或模块句柄。操作系统使用此值在内存中加载时识别可执行文件。某
//   些 Windows 函数需要实例句柄，例如加载图标或位图。
// * hPrevInstance 没有意义。它在 16 位 Windows 中使用，但现在始终为零。
// * pCmdLine 包含命令行参数，包含 Unicode 字符串。
// * nCmdShow 是一个标志，指示主应用程序窗口是处于最小化、最大化还是正常显示状态。
// 该函数返回一个 int 值。操作系统不会使用返回值，但你可以使用该值向其他程序传递状态码。
// WinMain 函数与 wWinMain 相同，只是命令行参数作为 ANSI 字符串传递。Unicode 字符串
// 是首选。
// 即使你将程序编译为 Unicode，也可以使用 ANSI 的 WinMain 函数。要获取命令行参数的
// Unicode 版本，请调用 GetCommandLine 函数。此函数返回一个包含所有参数的单一字符串。
// 如果你希望将参数作为类似 argv 的数组，将此字符串传递给 CommandLineToArgvW。编译器
// 如何知道调用 wWinMain 而不是标准的 main 函数呢？实际上，Microsoft C 运行时库
// （CRT）提供了一个 main 的实现，它会调用 WinMain 或 wWinMain。CRT 在 main 中还做
// 了一些其他工作。例如，它会在调用 wWinMain 之前调用任何静态初始化器。虽然你可以告诉
// 链接器使用不同的入口点函数，但如果你链接到 CRT，应该使用默认值。否则，CRT 初始化代
// 码将被跳过，可能会导致不可预测的结果，例如全局对象没有正确初始化。
//
// LPWSTR * CommandLineToArgvW(
//   [in]  LPCWSTR lpCmdLine,
//   [out] int     *pNumArgs
// );
// shellapi.h Shell32.lib Shell32.dll (version 6.0 or later)
// Windows 2000 Professional, Windows XP
// Windows 2000 Server, Windows Server 2003
//
// 解析 Unicode 命令行字符串，并返回一个指向命令行参数的指针数组，以及参数的数量，类似
// 于标准 C 运行时中的 argv 和 argc。如果函数失败，返回值为 NULL。要获取扩展错误信息，
// 请调用 GetLastError。
//
// 参数 lpCmdLine 指向一个以空字符结尾的 Unicode 字符串，该字符串包含完整的命令行。如
// 果此参数为空字符串，函数将返回当前可执行文件的路径。参数 pNumArgs 指向一个整数的指
// 针，该整数接收返回的数组元素数量，类似于 argc。返回 LPWSTR*，一个指向 LPWSTR 值的
// 数组的指针，类似于 argv。
//
// CommandLineToArgvW 返回的地址是 LPWSTR 值数组的第一个元素的地址；数组中的指针数量
// 由 pNumArgs 指示。每个指向以空字符结尾的 Unicode 字符串的指针表示命令行中的一个单
// 独参数。CommandLineToArgvW 为指向参数字符串的指针和参数字符串本身分配一块连续的内
// 存；调用应用程序在不再需要参数列表时必须释放这些内存。要释放内存，请调用 LocalFree
// 函数。
//
// 可以使用 GetCommandLineW 函数获取适合用作 lpCmdLine 参数的命令行字符串。此函数接
// 受包含程序名称的命令行；程序名称可以用引号括起来，也可以不加引号。当反斜杠字符后面跟
// 着一个引号字符（"）时，CommandLineToArgvW 对反斜杠字符有特殊的解释。这种解释假设任
// 何前面的参数都是有效的文件系统路径，否则其行为可能不可预测。
//
// 这种特殊解释控制了解析器跟踪的“在引号内”模式。当该模式关闭时，空白字符终止当前参数。
// 当该模式开启时，空白字符像其他字符一样被添加到参数中。2n 个反斜杠后跟一个引号：产生
// n 个反斜杠后跟开始/结束引号。这不会成为解析参数的一部分，但会切换“在引号内”模式。
// (2n) + 1 个反斜杠后跟一个引号：再次产生 n 个反斜杠后跟一个引号字面量（"）。这不会切
// 换“在引号内”模式。n 个反斜杠后不跟引号：直接产生 n 个反斜杠。
//
// 重要提示，CommandLineToArgvW 将引号外的空白字符视为参数分隔符。但是，如果 lpCmdLine
// 以任意数量的空白字符开头，CommandLineToArgvW 会将第一个参数视为一个空字符串。lpCmdLine
// 末尾多余的空白字符将被忽略。
#if defined(_UNICODE)
#include <shellapi.h>
extern int main(int argc, char **argv);
int WINAPI wWinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, PWSTR pCmdLine, int nCmdShow) {
    int argc = 0;
    wchar_t **wargv;
    UNREFERENCED_PARAMETER(hPrevInstance);
    UNREFERENCED_PARAMETER(pCmdLine);
    // 运行 GUI 应用程序时，C 运行库启动代码会调用 Windows 函数 GetCommandLineW() 来
    // 获取进程的完整命令行，忽略可执行文件的名称，然后将执行命令行剩余部分的指针传给主
    // 函数的 pCmdLine 参数。
    wargv = CommandLineToArgvW(GetCommandLineW(), &argc);
    if (wargv == prh_null) prh_prerr(GetLastError());
    int n = main(argc, (char **)wargv); // TODO: 将 wargv 转换成 UTF-8 版本的 argv
    if (wargv) LocalFree(wargv);
    return n;
}
#else
// int WINAPI WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, PSTR lpCmdLine, int nCmdShow);
#error "please use unicode for windows application"
#endif
#endif
#endif // WINDOWS
#endif // PRH_BASE_IMPLEMENTATION

#ifdef PRH_TEST_IMPLEMENTATION
#if defined(PRH_ATOMIC_INCLUDE) && defined(PRH_ATOMIC_IMPLEMENTATION)
void prh_impl_atomic_test(void);
#endif
#if defined(PRH_TIME_INCLUDE) && defined(PRH_TIME_IMPLEMENTATION)
void prh_impl_time_test(void);
#endif
#if defined(PRH_THRD_INCLUDE) && defined(PRH_THRD_IMPLEMENTATION)
void prh_impl_thrd_test(void);
#endif
#if defined(PRH_CONO_INCLUDE) && defined(PRH_CONO_IMPLEMENTATION)
void prh_impl_cono_test(void);
#endif
#if defined(PRH_SOCK_INCLUDE) && defined(PRH_SOCK_IMPLEMENTATION)
void prh_impl_sock_test(void);
#endif
typedef struct {
    char a;
    int b;
    short c;
    void *d;
} prh_impl_test_struct;
void prh_impl_basic_test(void) {
    int a[6] = {0}, b = 1, count = 0;
    int len, *len_ptr = a;
    len = (*len_ptr)++; prh_real_assert(len == 0 && a[0] == 1 && len_ptr == a);
    len = ++*len_ptr; prh_real_assert(len == 2 && a[0] == 2 && len_ptr == a);
    len = *len_ptr++; prh_real_assert(len == 2 && a[0] == 2 && len_ptr == a + 1);
    len = *++len_ptr; prh_real_assert(len == 0 && a[0] == 2 && len_ptr == a + 2);
    memcpy(&a, &b, count); // 长度参数可以传递数值零
    memmove(&a, &b, count);
    memset(&a, 2, count);
    prh_u32 s = 0xfffffffe;
    prh_u32 a[] = {0xfffffffe, 0xffffffff, 0, 1};
    prh_real_assert((prh_u32)(a[0] - s) == 0);
    prh_real_assert((prh_u32)(a[1] - s) == 1);
    prh_real_assert((prh_u32)(a[2] - s) == 2);
    prh_real_assert((prh_u32)(a[3] - s) == 3);
    prh_real_assert(prh_offsetof(prh_impl_test_struct, a) == 0);
    prh_real_assert(prh_offsetof(prh_impl_test_struct, b) == 4);
    prh_real_assert(prh_offsetof(prh_impl_test_struct, c) == 8);
#if prh_int_32
    prh_real_assert(prh_offsetof(prh_impl_test_struct, d) == 12);
#elif prh_int_64
    prh_real_assert(prh_offsetof(prh_impl_test_struct, d) == 16);
#endif
}
void prh_impl_test_code(void) {
#if defined(__linux__)
    printf("__linux__ %d defined\n", __linux__);
#endif
#if defined(__LINUX__)
    printf("__LINUX__ %d defined\n", __LINUX__);
#endif
#if defined(__linux)
    printf("__linux %d defined\n", __linux);
#endif
#if prh_plat_linux
#if defined(HZ)
    printf("Linux kernel HZ %lld\n", (long long)HZ);
#endif
#endif
#if defined(linux)
    printf("linux %d defined\n", linux);
#endif
#if defined(__unix__)
    printf("__unix__ %d defined\n", __unix__);
#endif
#if defined(__UNIX__)
    printf("__UNIX__ %d defined\n", __UNIX__);
#endif
#if defined(__unix)
    printf("__unix %d defined\n", __unix);
#endif
#if defined(unix)
    printf("unix %d defined\n", unix);
#endif
#if defined(BSD)
    printf("BSD %d defined\n", BSD);
#endif
    printf("PRH_DEBUG %d\n", PRH_DEBUG);
#if defined(MAC_OS_X_VERSION_MAX_ALLOWED)
    printf("MAC_OS_X_VERSION_MAX_ALLOWED %d\n", MAC_OS_X_VERSION_MAX_ALLOWED);
#endif
#if defined(MAC_OS_X_VERSION_MIN_REQUIRED)
    printf("MAC_OS_X_VERSION_MIN_REQUIRED %d\n", MAC_OS_X_VERSION_MIN_REQUIRED);
#endif
#if defined(WINVER_MAXVER)
    printf("WINVER_MAXVER %04x\n", WINVER_MAXVER);
#endif
#if defined(WDK_NTDDI_VERSION)
    printf("WDK_NTDDI_VERSION %08x\n", WDK_NTDDI_VERSION);
#endif
#if defined(WINVER)
    printf("WINVER %04x\n", WINVER);
#endif
#if defined(_WIN32_WINNT)
    printf("_WIN32_WINNT %04x\n", _WIN32_WINNT);
#endif
#if defined(NTDDI_VERSION)
    printf("NTDDI_VERSION %08x\n", NTDDI_VERSION);
#endif
#if defined(_MSC_VER)
    printf("msc version %d\n", _MSC_VER);
#endif
#if defined(PRH_GCC_VERSION)
    printf("gcc version %d\n", PRH_GCC_VERSION);
#endif
#if defined(PRH_CLANG_VERSION)
    printf("clang version %d\n", PRH_CLANG_VERSION);
#endif
#if defined(PRH_GLIBC_VERSION)
    printf("glibc version %d\n", PRH_GLIBC_VERSION);
#endif
#if defined(__STDC_VERSION__)
    printf("stdc version %ld\n", (long)__STDC_VERSION__);
#endif
#if defined(__cplusplus)
    printf("c++ version %ld\n", (long)__cplusplus);
#endif
    prh_impl_basic_test();
#if defined(PRH_ATOMIC_INCLUDE) && defined(PRH_ATOMIC_IMPLEMENTATION)
    prh_impl_atomic_test();
#endif
#if defined(PRH_TIME_INCLUDE) && defined(PRH_TIME_IMPLEMENTATION)
    prh_impl_time_test();
#endif
#if defined(PRH_THRD_INCLUDE) && defined(PRH_THRD_IMPLEMENTATION)
    prh_impl_thrd_test();
#endif
#if defined(PRH_CONO_INCLUDE) && defined(PRH_CONO_IMPLEMENTATION)
    prh_impl_cono_test();
#endif
#if defined(PRH_SOCK_INCLUDE) && defined(PRH_SOCK_IMPLEMENTATION)
    prh_impl_sock_test();
#endif
}
#endif // PRH_TEST_IMPLEMENTATION

// ARRAYS, SLICES, STRINGS
#ifdef PRH_ARRAY_INCLUDE
// 标准容器相关操作参考
// https://en.cppreference.com/w/cpp/container.html
// 调整容器大小，当增大时需要初始化新增元素
//  void resize(size_type count); 调整容器大小，尾部多余的元素会被移除，不够的元素会追加默认元素值，相当于移除多个元素或添加多个元素
//  void resize(size_type count, const value_type& value); 或追加提供的元素值 value
//  void resize_and_overwrite(size_type count, void (*method_op)(value_type *p, size_type count)); 在增加元素时避免初始化两次
//  void clear(); 清除容器所有元素，清除之后容器大小为零
// 调整容器容量
//  void reserve(size_type new_capacity); 增大容器容量，如果 new_capacity 大于当前容量将扩容
//  void shrink_to_fit(); 缩减容器容量，将没用的过多的容量释放掉
// 移除容器元素，以整个容器为范围（erase），或指定范围内移除元素（remove）
//  iterator erase(const_iterator pos); 移除所在位置处的元素，返回执行移除操作后其后第一个元素的位置
//  iterator erase(const_iterator first, const_iterator last); 移除所在范围内的元素
//  iterator erase_after(const_iterator pos); 移除位置pos后面的那个元素，返回执行移除操作后其后第一个元素的位置
//  iterator erase_after(const iterator first, const_iterator last); 移除范围内除了first之外的所有元素，即返回end()或last
//  size_type erase(const T& vlaue); 移除所有与值value相等的元素，返回移除的元素个数
//  size_type erase_if(Pred pred); 移除所有满足条件的元素，返回移除的元素个数
//  iterator remove(iterator first, iterator last, const T& value); 将范围内与值value相等的元素移除
//  iterator remove_if(iterator first, iterator last, Pred pred); 将范围内满足要求的元素移除，返回新容器范围[first, end)中的end位置
// 插入元素，在指定位置之前插入或之后插入一个或多个元素
//  iterator insert(const_iterator pos, const value_type& value); 将value插入到pos位置，插入后该值的位置是pos，返回插入元素的迭代器
//  iterator insert(const_iterator pos, value_type&& value); 将value插入到pos位置，使用移动语义，返回插入元素的迭代器
//  iterator insert(const_iterator pos, size_type count, const value_type& value); 将多个元素插入到pos位置，返回第一个插入元素的迭代器
//  iterator insert(const_iterator pos, iterator first, iterator last); 将范围内的元素插入到pos位置
//  iterator insert(const_iterator pos, initializer_list<value_type> list); 将初始化列表中的元素插入到pos位置
//  iterator insert_range(const_iterator pos, range_type&& range); 将范围内的元素插入到pos位置之前
//  iterator insert_after(const_iterator pos, const value_type& value); 将值value插入到pos位置之后，返回插入元素的迭代器
//  iterator insert_after(const_iterator pos, iterator first, iterator last); 将范围内的元素插入到pos位置之后，返回最后一个插入元素的迭代器
//  pair<iterator, bool> insert_or_assign(const key_type& key, mapped_type&& value); 映射中已经存在key赋值，否则插入
//  pair<iterator, bool> insert_or_assign(const_iterator hint, const key_type& key, mapped_type&& value); 插入位置在hint位置
//  iterator before_begin(); 容器第一个元素的之前的元素位置，用于 insert_after() erase_after() 等函数
// 插入一个原地构造的元素，新元素使用提供的参数列表直接原地构造（use placement new to construct the element in-place at the location）
//  iterator emplace(const_iterator pos, Args&&... args); 将新元素插入到pos位置
//  iterator emplace_after(const_iterator pos, Args&&... args); 将新元素插入到pos位置之后
//  reference_type emplace_back(Args&&... args); 在容器尾部插入一个元素，该元素使用提供的参数列表直接原地构造，而 push_back() 需要先构造一个对象再将对象拷贝或移动到容器
//  reference_type emplace_front(Args&&... args); 在容器头部插入一个元素，emplace_back() emplace_front() 可以直接在容器内部构造对象，少了拷贝或移动的操作
//  pair<iterator, bool> map::emplace(Args&&... args); 使用参数列表构造 pair<key_type, value_type>，并将键值对插入到映射对象，如果键值已经存在返回false此时需要析构新建元素
//  pair<iterator, bool> map::try_emplace(const key_type& key, Args&&... args); 如果键值已经存在，不会构造新元素，直接返回false
//  iterator map::emplace_hint(const_iterator hint, Args&&... args); 插入位置在hint位置，参考hint位置插入一个不存在的键值对，如果键已经存在返回false
//  iterator map::try_emplace(const_iterator hint, const key_type& key, Args&&... args); 参考hint位置插入一个不存在的键值对，如果键已经存在直接返回false
// 弹压元素
//  void push_back(const value_type& value); 在容器尾拷贝构造一个新元素
//  void push_back(value_type&& value); 在容器尾移动构造一个新元素
//  void push_front(const value_type& value); 在容器头部压入新元素
//  void push_front(value_type&& value); 在容器头部压入新元素
//  void pop_back(); 弹出容器尾部元素
//  void pop_front(); 弹出容器头部元素
//  void append_range(range_type&& range); 在容器尾部压入多个元素
//  void prepend_range(range_type&& range); 将多个元素压入到容器头部

typedef struct { void *arrvew; prh_int size; } prh_impl_arrvew;
typedef struct { void *arrfix; prh_int size; } prh_impl_arrfix;
typedef struct { void *arrfit; prh_int capacity; prh_int size; } prh_impl_arrfit;
typedef struct { void *arrdyn; prh_int capacity; prh_int size; } prh_impl_arrdyn;
typedef struct { void *arrlax; prh_int capacity; prh_int size; prh_int start; } prh_impl_arrlax;

#define prh_arrvew(elem_type) struct { elem_type *arrvew; prh_int size; } // 只读，不拥有内存
#define prh_arrfix(elem_type) struct { elem_type *arrfix; prh_int size; } // 读写，大小固定的定长数组，负责内存分配和释放（array with fixed size）
#define prh_arrfit(elem_type) struct { elem_type *arrfit; prh_int capacity; prh_int size; } // 读写，容量固定大小有限可调，一旦初始化后不再重新分配内存（the allocated array is fixed in the place, never realloc）
#define prh_arrdyn(elem_type) struct { elem_type *arrdyn; prh_int capacity; prh_int size; } // 读写，容量和大小都动态可变，初始化后一旦调整容量迭代器将失效（array can dynamic re-allocated and re-sized）
#define prh_arrlax(elem_type) struct { elem_type *arrlax; prh_int capacity; prh_int size; prh_int start; } // 读写，容量和大小都动态可变，数组头部空间可伸展（relaxed array - header space can stretch around）
#define prh_slice(elem_type)  struct { elem_type *slice; prh_int capacity; prh_int size; } // 读写，不拥有内存，操作相当于是一个 arrfit

typedef struct { prh_byte *s; prh_int size; } prh_strvew; // 只读，不拥有内存
typedef struct { prh_byte *s; prh_int size; } prh_strfix; // 读写，大小固定的定长字符串，负责内存分配和释放
typedef struct { prh_byte *s; prh_int capacity; prh_int size; } prh_strfit; // 读写，容量固定大小有限可调，一旦初始化后不再重新分配内存
typedef struct { prh_byte *s; prh_int capacity; prh_int size; } prh_string; // 读写，容量和大小都动态可变，初始化后一旦调整容量迭代器将失效
typedef struct { prh_byte *s; prh_int capacity; prh_int size; prh_int start; } prh_strlax; // 读写，容量和大小都动态可变，字符串头部空间可伸展
typedef struct { prh_byte *slice; prh_int capacity; prh_int size; } prh_sslice; // 读写，不拥有内存

#define prh_impl_arrvew_eptr_type(p) prh_typeof((p)->arrvew)
#define prh_impl_arrfix_eptr_type(p) prh_typeof((p)->arrfix)
#define prh_impl_arrfit_eptr_type(p) prh_typeof((p)->arrfit)
#define prh_impl_arrdyn_eptr_type(p) prh_typeof((p)->arrdyn)
#define prh_impl_arrlax_eptr_type(p) prh_typeof((p)->arrlax)

#define prh_impl_arrvew_elem_type(p) prh_typeof(*((p)->arrvew))
#define prh_impl_arrfix_elem_type(p) prh_typeof(*((p)->arrfix))
#define prh_impl_arrfit_elem_type(p) prh_typeof(*((p)->arrfit))
#define prh_impl_arrdyn_elem_type(p) prh_typeof(*((p)->arrdyn))
#define prh_impl_arrlax_elem_type(p) prh_typeof(*((p)->arrlax))

#define prh_impl_arrvew_elem_size(p) sizeof(*((p)->arrvew))
#define prh_impl_arrfix_elem_size(p) sizeof(*((p)->arrfix))
#define prh_impl_arrfit_elem_size(p) sizeof(*((p)->arrfit))
#define prh_impl_arrdyn_elem_size(p) sizeof(*((p)->arrdyn))
#define prh_impl_arrlax_elem_size(p) sizeof(*((p)->arrlax))

#define prh_impl_arrvew_addr(p) (prh_impl_arrvew *)(&((p)->arrvew))
#define prh_impl_arrfix_addr(p) (prh_impl_arrfix *)(&((p)->arrfix))
#define prh_impl_arrfit_addr(p) (prh_impl_arrfit *)(&((p)->arrfit))
#define prh_impl_arrdyn_addr(p) (prh_impl_arrdyn *)(&((p)->arrdyn))
#define prh_impl_arrlax_addr(p) (prh_impl_arrlax *)(&((p)->arrlax))

#define prh_arrvew_type(S, a) prh_typeof(((S){0})->a)
#define prh_arrfix_type(S, a) prh_typeof(((S){0})->a)
#define prh_arrfit_type(S, a) prh_typeof(((S){0})->a)
#define prh_arrdyn_type(S, a) prh_typeof(((S){0})->a)
#define prh_arrlax_type(S, a) prh_typeof(((S){0})->a)
#define prh_slice_type(S, a)  prh_typeof(((S){0})->a)

prh_inline void prh_impl_arrfix_init_inplace(prh_impl_arrfix *arrfix, void *buffer, prh_int size) {
    assert(buffer != prh_null);
    assert(size > 0);
    arrfix->arrfix = buffer;
    arrfix->size = size;
}

prh_inline void prh_impl_arrfit_init_inplace(prh_impl_arrfit *arrfit, void *buffer, prh_int capacity) {
    assert(buffer != prh_null);
    assert(capacity > 0);
    arrfit->arrfit = buffer;
    arrfit->capacity = capacity;
    arrfit->size = 0;
}

#define prh_arrfix_init(p, size) prh_impl_arrfix_init_inplace(prh_impl_arrfix_addr(p), prh_malloc((size) * prh_impl_arrfix_elem_size(p)), (size))
#define prh_arrfit_init(p, capacity) prh_impl_arrfit_init_inplace(prh_impl_arrfit_addr(p), prh_malloc((capacity) * prh_impl_arrfix_elem_size(p)), (capacity))
#define prh_arrfit_init_inplace(p, buffer, capacity) prh_impl_arrfit_init_inplace(prh_impl_arrfit_addr(p), (buffer), (capacity))
#define prh_arrdyn_init(p, capacity) prh_impl_arrdyn_initialize((prh_impl_arrdyn *)(p), (capacity), prh_impl_arrdyn_elem_size(p)) // 生成的数组 capacity 总是 2 的幂
#define prh_arrlax_init(p, capacity) { prh_impl_arrdyn_initialize((prh_impl_arrdyn *)(p), (capacity), prh_impl_arrlax_elem_size(p)); (p)->start = 0; } // 生成的数组 capacity 总是 2 的幂

#define prh_arrfix_free(p) { prh_free((p)->arrfix); prh_debug((p)->arrfix = prh_null); }
#define prh_arrfit_free(p) { prh_free((p)->arrfit); prh_debug((p)->arrfit = prh_null); }
#define prh_arrdyn_free(p) { prh_free((p)->arrdyn); prh_debug((p)->arrdyn = prh_null); }
#define prh_arrlax_free(p) { prh_free((p)->arrlax); prh_debug((p)->arrlax = prh_null); }

prh_inline void prh_impl_arrdyn_clear(prh_impl_arrdyn *p) { p->size = 0; }
#define prh_arrfit_clear(p) prh_impl_arrdyn_clear((prh_impl_arrdyn *)prh_impl_arrfit_addr(p))
#define prh_arrdyn_clear(p) prh_impl_arrdyn_clear((prh_impl_arrdyn *)prh_impl_arrdyn_addr(p))
#define prh_arrlax_clear(p) prh_impl_arrdyn_clear((prh_impl_arrdyn *)prh_impl_arrlax_addr(p))

void prh_impl_arrdyn_initialize(prh_impl_arrdyn *p, prh_int new_capacity, prh_int elem_size);
void prh_impl_arrdyn_expand_capacity(prh_impl_arrdyn *p, prh_int new_capacity, prh_int elem_size);
void prh_impl_arrdyn_shrink_capacity(prh_impl_arrdyn *p, prh_int new_capacity, prh_int elem_size); // 缩减不能缩减至小于元素个数
prh_int prh_impl_arrdyn_expand_size(prh_impl_arrdyn *p, prh_int expand_size, prh_int elem_size); // 增加元素个数时容量可能增大
prh_int prh_impl_arrlax_expand_size(prh_impl_arrlax *p, prh_int expand_size, prh_int elem_size); // 增加元素个数时容量可能增大
prh_int prh_impl_arrdyn_shrink_size(prh_impl_arrdyn *p, prh_int shrink_size); // 缩减元素个数时保持容量不变
prh_int prh_impl_arrlax_shrink_size(prh_impl_arrlax *p, prh_int shrink_size); // 缩减元素个数时保持容量不变
prh_int prh_impl_arrdyn_unchecked_push(prh_impl_arrdyn *p, prh_int expand_size);
prh_int prh_impl_arrlax_unchecked_push(prh_impl_arrlax *p, prh_int expand_size);

#define prh_arrdyn_reserve(p, new_capacity) prh_impl_arrdyn_expand_capacity((prh_impl_arrdyn *)(p), (new_capacity), prh_impl_arrdyn_elem_size(p))
#define prh_arrlax_reserve(p, new_capacity) prh_impl_arrdyn_expand_capacity((prh_impl_arrdyn *)(p), (new_capacity), prh_impl_arrlax_elem_size(p))
#define prh_arrdyn_shrink_to_fit(p) prh_impl_arrdyn_shrink_capacity((prh_impl_arrdyn *)(p), (p)->size, prh_impl_arrdyn_elem_size(p))
#define prh_arrlax_shrink_to_fit(p) prh_impl_arrdyn_shrink_capacity((prh_impl_arrdyn *)(p), (p)->size + (p)->start, prh_impl_arrlax_elem_size(p))

#define prh_arrdyn_push_back(p) ((p)->arrdyn + prh_impl_arrdyn_expand_size((prh_impl_arrdyn *)(p), 1, prh_impl_arrdyn_elem_size(p)))
#define prh_arrlax_push_back(p) ((p)->arrlax + prh_impl_arrlax_expand_size((prh_impl_arrlax *)(p), 1, prh_impl_arrlax_elem_size(p)))
#define prh_arrdyn_multi_push_back(p, n) ((p)->arrdyn + prh_impl_arrdyn_expand_size((prh_impl_arrdyn *)(p), (n), prh_impl_arrdyn_elem_size(p)))
#define prh_arrlax_multi_push_back(p, n) ((p)->arrlax + prh_impl_arrlax_expand_size((prh_impl_arrlax *)(p), (n), prh_impl_arrlax_elem_size(p)))

#define prh_arrfit_push_back(p) // 返回空表示失败
#define prh_arrfit_multi_push_back(p, n) // 要么失败要么添加n个元素
#define prh_arrfit_multi_push_back_best_effort(p, n, out) // 要么失败要么添加out个元素

#define prh_arrfit_unchecked_push_back(p) ((p)->arrfit + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)(p), 1))
#define prh_arrdyn_unchecked_push_back(p) ((p)->arrdyn + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)(p), 1))
#define prh_arrlax_unchecked_push_back(p) ((p)->arrlax + prh_impl_arrlax_unchecked_push((prh_impl_arrlax *)(p), 1))
#define prh_arrfit_unchecked_multi_push_back(p, n) ((p)->arrfit + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)(p), (n)))
#define prh_arrdyn_unchecked_multi_push_back(p, n) ((p)->arrdyn + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)(p), (n)))
#define prh_arrlax_unchecked_multi_push_back(p, n) ((p)->arrlax + prh_impl_arrlax_unchecked_push((prh_impl_arrlax *)(p), (n)))

#define prh_arrdyn_unchecked_pop_back(p) ((p)->arrdyn + prh_impl_arrdyn_shrink_size((prh_impl_arrdyn *)(p), 1)) // 必须有足够的元素
#define prh_arrlax_unchecked_pop_back(p) ((p)->arrlax + prh_impl_arrlax_shrink_size((prh_impl_arrlax *)(p), 1))
#define prh_arrdyn_unchecked_multi_pop_back(p, n) ((p)->arrdyn + prh_impl_arrdyn_shrink_size((prh_impl_arrdyn *)(p), (n)))
#define prh_arrlax_unchecked_multi_pop_back(p, n) ((p)->arrlax + prh_impl_arrlax_shrink_size((prh_impl_arrlax *)(p), (n)))

#define prh_arrdyn_pop_back(p) (((p)->size > 0) ? prh_arrdyn_unchecked_pop_back(p) : prh_null)
#define prh_arrlax_pop_back(p) (((p)->size > 0) ? prh_arrlax_unchecked_pop_back(p) : prh_null)
#define prh_arrdyn_multi_pop_back(p, n) (((p)->size >= (n)) ? prh_arrdyn_unchecked_multi_pop_back((p), (n)) : prh_null)
#define prh_arrlax_multi_pop_back(p, n) (((p)->size >= (n)) ? prh_arrlax_unchecked_multi_pop_back((p), (n)) : prh_null)

void prh_impl_string_initialize(prh_impl_arrdyn *p, prh_int new_capacity);
void prh_impl_string_expand_capacity(prh_impl_arrdyn *p, prh_int new_capacity);
void prh_impl_string_shrink_capacity(prh_impl_arrdyn *p, prh_int new_capacity); // 缩减不能缩减至小于元素个数
prh_int prh_impl_string_expand_size(prh_impl_arrdyn *p, prh_int expand_size); // 增加元素个数时容量可能增大
prh_int prh_impl_strlax_expand_size(prh_impl_arrlax *p, prh_int expand_size); // 增加元素个数时容量可能增大

prh_inline void prh_strfix_init(prh_strfix *p, prh_int size) { (p)->s = prh_malloc(size); (p)->size = size; }
prh_inline void prh_strfit_init(prh_strfit *p, prh_int capacity) { prh_impl_string_initialize((prh_impl_arrdyn *)p, capacity); }
prh_inline void prh_string_init(prh_string *p, prh_int capacity) { prh_impl_string_initialize((prh_impl_arrdyn *)p, capacity); }
prh_inline void prh_strlax_init(prh_strlax *p, prh_int capacity) { prh_impl_string_initialize((prh_impl_arrdyn *)p, capacity); p->start = 0; }

prh_inline void prh_strfix_free(prh_strfix *p) { prh_free(p->s); prh_debug(p->s = prh_null); }
prh_inline void prh_strfit_free(prh_strfit *p) { prh_free(p->s); prh_debug(p->s = prh_null); }
prh_inline void prh_string_free(prh_string *p) { prh_free(p->s); prh_debug(p->s = prh_null); }
prh_inline void prh_strlax_free(prh_strlax *p) { prh_free(p->s); prh_debug(p->s = prh_null); }

prh_inline void prh_strfit_clear(prh_strfit *p) { p->size = 0; }
prh_inline void prh_string_clear(prh_string *p) { p->size = 0; }
prh_inline void prh_strlax_clear(prh_strlax *p) { p->size = 0; }

prh_inline void prh_string_reserve(prh_string *p, prh_int new_capacity) { prh_impl_string_expand_capacity((prh_impl_arrdyn *)p, new_capacity); }
prh_inline void prh_strlax_reserve(prh_strlax *p, prh_int new_capacity) { prh_impl_string_expand_capacity((prh_impl_arrdyn *)p, new_capacity); }
prh_inline void prh_string_shrink_to_fit(prh_string *p) { prh_impl_string_shrink_capacity((prh_impl_arrdyn *)p, p->size); }
prh_inline void prh_strlax_shrink_to_fit(prh_strlax *p) { prh_impl_string_shrink_capacity((prh_impl_arrdyn *)p, p->size + p->start); }

prh_inline prh_byte *prh_string_push_back(prh_string *p) { return p->s + prh_impl_string_expand_size((prh_impl_arrdyn *)p, 1); }
prh_inline prh_byte *prh_strlax_push_back(prh_strlax *p) { return p->s + prh_impl_strlax_expand_size((prh_impl_arrlax *)p, 1); }
prh_inline prh_byte *prh_string_multi_push_back(prh_string *p, prh_int n) { return p->s + prh_impl_string_expand_size((prh_impl_arrdyn *)p, n); }
prh_inline prh_byte *prh_strlax_multi_push_back(prh_strlax *p, prh_int n) { return p->s + prh_impl_strlax_expand_size((prh_impl_arrlax *)p, n); }

prh_byte *prh_strfit_push_back(prh_strfit *p); // 返回空表示失败
prh_byte *prh_strfit_multi_push_back(prh_strfit *p, prh_int n); // 要么失败要么添加n个元素
prh_byte *prh_strfit_multi_push_back_best_effort(prh_strfit *p, prh_int n, prh_int *out); // 要么失败要么添加out个元素

prh_inline prh_byte *prh_strfit_unchecked_push_back(prh_strfit *p) { return p->s + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)p, 1); }
prh_inline prh_byte *prh_string_unchecked_push_back(prh_string *p) { return p->s + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)p, 1); }
prh_inline prh_byte *prh_strlax_unchecked_push_back(prh_strlax *p) { return p->s + prh_impl_arrlax_unchecked_push((prh_impl_arrlax *)p, 1); }
prh_inline prh_byte *prh_strfit_unchecked_multi_push_back(prh_strfit *p, prh_int n) { return p->s + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)p, n); }
prh_inline prh_byte *prh_string_unchecked_multi_push_back(prh_string *p, prh_int n) { return p->s + prh_impl_arrdyn_unchecked_push((prh_impl_arrdyn *)p, n); }
prh_inline prh_byte *prh_strlax_unchecked_multi_push_back(prh_strlax *p, prh_int n) { return p->s + prh_impl_arrlax_unchecked_push((prh_impl_arrlax *)p, n); }

prh_inline prh_byte *prh_string_unchecked_pop_back(prh_string *p) { return p->s + prh_impl_arrdyn_shrink_size((prh_impl_arrdyn *)p, 1); } // 必须有足够的元素
prh_inline prh_byte *prh_strlax_unchecked_pop_back(prh_strlax *p) { return p->s + prh_impl_arrlax_shrink_size((prh_impl_arrlax *)p, 1); }
prh_inline prh_byte *prh_string_unchecked_multi_pop_back(prh_string *p, prh_int n) { return p->s + prh_impl_arrdyn_shrink_size((prh_impl_arrdyn *)p, n); }
prh_inline prh_byte *prh_strlax_unchecked_multi_pop_back(prh_strlax *p, prh_int n) { return p->s + prh_impl_arrlax_shrink_size((prh_impl_arrlax *)p, n); }

prh_inline prh_byte *prh_string_pop_back(prh_string *p) { return (p->size > 0) ? prh_string_unchecked_pop_back(p) : prh_null; }
prh_inline prh_byte *prh_strlax_pop_back(prh_strlax *p) { return (p->size > 0) ? prh_strlax_unchecked_pop_back(p) : prh_null; }
prh_inline prh_byte *prh_string_multi_pop_back(prh_string *p, prh_int n) { return (p->size >= n) ? prh_string_unchecked_multi_pop_back(p, n) : prh_null; }
prh_inline prh_byte *prh_strlax_multi_pop_back(prh_strlax *p, prh_int n) { return (p->size >= n) ? prh_strlax_unchecked_multi_pop_back(p, n) : prh_null; }

#define prh_arrfix_begin(p) ((p)->arrfix)
#define prh_arrfit_begin(p) ((p)->arrfit)
#define prh_arrdyn_begin(p) ((p)->arrdyn)
#define prh_arrlax_begin(p) ((p)->arrlax + (p)->start)

#define prh_arrfix_end(p) (prh_arrfix_begin(p) + (p)->size)
#define prh_arrfit_end(p) (prh_arrfit_begin(p) + (p)->size)
#define prh_arrdyn_end(p) (prh_arrdyn_begin(p) + (p)->size)
#define prh_arrlax_end(p) (prh_arrlax_begin(p) + (p)->size)

#define prh_arrfit_cap_end(p) ((p)->arrfit + (p)->capacity)
#define prh_arrdyn_cap_end(p) ((p)->arrdyn + (p)->capacity)
#define prh_arrlax_cap_end(p) ((p)->arrlax + (p)->capacity)

prh_inline prh_int prh_impl_arrfix_at(prh_impl_arrfix *p, prh_int i) {
    assert(i >= 0 && i < p->size);
    return i;
}

prh_inline prh_int prh_impl_arrdyn_at(prh_impl_arrdyn *p, prh_int i) {
    assert(i >= 0 && i < p->size);
    return i;
}

prh_inline prh_int prh_impl_arrlax_at(prh_impl_arrlax *p, prh_int i) {
    assert(i >= 0 && i < p->size);
    return p->start + i;
}

prh_inline prh_int prh_impl_arrfix_insert_at(prh_impl_arrfix *p, prh_int i) {
    assert(i >= 0 && i <= p->size);
    return i;
}

prh_inline prh_int prh_impl_arrdyn_insert_at(prh_impl_arrdyn *p, prh_int i) {
    assert(i >= 0 && i <= p->size);
    return i;
}

prh_inline prh_int prh_impl_arrlax_insert_at(prh_impl_arrlax *p, prh_int i) {
    assert(i >= 0 && i <= p->size);
    return p->start + i;
}

#define prh_arrfix_at(p, i) ((p)->arrfix + prh_impl_arrfix_at((prh_impl_arrfix *)(p), (i)))
#define prh_arrfit_at(p, i) ((p)->arrfit + prh_impl_arrdyn_at((prh_impl_arrdyn *)(p), (i)))
#define prh_arrdyn_at(p, i) ((p)->arrdyn + prh_impl_arrdyn_at((prh_impl_arrdyn *)(p), (i)))
#define prh_arrlax_at(p, i) ((p)->arrlax + prh_impl_arrlax_at((prh_impl_arrlax *)(p), (i)))

#define prh_priv_arrfix_insert_at(p, i) ((p)->arrfix + prh_impl_arrfix_insert_at((prh_impl_arrfix *)(p), (i)))
#define prh_priv_arrfit_insert_at(p, i) ((p)->arrfit + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)(p), (i)))
#define prh_priv_arrdyn_insert_at(p, i) ((p)->arrdyn + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)(p), (i)))
#define prh_priv_arrlax_insert_at(p, i) ((p)->arrlax + prh_impl_arrlax_insert_at((prh_impl_arrlax *)(p), (i)))

prh_inline prh_byte *prh_strfix_begin(prh_strfix *p) { return p->s; }
prh_inline prh_byte *prh_strfit_begin(prh_strfit *p) { return p->s; }
prh_inline prh_byte *prh_string_begin(prh_string *p) { return p->s; }
prh_inline prh_byte *prh_strlax_begin(prh_strlax *p) { return p->s + p->start; }

prh_inline prh_byte *prh_strfix_end(prh_strfix *p) { return prh_strfix_begin(p) + p->size; }
prh_inline prh_byte *prh_strfit_end(prh_strfit *p) { return prh_strfit_begin(p) + p->size; }
prh_inline prh_byte *prh_string_end(prh_string *p) { return prh_string_begin(p) + p->size; }
prh_inline prh_byte *prh_strlax_end(prh_strlax *p) { return prh_strlax_begin(p) + p->size; }

prh_inline prh_byte *prh_strfit_cap_end(prh_strfit *p) { return p->s + p->capacity; }
prh_inline prh_byte *prh_string_cap_end(prh_string *p) { return p->s + p->capacity; }
prh_inline prh_byte *prh_strlax_cap_end(prh_strlax *p) { return p->s + p->capacity; }

prh_inline prh_byte *prh_strfix_at(prh_strfix *p, prh_int i) { return p->s + prh_impl_arrfix_at((prh_impl_arrfix *)p, i); }
prh_inline prh_byte *prh_strfit_at(prh_strfit *p, prh_int i) { return p->s + prh_impl_arrdyn_at((prh_impl_arrdyn *)p, i); }
prh_inline prh_byte *prh_string_at(prh_string *p, prh_int i) { return p->s + prh_impl_arrdyn_at((prh_impl_arrdyn *)p, i); }
prh_inline prh_byte *prh_strlax_at(prh_strlax *p, prh_int i) { return p->s + prh_impl_arrlax_at((prh_impl_arrlax *)p, i); }

#define prh_arrfit_unordered_remove(p, i) *prh_arrfit_at((p), (i)) = (p)->arrfit[(--((p)->size))]
#define prh_arrdyn_unordered_remove(p, i) *prh_arrdyn_at((p), (i)) = (p)->arrdyn[(--((p)->size))]
#define prh_arrlax_unordered_remove(p, i) *prh_arrlax_at((p), (i)) = (p)->arrlax[(p)->start + (--((p)->size))]

#define prh_arrfit_remove(p, i) { /* [0,1,(2),3,4,5,6,7] size 8 => copy len = (size - 1 - 2) = 5 */                     \
    prh_impl_arrfit_eptr_type(p) prh_impl_dest = prh_arrfit_at((p), (i));                                               \
    memmove(prh_impl_dest, prh_impl_dest + 1, ((--((p)->size)) - (i)) * prh_impl_arrfit_elem_size(p)); /* 长度参数可为零 */\
}

#define prh_arrdyn_remove(p, i) { /* [0,1,(2),3,4,5,6,7] size 8 => copy len = (size - 1 - 2) = 5 */                     \
    prh_impl_arrdyn_eptr_type(p) prh_impl_dest = prh_arrdyn_at((p), (i));                                               \
    memmove(prh_impl_dest, prh_impl_dest + 1, ((--((p)->size)) - (i)) * prh_impl_arrdyn_elem_size(p)); /* 长度参数可为零 */\
}

#define prh_arrlax_remove(p, i) { /* [0,1,(2),3,4,5,6,7] size 8 => copy len = (size - 1 - 2) = 5 */                     \
    prh_impl_arrlax_eptr_type(p) prh_impl_dest = prh_arrlax_at((p), (i));                                               \
    memmove(prh_impl_dest, prh_impl_dest + 1, ((--((p)->size)) - (i)) * prh_impl_arrlax_elem_size(p)); /* 长度参数可为零 */\
}

#define prh_arrfit_multi_remove(p, i, n) {                                                                              \
    assert((n) > 0 && (i) + (n) <= (p)->size);                                                                          \
    prh_impl_arrfit_eptr_type(p) prh_impl_dest = prh_arrfit_at((p), (i));                                               \
    memmove(prh_impl_dest, prh_impl_dest + (n), ((p)->size - 1 - (i)) * prh_impl_arrfit_elem_size(p)); /* 长度参数可为零 */\
    (p)->size -= (n);                                                                                                   \
}

#define prh_arrdyn_multi_remove(p, i, n) {                                                                              \
    assert((n) > 0 && (i) + (n) <= (p)->size);                                                                          \
    prh_impl_arrdyn_eptr_type(p) prh_impl_dest = prh_arrdyn_at((p), (i));                                               \
    memmove(prh_impl_dest, prh_impl_dest + (n), ((p)->size - 1 - (i)) * prh_impl_arrdyn_elem_size(p)); /* 长度参数可为零 */\
    (p)->size -= (n);                                                                                                   \
}

#define prh_arrlax_multi_remove(p, i, n) {                                                                              \
    assert((n) > 0 && (i) + (n) <= (p)->size);                                                                          \
    prh_impl_arrlax_eptr_type(p) prh_impl_dest = prh_arrlax_at((p), (i));                                               \
    memmove(prh_impl_dest, prh_impl_dest + (n), ((p)->size - 1 - (i)) * prh_impl_arrlax_elem_size(p)); /* 长度参数可为零 */\
    (p)->size -= (n);                                                                                                   \
}

prh_inline void prh_strfit_unordered_remove(prh_strfit *p, prh_int i) { *prh_strfit_at(p, i) = p->s[--(p->size)]; }
prh_inline void prh_string_unordered_remove(prh_string *p, prh_int i) { *prh_string_at(p, i) = p->s[--(p->size)]; }
prh_inline void prh_strlax_unordered_remove(prh_strlax *p, prh_int i) { *prh_strlax_at(p, i) = p->s[p->start + (--(p->size))]; }

prh_inline void prh_strfit_remove(prh_strfit *p, prh_int i) {
    prh_byte *dest = prh_strfit_at(p, i);
    memmove(dest, dest + 1, (--(p->size)) - i); // 长度参数可为零
}

prh_inline void prh_string_remove(prh_string *p, prh_int i) {
    prh_byte *dest = prh_string_at(p, i);
    memmove(dest, dest + 1, (--(p->size)) - i); // 长度参数可为零
}

prh_inline void prh_strlax_remove(prh_strlax *p, prh_int i) {
    prh_byte *dest = prh_strlax_at(p, i);
    memmove(dest, dest + 1, (--(p->size)) - i); // 长度参数可为零
}

prh_inline void prh_strfit_multi_remove(prh_strfit *p, prh_int i, prh_int n) {
    assert(n > 0 && i + n <= p->size);
    prh_byte *dest = prh_strfit_at(p, i);
    memmove(dest, dest + n, p->size - 1 - i); // 长度参数可为零
    p->size -= n;
}

prh_inline void prh_string_multi_remove(prh_string *p, prh_int i, prh_int n) {
    assert(n > 0 && i + n <= p->size);
    prh_byte *dest = prh_string_at(p, i);
    memmove(dest, dest + n, p->size - 1 - i); // 长度参数可为零
    p->size -= n;
}

prh_inline void prh_strlax_multi_remove(prh_strlax *p, prh_int i, prh_int n) {
    assert(n > 0 && i + n <= p->size);
    prh_byte *dest = prh_strlax_at(p, i);
    memmove(dest, dest + n, p->size - 1 - i); // 长度参数可为零
    p->size -= n;
}

#define prh_arrdyn_unordered_insert(p, i, elem_ptr) (                                               \
    prh_impl_arrdyn_expand_size((prh_impl_arrdyn *)(p), 1, prh_impl_arrdyn_elem_size(p)),           \
    ((elem_ptr) = prh_priv_arrdyn_insert_at((p), (i))), ((p)->arrdyn[(p)->size - 1] = *(elem_ptr)), (elem_ptr))

#define prh_arrlax_unordered_insert(p, i, elem_ptr) (                                               \
    prh_impl_arrlax_expand_size((prh_impl_arrlax *)(p), 1, prh_impl_arrlax_elem_size(p)),           \
    ((elem_ptr) = prh_priv_arrlax_insert_at((p), (i))), ((p)->arrlax[(p)->start + (p)->size - 1] = *(elem_ptr)), (elem_ptr))

prh_inline void *prh_impl_arrdyn_insert(void *pos, prh_int len, prh_int elem_size) {
    memmove((prh_byte *)pos + elem_size, pos, (len - 1) * elem_size); // [0,1,(2),3,4,5,6,7] size 8 => copy len (origin_size - 2) = 6
    return pos;
}

prh_inline void *prh_impl_arrdyn_multi_insert(void *pos, prh_int len, prh_int insert_elems, prh_int elem_size) {
    assert(insert_elems > 0);
    memmove((prh_byte *)pos + insert_elems * elem_size, pos, (len - insert_elems) * elem_size);
    return pos;
}

#if defined(prh_cl_msc)
#define prh_arrfit_unchecked_insert(p, i) ((prh_impl_arrfit_eptr_type(p))prh_impl_arrdyn_insert(prh_priv_arrfit_insert_at((p), (i)), ((p)->size++) - (i), prh_impl_arrfit_elem_size(p)))
#define prh_arrdyn_unchecked_insert(p, i) ((prh_impl_arrdyn_eptr_type(p))prh_impl_arrdyn_insert(prh_priv_arrdyn_insert_at((p), (i)), ((p)->size++) - (i), prh_impl_arrdyn_elem_size(p)))
#define prh_arrlax_unchecked_insert(p, i) ((prh_impl_arrlax_eptr_type(p))prh_impl_arrdyn_insert(prh_priv_arrlax_insert_at((p), (i)), ((p)->size++) - (i), prh_impl_arrlax_elem_size(p)))
#define prh_arrfit_unchecked_multi_insert(p, i, n) ((prh_impl_arrfit_eptr_type(p))prh_impl_arrdyn_multi_insert(prh_priv_arrfit_insert_at((p), (i)), ((p)->size += (n)) - (i), (n), prh_impl_arrfit_elem_size(p)))
#define prh_arrdyn_unchecked_multi_insert(p, i, n) ((prh_impl_arrdyn_eptr_type(p))prh_impl_arrdyn_multi_insert(prh_priv_arrdyn_insert_at((p), (i)), ((p)->size += (n)) - (i), (n), prh_impl_arrdyn_elem_size(p)))
#define prh_arrlax_unchecked_multi_insert(p, i, n) ((prh_impl_arrlax_eptr_type(p))prh_impl_arrdyn_multi_insert(prh_priv_arrlax_insert_at((p), (i)), ((p)->size += (n)) - (i), (n), prh_impl_arrlax_elem_size(p)))
#define prh_arrdyn_insert(p, i) (prh_impl_arrdyn_expand_size((prh_impl_arrdyn *)(p), 1, prh_impl_arrdyn_elem_size(p)), prh_impl_arrdyn_eptr_type(p)prh_impl_arrdyn_insert(prh_priv_arrdyn_insert_at((p), (i)), (p)->size - (i), prh_impl_arrdyn_elem_size(p)))
#define prh_arrlax_insert(p, i) (prh_impl_arrlax_expand_size((prh_impl_arrlax *)(p), 1, prh_impl_arrlax_elem_size(p)), prh_impl_arrlax_eptr_type(p)prh_impl_arrdyn_insert(prh_priv_arrlax_insert_at((p), (i)), (p)->size - (i), prh_impl_arrlax_elem_size(p)))
#define prh_arrdyn_multi_insert(p, i, n) (prh_impl_arrdyn_expand_size((prh_impl_arrdyn *)(p), (n), prh_impl_arrdyn_elem_size(p)), prh_impl_arrdyn_eptr_type(p)prh_impl_arrdyn_multi_insert(prh_priv_arrdyn_insert_at((p), (i)), (p)->size - (i), (n), prh_impl_arrdyn_elem_size(p)))
#define prh_arrlax_multi_insert(p, i, n) (prh_impl_arrlax_expand_size((prh_impl_arrlax *)(p), (n), prh_impl_arrlax_elem_size(p)), prh_impl_arrlax_eptr_type(p)prh_impl_arrdyn_multi_insert(prh_priv_arrlax_insert_at((p), (i)), (p)->size - (i), (n), prh_impl_arrlax_elem_size(p)))
#else
#define prh_arrfit_unchecked_insert(p, i) ({prh_impl_arrfit_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_insert(prh_priv_arrfit_insert_at((p), (i)), ((p)->size++) - (i), prh_impl_arrfit_elem_size(p)); prh_impl_ptr; })
#define prh_arrdyn_unchecked_insert(p, i) ({prh_impl_arrdyn_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_insert(prh_priv_arrdyn_insert_at((p), (i)), ((p)->size++) - (i), prh_impl_arrdyn_elem_size(p)); prh_impl_ptr; })
#define prh_arrlax_unchecked_insert(p, i) ({prh_impl_arrlax_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_insert(prh_priv_arrlax_insert_at((p), (i)), ((p)->size++) - (i), prh_impl_arrlax_elem_size(p)); prh_impl_ptr; })
#define prh_arrfit_unchecked_multi_insert(p, i, n) ({prh_impl_arrfit_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_multi_insert(prh_priv_arrfit_insert_at((p), (i)), ((p)->size += (n)) - (i), (n), prh_impl_arrfit_elem_size(p)); prh_impl_ptr; })
#define prh_arrdyn_unchecked_multi_insert(p, i, n) ({prh_impl_arrdyn_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_multi_insert(prh_priv_arrdyn_insert_at((p), (i)), ((p)->size += (n)) - (i), (n), prh_impl_arrdyn_elem_size(p)); prh_impl_ptr; })
#define prh_arrlax_unchecked_multi_insert(p, i, n) ({prh_impl_arrlax_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_multi_insert(prh_priv_arrlax_insert_at((p), (i)), ((p)->size += (n)) - (i), (n), prh_impl_arrlax_elem_size(p)); prh_impl_ptr; })
#define prh_arrdyn_insert(p, i) ({                                                                  \
    prh_impl_arrdyn_expand_size((prh_impl_arrdyn *)(p), 1, prh_impl_arrdyn_elem_size(p));           \
    prh_impl_arrdyn_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_insert(prh_priv_arrdyn_insert_at((p), (i)), (p)->size - (i), prh_impl_arrdyn_elem_size(p)); prh_impl_ptr; })
#define prh_arrlax_insert(p, i) ({                                                                  \
    prh_impl_arrlax_expand_size((prh_impl_arrlax *)(p), 1, prh_impl_arrlax_elem_size(p));           \
    prh_impl_arrlax_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_insert(prh_priv_arrlax_insert_at((p), (i)), (p)->size - (i), prh_impl_arrlax_elem_size(p)); prh_impl_ptr; })
#define prh_arrdyn_multi_insert(p, i, n) ({                                                         \
    prh_impl_arrdyn_expand_size((prh_impl_arrdyn *)(p), (n), prh_impl_arrdyn_elem_size(p));         \
    prh_impl_arrdyn_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_multi_insert(prh_priv_arrdyn_insert_at((p), (i)), (p)->size - (i), (n), prh_impl_arrdyn_elem_size(p)); \
    prh_impl_ptr; })
#define prh_arrlax_multi_insert(p, i, n) ({                                                         \
    prh_impl_arrlax_expand_size((prh_impl_arrlax *)(p), (n), prh_impl_arrlax_elem_size(p));         \
    prh_impl_arrlax_eptr_type(p) prh_impl_ptr = prh_impl_arrdyn_multi_insert(prh_priv_arrlax_insert_at((p), (i)), (p)->size - (i), (n), prh_impl_arrlax_elem_size(p)); \
    prh_impl_ptr; })
#endif

prh_inline prh_byte *prh_string_unordered_insert(prh_string *p, prh_int i) {
    prh_impl_string_expand_size((prh_impl_arrdyn *)p, 1);
    prh_byte *pos = p->s + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)p, i);
    p->s[p->size - 1] = *pos;
    return pos;
}

prh_inline prh_byte *prh_strlax_unordered_insert(prh_strlax *p, prh_int i) {
    prh_impl_strlax_expand_size((prh_impl_arrlax *)p, 1);
    prh_byte *pos = p->s + prh_impl_arrlax_insert_at((prh_impl_arrlax *)p, i);
    p->s[p->start + p->size - 1] = *pos;
    return pos;
}

prh_inline prh_byte *prh_strfit_unchecked_insert(prh_strfit *p, prh_int i) {
    prh_byte *pos = p->s + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)p, i);
    memmove(pos + 1, pos, p->size - i);
    p->size += 1;
    return pos;
}

prh_inline prh_byte *prh_string_unchecked_insert(prh_string *p, prh_int i) {
    prh_byte *pos = p->s + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)p, i);
    memmove(pos + 1, pos, p->size - i);
    p->size += 1;
    return pos;
}

prh_inline prh_byte *prh_strlax_unchecked_insert(prh_strlax *p, prh_int i) {
    prh_byte *pos = p->s + prh_impl_arrlax_insert_at((prh_impl_arrlax *)p, i);
    memmove(pos + 1, pos, p->size - i);
    p->size += 1;
    return pos;
}

prh_inline prh_byte *prh_string_insert(prh_string *p, prh_int i) {
    prh_impl_string_expand_size((prh_impl_arrdyn *)p, 1);
    prh_byte *pos = p->s + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)p, i);
    memmove(pos + 1, pos, p->size - 1 - i);
    return pos;
}

prh_inline prh_byte *prh_strlax_insert(prh_strlax *p, prh_int i) {
    prh_impl_strlax_expand_size((prh_impl_arrlax *)p, 1);
    prh_byte *pos = p->s + prh_impl_arrlax_insert_at((prh_impl_arrlax *)p, i);
    memmove(pos + 1, pos, p->size - 1 - i);
    return pos;
}

prh_inline prh_byte *prh_strfit_unchecked_multi_insert(prh_strfit *p, prh_int i, prh_int n) {
    assert(n > 0);
    prh_byte *pos = p->s + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)p, i);
    memmove(pos + n, pos, p->size - i);
    p->size += n;
    return pos;
}

prh_inline prh_byte *prh_string_unchecked_multi_insert(prh_string *p, prh_int i, prh_int n) {
    assert(n > 0);
    prh_byte *pos = p->s + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)p, i);
    memmove(pos + n, pos, p->size - i);
    p->size += n;
    return pos;
}

prh_inline prh_byte *prh_strlax_unchecked_multi_insert(prh_strlax *p, prh_int i, prh_int n) {
    assert(n > 0);
    prh_byte *pos = p->s + prh_impl_arrlax_insert_at((prh_impl_arrlax *)p, i);
    memmove(pos + n, pos, p->size - i);
    p->size += n;
    return pos;
}

prh_inline prh_byte *prh_string_multi_insert(prh_string *p, prh_int i, prh_int n) {
    prh_impl_string_expand_size((prh_impl_arrdyn *)p, n);
    prh_byte *pos = p->s + prh_impl_arrdyn_insert_at((prh_impl_arrdyn *)p, i);
    memmove(pos + n, pos, p->size - n - i);
    return pos;
}

prh_inline prh_byte *prh_strlax_multi_insert(prh_strlax *p, prh_int i, prh_int n) {
    prh_impl_strlax_expand_size((prh_impl_arrlax *)p, n);
    prh_byte *pos = p->s + prh_impl_arrlax_insert_at((prh_impl_arrlax *)p, i);
    memmove(pos + n, pos, p->size - n - i);
    return pos;
}

#define prh_arrvew_init(p, addr, size) /* 不需要释放内存，只读 */ {               \
    (p)->arrvew = (addr);                                                       \
    (p)->size = (size);                                                         \
}

prh_inline void prh_strvew_init(prh_strvew *p, const prh_byte *addr, prh_int size) {
    p->s = (prh_byte *)addr; // 不需要释放内存，只读
    p->size = size;
}

void prh_strfit_slice(prh_sslice *p, const prh_strfit *s, prh_int i, prh_int j);
void prh_string_slice(prh_sslice *p, const prh_string *s, prh_int i, prh_int j);
void prh_strlax_slice(prh_sslice *p, const prh_strlax *s, prh_int i, prh_int j);

#define prh_arrfit_slice(p, a, i, j) /* [i, j) 不需要释放内存，可读可写 */ {       \
    assert((i) >= (0) && (i) < (a)->size);                                      \
    assert((j) >= (i) && (j)<= (a)->size);                                      \
    (p)->slice = prh_arrfit_begin(a) + (i);                                     \
    (p)->capacity = prh_arrfit_cap_end(a) - (p)->slice;                         \
    (p)->size = (j) - (i);                                                      \
}

#define prh_arrdyn_slice(p, a, i, j) /* [i, j) */ {                             \
    assert((i) >= (0) && (i) < (a)->size);                                      \
    assert((j) >= (i) && (j)<= (a)->size);                                      \
    (p)->slice = prh_arrdyn_begin(a) + (i);                                     \
    (p)->capacity = prh_arrdyn_cap_end(a) - (p)->slice;                         \
    (p)->size = (j) - (i);                                                      \
}

#define prh_arrlax_slice(p, a, i, j) /* [i, j) */ {                             \
    assert((i) >= (0) && (i) < (a)->size);                                      \
    assert((j) >= (i) && (j)<= (a)->size);                                      \
    (p)->slice = prh_arrlax_begin(a) + (i);                                     \
    (p)->capacity = prh_arrlax_cap_end(a) - (p)->slice;                         \
    (p)->size = (j) - (i);                                                      \
}

#ifdef PRH_ARRAY_IMPLEMENTATION
void prh_impl_arrdyn_initialize(prh_impl_arrdyn *p, prh_int new_capacity, prh_int elem_size) {
    prh_int capacity = 1;
    while (new_capacity > capacity) capacity *= 2;
    p->arrdyn = prh_malloc(capacity * elem_size);
    p->capacity = capacity;
    p->size = 0;
}

void prh_impl_string_initialize(prh_impl_arrdyn *p, prh_int new_capacity) {
    prh_int capacity = 1;
    while (new_capacity > capacity) capacity *= 2;
    p->arrdyn = prh_malloc(capacity);
    p->capacity = capacity;
    p->size = 0;
}

void prh_impl_arrdyn_expand_capacity(prh_impl_arrdyn *p, prh_int new_capacity, prh_int elem_size) {
    prh_int capacity = p->capacity;
    if (new_capacity > capacity) {
        do capacity *= 2; while (new_capacity > capacity);
        p->capacity = capacity;
        p->arrdyn = prh_realloc(p->arrdyn, capacity * elem_size);
    }
}

void prh_impl_string_expand_capacity(prh_impl_arrdyn *p, prh_int new_capacity) {
    prh_int capacity = p->capacity;
    if (new_capacity > capacity) {
        do capacity *= 2; while (new_capacity > capacity);
        p->capacity = capacity;
        p->arrdyn = prh_realloc(p->arrdyn, capacity);
    }
}

void prh_impl_arrdyn_shrink_capacity(prh_impl_arrdyn *p, prh_int new_capacity, prh_int elem_size) { // 缩减不能缩减至小于元素个数
    prh_int capacity = p->capacity;
    if (new_capacity <= capacity / 2) { // 只要新容量大于旧容量的一半就不需要缩减，因为容量总是2的幂
        do capacity /= 2; while (new_capacity <= capacity / 2);
        p->capacity = capacity;
        p->arrdyn = prh_realloc(p->arrdyn, capacity * elem_size);
    }
}

void prh_impl_string_shrink_capacity(prh_impl_arrdyn *p, prh_int new_capacity) {
    prh_int capacity = p->capacity;
    if (new_capacity <= capacity / 2) {
        do capacity /= 2; while (new_capacity <= capacity / 2);
        p->capacity = capacity;
        p->arrdyn = prh_realloc(p->arrdyn, capacity);
    }
}

prh_int prh_impl_arrdyn_expand_size(prh_impl_arrdyn *p, prh_int expand_size, prh_int elem_size) { // 增加元素个数时容量可能增大
    assert(expand_size > 0);
    prh_int size = p->size;
    prh_impl_arrdyn_expand_capacity(p, size + expand_size, elem_size);
    p->size += expand_size;
    return size;
}

prh_int prh_impl_string_expand_size(prh_impl_arrdyn *p, prh_int expand_size) {
    assert(expand_size > 0);
    prh_int size = p->size;
    prh_impl_string_expand_capacity(p, size + expand_size);
    p->size += expand_size;
    return size;
}

prh_int prh_impl_arrlax_expand_size(prh_impl_arrlax *p, prh_int expand_size, prh_int elem_size) {
    assert(expand_size > 0);
    prh_int size = p->start + p->size;
    prh_impl_arrdyn_expand_capacity((prh_impl_arrdyn *)p, size + expand_size, elem_size);
    p->size += expand_size;
    return size;
}

prh_int prh_impl_strlax_expand_size(prh_impl_arrlax *p, prh_int expand_size) {
    assert(expand_size > 0);
    prh_int size = p->start + p->size;
    prh_impl_string_expand_capacity((prh_impl_arrdyn *)p, size + expand_size);
    p->size += expand_size;
    return size;
}

prh_int prh_impl_arrdyn_shrink_size(prh_impl_arrdyn *p, prh_int shrink_size) { // 缩减元素个数时保持容量不变
    assert(shrink_size > 0 && shrink_size <= p->size);
    p->size -= shrink_size;
    return p->size;
}

prh_int prh_impl_arrlax_shrink_size(prh_impl_arrlax *p, prh_int shrink_size) {
    assert(shrink_size > 0 && shrink_size <= p->size);
    p->size -= shrink_size;
    return p->start + p->size;
}

prh_int prh_impl_arrdyn_unchecked_push(prh_impl_arrdyn *p, prh_int expand_size) {
    assert(expand_size > 0 && p->size + expand_size <= p->capacity);
    prh_int size = p->size;
    p->size += expand_size;
    return size;
}

prh_int prh_impl_arrlax_unchecked_push(prh_impl_arrlax *p, prh_int expand_size) {
    assert(expand_size > 0 && p->start + p->size + expand_size <= p->capacity);
    prh_int size = p->start + p->size;
    p->size += expand_size;
    return size;
}

void prh_strfit_slice(prh_sslice *p, const prh_strfit *s, prh_int i, prh_int j) {
    assert(i >= 0 && i < s->size); // [i, j) 不需要释放内存，可读可写
    assert(j >= i && j<= s->size);
    p->slice = prh_strfit_begin((prh_strfit *)s) + i;
    p->capacity = prh_strfit_cap_end((prh_strfit *)s) - p->slice;
    p->size = j - i;
}

void prh_string_slice(prh_sslice *p, const prh_string *s, prh_int i, prh_int j) {
    assert(i >= 0 && i < s->size); // [i, j)
    assert(j >= i && j<= s->size);
    p->slice = prh_string_begin((prh_string *)s) + i;
    p->capacity = prh_string_cap_end((prh_string *)s) - p->slice;
    p->size = j - i;
}

void prh_strlax_slice(prh_sslice *p, const prh_strlax *s, prh_int i, prh_int j) {
    assert(i >= 0 && i < s->size); // [i, j)
    assert(j >= i && j<= s->size);
    p->slice = prh_strlax_begin((prh_strlax *)s) + i;
    p->capacity = prh_strlax_cap_end((prh_strlax *)s) - p->slice;
    p->size = j - i;
}
#endif // PRH_ARRAY_IMPLEMENTAION
#endif // PRH_ARRAY_INCLUDE

#ifdef PRH_STRING_INCLUDE
#define prh_impl_strfix_data(s, a) (s->prh_macro_concat_name(a, _strfix_type))
#define prh_impl_strfit_data(s, a) (s->prh_macro_concat_name(a, _strfit_type))
#define prh_impl_strdyn_data(s, a) (s->prh_macro_concat_name(a, _string_type))
#define prh_impl_strlax_data(s, a) (s->prh_macro_concat_name(a, _strlax_type))

#define prh_impl_strfix_addr(s, a) (prh_impl_array *)&prh_impl_strfix_data(s, a)
#define prh_impl_strfit_addr(s, a) (prh_impl_array *)&prh_impl_strfit_data(s, a)
#define prh_impl_strdyn_addr(s, a) (prh_impl_array *)&prh_impl_strdyn_data(s, a)
#define prh_impl_strlax_addr(s, a) (prh_impl_array *)&prh_impl_strlax_data(s, a)

#define prh_impl_strfix_dvar(a) prh_macro_concat_name(a, _strfix_type)
#define prh_impl_strfit_dvar(a) prh_macro_concat_name(a, _strfit_type)
#define prh_impl_strdyn_dvar(a) prh_macro_concat_name(a, _string_type)
#define prh_impl_strlax_dvar(a) prh_macro_concat_name(a, _strlax_type)

#define prh_impl_strfix_avar(a) (*prh_macro_concat_name(a, _strfix_addr_type))
#define prh_impl_strfit_avar(a) (*prh_macro_concat_name(a, _strfit_addr_type))
#define prh_impl_strdyn_avar(a) (*prh_macro_concat_name(a, _string_addr_type))
#define prh_impl_strlax_avar(a) (*prh_macro_concat_name(a, _strlax_addr_type))

#define prh_impl_strfix_avar_addr(a) (prh_impl_array *)prh_impl_strfix_avar(a)
#define prh_impl_strfit_avar_addr(a) (prh_impl_array *)prh_impl_strfit_avar(a)
#define prh_impl_strdyn_avar_addr(a) (prh_impl_array *)prh_impl_strdyn_avar(a)
#define prh_impl_strlax_avar_addr(a) (prh_impl_array *)prh_impl_strlax_avar(a)

typedef struct {
    prh_int count; // count bytes of string
    prh_byte *data;
} prh_strvew; // read-only string view

prh_inline void prh_impl_string_view(prh_byte *elem_ptr, prh_strvew *view) {
    prh_assert(prh_impl_p != prh_null);
    view->count = *prh_impl_arr_len(prh_impl_p);
    view->data = prh_impl_p;
}

prh_inline void prh_impl_strlax_view(prh_byte *elem_ptr, prh_strvew *view) {
    prh_assert(prh_impl_p != prh_null);
    view->count = *prh_impl_arr_len(prh_impl_p);
    view->data = prh_impl_p + *prh_impl_arr_start(prh_impl_p);
}

#define prh_strfit_view(s, a, view) prh_impl_string_view(prh_impl_strfit_data((s), a), view)
#define prh_string_view(s, a, view) prh_impl_string_view(prh_impl_strdyn_data((s), a), view)
#define prh_strlax_view(s, a, view) prh_impl_strlax_view(prh_impl_strlax_data((s), a), view)

#define prh_strfit_v_view(a, view) prh_impl_string_view(prh_impl_strfit_dvar(a), view)
#define prh_string_v_view(a, view) prh_impl_string_view(prh_impl_strdyn_dvar(a), view)
#define prh_strlax_v_view(a, view) prh_impl_strlax_view(prh_impl_strlax_dvar(a), view)

#define prh_strfit_a_view(a, view) prh_impl_string_view(prh_impl_strfit_avar(a), view)
#define prh_string_a_view(a, view) prh_impl_string_view(prh_impl_strdyn_avar(a), view)
#define prh_strlax_a_view(a, view) prh_impl_strlax_view(prh_impl_strlax_avar(a), view)

#define prh_string_addr(s, a) &prh_impl_string_data((s), a)
#define prh_strlax_addr(s, a) &prh_impl_strlax_data((s), a)

#define prh_strfit_clear(s, a) prh_impl_array_clear(prh_impl_strfit_data((s), a))
#define prh_string_clear(s, a) prh_impl_array_clear(prh_impl_string_data((s), a))
#define prh_strlax_clear(s, a) prh_impl_array_clear(prh_impl_strlax_data((s), a))

#define prh_strfit_v_clear(a) prh_impl_array_clear(prh_impl_strfit_dvar_data(a))
#define prh_string_v_clear(a) prh_impl_array_clear(prh_impl_string_dvar_data(a))
#define prh_strlax_v_clear(a) prh_impl_array_clear(prh_impl_strlax_dvar_data(a))

#define prh_strfit_free(s, a) prh_impl_array_free(prh_impl_strfit_addr((s), a), sizeof(prh_impl_arrfit_hdr))
#define prh_string_free(s, a) prh_impl_array_free(prh_impl_string_addr((s), a), sizeof(prh_impl_arrdyn_hdr))
#define prh_strlax_free(s, a) prh_impl_array_free(prh_impl_strlax_addr((s), a), sizeof(prh_impl_arrlax_hdr))

#define prh_strfit_a_free(a) prh_impl_array_free(prh_impl_strfit_avar_addr(a), sizeof(prh_impl_arrfit_hdr))
#define prh_string_a_free(a) prh_impl_array_free(prh_impl_string_avar_addr(a), sizeof(prh_impl_arrdyn_hdr))
#define prh_strlax_a_free(a) prh_impl_array_free(prh_impl_strlax_avar_addr(a), sizeof(prh_impl_arrlax_hdr))

#define prh_strfit_init(s, a, cap) prh_impl_strfit_data((s), a) = prh_impl_arrdyn_init((cap), 1)
#define prh_string_init(s, a, cap) prh_impl_string_data((s), a) = prh_impl_arrdyn_init((cap), 1)
#define prh_strlax_init(s, a, cap) prh_impl_strlax_data((s), a) = prh_impl_arrlax_init((cap), 1)

#define prh_string_expand(s, a, num_grow_elts) prh_impl_array_expand(prh_impl_strdyn_addr((s), a), sizeof(prh_impl_arrdyn_hdr), (num_grow_elts), 1)
#define prh_strlax_expand(s, a, num_grow_elts) prh_impl_array_expand(prh_impl_strlax_addr((s), a), sizeof(prh_impl_arrlax_hdr), (num_grow_elts), 1)
#define prh_string_shrink(s, a, new_cap) prh_impl_array_shrink(prh_impl_strdyn_addr((s), a), sizeof(prh_impl_arrdyn_hdr), (new_cap), 1)
#define prh_strlax_shrink(s, a, new_cap) prh_impl_array_shrink(prh_impl_strlax_addr((s), a), sizeof(prh_impl_arrlax_hdr), (new_cap), 1)

#define prh_string_a_expand(a, num_grow_elts) prh_impl_array_expand(prh_impl_strdyn_avar_addr(a), sizeof(prh_impl_arrdyn_hdr), (num_grow_elts), 1)
#define prh_strlax_a_expand(a, num_grow_elts) prh_impl_array_expand(prh_impl_strlax_avar_addr(a), sizeof(prh_impl_arrlax_hdr), (num_grow_elts), 1)
#define prh_string_a_shrink(a, new_cap) prh_impl_array_shrink(prh_impl_strdyn_avar_addr(a), sizeof(prh_impl_arrdyn_hdr), (new_cap), 1)
#define prh_strlax_a_shrink(a, new_cap) prh_impl_array_shrink(prh_impl_strlax_avar_addr(a), sizeof(prh_impl_arrlax_hdr), (new_cap), 1)

#define prh_strfit_resize(s, a, new_len) prh_impl_arrfit_resize(prh_impl_strfit_data((s), a), (new_len))
#define prh_string_resize(s, a, new_len) prh_impl_arrdyn_resize(prh_impl_strdyn_addr((s), a), sizeof(prh_impl_arrdyn_hdr), (new_len), 1)
#define prh_strlax_resize(s, a, new_len) prh_impl_arrdyn_resize(prh_impl_strlax_addr((s), a), sizeof(prh_impl_arrlax_hdr), (new_len), 1)

#define prh_strfit_v_resize(a, new_len) prh_impl_arrfit_resize(prh_impl_strfit_dvar(a), (new_len))
#define prh_string_a_resize(a, new_len) prh_impl_arrdyn_resize(prh_impl_strdyn_avar_addr(a), sizeof(prh_impl_arrdyn_hdr), (new_len), 1)
#define prh_strlax_a_resize(a, new_len) prh_impl_arrdyn_resize(prh_impl_strlax_avar_addr(a), sizeof(prh_impl_arrlax_hdr), (new_len), 1)

prh_byte *prh_impl_strfit_push(prh_byte *elem_ptr, prh_int num_elts);
prh_byte *prh_impl_strfit_try_push(prh_byte *elem_ptr, prh_int *num_elts_ptr);
prh_byte *prh_impl_strdyn_push(prh_impl_array *array, prh_int hdr_size, prh_int num_elts);
prh_byte *prh_impl_string_unchecked_push(prh_byte *elem_ptr, prh_int num_elts);

#define prh_strfit_push(s, a, elt_value) {                                      \
    prh_byte *prh_impl_p = prh_impl_strfit_push(prh_impl_strfit_data((s), a), 1); \
    if (prh_impl_p) *prh_impl_p = (elt_value);                                  \
}
#define prh_string_push(s, a, elt_value) {                                      \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strdyn_addr((s), a), sizeof(prh_impl_arrdyn_hdr), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_push(s, a, elt_value) {                                      \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strlax_addr((s), a), sizeof(prh_impl_arrlax_hdr), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strfit_v_push(a, elt_value) {                                       \
    prh_byte *prh_impl_p = prh_impl_strfit_push(prh_impl_strfit_dvar(a), 1);    \
    if (prh_impl_p) *prh_impl_p = (elt_value);                                  \
}
#define prh_string_a_push(a, elt_value) {                                       \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strdyn_avar_addr(a), sizeof(prh_impl_arrdyn_hdr), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_a_push(a, elt_value) {                                       \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strlax_avar_addr(a), sizeof(prh_impl_arrlax_hdr), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strfit_push_many(s, a, elt_ptr, num_elts) {                         \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_strfit_push(prh_impl_strfit_data((s), a), prh_impl_n); \
    if (prh_impl_p) memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                  \
}
#define prh_string_push_many(s, a, elt_ptr, num_elts) {                         \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strdyn_addr((s), a), sizeof(prh_impl_arrdyn_hdr), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_strlax_push_many(s, a, elt_ptr, num_elts) {                         \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strlax_addr((s), a), sizeof(prh_impl_arrlax_hdr), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_strfit_v_push_many(a, elt_ptr, num_elts) {                          \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_strfit_push(prh_impl_strfit_dvar_data(a), prh_impl_n); \
    if (prh_impl_p) memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                  \
}
#define prh_string_a_push_many(a, elt_ptr, num_elts) {                          \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strdyn_avar_addr(a), sizeof(prh_impl_arrdyn_hdr), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_strlax_a_push_many(a, elt_ptr, num_elts) {                          \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_strdyn_push(prh_impl_strlax_avar_addr(a), sizeof(prh_impl_arrlax_hdr), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}

#define prh_strfit_unchecked_push(s, a, elt_value) {                            \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strfit_data((s), a), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_string_unchecked_push(s, a, elt_value) {                            \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strdyn_data((s), a), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_unchecked_push(s, a, elt_value) {                            \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strlax_data((s), a), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strfit_v_unchecked_push(a, elt_value) {                             \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strfit_dvar(a), 1);    \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_string_v_unchecked_push(a, elt_value) {                             \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strdyn_dvar(a), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_v_unchecked_push(a, elt_value) {                             \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strlax_dvar(a), 1); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strfit_unchecked_push_many(s, a, elt_ptr, num_elts) {               \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strfit_data((s), a), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_string_unchecked_push_many(s, a, elt_ptr, num_elts) {               \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strdyn_addr((s), a), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_strlax_unchecked_push_many(s, a, elt_ptr, num_elts) {               \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strlax_addr((s), a), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_strfit_v_unchecked_push_many(a, elt_ptr, num_elts) {                \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strfit_dvar(a), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_string_v_unchecked_push_many(a, elt_ptr, num_elts) {                \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strdyn_dvar(a), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}
#define prh_strlax_v_unchecked_push_many(a, elt_ptr, num_elts) {                \
    prh_int prh_impl_n = (prh_int)(num_elts);                                   \
    prh_byte *prh_impl_p = prh_impl_string_unchecked_push(prh_impl_strlax_dvar(a), prh_impl_n); \
    memcpy(prh_impl_p, (elt_ptr), prh_impl_n);                                  \
}

void prh_impl_strdyn_erase(prh_byte *elem_ptr, prh_int start, prh_int i);

#define prh_strfit_erase(s, a, i) prh_impl_strdyn_erase(prh_impl_strfit_data((s), a), 0, (i))
#define prh_string_erase(s, a, i) prh_impl_strdyn_erase(prh_impl_strdyn_data((s), a), 0, (i))
#define prh_strlax_erase(s, a, i) {                                             \
    prh_byte *elem_ptr = prh_impl_strlax_data((s), a);                          \
    prh_impl_strdyn_erase(elem_ptr, *prh_impl_arr_start(elem_ptr), (i));        \
}
#define prh_strfit_v_erase(a, i) prh_impl_strdyn_erase(prh_impl_strfit_dvar(a), 0, (i))
#define prh_string_v_erase(a, i) prh_impl_strdyn_erase(prh_impl_strdyn_dvar(a), 0, (i))
#define prh_strlax_v_erase(a, i) {                                              \
    prh_byte *elem_ptr = prh_impl_strlax_dvar(a);                               \
    prh_impl_strdyn_erase(elem_ptr, *prh_impl_arr_start(elem_ptr), (i));        \
}

prh_byte *prh_impl_strfit_insert(prh_byte *elem_ptr, prh_int i);
prh_byte *prh_impl_strfit_unchecked_insert(prh_byte *elem_ptr, prh_int i);
prh_byte *prh_impl_strdyn_insert(prh_byte *elem_ptr, prh_int start, prh_int i);

#define prh_strfit_insert(s, a, i, elt_value) {                                 \
    prh_byte *prh_impl_p = prh_impl_strfit_insert(prh_impl_strfit_data((s), a), (i)); \
    if (prh_impl_p) *prh_impl_p = (elt_value);                                  \
}
#define prh_string_insert(s, a, i, elt_value) {                                 \
    prh_impl_array_expand(prh_impl_strdyn_addr((s), a), sizeof(prh_impl_arrdyn_hdr), 1, 1); \
    prh_byte *prh_impl_p = prh_impl_strdyn_insert(prh_impl_strdyn_data((s), a), 0, (i)); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_insert(s, a, i, elt_value) {                                 \
    prh_impl_array_expand(prh_impl_strlax_addr((s), a), sizeof(prh_impl_arrlax_hdr), 1, 1); \
    prh_byte *prh_impl_p = prh_impl_strlax_data((s), a);                        \
    prh_byte *prh_impl_elt = prh_impl_strdyn_insert(prh_impl_p, *prh_impl_arr_start(prh_impl_p), (i)); \
    *prh_impl_elt = (elt_value);                                                \
}
#define prh_strfit_v_insert(a, i, elt_value) {                                  \
    prh_byte *prh_impl_p = prh_impl_strfit_insert(prh_impl_strfit_dvar(a), (i)); \
    if (prh_impl_p) *prh_impl_p = (elt_value);                                  \
}
#define prh_string_a_insert(a, i, elt_value) {                                  \
    prh_impl_array_expand(prh_impl_strdyn_avar_addr(a), sizeof(prh_impl_arrdyn_hdr), 1, 1); \
    prh_byte *prh_impl_p = prh_impl_strdyn_insert(prh_impl_strdyn_avar(a), 0, (i)); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_a_insert(a, i, elt_value) {                                  \
    prh_impl_array_expand(prh_impl_strlax_avar_addr(a), sizeof(prh_impl_arrlax_hdr), 1, 1); \
    prh_byte *prh_impl_p = prh_impl_strlax_avar(a);                             \
    prh_byte *prh_impl_elt = prh_impl_strdyn_insert(prh_impl_p, *prh_impl_arr_start(prh_impl_p), (i)); \
    *prh_impl_elt = (elt_value);                                                \
}

#define prh_strfit_unchecked_insert(s, a, i, elt_value) {                       \
    prh_byte *prh_impl_p = prh_impl_strfit_unchecked_insert(prh_impl_strfit_data((s), a), (i)); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_string_unchecked_insert(s, a, i, elt_value) {                       \
    prh_byte *prh_impl_p = prh_impl_strdyn_insert(prh_impl_strdyn_data((s), a), 0, (i)); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_unchecked_insert(s, a, i, elt_value) {                       \
    prh_byte *prh_impl_p = prh_impl_strlax_data((s), a);                        \
    prh_byte *prh_impl_elt = prh_impl_strdyn_insert(prh_impl_p, *prh_impl_arr_start(prh_impl_p), (i)); \
    *prh_impl_elt = (elt_value);                                                \
}
#define prh_strfit_v_unchecked_insert(a, i, elt_value) {                        \
    prh_byte *prh_impl_p = prh_impl_strfit_unchecked_insert(prh_impl_strfit_dvar(a), (i)); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_string_v_unchecked_insert(a, i, elt_value) {                        \
    prh_byte *prh_impl_p = prh_impl_strdyn_insert(prh_impl_strdyn_avar(a), 0, (i)); \
    *prh_impl_p = (elt_value);                                                  \
}
#define prh_strlax_v_unchecked_insert(a, i, elt_value) {                        \
    prh_byte *prh_impl_p = prh_impl_strlax_avar(a);                             \
    prh_byte *prh_impl_elt = prh_impl_strdyn_insert(prh_impl_p, *prh_impl_arr_start(prh_impl_p), (i)); \
    *prh_impl_elt = (elt_value);                                                \
}

#define prh_strfix_len(s, a) *prh_impl_arr_len(prh_impl_strfix_data((s), a))
#define prh_strfix_data(s, a) prh_impl_strfix_data((s), a)
#define prh_strfix_end(s, a) prh_impl_strfix_data((s), a) + *prh_impl_arr_len(prh_impl_strfix_data((s), a))
#define prh_strfix_get(s, a, i) prh_impl_strfix_data((s), a) + (i)
#define prh_strfix_v_len(a) *prh_impl_arr_len(prh_impl_strfix_dvar(a))
#define prh_strfix_v_data(a) prh_impl_strfix_dvar(a)
#define prh_strfix_v_end(a) prh_impl_strfix_dvar(a) + *prh_impl_arr_len(prh_impl_strfix_dvar(a))
#define prh_strfix_v_get(a, i) prh_impl_strfix_dvar(a) + (i)

#define prh_strfit_cap(s, a) *prh_impl_arr_cap(prh_impl_strfit_data((s), a))
#define prh_strfit_len(s, a) *prh_impl_arr_len(prh_impl_strfit_data((s), a))
#define prh_strfit_data(s, a) prh_impl_strfit_data((s), a)
#define prh_strfit_end(s, a) prh_impl_strfit_data((s), a) + *prh_impl_arr_len(prh_impl_strfit_data((s), a))
#define prh_strfit_get(s, a, i) prh_impl_strfit_data((s), a) + (i)
#define prh_strfit_v_cap(a) *prh_impl_arr_cap(prh_impl_strfit_dvar(a))
#define prh_strfit_v_len(a) *prh_impl_arr_len(prh_impl_strfit_dvar(a))
#define prh_strfit_v_data(a) prh_impl_strfit_dvar(a)
#define prh_strfit_v_end(a) prh_impl_strfit_dvar(a) + *prh_impl_arr_len(prh_impl_strfit_dvar(a))
#define prh_strfit_v_get(a, i) prh_impl_strfit_dvar(a) + (i)

#define prh_string_cap(s, a) *prh_impl_arr_cap(prh_impl_strdyn_data((s), a))
#define prh_string_len(s, a) *prh_impl_arr_len(prh_impl_strdyn_data((s), a))
#define prh_string_data(s, a) prh_impl_strdyn_data((s), a)
#define prh_string_end(s, a) prh_impl_strdyn_data((s), a) + *prh_impl_arr_len(prh_impl_strdyn_data((s), a))
#define prh_string_get(s, a, i) prh_impl_strdyn_data((s), a) + (i)
#define prh_string_v_cap(a) *prh_impl_arr_cap(prh_impl_strdyn_dvar(a))
#define prh_string_v_len(a) *prh_impl_arr_len(prh_impl_strdyn_dvar(a))
#define prh_string_v_data(a) prh_impl_strdyn_dvar(a)
#define prh_string_v_end(a) prh_impl_strfdyn_dvar(a) + *prh_impl_arr_len(prh_impl_strdyn_dvar(a))
#define prh_string_v_get(a, i) prh_impl_strdyn_dvar(a) + (i)

#define prh_strlax_cap(s, a) *prh_impl_arr_cap(prh_impl_strlax_data((s), a))
#define prh_strlax_len(s, a) *prh_impl_arr_len(prh_impl_strlax_data((s), a))
#define prh_strlax_data(s, a) prh_impl_strlax_data((s), a) + *prh_impl_arr_start(prh_impl_strlax_data((s), a))
#define prh_strlax_end(s, a) prh_strlax_data((s), a) + *prh_impl_arr_len(prh_impl_strlax_data((s), a))
#define prh_strlax_get(s, a, i) prh_strlax_data((s), a) + (i)
#define prh_strlax_v_cap(a) *prh_impl_arr_cap(prh_impl_strlax_dvar(a))
#define prh_strlax_v_len(a) *prh_impl_arr_len(prh_impl_strlax_dvar(a))
#define prh_strlax_v_data(a) prh_impl_strlax_dvar(a) + *prh_impl_arr_start(prh_impl_strlax_dvar(a))
#define prh_strlax_v_end(a) prh_strlax_v_data(a) + *prh_impl_arr_len(prh_impl_strlax_dvar(a))
#define prh_strlax_v_get(a, i) prh_strlax_v_data(a) + (i)

#ifdef PRH_STRING_STRIP_PREFIX
#endif // PRH_STRING_STRIP_PREFIX

#ifdef PRH_STRING_IMPLEMENTATION
prh_byte *prh_impl_strfit_push(prh_byte *elem_ptr, prh_int num_elts) {
    prh_impl_arrfit_hdr *p = (prh_impl_arrfit_hdr)elem_ptr - 1;
    prh_assert(elem_ptr != prh_null);
    prh_assert(num_elts >= 0); // num_elts 可以为零，虽然返回了有效指针但外面的拷贝会不生效
    prh_int count = p->count;
    if (count + num_elts > p->capacity) {
        return prh_null;
    }
    p->count += num_elts;
    return elem_ptr + count;
}

prh_byte *prh_impl_string_unchecked_push(prh_byte *elem_ptr, prh_int num_elts) {
    prh_int *count_ptr = prh_impl_arr_len(elem_ptr);
    prh_assert(elem_ptr != prh_null);
    prh_assert(num_elts >= 0); // num_elts 可以为零，虽然返回了有效指针但外面的拷贝会不生效
    prh_int count = *count_ptr;
    *count_ptr += num_elts;
    return elem_ptr + count;
}

prh_byte *prh_impl_strfit_try_push(prh_byte *elem_ptr, prh_int *num_elts_ptr) { // push many as possible
    prh_assert(elem_ptr != prh_null);
    prh_assert(*num_elts_ptr >= 0);
    prh_int *count_ptr = prh_impl_arr_len(elem_ptr);
    prh_int capacity = *prh_impl_arr_cap(elem_ptr);
    prh_int count = *count_ptr, num_elts = *num_elts_ptr;
    if (count + num_elts > capacity) {
        num_elts = capacity - count;
        *num_elts_ptr = num_elts;
    }
    *count_ptr += num_elts; // num_elts 可以为零，虽然返回了有效指针但外面的拷贝会不生效
    return elem_ptr + count;
}

prh_byte *prh_impl_strdyn_push(prh_impl_array *array, prh_int hdr_size, prh_int num_elts) {
    prh_impl_array_expand(array, hdr_size, num_elts, 1);
    prh_byte *elem_ptr = s->data;
    prh_int *count_ptr = prh_impl_arr_len(elem_ptr);
    prh_int count = *count_ptr;
    *count_ptr += num_elts; // num_elts 可以为零，虽然返回了有效指针但外面的拷贝会不生效
    return elem_ptr + count;
}

void prh_impl_strdyn_erase(prh_byte *elem_ptr, prh_int start, prh_int i) {
    prh_int *count_ptr = prh_impl_arr_len(elem_ptr);
    prh_assert(elem_ptr != prh_null);
    prh_assert(i >= 0 && i < *count_ptr); // 数组为空不能移除元素
    prh_int new_count = --(*count_ptr);
    prh_byte *dest = elem_ptr + start + i;
    memmove(dest, dest + 1, new_count - i); // 长度参数可为零
}

prh_byte *prh_impl_strfit_insert(prh_byte *elem_ptr, prh_int i) {
    prh_int *count_ptr = prh_impl_arr_len(elem_ptr);
    prh_assert(elem_ptr != prh_null);
    prh_assert(i >= 0 && i <= *count_ptr);
    prh_int count = *count_ptr;
    if (count >= *prh_impl_arr_cap(elem_ptr)) {
        return prh_null;
    }
    *count_ptr += 1;
    prh_byte *source = elem_ptr + i;
    memmove(source + 1, source, count - i); // 长度参数可为零
    return source;
}

prh_byte *prh_impl_strfit_unchecked_insert(prh_byte *elem_ptr, prh_int i) {
    prh_int *count_ptr = prh_impl_arr_len(elem_ptr);
    prh_assert(elem_ptr != prh_null);
    prh_assert(i >= 0 && i <= *count_ptr);
    prh_int count = (*count_ptr)++;
    prh_byte *source = elem_ptr + i;
    memmove(source + 1, source, count - i); // 长度参数可为零
    return source;
}

prh_byte *prh_impl_strdyn_insert(prh_byte *elem_ptr, prh_int start, prh_int i) {
    prh_int *count_ptr = prh_impl_arr_len(elem_ptr);
    prh_assert(elem_ptr != prh_null);
    prh_assert(i >= 0 && i <= *count_ptr);
    prh_int count = (*count_ptr)++;
    prh_byte *source = elem_ptr + start + i;
    memmove(source + 1, source, count - i); // 长度参数可为零
    return source;
}
#endif // PRH_STRING_IMPLEMENTATION
#endif // PRH_STRING_INCLUDE

#ifdef PRH_LIST_INCLUDE
typedef struct prh_snode { // node single linked
    struct prh_snode *next;
} prh_snode;

typedef bool (*prh_less_than)(prh_snode *a, prh_snode *b);
void prh_snode_priority_push(prh_snode *head, prh_snode *node, prh_less_than less); // 节点从小到大串连

typedef struct prh_data_snode {
    struct prh_data_snode *next;
    void *data; // node only contain a data pointer
} prh_data_snode;

typedef struct {
    prh_data_snode *next;
} prh_data_snode_head;

typedef struct { // zero initialized
    prh_snode *head;
    prh_snode *tail;
} prh_slist;

typedef struct prh_xnode { // node xored double linked (both = prev XOR next)
    struct prh_xnode *both;
} prh_xnode;

typedef struct prh_data_xnode {
    struct prh_data_xnode *both;
    void *data; // node only contain a data pointer
} prh_data_xnode;

typedef struct { // zero initialized
    prh_xnode *head;
    prh_xnode *tail;
} prh_xlist;

typedef struct prh_node { // node double linked
    struct prh_node *next;
    struct prh_node *prev;
} prh_node;

typedef struct prh_data_node {
    struct prh_data_node *next;
    struct prh_data_node *prev;
    void *data; // node only contain a data pointer
} prh_data_node;

typedef struct { // zero initialized
    prh_node *head;
    prh_node *tail;
} prh_list;

typedef struct prh_tnode { // node tripple linked
    struct prh_tnode *next;
    struct prh_tnode *prev;
    struct prh_tnode *parent;
} prh_tnode;

typedef struct prh_data_tnode {
    struct prh_data_tnode *next;
    struct prh_data_tnode *prev;
    struct prh_data_tnode *parent;
    void *data; // node only contain a data pointer
} prh_data_tnode;

typedef struct { // zero initialized
    prh_tnode *root;
} prh_tree;

void prh_impl_list_free_each_node(prh_snode *head, void (*node_free)(void *));
void prh_impl_list_free_each_node_and_clear(prh_slist *list, void (*node_free)(void *));

#ifdef PRH_LIST_IMPLEMENTATION
void prh_impl_list_free_each_node(prh_snode *head, void (*node_free)(void *)) {
    while (head) {
        prh_snode *curr = head;
        head = head->next; // get next before free
        node_free(curr);
    }
}

void prh_impl_list_free_each_node_and_clear(prh_slist *list, void (*node_free)(void *)) {
    if (node_free) prh_impl_list_free_each_node(list->head, node_free);
    list->head = prh_null;
}

void prh_snode_priority_push(prh_snode *head, prh_snode *node, prh_less_than less) { // 节点从小到大串连
    prh_snode *curr;
    assert(head != prh_null);
    assert(node != prh_null);
    while ((curr = head->next) && less(curr, node)) {
        head = curr;
    }
    head->next = node;
    node->next = curr;
}
#endif // PRH_LIST_IMPLEMENTATION
#endif // PRH_LIST_INCLUDE

#ifdef PRH_STACK_INCLUDE
// Just link the node into the stack, dont allocate any memory. Each node can
// have different size, but must cotain prh_snode as the header.
//  struct stack_custom_node {
//      prh_snode head; // must be 1st field
//      ... other custom node data ...
//  };
typedef struct { // zero initialize
    prh_snode *head;
} prh_nstack;

prh_inline void prh_nstack_init(prh_nstack *s) {
    s->head = prh_null;
}

prh_inline void prh_nstack_clear(prh_nstack *s, void (*node_free_func)(void *)) {
    prh_impl_list_free_each_node_and_clear((prh_slist *)s, node_free_func);
}

prh_inline prh_snode *prh_nstack_top(prh_nstack *s) {
    return s->head;
}

prh_inline bool prh_nstack_empty(prh_nstack *s) {
    return s->head == prh_null;
}

void prh_nstack_push(prh_nstack *s, prh_snode *node);
prh_snode *prh_nstack_pop(prh_nstack *s);

#ifdef PRH_STACK_STRIP_PREFIX
#define nstack_t         prh_nstack
#define nstack_init      prh_nstack_init
#define nstack_clear     prh_nstack_clear
#define nstack_empty     prh_nstack_empty
#define nstack_push      prh_nstack_push
#define nstack_pop       prh_nstack_pop
#define nstack_top       prh_nstack_top
#endif

#ifdef PRH_STACK_IMPLEMENTATION
void prh_nstack_push(prh_nstack *s, prh_snode *node) {
    node->next = s->head;
    s->head = node;
}

prh_snode *prh_nstack_pop(prh_nstack *s) {
    prh_snode *head = s->head;
    if (head == prh_null) return prh_null;
    s->head = head->next;
    return head;
}
#endif // PRH_STACK_IMPLEMENTATION
#endif // PRH_STACK_INCLUDE

#ifdef PRH_QUEUE_INCLUDE
#define prh_fixed_arrque_ptr(elem_type) struct {                                \
    prh_int fixed_arrque_head;                                                  \
    prh_int fixed_arrque_len;                                                   \
    prh_int fixed_arrque_size_minus_one;                                        \
    elem_type fixed_arrque;                                                     \
} *

prh_int prh_fixed_arrque_alloc_size(prh_int size, prh_int elem_bytes);
void prh_impl_fixed_arrque_init(void *arrque, prh_int size);
prh_int prh_impl_fixed_arrque_empty_items(void *arrque);
prh_int prh_impl_fixed_arrque_push(void *arrque);
prh_int prh_impl_fixed_arrque_push_at(void *arrque, prh_int index);
prh_int prh_impl_fixed_arrque_pop(void *arrque);

#define prh_fixed_arrque_init(p, size) prh_impl_fixed_arrque_init(&(p)->fixed_arrque_head, (size))
#define prh_fixed_arrque_elem_size(p) ((int)sizeof((p)->fixed_arrque))
#define prh_fixed_arrque_eptr_type(p) prh_typeof(&(p)->fixed_arrque))
#define prh_fixed_arrque_elem_addr(p) (&(p)->fixed_arrque)
#define prh_fixed_arrque_len(p) ((p)->fixed_arrque_len)
#define prh_fixed_arrque_cap(p) ((p)->fixed_arrque_size_minus_one + 1)
#define prh_fixed_arrque_empty_items(p) prh_impl_fixed_arrque_empty_items(&(p)->fixed_arrque_head)
#define prh_fixed_arrque_unchecked_push(p) (prh_fixed_arrque_elem_addr(p) + prh_impl_fixed_arrque_push(&(p)->fixed_arrque_head))
#define prh_fixed_arrque_unchecked_push_at(p, index) (prh_fixed_arrque_elem_addr(p) + prh_impl_fixed_arrque_push_at(&(p)->fixed_arrque_head, (index)))
#define prh_fixed_arrque_unchecked_pop(p) (prh_fixed_arrque_elem_addr(p) + prh_impl_fixed_arrque_pop(&(p)->fixed_arrque_head))
#define prh_impl_fixed_arrque_top(p) (prh_fixed_arrque_elem_addr(p) + (p)->fixed_arrque_head)

#if defined(prh_cl_msc)
#define prh_fixed_arrque_push(p) ((prh_fixed_arrque_eptr_type(p))(prh_fixed_arrque_empty_items(p) ? prh_fixed_arrque_unchecked_push(p) : prh_null))
#define prh_fixed_arrque_push_at(p, index) ((prh_fixed_arrque_eptr_type(p))(prh_fixed_arrque_empty_items(p) ? prh_fixed_arrque_unchecked_push_at((p), (index)) : prh_null))
#define prh_fixed_arrque_top(p) ((prh_fixed_arrque_eptr_type(p))(prh_fixed_arrque_len(p) ? prh_impl_fixed_arrque_top(p) : prh_null))
#define prh_fixed_arrque_pop(p) ((prh_fixed_arrque_eptr_type(p))(prh_fixed_arrque_len(p) ? prh_fixed_arrque_unchecked_pop(p) : prh_null))
#else
#define prh_fixed_arrque_push(p) ({prh_fixed_arrque_eptr_type(p) prh_impl_ptr = (prh_fixed_arrque_empty_items(p) ? prh_fixed_arrque_unchecked_push(p) : prh_null); prh_impl_ptr;})
#define prh_fixed_arrque_push_at(p) ({prh_fixed_arrque_eptr_type(p) prh_impl_ptr = (prh_fixed_arrque_empty_items(p) ? prh_fixed_arrque_unchecked_push_at((p), (index)) : prh_null); prh_impl_ptr;})
#define prh_fixed_arrque_top(p) ({prh_fixed_arrque_eptr_type(p) prh_impl_ptr = (prh_fixed_arrque_len(p) ? prh_impl_fixed_arrque_top(p) : prh_null); prh_impl_ptr;})
#define prh_fixed_arrque_pop(p) ({prh_fixed_arrque_eptr_type(p) prh_impl_ptr = (prh_fixed_arrque_len(p) ? prh_fixed_arrque_unchecked_pop(p) : prh_null); prh_impl_ptr;})
#endif

typedef struct { void *arrque; prh_int capacity; prh_int size; prh_int tail; } prh_impl_arrque; // arrque 动态分配，可以自动增长
#define prh_arrque(elem_type) struct { elem_type *arrque; prh_int capacity; prh_int size; prh_int tail; }
#define prh_impl_arrque_npos(p, pos) ((pos) & ((p)->capacity - 1)) // 队列数据容量总是 2 的幂
#define prh_impl_arrque_head_index(p) prh_impl_arrque_npos((p), (p)->tail - (p)->size)
#define prh_impl_arrque_elem_size(p) sizeof(*((p)->arrque))
#define prh_impl_arrque_eptr_type(p) prh_typeof((p)->arrque)

#define prh_arrque_init(p, capacity) { prh_impl_arrdyn_initialize((prh_impl_arrdyn *)(p), (capacity), prh_impl_arrque_elem_size(p)); (p)->tail = 0; }
#define prh_arrque_free(p) { prh_free((p)->arrque); prh_debug((p)->arrque = prh_null); }

void *prh_impl_arrque_push(prh_impl_arrque *p, prh_int elem_size);
void *prh_impl_arrque_auto_grow_push(prh_impl_arrque *p, prh_int elem_size);
void *prh_impl_arrque_top(prh_impl_arrque *p, prh_int elem_size);
void *prh_impl_arrque_pop(prh_impl_arrque *p, prh_int elem_size);

#if defined(prh_cl_msc)
#define prh_arrque_push(p) ((prh_impl_arrque_eptr_type(p))(((p)->size < (p)->capacity) ? prh_impl_arrque_push((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)) : prh_null))
#define prh_arrque_unchecked_push(p) ((prh_impl_arrque_eptr_type(p))prh_impl_arrque_push((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)))
#define prh_arrque_auto_grow_push(p) ((prh_impl_arrque_eptr_type(p))prh_impl_arrque_auto_grow_push((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)))
#define prh_arrque_top(p) ((prh_impl_arrque_eptr_type(p))((p)->size > 0 ? prh_impl_arrque_top((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)) : prh_null))
#define prh_arrque_pop(p) ((prh_impl_arrque_eptr_type(p))((p)->size > 0 ? prh_impl_arrque_pop((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)) : prh_null))
#define prh_arrque_unchecked_pop(p) ((prh_impl_arrque_eptr_type(p))prh_impl_arrque_pop((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)))
#else
#define prh_arrque_push(p) ({prh_impl_arrque_eptr_type(p) prh_impl_ptr = (((p)->size < (p)->capacity) ? prh_impl_arrque_push((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)) : prh_null); prh_impl_ptr;})
#define prh_arrque_unchecked_push(p) ({prh_impl_arrque_eptr_type(p) prh_impl_ptr = prh_impl_arrque_push((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)); prh_impl_ptr;})
#define prh_arrque_auto_grow_push(p) ({prh_impl_arrque_eptr_type(p) prh_impl_ptr = prh_impl_arrque_auto_grow_push((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)); prh_impl_ptr;})
#define prh_arrque_top(p) ({prh_impl_arrque_eptr_type(p) prh_impl_ptr = ((p)->size > 0 ? prh_impl_arrque_top((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)) : prh_null); prh_impl_ptr;})
#define prh_arrque_pop(p) ({prh_impl_arrque_eptr_type(p) prh_impl_ptr = ((p)->size > 0 ? prh_impl_arrque_pop((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)) : prh_null); prh_impl_ptr;})
#define prh_arrque_unchecked_pop(p) ({prh_impl_arrque_eptr_type(p) prh_impl_ptr = prh_impl_arrque_pop((prh_impl_arrque *)(p), prh_impl_arrque_elem_size(p)); prh_impl_ptr;})
#endif

#ifdef PRH_QUEUE_IMPLEMENTATION
typedef struct {
    prh_int head;
    prh_int len;
    prh_int size_minus_one; // size 必须是 2 的幂
} prh_impl_fixed_arrque;

prh_int prh_fixed_arrque_alloc_size(prh_int size, prh_int elem_bytes) {
    assert(size > 0 && prh_is_power_of_2(size));
    assert(elem_bytes > 0);
    return prh_round_16_byte(sizeof(prh_impl_fixed_arrque)) + prh_round_ptrsize(size * elem_bytes);
}

void prh_impl_fixed_arrque_init(void *arrque, prh_int size) {
    assert(size > 0 && prh_is_power_of_2(size));
    prh_impl_fixed_arrque *q = (prh_impl_fixed_arrque *)arrque;
    arrque->head = arrque->len = 0;
    arrque->size_minus_one = size - 1;
}

prh_int prh_impl_fixed_arrque_empty_items(void *arrque) {
    prh_impl_fixed_arrque *q = (prh_impl_fixed_arrque *)arrque;
    return q->size_minus_one + 1 - q->len;
}

prh_int prh_impl_fixed_arrque_push(void *arrque) {
    prh_impl_fixed_arrque *q = (prh_impl_fixed_arrque *)arrque;
    return (q->head + q->len++) & q->size_minus_one;
}

prh_int prh_impl_fixed_arrque_push_at(void *arrque, prh_int index) {
    prh_impl_fixed_arrque *q = (prh_impl_fixed_arrque *)arrque;
    return (q->head + q->len++ + index) & q->size_minus_one;
}

prh_int prh_impl_fixed_arrque_pop(void *arrque) {
    prh_impl_fixed_arrque *q = (prh_impl_fixed_arrque *)arrque;
    prh_int head = q->head;
    q->len -= 1;
    q->head = (head + 1) & q->size_minus_one;
    return head;
}

void *prh_impl_arrque_push(prh_impl_arrque *p, prh_int elem_size) {
    prh_int tail_offset = p->tail * elem_size;
    p->tail = prh_impl_arrque_npos(p, p->tail + 1);
    p->size += 1;
    return (prh_byte *)p->arrque + tail_offset;
}

void *prh_impl_arrque_top(prh_impl_arrque *p, prh_int elem_size) {
    prh_int head_offset = prh_impl_arrque_npos(p, p->tail - p->size) * elem_size;
    return (prh_byte *)p->arrque + head_offset;
}

void *prh_impl_arrque_pop(prh_impl_arrque *p, prh_int elem_size) {
    void *top = prh_impl_arrque_top(p, elem_size);
    p->size -= 1;
    return top;
}

void *prh_impl_arrque_auto_grow_push(prh_impl_arrque *p, prh_int elem_size) {
    prh_int capacity = p->capacity;
    prh_int middle_offset, new_capacity = (p->size += 1);
    prh_int tail_offset = p->tail * elem_size;
    if (new_capacity > capacity) {
        middle_offset = capacity * elem_size;
        p->arrque = prh_realloc(p->arrque, middle_offset * 2);
        memcpy((prh_byte *)p->arrque + middle_offset, p->arrque, tail_offset);
        tail_offset += middle_offset; // 当tail_offset恰好为0时最后一个元素恰好在数组尾部不需要拷贝，参数 tail_offset 为零 memcpy 实际也不会拷贝
        p->tail += capacity + 1;
        p->capacity *= 2;
    } else {
        p->tail = prh_impl_arrque_npos(p, p->tail + 1);
    }
    return (prh_byte *)p->arrque + tail_offset;
}
#endif // PRH_QUEUE_IMPLEMENTATION

// Just link the node into the queue, dont allocate any memory. Each node can
// have different size, but must cotain prh_snode as the header.
typedef struct { // zero initialize
    prh_snode *head;
    prh_snode *tail;
} prh_quefit;

typedef struct { // zero initialize
    prh_data_snode *head;
    prh_data_snode *tail;
} prh_data_quefit;

prh_inline void prh_quefit_init(prh_quefit *q) {
    q->head = q->tail = prh_null;
}

prh_inline bool prh_quefit_empty(prh_quefit *q) {
    return q->head == prh_null;
}

prh_inline prh_snode *prh_quefit_top(prh_quefit *q) {
    return q->head;
}

void prh_quefit_push(prh_quefit *q, prh_snode *new_node);
prh_snode *prh_quefit_pop(prh_quefit *q);
prh_quefit prh_quefit_move(prh_quefit *q);

#define prh_quefit_for_begin(quefit) {                                          \
        prh_snode *it = (quefit)->head;                                         \
        prh_snode *prh_impl_next;                                               \
        for (; it; it = prh_impl_next) {                                        \
            prh_impl_next = it->next;

#define prh_quefit_for_end()                                                    \
        }                                                                       \
    }

#define prh_data_quefit_for_begin(data_quefit) {                                \
        prh_data_snode *it = (data_quefit)->head;                               \
        prh_data_snode *prh_impl_next;                                          \
        for (; it; it = prh_impl_next) {                                        \
            prh_impl_next = it->next;

#define prh_data_quefit_for_end()                                               \
        }                                                                       \
    }

prh_inline void prh_data_quefit_init(prh_data_quefit *q) {
    prh_quefit_init((prh_quefit *)q);
}

prh_inline bool prh_data_quefit_empty(prh_data_quefit *q) {
    return prh_quefit_empty((prh_quefit *)q);
}

prh_data_snode *prh_data_quefit_top(prh_data_quefit *q) {
    return (prh_data_snode *)prh_quefit_top((prh_quefit *)q);
}

prh_data_snode *prh_data_quefit_pop(prh_data_quefit *q) {
    return (prh_data_snode *)prh_quefit_pop((prh_quefit *)q);
}

prh_inline void prh_data_quefit_push(prh_data_quefit *q, prh_data_snode *node) {
    prh_quefit_push((prh_quefit *)q, (prh_snode *)node);
}

#ifdef PRH_QUEUE_IMPLEMENTATION
prh_quefit prh_quefit_move(prh_quefit *q) {
    prh_quefit que = *q;
    prh_quefit_init(q);
    return que;
}

void prh_quefit_push(prh_quefit *q, prh_snode *new_node) {
    prh_snode *tail = q->tail;
    if (tail == prh_null) tail = (prh_snode *)q;
    q->tail = tail->next = new_node;
    new_node->next = prh_null;
}

void prh_quefit_push_front(prh_quefit *q, prh_snode *new_node) {
    prh_snode *head = q->head;
    new_node->next = head;
    q->head = new_node;
    if (q->tail == prh_null) q->tail = new_node;
}

prh_snode *prh_quefit_pop(prh_quefit *q) {
    prh_snode *top = q->head;
    if (top == prh_null) return prh_null;
    q->head = top->next;
    if (top == q->tail) {
        q->tail = prh_null;
    }
    return top;
}

prh_snode *prh_quefit_remove_after(prh_quefit *q, prh_snode *node) {
    prh_snode *next = node->next;
    node->next = next->next;
    if (next == q->tail) q->tail = node;
    return next;
}
#endif // PRH_QUEUE_IMPLEMENTATION

// 队列不负责分配实际的节点，整个节点都由使用者提供，节点可以是任意长度，其内容由使用者
// 决定没有限制。队列仅将用户提供的节点链接到队列中，节点的类型由用户自定义，只要其中包
// 含一个自身类型的 next 指针即可，这个 next 指针的名字可以自定义，且这个 next 指针可
// 以定义在任何位置，不需要像 prh_quefit 和 prh_data_quefit 一样，next 指针必须是结
// 构体头部的第一个成员。
//
// 队列也由用户自定义，但必须按顺序包含 head 和 tail 两个成员。用户自定义节点类型、队列
// 类型示例如下：
//
// struct user_node {
//      int a, b, c;
//      struct user_node *chain;
//      void *d, *e;
// };
//
// struct user_relaxed_quefit { // 零初始化
//      struct user_node *head; // 第一个成员
//      struct user_node *tail; // 第二个成员
// };
//
// struct user_relaxed_quefit q = {0};
// prh_relaxed_quefit_push(&q, user_node, chain);
#define prh_relaxed_quefit(type) struct { type *head; type *tail; }

void prh_impl_relaxed_quefit_push(void **quefit, void *node, prh_i32 next_offset);
void prh_impl_relaxed_quefit_push_front(void **quefit, void *node, prh_i32 next_offset);
void prh_impl_relaxed_quefit_push_queue(void **quefit, void **from_que, prh_i32 next_offset); // from_que is not cleared
void prh_impl_relaxed_quefit_push_queue_front(void **quefit, void **from_que, prh_i32 next_offset); // form_que is not cleared
void *prh_impl_relaxed_quefit_pop(void **quefit, prh_i32 next_offset);

#define prh_relaxed_quefit_init(relaxed_quefit_ptr) { /* zero initialization */ \
    prh_typeof(relaxed_quefit_ptr) prh_impl_que_ptr = (relaxed_quefit_ptr);     \
    relaxed_quefit_ptr->head = relaxed_quefit_ptr->tail = prh_null;             \
}

#define prh_relaxed_quefit_push(relaxed_quefit_ptr, node_type_ptr, next_field_name) { \
    prh_typeof(relaxed_quefit_ptr) prh_impl_que_ptr = (relaxed_quefit_ptr);     \
    typedef prh_typeof(*(prh_impl_que_ptr->tail)) prh_impl_node_type;           \
    assert((void **)prh_impl_que_ptr == (void **)&prh_impl_que_ptr->head);      \
    assert((void **)prh_impl_que_ptr + 1 == (void **)&prh_impl_que_ptr->tail);  \
    prh_impl_node_type *prh_impl_node_ptr = (node_type_ptr);                    \
    prh_impl_relaxed_quefit_push((void **)prh_impl_que_ptr, prh_impl_node_ptr, (prh_i32)prh_offsetof(prh_impl_node_type, next_field_name)); \
}

#define prh_relaxed_quefit_push_queue(relaxed_quefit_ptr, from_quefit_ptr, next_field_name) { \
    typedef prh_typeof(relaxed_quefit_ptr) prh_impl_quefit_ptr_type;            \
    prh_impl_quefit_ptr_type prh_impl_que_ptr = (relaxed_quefit_ptr);           \
    prh_impl_quefit_ptr_type prh_impl_from_que = (from_quefit_ptr);             \
    assert((void **)prh_impl_que_ptr == (void **)&prh_impl_que_ptr->head);      \
    assert((void **)prh_impl_que_ptr + 1 == (void **)&prh_impl_que_ptr->tail);  \
    typedef prh_typeof(*(prh_impl_que_ptr->tail)) prh_impl_node_type;           \
    prh_impl_relaxed_quefit_push_queue((void **)prh_impl_que_ptr, (void **)prh_impl_from_que, (prh_i32)prh_offsetof(prh_impl_node_type, next_field_name)); \
}

#define prh_relaxed_quefit_push_front(relaxed_quefit_ptr, node_type_ptr, next_field_name) { \
    prh_typeof(relaxed_quefit_ptr) prh_impl_que_ptr = (relaxed_quefit_ptr);     \
    typedef prh_typeof(*(prh_impl_que_ptr->head)) prh_impl_node_type;           \
    assert((void **)prh_impl_que_ptr == (void **)&prh_impl_que_ptr->head);      \
    assert((void **)prh_impl_que_ptr + 1 == (void **)&prh_impl_que_ptr->tail);  \
    prh_impl_node_type *prh_impl_node_ptr = (node_type_ptr);                    \
    prh_impl_relaxed_quefit_push_front((void **)prh_impl_que_ptr, prh_impl_node_ptr, (prh_i32)prh_offsetof(prh_impl_node_type, next_field_name)); \
}

#define prh_relaxed_quefit_push_queue_front(relaxed_quefit_ptr, from_quefit_ptr, next_field_name) { \
    typedef prh_typeof(relaxed_quefit_ptr) prh_impl_quefit_ptr_type;            \
    prh_impl_quefit_ptr_type prh_impl_que_ptr = (relaxed_quefit_ptr);           \
    prh_impl_quefit_ptr_type prh_impl_from_que = (from_quefit_ptr);             \
    assert((void **)prh_impl_que_ptr == (void **)&prh_impl_que_ptr->head);      \
    assert((void **)prh_impl_que_ptr + 1 == (void **)&prh_impl_que_ptr->tail);  \
    typedef prh_typeof(*(prh_impl_que_ptr->head)) prh_impl_node_type;           \
    prh_impl_relaxed_quefit_push_queue_front((void **)prh_impl_que_ptr, (void **)prh_impl_from_que, (prh_i32)prh_offsetof(prh_impl_node_type, next_field_name)); \
}

#define prh_relaxed_quefit_empty(relaxed_quefit_ptr) ((relaxed_quefit_ptr)->head == prh_null)
#define prh_relaxed_quefit_not_empty(relaxed_quefit_ptr) ((relaxed_quefit_ptr)->head != prh_null)

#define prh_relaxed_quefit_top(relaxed_quefit_ptr, node_out) {                  \
    node_out = (relaxed_quefit_ptr)->head;                                      \
}

#define prh_relaxed_quefit_pop(relaxed_quefit_ptr, node_out, next_field_name) { \
    prh_typeof(relaxed_quefit_ptr) prh_impl_que_ptr = (relaxed_quefit_ptr);     \
    typedef prh_typeof(*(prh_impl_que_ptr->head)) prh_impl_node_type;           \
    assert((void **)prh_impl_que_ptr == (void **)&prh_impl_que_ptr->head);      \
    assert((void **)prh_impl_que_ptr + 1 == (void **)&prh_impl_que_ptr->tail);  \
    node_out = (prh_impl_node_type *)prh_impl_relaxed_quefit_pop((void **)prh_impl_que_ptr, (prh_i32)prh_offsetof(prh_impl_node_type, next_field_name)); \
}

#if defined(PRH_QUEUE_IMPLEMENTATION)
void prh_impl_relaxed_quefit_push(void **quefit, void *node, prh_i32 next_offset) {
    prh_byte *tail = quefit[1]; // 由于next可能不是第一个成员，因此不能定义成循环列表，因为无法定义一个固定的包含next的头节点
    if (tail == prh_null) {
        quefit[0] = node;
    } else {
        *(void **)(tail + next_offset) = node;
    }
    *(void **)((prh_byte *)node + next_offset) = prh_null;
    quefit[1] = node;
}

void prh_impl_relaxed_quefit_push_queue(void **quefit, void **from_que, prh_i32 next_offset) {
    prh_byte *from_tail = from_que[1];
    if (from_tail == prh_null) return;
    prh_byte *tail = quefit[1];
    if (tail == prh_null) {
        quefit[0] = from_que[0];
    } else {
        *(void **)(tail + next_offset) = from_que[0];
    }
    quefit[1] = from_tail;
}

void prh_impl_relaxed_quefit_push_front(void **quefit, void *node, prh_i32 next_offset) {
    prh_byte *head = quefit[0];
    quefit[0] = node;
    *(void **)((prh_byte *)node + next_offset) = head;
    if (head == prh_null) {
        quefit[1] = node;
    }
}

void prh_impl_relaxed_quefit_push_queue_front(void **quefit, void **from_que, prh_i32 next_offset) {
    prh_byte *from_head = from_que[0];
    if (from_head == prh_null) return;
    prh_byte *head = quefit[0];
    quefit[0] = from_head;
    prh_byte *from_tail = from_que[1];
    *(void **)((prh_byte *)from_tail + next_offset) = head;
    if (head == prh_null) {
        quefit[1] = from_tail;
    }
}

void *prh_impl_relaxed_quefit_pop(void **quefit, prh_i32 next_offset) {
    prh_byte *head = quefit[0];
    if (head) {
        quefit[0] = *(void **)(head + next_offset);
        if (head == quefit[1]) {
            quefit[1] = prh_null;
        }
    }
    return head;
}
#endif /* PRH_QUEUE_IMPLEMENTATION */

// Dynamic allocated variable size queue. The node can contain any object and
// with any different size. If the size < sizeof(void *), the size is rounded
// up to sizeof(void *).
typedef struct { // zero initialize
    prh_snode *head;
    prh_snode *tail;
} prh_quedyn;

prh_inline void prh_quedyn_init(prh_quedyn *q) {
    prh_quefit_init((prh_quefit *)q);
}

prh_inline bool prh_quedyn_empty(prh_quedyn *q) {
    return prh_quefit_empty((prh_quefit *)q);
}

prh_inline void prh_quedyn_free_node(void *ptr_node_object) {
    if (ptr_node_object) prh_free((prh_snode *)ptr_node_object - 1);
}

void prh_quedyn_clear(prh_quedyn *q, void (*object_deinit_func)(void *));
void *prh_quedyn_push(prh_quedyn *q, int object_size); // return allocated zero initialized object address
void *prh_quedyn_top(prh_quedyn *q); // return null or object address inside the top node
void *prh_quedyn_pop(prh_quedyn *q); // pop top node but dont free it, return object address inside the node

#ifdef PRH_QUEUE_STRIP_PREFIX
#define quedyn_t         prh_quedyn
#define quedyn_init      prh_quedyn_init
#define quedyn_empty     prh_quedyn_empty
#define quedyn_free_node prh_quedyn_free_node
#define quedyn_clear     prh_quedyn_clear
#define quedyn_move      prh_quedyn_move
#define quedyn_push      prh_quedyn_push
#define quedyn_top       prh_quedyn_top
#define quedyn_pop       prh_quedyn_pop
#endif

#ifdef PRH_QUEUE_IMPLEMENTATION
void prh_quedyn_clear(prh_quedyn *q, void (*object_deinit_func)(void *)) {
    prh_snode *next = q->head;
    while (next) {
        prh_snode *curr = next;
        next = next->next; // get next before free the node
        if (object_deinit_func) {
            object_deinit_func(curr + 1);
        }
        prh_free(curr);
    }
    prh_quedyn_init(q);
}

prh_quedyn prh_quedyn_move(prh_quedyn *q) {
    prh_quedyn que = *q;
    prh_quedyn_init(q);
    return que;
}

void *prh_quedyn_push(prh_quedyn *q, int object_size) {
    if (object_size < sizeof(void *)) object_size = sizeof(void *);
    prh_snode *new_node = prh_calloc(sizeof(prh_snode) + prh_round_ptrsize(object_size));
    prh_quefit_push((prh_quefit *)q, new_node);
    return (new_node + 1);
}

void *prh_quedyn_top(prh_quedyn *q) {
    prh_snode *top = q->head;
    return (top == prh_null) ? prh_null : (top + 1);
}

void *prh_quedyn_pop(prh_quedyn *q) {
    prh_snode *top = prh_quefit_pop((prh_quefit *)q);
    return (top == prh_null) ? prh_null : (top + 1);
}
#endif // PRH_QUEUE_IMPLEMENTATION
#endif // PRH_QUEUE_INCLUDE

#ifdef PRH_ALLOC_INCLUDE
#ifdef PRH_ALLOC_IMPLEMENTATION
#if defined(prh_plat_windows)
// LPVOID VirtualAlloc(
//  [in, optional] LPVOID lpAddress,
//  [in]           SIZE_T dwSize,
//  [in]           DWORD  flAllocationType,
//  [in]           DWORD  flProtect
// );
//
// 在调用进程的虚拟地址空间中保留、提交或更改一个页面区域的状态。通过此函数分配的内存将
// 自动初始化为零。若要在另一个进程的地址空间中分配内存，请使用 VirtualAllocEx 函数。
// 如果函数成功，则返回值是已分配页面区域的基地址。如果函数失败，则返回值为 NULL。要获取
// 扩展错误信息，请调用 GetLastError。
//
// 参数 lpAddress 要分配区域的起始地址。如果正在保留内存，则指定的地址会向下舍入（rounded
// down）到分配粒度的最近倍数。如果内存已经保留且正在提交，则地址会向下舍入到下一个页面
// 边界。要确定宿主计算机上的页面大小和分配粒度，请使用 GetSystemInfo 函数。如果此参数
// 为 NULL，系统将确定在何处分配该区域。
//
// 如果此地址位于你尚未通过调用 InitializeEnclave 初始化的安全区域中，VirtualAlloc 会
// 在该地址处为安全区域分配一个零内容页面。该页面必须是先前未提交的，并且不会通过 Intel
// 软件保护扩展编程模型的 EEXTEND 指令进行测量。如果地址位于你已初始化的安全区域中，则分
// 配操作会因 ERROR_INVALID_ADDRESS 错误而失败。对于不支持动态内存管理的安全区域（即
// SGX1），这是真的。而 SGX2 安全区域将允许分配，并且在分配后，页面必须被安全区域接受。
//
// 参数 dwSize 区域的大小（以字节为单位）。如果 lpAddress 参数为 NULL，则此值会向上舍
// 入（rounded up）到下一个页面边界。否则，分配的页面包含从 lpAddress 到 lpAddress+dwSize
// 范围内的所有页面。这意味着一个跨越页面边界的 2 字节范围会导致两个页面都被包含在分配的
// 区域内。
//
// 作为一种替代动态分配的方法，进程可以直接提交整个区域，而不仅仅是保留它。这两种方法在物  *** 按需提交和直接提交两种方法在物理内存使用上相同
// 理内存使用上结果相同，因为已提交的页面直到首次被访问时才会消耗实际物理存储。动态分配的
// 优点在于，它将系统上已提交页面的总数降至最低。对于非常大的分配，预先提交整个分配可能会
// 导致系统耗尽可提交的页面，从而导致虚拟内存分配失败。
//
// 参数 AllocationType 内存分配的类型。此参数必须包含以下值之一。
//
//  MEM_COMMIT      0x00001000
//          为指定的保留内存页面分配内存（来自内存和磁盘上的分页文件）。该函数还保证，当
//          调用方稍后首次访问内存时，内容将为零。实际的物理页面只有在虚拟地址实际被访问   *** 物理页面只有在虚拟地址实际被访问时才会被分配
//          时才会被分配。
//          要同时保留和提交页面，同时指定 MEM_COMMIT 和 MEM_RESERVE。尝试通过指定
//          MEM_COMMIT 而不使用 MEM_RESERVE 和非 NULL lpAddress 来提交特定地址范围会
//          失败，除非整个范围已经保留。导致的错误代码是 ERROR_INVALID_ADDRESS。
//          尝试提交已经提交的页面不会导致函数失败。这意味着你可以提交页面，而无需先确定
//          每页的当前提交状态。
//          如果 lpAddress 指定安全区域内的地址，则 flAllocationType 必须是 MEM_COMMIT。
//  MEM_RESERVE     0x00002000
//          在不分配实际物理存储（在内存或磁盘上的分页文件中）的情况下，保留进程虚拟地址
//          空间的一个范围。
//          你可以通过后续对 VirtualAlloc 函数的调用来提交保留的页面。要同时保留和提交
//          页面，同时指定 MEM_COMMIT 和 MEM_RESERVE。
//          其他内存分配函数（如 malloc 和 LocalAlloc）无法使用保留的内存范围。
//  MEM_RESET       0x00080000
//          指示 lpAddress 和 dwSize 指定的内存范围内的数据不再感兴趣。不应将页面读取
//          或写入到分页文件中。但是，稍后还会再次使用该内存块，因此不应取消提交。此值
//          不能与其他值一起使用。
//          使用此值并不能保证使用 MEM_RESET 操作的范围将包含零。如果希望范围包含零，
//          请取消提交内存，然后重新提交。
//          当你指定 MEM_RESET 时，VirtualAlloc 函数会忽略 flProtect 的值。但是，仍
//          必须将 flProtect 设置为有效的保护值，例如 PAGE_NOACCESS。
//          如果使用 MEM_RESET 并且内存范围映射到文件，VirtualAlloc 将返回错误。只有
//          映射到分页文件的共享视图才是可接受的。
//  MEM_RESET_UNDO  0x1000000
//          MEM_RESET_UNDO 只能在之前成功应用了 MEM_RESET 的地址范围上调用。它表明调
//          用方对 lpAddress 和 dwSize 指定的内存范围内的数据感兴趣，并尝试撤销 MEM_RESET
//          的效果。如果函数成功，则表示指定地址范围内的所有数据都保持完整。如果函数失败，
//          则地址范围内的至少部分数据已被零替换。
//          此值不能与其他值一起使用。如果在之前未使用 MEM_RESET 的地址范围上调用 MEM_RESET_UNDO，
//          行为是未定义的。当指定 MEM_RESET 时，VirtualAlloc 函数会忽略 flProtect
//          的值。但是，你仍必须将 flProtect 设置为有效的保护值，例如 PAGE_NOACCESS。
//          Windows Server 2008 R2、Windows 7、Windows Server 2008、Windows Vista、
//          Windows Server 2003 和 Windows XP：直到 Windows 8 和 Windows Server 2012
//          才支持 MEM_RESET_UNDO 标志。
//  MEM_LARGE_PAGES 0x20000000
//          使用大页面支持分配内存。大小和对齐必须是大页面最小值的倍数。要获取此值，请使
//          用 GetLargePageMinimum 函数。
//          如果指定此值，则还必须指定 MEM_RESERVE 和 MEM_COMMIT。
//  MEM_PHYSICAL    0x00400000
//          保留一个可以用来映射地址窗口扩展（AWE）页面的地址范围。此值必须与 MEM_RESERVE
//          一起使用，且不能与其他值一起使用。
//  MEM_TOP_DOWN    0x00100000
//          在尽可能高的地址处分配内存。这可能比普通分配更慢，尤其是当存在许多分配时。
//  MEM_WRITE_WATCH 0x00200000
//          使系统跟踪已分配区域内被写入的页面。如果指定此值，则还必须指定 MEM_RESERVE。
//          要检索自区域分配或写入跟踪状态重置以来已写入的页面的地址，请调用 GetWriteWatch
//          函数。要重置写入跟踪状态，请调用 GetWriteWatch 或 ResetWriteWatch。写入跟
//          踪功能将一直启用，直到释放该内存区域。
//
// 参数 flProtect 要分配页面区域的内存保护。如果正在提交页面，则可以指定以下内存保护常量
// 之一。
//
//  PAGE_EXECUTE (0x10)
//      启用对已提交页面区域的执行访问权限。尝试写入已提交区域将导致访问违规。
//      注意：CreateFileMapping 函数不支持此标志。
//  PAGE_EXECUTE_READ (0x20)
//      启用对已提交页面区域的执行或只读访问权限。尝试写入已提交区域将导致访问违规。
//      注意：Windows Server 2003 和 Windows XP（SP2 之前）不支持此标志。
//  PAGE_EXECUTE_READWRITE (0x40)
//      启用对已提交页面区域的执行、只读或读写访问权限。
//      注意：Windows Server 2003 和 Windows XP（SP2 之前）不支持此标志。
//  PAGE_EXECUTE_WRITECOPY (0x80)
//      启用对文件映射对象的映射视图的执行、只读或写时复制访问权限。尝试写入已提交的写时
//      复制页面时，将为进程创建该页面的私有副本，并标记为 PAGE_EXECUTE_READWRITE。
//      注意：VirtualAlloc 和 VirtualAllocEx 函数不支持此标志。Windows Server 2003
//      和 Windows XP（SP1 之前）不支持此标志。
//  PAGE_NOACCESS (0x01)
//      禁止对已提交页面区域的所有访问。尝试读取、写入或执行已提交区域将导致访问违规。
//      注意：CreateFileMapping 函数不支持此标志。
//  PAGE_READONLY (0x02)
//      启用对已提交页面区域的只读访问权限。尝试写入已提交区域将导致访问违规。
//      如果启用了数据执行保护（DEP），尝试在已提交区域中执行代码将导致访问违规。
//  PAGE_READWRITE (0x04)
//      启用对已提交页面区域的只读或读写访问权限。
//      如果启用了数据执行保护（DEP），尝试在已提交区域中执行代码将导致访问违规。
//  PAGE_WRITECOPY (0x08)
//      启用对文件映射对象的映射视图的只读或写时复制访问权限。尝试写入已提交的写时复制页
//      面时，将为进程创建该页面的私有副本，并标记为 PAGE_READWRITE。
//      如果启用了数据执行保护（DEP），尝试在已提交区域中执行代码将导致访问违规。
//      注意：VirtualAlloc 和 VirtualAllocEx 函数不支持此标志。
//  PAGE_TARGETS_INVALID (0x40000000)
//      将页面中的所有位置设置为 CFG（控制流保护）的无效目标。与任何执行页面保护（如 PAGE_EXECUTE、
//      PAGE_EXECUTE_READ、PAGE_EXECUTE_READWRITE 和 PAGE_EXECUTE_WRITECOPY）一起
//      使用。任何对这些页面的间接调用都会导致 CFG 检查失败，进程将被终止。
//      注意：VirtualProtect 和 CreateFileMapping 函数不支持此标志。
//  PAGE_TARGETS_NO_UPDATE (0x40000000)
//      在使用 VirtualProtect 更改保护时，区域中的页面不会更新其 CFG 信息。例如，如果
//      区域中的页面是使用 PAGE_TARGETS_INVALID 分配的，则在页面保护更改时，无效信息将
//      被保留。此标志仅在保护更改为执行类型（如 PAGE_EXECUTE、PAGE_EXECUTE_READ、PAGE_EXECUTE_READWRITE
//      和 PAGE_EXECUTE_WRITECOPY）时有效。
//      注意：VirtualProtect 更改为执行保护时的默认行为是将所有位置标记为 CFG 的有效调
//      用目标。
//  PAGE_GUARD (0x100)
//      将区域中的页面设置为保护页面。尝试访问保护页面会导致系统引发 STATUS_GUARD_PAGE_VIOLATION
//      异常，并关闭保护页面状态。保护页面因此充当一次性访问报警。
//      注意：不能与 PAGE_NOACCESS 一起使用。CreateFileMapping 函数不支持此标志。
//  PAGE_NOCACHE (0x200)
//      将所有页面设置为不可缓存。应用程序除非明确需要，否则不应使用此属性。使用 interlocked
//      函数访问映射为 SEC_NOCACHE 的内存将导致 EXCEPTION_ILLEGAL_INSTRUCTION 异常。
//      注意：不能与 PAGE_GUARD、PAGE_NOACCESS 或 PAGE_WRITECOMBINE 标志一起使用。
//      只能在使用 VirtualAlloc、VirtualAllocEx 或 VirtualAllocExNuma 函数分配私有
//      内存时使用。要为共享内存启用不可缓存内存访问，请在调用 CreateFileMapping 函数
//      时指定 SEC_NOCACHE 标志。
//  PAGE_WRITECOMBINE (0x400)
//      将所有页面设置为写时合并。应用程序除非明确需要，否则不应使用此属性。使用 interlocked
//      函数访问映射为写时合并的内存可能会导致 EXCEPTION_ILLEGAL_INSTRUCTION 异常。
//      注意：不能与 PAGE_NOACCESS、PAGE_GUARD 或 PAGE_NOCACHE 标志一起使用。
//      只能在使用 VirtualAlloc、VirtualAllocEx 或 VirtualAllocExNuma 函数分配私有
//      内存时使用。要为共享内存启用写时合并内存访问，请在调用 CreateFileMapping 函数
//      时指定 SEC_WRITECOMBINE 标志。
//      注意：Windows Server 2003 和 Windows XP（SP1 之前）不支持此标志。
//
// 以下常量仅在指定具有 Intel 软件保护扩展（SGX）架构的安全区域时，才能与支持的函数一起
// 使用。
//
//  PAGE_ENCLAVE_DECOMMIT
//      表示页面将被保护，以防止在安全区域中进一步使用。注意：此标志不能与其他标志一起使
//      用，仅适用于 SGX2 安全区域。支持函数：VirtualProtect。
//  PAGE_ENCLAVE_THREAD_CONTROL
//      页面包含线程控制结构（TCS）。支持函数：LoadEnclaveData、VirtualProtect。
//  PAGE_ENCLAVE_UNVALIDATED
//      提供的页面内容将被排除在 Intel SGX 编程模型的 EEXTEND 指令的测量之外。
//      支持函数：LoadEnclaveData
//
// 如果 lpAddress 指定安全区域内的地址，则 flProtect 不能是以下值之一：
//  *   PAGE_NOACCESS       禁止访问
//  *   PAGE_GUARD          设置页面保护以启用访问时生成的硬件异常
//  *   PAGE_NOCACHE        禁用 CPU 缓存
//  *   PAGE_WRITECOMBINE   禁用 CPU 缓存并允许写入合并
//
// 当为安全区域分配动态内存时，flProtect 参数必须是 PAGE_READWRITE 或 PAGE_EXECUTE_READWRITE。
//
// 每个页面都有一个关联的页面状态。VirtualAlloc 函数可以执行以下操作：
//  *   提交一个保留页面区域
//  *   保留一个空闲页面区域
//  *   同时保留和提交一个空闲页面区域
//
// VirtualAlloc 不能保留一个已经保留的页面。它可以提交一个已经提交的页面。这意味着你可
// 以提交一个页面范围，无论它们是否已经提交，函数都不会失败。
//
// 你可以使用 VirtualAlloc 预留一个页面块，然后进行额外的 VirtualAlloc 调用来提交保留
// 块中的单个页面。这使得一个进程可以在不消耗物理存储的情况下预留其虚拟地址空间的一个范围，
// 直到需要时为止。
//
// 如果 lpAddress 参数不为 NULL，则函数使用 lpAddress 和 dwSize 参数来计算要分配的页
// 面区域。整个页面范围的当前状态必须与 flAllocationType 参数指定的分配类型兼容。否则，
// 函数将失败，且不会分配任何页面。如前所述，这种兼容性要求不排除提交一个已经提交的页面。
//
// 为了执行动态生成的代码，请使用 VirtualAlloc 分配内存，并使用 VirtualProtect 函数授
// 予 PAGE_EXECUTE 访问权限。
//
// VirtualAlloc 函数可用于在指定进程的虚拟地址空间内预留一个地址窗口扩展（AWE）内存区域。
// 然后，该区域可用于根据应用程序的需求将物理页面映射到虚拟内存中或从虚拟内存中移出。必须
// 在 AllocationType 参数中设置 MEM_PHYSICAL 和 MEM_RESERVE 值，必须不设置 MEM_COMMIT
// 值。页面保护必须设置为 PAGE_READWRITE。
//
// VirtualFree 函数可以取消提交一个已提交的页面，释放页面的存储空间，或者同时执行取消提
// 交并释放一个已提交的页面两个操作。它还可以释放一个保留的页面，使其成为一个空闲页面。
//
// 当创建一个可执行区域时，调用程序有责任通过调用 FlushInstructionCache（在适当的时候）
// 确保缓存一致性，一旦代码就位。否则，尝试从新可执行区域执行代码可能会产生不可预测的结果。
//
// BOOL FlushInstructionCache(
//   [in] HANDLE  hProcess,
//   [in] LPCVOID lpBaseAddress,
//   [in] SIZE_T  dwSize
// );
//
// 如果应用程序在内存中生成或修改代码，则应调用 FlushInstructionCache。CPU 无法检测到
// 更改，可能会执行其缓存的旧代码。如果函数成功，则返回值是非零值。如果函数失败，则返回值
// 是零。要获取扩展错误信息，请调用 GetLastError。
//
// 参数 hProcess 要刷新指令缓存的进程的句柄。参数 lpBaseAddress 指向要刷新的区域的基地
// 址的指针，此参数可以为 NULL。参数 dwSize 如果 lpBaseAddress 参数不为 NULL，则为要
// 刷新的区域的大小（以字节为单位）。
//
// BOOL VirtualProtect(
//   [in]  LPVOID lpAddress,
//   [in]  SIZE_T dwSize,
//   [in]  DWORD  flNewProtect,
//   [out] PDWORD lpflOldProtect
// );
//
// 更改调用进程虚拟地址空间中已提交页面区域的保护。若要更改任何进程的访问保护，请使用
// VirtualProtectEx 函数。如果函数成功，则返回值是非零值。如果函数失败，则返回值是零。
// 要获取扩展错误信息，请调用 GetLastError。
//
// 参数 lpAddress 要更改访问保护属性的页面区域的起始页面的地址。指定区域中的所有页面必须
// 位于调用 VirtualAlloc 或 VirtualAllocEx 函数时使用 MEM_RESERVE 分配的同一保留区域
// 内。页面不能跨越通过单独调用 VirtualAlloc 或 VirtualAllocEx（使用 MEM_RESERVE）分
// 配的相邻保留区域。
//
// 参数 dwSize 要更改访问保护属性的区域的大小（以字节为单位）。受影响的页面区域包含从
// lpAddress 参数到 (lpAddress+dwSize) 范围内的所有页面。这意味着一个跨越页面边界的
// 2 字节范围会导致两个页面的保护属性都被更改。
//
// 参数 flNewProtect 内存保护选项。此参数可以是内存保护常量之一。对于映射视图，此值必须
// 与映射视图时指定的访问保护兼容（参见 MapViewOfFile、MapViewOfFileEx 和 MapViewOfFileExNuma）。
//
// 参数 lpflOldProtect 指向一个变量的指针，该变量接收指定页面区域中第一页的先前访问保护
// 值。如果此参数为 NULL 或不指向有效的变量，则函数失败。
//
// 只能在已提交的页面上设置访问保护值。如果指定区域中任何页面的状态不是已提交，函数将失败，
// 并且不会修改指定区域中任何页面的访问保护。PAGE_GUARD 保护修饰符用于建立保护页面。保护
// 页面作为一次性访问报警。
//
// 最好避免使用 VirtualProtect 更改由 GlobalAlloc、HeapAlloc 或 LocalAlloc 分配的内
// 存块的页面保护，因为单个页面上可能存在多个内存块。堆管理器假定堆中的所有页面至少授予读
// 取和写入访问权限。
//
// 当保护一个可执行区域时，调用程序有责任通过调用 FlushInstructionCache（在适当的时候）
// 确保缓存一致性，一旦代码就位。否则，尝试从新可执行区域执行代码可能会产生不可预测的结果。
//
// BOOL VirtualFree(
//   [in] LPVOID lpAddress,
//   [in] SIZE_T dwSize,
//   [in] DWORD  dwFreeType
// );
//
// 释放、取消提交或释放并取消提交调用进程虚拟地址空间内的一个页面区域。若要释放通过 VirtualAllocEx
// 函数在另一个进程中分配的内存，请使用 VirtualFreeEx 函数。如果函数成功，则返回值是非
// 零值。如果函数失败，则返回值是 0。要获取扩展错误信息，请调用 GetLastError。
//
// 参数 lpAddress 指向要释放的页面区域的基地址的指针。如果 dwFreeType 参数是 MEM_RELEASE，
// 则此参数必须是 VirtualAlloc 函数在保留页面区域时返回的基地址。
//
// 参数 dwSize 要释放的内存区域的大小（以字节为单位）。如果 dwFreeType 参数是 MEM_RELEASE，
// 则此参数必须是 0（零）。函数将释放 VirtualAlloc 初始分配调用中保留的整个区域。如果
// dwFreeType 参数是 MEM_DECOMMIT，则函数会取消提交从 lpAddress 参数到 (lpAddress+dwSize)
// 范围内包含的所有内存页面。例如，一个跨越页面边界的 2 字节内存区域会导致两个页面都被取
// 消提交。如果 lpAddress 是 VirtualAlloc 返回的基地址且 dwSize 是 0（零），则函数会
// 取消提交 VirtualAlloc 分配的整个区域。之后，整个区域处于保留状态。
//
// 参数 dwFreeType 释放操作的类型。此参数必须是以下值之一。
//
//  MEM_DECOMMIT    0x00004000
//      取消提交指定的已提交页面区域。操作完成后，页面处于保留状态。如果你尝试取消提交一
//      个未提交的页面，函数不会失败。这意味着你可以取消提交一个页面范围，而无需先确定每
//      页的当前提交状态。
//      当 lpAddress 参数提供安全区域的基地址时，不支持 MEM_DECOMMIT 值。这适用于不支
//      持动态内存管理的安全区域（即 SGX1）。SGX2 安全区域允许在安全区域内的任何位置使
//      用 MEM_DECOMMIT。
//  MEM_RELEASE     0x00008000
//      释放指定的页面区域，或占位符（对于占位符，地址空间被释放并可用于其他分配）。操作
//      完成后，页面处于空闲状态。
//      如果指定此值，则 dwSize 必须是 0（零），且 lpAddress 必须指向 VirtualAlloc 函
//      数在保留区域时返回的基地址。如果这些条件中的任何一个未满足，则函数失败。
//      如果区域中的任何页面当前处于已提交状态，则函数首先会取消提交，然后释放它们。
//      如果你尝试释放处于不同状态的页面（有些保留，有些已提交），函数不会失败。这意味着
//      你可以释放一个页面范围，而无需先确定每页的当前提交状态。
//
// 当使用 MEM_RELEASE 时，此参数还可以指定以下值之一。
//
//  MEM_COALESCE_PLACEHOLDERS   0x00000001
//      要合并两个相邻的占位符，请指定 MEM_RELEASE | MEM_COALESCE_PLACEHOLDERS。当你
//      合并占位符时，lpAddress 和 dwSize 必须完全匹配要合并的占位符的整个范围。
//  MEM_PRESERVE_PLACEHOLDER    0x00000002
//      在调用 VirtualAlloc2 或 Virtual2AllocFromApp 将占位符替换为私有分配之后，拆分
//      占位符。要将占位符拆分为两个占位符，请指定 MEM_RELEASE | MEM_PRESERVE_PLACEHOLDER。
//
// 进程虚拟地址空间中的每个内存页面都有一个页面状态。VirtualFree 函数可以取消提交处于
// 不同状态的页面范围，有些已提交，有些未提交。这意味着你可以取消提交一个页面范围，而无需
// 先确定每页的当前提交状态。取消提交页面会释放其物理存储，无论是在内存中还是在磁盘上的分
// 页文件中。
//
// 如果页面被取消提交但未释放，其状态会变为保留。之后，你可以调用 VirtualAlloc 来提交它，
// 或者调用 VirtualFree 来释放它。尝试读取或写入保留页面会导致访问违规异常。
//
// VirtualFree 函数可以释放处于不同状态的页面范围，有些保留，有些已提交。这意味着你可以
// 释放一个页面范围，而无需先确定每页的当前提交状态。VirtualAlloc 函数最初保留的整个页
// 面范围必须同时释放。
//
// 如果页面被释放，其状态会变为空闲，可用于后续分配操作。释放或取消提交内存后，你永远不能
// 再引用该内存。该内存中可能包含的任何信息都已永远丢失。尝试读取或写入空闲页面会导致访问
// 违规异常。如果你需要保留信息，请不要取消提交或释放包含该信息的内存。
//
// VirtualFree 函数可用于地址窗口扩展（AWE）内存区域，并在释放地址空间时使区域中的任何
// 物理页面映射失效。但是，物理页面不会被删除，应用程序可以使用它们。应用程序必须显式调用
// FreeUserPhysicalPages 来释放物理页面。当进程终止时，所有资源将自动清理。
//
// Windows 10（版本 1709）及更高版本和 Windows 11：完成使用安全区域后，调用 DeleteEnclave
// 来删除安全区域。你不能通过调用 VirtualFree 或 VirtualFreeEx 函数来删除 VBS 安全区域。
// 你仍然可以通过调用 VirtualFree 或 VirtualFreeEx 来删除 SGX 安全区域。
//
// Windows 10（版本 1507）、Windows 10（版本 1511）、Windows 10（版本 1607）和 Windows 10
// （版本 1703）：完成使用安全区域后，调用 VirtualFree 或 VirtualFreeEx 函数并指定以
// 下值：
//  *   lpAddress 参数的安全区域的基地址。
//  *   dwSize 参数为 0。
//  *   dwFreeType 参数为 MEM_RELEASE。

#define PRH_VMEM_RESERVE_UNIT 0x10000 // 64KB

void *prh_virtual_reserve(prh_unt size) {
    LPVOID p = VirtualAlloc(
        /* [in, optional] LPVOID lpAddress          */ prh_null,
        /* [in]           SIZE_T dwSize             */ size,
        /* [in]           DWORD  flAllocationType   */ MEM_RESERVE,
        /* [in]           DWORD  flProtect          */ PAGE_NOACCESS);
    if (p == prh_null) prh_abort_error(GetLastError());
    return p;
}

void *prh_virtual_reserve_from(void *base_address, prh_unt size) {
    LPVOID p = VirtualAlloc(
        /* [in, optional] LPVOID lpAddress          */ base_address,
        /* [in]           SIZE_T dwSize             */ size,
        /* [in]           DWORD  flAllocationType   */ MEM_RESERVE,
        /* [in]           DWORD  flProtect          */ PAGE_NOACCESS);
    if (p == prh_null) prh_abort_error(GetLastError());
    return p;
}

void *prh_virtual_alloc(prh_unt size) {
    LPVOID p = VirtualAlloc(
        /* [in, optional] LPVOID lpAddress          */ prh_null,
        /* [in]           SIZE_T dwSize             */ size,
        /* [in]           DWORD  flAllocationType   */ MEM_RESERVE | MEM_COMMIT,
        /* [in]           DWORD  flProtect          */ PAGE_READWRITE);
    if (p == prh_null) prh_abort_error(GetLastError());
    return p;
}

void *prh_virtual_alloc_from(void *base_address, prh_unt size) {
    LPVOID p = VirtualAlloc(
        /* [in, optional] LPVOID lpAddress          */ base_address,
        /* [in]           SIZE_T dwSize             */ size,
        /* [in]           DWORD  flAllocationType   */ MEM_RESERVE | MEM_COMMIT,
        /* [in]           DWORD  flProtect          */ PAGE_READWRITE);
    if (p == prh_null) prh_abort_error(GetLastError());
    return p;
}

void prh_virtual_commit(void *page, prh_unt size) {
    LPVOID p = VirtualAlloc(
        /* [in, optional] LPVOID lpAddress          */ page,
        /* [in]           SIZE_T dwSize             */ size,
        /* [in]           DWORD  flAllocationType   */ MEM_COMMIT,
        /* [in]           DWORD  flProtect          */ PAGE_READWRITE);
    if (p == prh_null) prh_abort_error(GetLastError());
}

void prh_virtual_set_execute(void *page, prh_unt size) {
    DWORD old_protect;
    BOOL b = VirtualProtect(
      /* [in]  LPVOID lpAddress         */ page,
      /* [in]  SIZE_T dwSize            */ size,
      /* [in]  DWORD  flNewProtect      */ PAGE_EXECUTE,
      /* [out] PDWORD lpflOldProtect    */ &old_protect);
    if (b == FALSE) prh_abort_error(GetLastError());
}

void prh_virtual_set_readwrite(void *page, prh_unt size) {
    DWORD old_protect;
    BOOL b = VirtualProtect(
      /* [in]  LPVOID lpAddress         */ page,
      /* [in]  SIZE_T dwSize            */ size,
      /* [in]  DWORD  flNewProtect      */ PAGE_READWRITE,
      /* [out] PDWORD lpflOldProtect    */ &old_protect);
    if (b == FALSE) prh_abort_error(GetLastError());
}

void prh_flush_code_cache(void *page, prh_unt size) {
    BOOL b = FlushInstructionCache(
      /* [in] HANDLE  hProcess,        */ GetCurrentProcess(),
      /* [in] LPCVOID lpBaseAddress,   */ page,
      /* [in] SIZE_T  dwSize           */ size);
    if (b == FALSE) prh_abort_error(GetLastError());
}

void prh_virtual_free(void *base_address) {
    BOOL b = VirtualFree(
      /* [in] LPVOID lpAddress      */ base_address,
      /* [in] SIZE_T dwSize         */ 0,
      /* [in] DWORD  dwFreeType     */ MEM_RELEASE);
    if (b == FALSE) prh_abort_error(GetLastError());
}

void prh_virtual_decommit(void *page, prh_unt size) {
    BOOL b = VirtualFree(
      /* [in] LPVOID lpAddress      */ page,
      /* [in] SIZE_T dwSize         */ size,
      /* [in] DWORD  dwFreeType     */ MEM_DECOMMIT);
    if (b == FALSE) prh_abort_error(GetLastError());
}

#else // POSIX BEGIN
// 现代处理器架构一般允许CPU至少在两种不同状态下运行，即用户态和内核态，内核态有时也称
// 之为监管态（supervisor mode）。执行硬件指令可使CPU在两种状态间来回切换。与之对应，
// 可将虚拟内存区域划分或标记为用户空间部分和内核空间部分。在用户态下运行时，CPU只能访
// 问被标记为用户空间的内存，试图访问属于内核空间的内存会引发硬件异常。当运行在内核态
// 时，CPU 既能访问用户空间内存，也能访问内核空间内存。仅当处理器在内核态运行时，才能
// 执行某些特定操作，这些操作包括：执行宕机（halt）指令关闭系统，访问内存管理硬件，以
// 及设备 IO 的初始化等。
//
// 从内核角度看，进程由用户内存空间和一系列内核数据结构组成，其中用户内存空间包含了程序
// 代码以及代码所使用的变量，而内核数据结构则用于维护进程状态信息。记录在内核数据结构种
// 的信息包括许多与进程相关的标识号（IDs）、虚拟内存表、打开的文件描述表、信号传递及处
// 理的有关信息、进程资源使用及限制、当前工作目录、以及大量其他信息。
//
// 进程内存布局。每个进程分配的内存由多部分组成，通常称之为段（segment）。size(1) 命
// 令可显式二进制可执行文件的文本段、初始化数据段、非初始化数据段的段大小。
//  1.  文本段包含了进程运行的程序机器指令，文本段具有只读属性，以防止进程通过错误指针
//      意外修改自身指令。因为多个进程可同时运行同一程序，所以文本段可设为共享，这样一
//      份程序代码的拷贝可以映射到所有这些进程的虚拟地址空间中。
//  2.  初始化数据段包含显式初始化的全局变量和静态变量，当程序加载到内存时，从可执行文
//      件中读取这些变量的值。
//  3.  未初始化数据段包含了未进行初始化的全局变量和静态变量。程序启动之前，系统将本段
//      内所有内存初始化为 0。处于历史原因，此段常被称为 BSS 段，这源于老版本的汇编语
//      言助记符（block started by symbol）。将初始化和未初始化的数据分开存放，其主
//      要原因在于程序在存储时，没必要为未初始化的数据分配存储空间。相反，可执行文件只
//      需记录未初始化数据段的位置及所需大小，直到运行时再由程序加载器分配这一空间。
//  4.  栈（stack）是一个动态增长和收缩的段，由栈帧（stack frames）组成。系统会为每个
//      当前调用的函数分配一个栈帧。栈帧给存储了函数的局部变量（所谓自动变量）、实参和
//      返回值。
//  5.  堆（heap）是可在运行时动态进行内存分配的一块区域。堆顶称为 program break。
//
// 进程是一个可执行程序的实例，同一个程序可以创建多个进程，程序是包含了一系列信息的文
// 件，这些信息描述了如何在运行时创建一个进程：
//  1.  二进制文件格式描述，每个程序文件都包含用于描述可执行文件格式的元信息，内核利用
//      此信息来解释文件中的其他信息。历史上，UNIX 可执行文件曾有两种广泛使用的格式，
//      分别为最初的 a.out（汇编程序输出）和更加复杂的通用对象文件格式（COFF）。现在，
//      大多数 UNIX 实现（包括 LINUX）采用可执行链接格式（ELF），这一文件格式比老版本
//      格式具有更多优点。
//  2.  机器语言指令，对程序算法进行编码。
//  3.  程序入口地址，标识程序开始执行时的起始指令位置。
//  4.  数据，程序文件包含的变量初始值和程序使用的常量值。
//  5.  符号表及重定位表，描述程序中函数和变量的位置及名称，这些表格有多种用途，其中包
//      括调式和运行时的符号解析（动态链接）。
//  6.  共享库和动态链接信息，程序文件所包含的一些字段，列出了程序运行时需要使用的共享
//      库，以及加载共享库的动态链接器的路径名。
//  7.  其他信息，程序文件还包含许多其他信息，用以描述如何创建进程。
//
// 每个进程都有一个进程号（PID），进程号是一个正整数，用以唯一标识系统中的某个进程。系
// 统调用 getpid() 返回调用进程的进程号。除了少数系统调用外，比如 init 进程（进程号为
// 1），程序与运行该程序进程的进程号之间没有固定关系。Linux 内核限制进程号小于等于
// 32767，新进程创建时，内核会按顺序将下一个可用进程号分配给其使用。每当进程号达到
// 32767 的限制时，内核将重置进程号计数器，以便从小整数开始分配。在 Linux 2.6 以后，
// 进程号的默认上限仍是 32767（PID_MAX），但可以通过 Linux 系统特有的配置文件进行调
// 整（/proc/sys/kernel/pid_max）。
//
// 每个进程都有一个创建自己的父进程，使用系统调用 getppid() 可以获取父进程进程号。实际
// 上，每个进程的父进程号属性反映了系统上所有进程间的树状关系。每个进程的父进程又有自己
// 的父进程，以此类推，回溯到1号进程（init）。使用 pstree(1) 可以查看这一进程家族树。
// 如果子进程的父进程终止，则子进程就会变成孤儿，init 进程随即将收养该进程，子进程后续
// 对 getppid() 的调用将返回进程号1。
//
// #include <unistd.h>
// pid_t getpid(void);
// pid_t getppid(void);
//
// Linux/x86-32 典型的进程内存结构如下，左侧虚拟地址会因内核配置和程序链接选项差异而有
// 所不同。另外，线程栈的位置可能会与共享库和共享内存区域混杂在一起，这却决于创建线程、
// 加载共享库、以及映射共享内存的具体顺序。而且，对于不同的 Linux 发行版，线程栈地址也
// 会有所不同。
//
//  0x0000_0000 [XXXXXXXXXXXXXXXXX] 保留区
//  0x0804_8000 [ text segment    ] 代码段
//    |         [                 ] etext
//    |         [ data segment    ] 数据段
//    |         [                 ] edata
//    |         [ bss segment     ] 未初始化数据段
//    |         [                 ] end
//   (1G)       ------------------- start_brk
//    |         [ heap            ] 堆
//    |         [                 ] heap top
//    |         ------------------- brk (program break)
//    v         [XXXXXXXXXXXXXXXXX] |
//    v         [XXXXXXXXXXXXXXXXX] v
//  0x4000_0000 ------------------- TASK_UNMAPPED_BASE（旧）阻止了堆的扩展（task_size/3）
//    ^         [ shared libs     ] 共享函数库（同一个物理内存区域可以映射到不同
//    ^         [ shared memory   ] 共享内存  （进程中的不同虚拟地址来实现共享）
//    |         [ memory map      ] 内存映射
//    |         [ thread 1 stack  ] 线程栈         ^
//    |         [ thread n stack  ] 线程栈         ^
//    |         ------------------- mmap_base（新）| 内存映射向低地址方向增长
//    |         [ stack_guard_gap ] 1MB
//    |         [XXXXXXXXXXXXXXXXX] RLIMIT_STACK（8MB）
//   (2G)       [XXXXXXXXXXXXXXXXX] ^
//    |         [XXXXXXXXXXXXXXXXX] |
//    |         [                 ] stack top
//    |         [ main stack      ] 主线程栈
//    |         [ environ         ] 环境变量参数
//    |         [ argv            ] 命令行参数
//    |         ------------------- task_size 3G 进程虚拟内存空间和内核空间的分界
//  0xC000_0000 [ Kernel          ] 内核
//  0xFFFF_FFFF [XXXXXXXXXXXXXXXXX] 1G
//
// 命令函数参数和环境变量数组，都驻留在进程栈中的一个单一连续的内存区域。此区域可存储
// 的字节数有上限要求，SUSv3 规定使用 ARG_MAX 常量或调用 sysconf(_SC_ARG_MAX) 确定
// 该上限值，并且 SUSv3 还要求 ARG_MAX 的下限为 _POSIX_ARG_MAX（4096）个字节，大多
// 数 UNIX 实现的限制都远高于此。但 SUSv3 并未规定对 ARG_MAX 限制的实现中是否要将一
// 些开销字节计算在内，比如终止空字符、字节对齐、argv 和 environ 指针数组。Linux 中
// 的 ARG_MAX 曾一度固定为 32 个页面，且包含了开销字节。自内核 2.6.23 开始，可以通过
// 资源限制 RLIMIT_STACK 来控制 argv 和 environ 参数所使用空间总量的上限，在这种情况
// 下，运行 argv 和 environ 参数使用的空间上限要比以前大出许多，具体限额为软限制
// RLIMIT_STACK 的四分之一。RLIMIT_STACK 在调用 execve() 时已经生效，参考 execve(2)
// 手册页。另外，库函数 getopt() 可用来解析命令行选项。
//
// 在x86-32架构上，共享内存段被附加在向上增长的堆和向下增长的栈之间未被分配的空间中。
// 为给堆和栈的增长腾出空间，附加共享内存的虚拟地址从 0x4000_0000 开始。内存映射和共
// 享库被放置在这个区域中。共享内存映射和内存段默认被放置的位置可能会有些不同，这依赖
// 于内核版本和进程的 RLIMIT_STACK 资源限制的设置。地址 0x4000_0000 被定义为内核常
// 量 TASK_UNMAPPED_BASE，通过将这个常量定义成一个不同的值并且重建内核而改变这个地址
// 的值。然而，如果在调用 shmat() 或 mmap() 时采用了非推荐方法，即显式地指定一个地
// 址，那么一个共享内存段或内存映射，可以被放置在低于 TASK_UNMAPPED_BASE 的地址处。
// 通过 Linux 特有的 /proc/PID/maps 文件能够看到一个程序映射的共享内存和共享库的位
// 置。从内核 2.6.14 开始，Linux 还提供了 /proc/PID/smaps 文件，它给出了一个进程中
// 各个映射的内存消耗方面的更多信息，请参考 proc(5) 手册。由于动态链接器总是一开始就
// 被加载，因此可以比较动态链接器被加载地址与其他库的被加载地址，可以看出当前进行使用
// 的旧式布局（像堆一样向高地址分配）还是新式布局（像栈一样向低地址分配）。
//
// 新旧布局可以查看 /proc/sys/vm/legacy_va_layout 文件，0 表示新局部，1 表示旧布局。
// 如果是旧布局，内存映射区起始地址 mmap_legacy_base 被设置为 __TASK_UNMAPPED_BASE，
// 其值是 task_size 的三分之一。在新布局中，栈的空间大小会被限制，进程栈（主线程栈）最
// 大空间大小由 RLIMIT_STACK 控制。由于栈变得有界了，内存映射区可以在进程栈结束的地方
// 立即开始，为确保与映射区不冲突，栈的结尾还设置了 1MB 的安全间隙 stack_guard_gap。
//
// 对于 64 位系统，x64（AMD64）的虚拟内存布局为：
//
//  0x00000000_0000_0000 [XXXXXXXXXXXXXXXXXXXXXXXXX] 保留区
//  0x00000000_0040_0000 [ + random offset         ] 随机偏移
//    |                  [ text segment            ] 代码段
//    |                  [                         ] etext
//    |                  [ + random offset         ]
//    |                  [ data segment            ] 数据段
//    |                  [                         ] edata
//    |                  [ + random offset         ]
//    |                  [ bss segment             ] 未初始化数据段
//    |                  [                         ] end
//    |                  [ + random offset         ]
//  (~42T)               --------------------------- start_brk
//    |                  [ heap                    ] 堆
//    |                  [                         ] heap top
//    |                  --------------------------- brk (program break)
//    v                  [XXXXXXXXXXXXXXXXXXXXXXXXX] |
//    v                  [XXXXXXXXXXXXXXXXXXXXXXXXX] v
//  0x00002AXX_XXXX_X000 --------------------------- TASK_UNMAPPED_BASE（旧）阻止了堆的扩展 PAGE_ALIGN(task_size/3 + random)
//    ^                  [ + random offset         ] 随机偏移
//    ^                  [ shared libs             ] 共享函数库（同一个物理内存区域可以映射到不同
//    |                  [ shared memory           ] 共享内存  （进程中的不同虚拟地址来实现共享）
//    |                  [ memory map              ] 内存映射
//    |                  [ thread 1 stack          ] 线程栈
//    |                  [ thread n stack          ] 线程栈         ^
//    |                  [ + random offset         ] 随机偏移       ^
//    |                  --------------------------- mmap_base（新）| 内存映射向低地址方向增长 (task_size-gap + random)
//    |                  [ stack_guard_gap         ] 1MB
//    |                  [XXXXXXXXXXXXXXXXXXXXXXXXX] RLIMIT_STACK（8MB）
//  (~84T)               [XXXXXXXXXXXXXXXXXXXXXXXXX] ^
//    |                  [XXXXXXXXXXXXXXXXXXXXXXXXX] |
//    |                  [                         ] stack top
//    |                  [ main stack              ] 主线程栈
//    |                  [ environ                 ] 环境变量参数
//    |                  [ argv                    ] 命令行参数
//    |                  --------------------------- stack bottom
//    |                  [ + random offset         ] 随机偏移
//  0x00007FFF_FFFF_F000 --------------------------- task_size
//  0x00007FFF_FFFF_FFFF --------------------------- 128T
//                       [ canonical address space ] 规范地址空间
//  0xFFFF8000_0000_0000 [ Kernel                  ] 内核
//  0xFFFFFFFF_FFFF_FFFF [XXXXXXXXXXXXXXXXXXXXXXXXX] 128T
//
// 在 64 位架构中，规范地址（Canonical Address）是指符合特定格式的虚拟地址。由于硬件
// 限制，当前的 64 位系统并未完全使用 64 位地址空间，而是通过“规范地址”来有效利用地址
// 空间。在 x86-64 架构中，虚拟地址的高 16 位必须与前一位的值相同，即进行符号扩展。这
// 样将地址空间分为大小都为 128T 的两个有效部分，分别用于用户空间和内核空间：
//      低规范地址 0x00000000_0000_0000 到 0x00007FFF_FFFF_FFFF，通常用于用户空间
//      高规范地址 0xFFFF8000_0000_0000 到 0xFFFFFFFF_FFFF_FFFF，通常用于内核空间
//
// 另外，配置文件 /proc/sys/kernel/randomize_va_space (Linux 2.6.12) 设置了随机段
// 偏移。选择系统的地址空间布局随机化（ASLR）策略（在支持 ASLR 的架构上）。这个文件支
// 持三种值：
//      0   关闭 ASLR。这是不支持 ASLR 的架构的默认值，以及当内核使用 norandmaps 参
//          数启动时的默认值。
//      1   使 mmap(2) 分配的地址、栈和 VDSO 页面的地址随机化。这还意味着共享库将在
//          随机地址加载。PIE（位置无关可执行文件）链接的二进制文件的文本段也将加载到
//          随机地址。如果内核配置了 CONFIG_COMPAT_BRK，这个值是默认值。
//      2   （Linux 2.6.25）还支持堆随机化。如果内核没有配置 CONFIG_COMPAT_BRK，这
//          个值是默认值。
//
// https://manybutfinite.com/post/anatomy-of-a-program-in-memory/
// https://manybutfinite.com/post/how-the-kernel-manages-your-memory/
// https://manybutfinite.com/post/the-thing-king/
// https://manybutfinite.com/post/page-cache-the-affair-between-memory-and-files/
// https://manybutfinite.com/post/memory-translation-and-segmentation/
// https://manybutfinite.com/post/kernel-boot-process/
//
// 内存管理是操作系统的核心；它对编程和系统管理都至关重要。虽然概念是通用的，但示例的主
// 要是 32 位 x86 架构上的 Linux 和 Windows。这篇文章首先描述程序在内存中的布局方式。
// 在多任务操作系统中，每个进程都在自己的内存沙盒中运行。这个沙盒就是虚拟地址空间，在32
// 位模式下，它始终是一个 4GB 的内存地址块。这些虚拟地址通过页表映射到物理内存，页表由
// 操作系统内核维护，并由处理器查询。每个进程都有自己的页表集合，但有一个问题。一旦启用
// 了虚拟地址，它们就适用于机器上运行的所有软件，包括内核本身。因此，必须为内核保留虚拟
// 地址空间的一部分。
//
// 内核/用户内存划分。这并不意味着内核使用了那么多物理内存，只是它有这部分地址空间可用
// 于映射任何它想要的物理内存。在页表中标记内核空间仅对特权代码（ring 2 或更低）开放，
// 因此如果用户模式程序尝试访问它，就会触发页面错误。在 Linux 中，内核空间始终存在，并
// 在所有进程中映射相同的物理内存。内核代码和数据始终可寻址，随时准备处理中断或系统调
// 用。相比之下，用户模式部分的地址空间映射会在进程切换时发生变化。
//
// 进程切换对虚拟内存的影响。蓝色区域表示映射到物理内存的虚拟地址，而白色区域则未映射。
// 地址空间中的不同带状区域对应于内存段，如堆、栈等。记住，这些段仅仅是内存地址的范围，
// 与 Intel 风格的段无关。Linux 进程中灵活的进程地址空间布局。当计算还处于快乐、安全
// 和温馨的状态时，Linux 进程标准内存段布局显示的段的起始虚拟地址对于机器中的几乎所有
// 进程都是完全相同的。这使得远程利用安全漏洞变得很容易。攻击通常需要引用绝对内存位置：
// 栈上的地址、库函数的地址等。远程攻击者必须盲目选择这个位置，指望地址空间都是相同的。
// 当它们相同时，人们就会被攻破。因此，地址空间随机化变得流行起来。Linux 通过为栈、内
// 存映射段和堆的起始地址添加偏移量来随机化它们。不幸的是，32 位地址空间相当紧张，留给
// 随机化的空间很小，削弱了其有效性。
//
// 进程地址空间的最顶部（高地址）是栈，它在大多数编程语言中存储局部变量和函数参数。调用
// 方法或函数会在栈上推送一个新的栈帧。当函数返回时，栈帧被销毁。这种简单的设计之所以可
// 能，是因为数据遵循严格的后进先出（LIFO）顺序，这意味着不需要复杂的数据结构来跟踪栈内
// 容，一个指向栈顶的简单指针就足够了。因此，推送和弹出都非常快且确定性强。此外，栈区域
// 的重复使用倾向于将活动栈内存保留在 CPU 缓存中，从而加快访问速度。进程中的每个线程都
// 有自己的栈。通过推送比它能容纳的更多的数据，可能会耗尽映射栈的区域。这会触发一个页面
// 错误，在 Linux 中由 expand_stack() 处理，它反过来调用 acct_stack_growth() 来检查
// 是否适合扩展栈。如果栈大小低于 RLIMIT_STACK（通常为 8MB），那么通常栈会扩展，程序
// 继续愉快地运行，不知道刚刚发生了什么。这是栈大小根据需求调整的正常机制。然而，如果达
// 到了最大栈大小，我们就有了栈溢出，程序会收到一个段错误。尽管映射的栈区域会根据需求扩
// 展，但当栈变小时，它不会收缩回去。就像联邦预算一样，它只会膨胀。动态栈扩展是访问未映
// 射内存区域可能有效的唯一情况。对未映射内存的任何其他访问都会触发一个页面错误，导致段
// 错误。一些映射区域是只读的，因此对这些区域的写入尝试也会导致段错误。
//
// 在栈下方（低地址方向），我们有内存映射段。在这里，内核将文件的内容直接映射到内存中。
// 任何应用程序都可以通过 Linux 的 mmap() 系统调用（实现）或 Windows 中的
// CreateFileMapping() / MapViewOfFile() 来请求这样的映射。内存映射是一种方便且高性
// 能的文件 I/O 方式，因此它被用于加载动态库。也可以创建不对应任何文件的匿名内存映射，
// 而是用于程序数据。在 Linux 中，如果你通过 malloc() 请求一大块内存，C 库会创建这样
// 一个匿名映射，而不是使用堆内存。“大”意味着大于 MMAP_THRESHOLD 字节，默认为 128kB，
// 可以通过 mallopt() 调整。
//
// 说到堆，它在我们深入地址空间的旅程中排在下一个。堆与栈类似提供运行时内存分配，不同的
// 是用于必须比执行分配的函数存活时间更长的数据。大多数语言为程序提供堆管理。因此，满足
// 内存请求是语言运行时和内核之间的共同事务。在 C 中，堆分配的接口是 malloc() 和相关
// 函数，而在像 C# 这样的垃圾收集语言中，接口是 new 关键字。如果堆中有足够的空间来满足
// 内存请求，它可以由语言运行时处理，无需内核介入。否则，通过 brk() 系统调用（实现）扩
// 展堆，为请求的块腾出空间。堆管理很复杂，需要复杂的算法，这些算法努力在我们程序混乱的
// 分配模式面前实现速度和高效内存使用的平衡。满足堆请求所需的时间可能会有很大差异。实时
// 系统有特殊的分配器来处理这个问题。另外，堆会变得碎片化。
//
// 最后，我们来到了内存的最低段：BSS、数据和程序文本。BSS 和数据都存储 C 中静态变量的
// 内容。区别在于，BSS 存储未初始化静态变量的内容，这些变量的值未在源代码中由程序员设
// 置。BSS 内存区域是匿名的：它不映射任何文件。另一方面，数据段存储在源代码中初始化的
// 静态变量的内容。这个内存区域不是匿名的。它映射程序的二进制镜像中包含源代码中给出的
// 初始静态值的部分。尽管数据段映射了一个文件的内容，但它是一个私有内存映射，这意味着对
// 内存的更新不会反映在底层文件中。这必须是这样，否则对全局变量的赋值会改变你磁盘上的二
// 进制镜像。难以置信！另外，你可以通过读取文件 /proc/PID/maps 来检查 Linux 进程中的
// 内存区域。还可以使用 nm 和 objdump 命令来检查二进制镜像，以显示符号、它们的地址、
// 段等。
//
// 虚拟内存。Linux 像多数现代内核一样，采用了虚拟内存管理技术。该技术利用了大多数程序
// 的一个典型特征，即访问局部性（locality of reference），以求高效使用 CPU 和 RAM
// （物理内存）。空间局部性（spatial locality）是指程序倾向于访问在最近访问过的内存
// 地址附近的内存（由于指令是顺序执行的，且有时会按顺序处理数据结构）。时间局部性
// （temporal locality）是指程序倾向于在不久的将来再次访问最近刚刚访问过的内存地址
// （由于循环）。正是由于访问局部性特征，使得程序即便仅有部分地址空间存在于 RAM 中（进
// 程虚拟空间仅有部分区域实际映射到了物理空间中），依然得以执行。
//
// 虚拟内存的规划之一是将每个程序使用的内存切割成小型的固定大小的页（page）。相应地，
// 将 RAM 划分成一些列与虚拟内存页尺寸相同的页帧。任一时刻，每个程序仅有部分页需要驻留
// 在物理内存帧中，这些页构成了所谓的驻留集合（resident set）。程序未使用的页拷贝保存
// 在交换区（swap area）内，这是磁盘空间中的保留区域，作为计算机 RAM 的补充，仅在需要
// 时才会载入物理内存。若进程欲访问的页面目前未驻留在物理内存中，将会发生页面错误（page
// fault），内核即刻挂起进程的执行，同时从磁盘中将该页面载入内存。程序可调用
// sysconf(_SC_PAGESIZE) 来获取系统虚拟内存的页面大小。
//
// 为支持这一组织方式，内核需要为每个进程维护一张页表（page table），该页表描述了每页
// 在进程虚拟地址空间中的位置。页表中的每个条目要么指出一个虚拟页面在 RAM 中的所在位
// 置，要么表明其当前驻留在磁盘上。在进程虚拟地址空间中，并非所有的地址范围都需要页表条
// 目，通常情况下，由于可能存在大段的虚拟地址空间并非投入使用，故而页无须为其维护相应的
// 页表条目。如进程试图访问的地址并无页表条目与之对应，那么进程将受到一个 SIGSEGV 信
// 号。由于内核能够为进程分配和释放页，所以进程的有效虚拟地址范围在其生命周期中可以发生
// 变化。这可能会发生于以下场景中：
//  1.  由于栈向低地址增长超出之前曾达到的位置。
//  2.  当在堆分配或释放内存时，通过调用 brk() sbrk() malloc() 等来提升 program
//      break 的位置。
//  3.  当调用 shmat() 连接 System V 共享内存区时，或者当调用 shmdt() 脱离共享内存区
//      时。
//  4.  当调用 mmap() 创建内存映射时，或者当调用 munmap() 解除内存映射时。
//
// 虚拟内存的实现需要硬件中分页内存管理单元（PMMU）的支持，PMMU 把要访问的每个虚拟内存
// 地址转换成相应的物理内存地址。当特定虚拟内存地址所对应的页没有驻留在 RAM 中时，将以
// 页面错误通知内核。虚拟内存管理使进程的虚拟地址空间与 RAM 物理地址空间隔离开来，这带
// 来许多优点。
//  1.  进程与进程、进程与内核相互隔离，所以一个进程不能读取或修改另一个进程或内核的内
//      存。这是因为每个进程的页表条目指向 RAM 或磁盘交换区中截然不同的物理页面集合。
//  2.  适当情况下，两个或更多进程能够共享内存。这是由于内核可以使不同进程的页表条目指
//      向相同的 RAM 页。内存共享常发生于如下两种场景：执行同一个程序的多个进程，可共
//      享一份只读的程序代码副本，当多个程序执行相同的程序文件或加载相同的共享库时，会
//      隐式地实现这一类型的共享；进程可以使用 shmget() mmap() 系统调用显式地请求与其
//      他进程共享内存区，这么做是出于进程间通信的目的。
//  3.  便于实现内存保护机制，也就是说，可以对页表条目进行标记，以表示相关页面内容是可
//      读、可写、可执行亦或是这些保护措施的组合。多个进程共享 RAM 页面时，允许每个进
//      程对内存采取不同的保护措施。例如一个进程可能以只读方式访问某页面，而另一进程则
//      以读写方式访问同一页面。
//  4.  程序员和编译器、链接器之类的工具无需关注程序在 RAM 中的物理布局。
//  5.  因为需要驻留在内存中的仅是程序的一部分，所以程序的加载和运行都很快，而且一个进
//      程所占用的内存，即虚拟内存大小，可以超出 RAM 容量。
//  6.  由于每个进程使用的 RAM 减少了，RAM 中同时可以容纳的进程数量就增多了。这增大了
//      如下事件的概率：在任一时刻，CPU 都可执行至少一个进程，因而往往也会提高 CPU 的
//      利用率。
//
// 有时会用用户栈（user stack）表示进程中讨论的栈，以便与内核栈区分开来。内核栈是每个
// 进程保留在内核内存中的内存区域，在执行系统调用的过程中供内核内部函数调用使用。由于用
// 户栈驻留在不受保护的用户空间内存中，所以内核无法利用用户栈来执行自己的函数。每个用户
// 栈帧（每个函数调用期间分配的一段栈空间）包括以下信息：
//  1.  函数实参和局部变量，由于这些变量都是在调用函数时自动创建的，因此在 C 语言中称
//      其为自动变量。函数返回时将自动销毁这些变量，因为栈帧会被释放，这也是自动变量与
//      静态以及全局变量主要的语言区别，后者与函数执行无关，且长期存在。
//  2.  函数调用的链接信息，每个函数都会用到一些 CPU 寄存器，比如程序计数器，其指向下
//      一条将要执行的机器语言指令。每当一个函数调用另一函数时，会在被调用函数的栈帧中
//      保存这些寄存器的副本，以便函数返回时能为函数调用者将寄存器恢复原状。
//
// 内存分配。进程可以通过增加堆的大小来分配内存，所谓堆是一段长度可变的连续虚拟内存，
// 始于进程的未初始化数据段末尾，随着内存的分配和释放而增减。通常将堆的当前内存边界称
// 为 “program break”。稍后将介绍 C 语言程序分配内存所惯用的 malloc 函数族，但首先
// 还要从 malloc 函数所基于的 brk() 和 sbrk() 开始谈起。
//
// 改变堆的大小，即分配或释放内存，其实就像命令内核改变进程的 program break 位置一样
// 简单。最初，brk 位置正好位于未初始化数据段末尾之后。在 brk 抬升后，程序可以访问新分
// 配区域内的任何内存地址，而此时物理内存页尚未分配，内核会在进程首次试图访问这些虚拟内
// 存地址时自动分配新的物理内存页。
//
// #include <unistd.h>
// int brk(void *end_data_segment); 成功返回0，失败返回-1和errno
// void *sbrk(intptr_t increment); 成功返回原来的brk位置，失败返回-1和errno
//
// 系统调用 brk() 会将 brk 设置为参数 end_data_segment 所指定的位置。由于虚拟内存以
// 页为单位进行分配，end_data_segment 实际会四舍五入到下一个内存页的边界处。当试图将
// brk 设置一个低于 end 的位置时，有可能会导致无法预知的行为。brk 可以设定的精确上限，
// 却决于一系列因素，这包括进程中堆数据段大小的资源限制（RLIMIT_DATA），以及内存映射、
// 共享内存、共享库的位置。调用 sbrk() 将 brk 在原有地址上增加 increment。sbrk(0)
// 将返回 brk 的当前位置。SUSv2 定义了 brk() 和 sbrk()，标记为 Legacy，SUSv3 删除了
// 这些定义。
//
// 一般情况下，C 程序使用 malloc 函数族在堆上分配和释放内存。较之 brk() 和 sbrk()，
// 这些函数具备不少优点：属于 C 标准的一部分；更易于在多线程程序中使用；接口简单，允许
// 分配小块内存；允许随意释放内存，它们被维护在一张空闲内存列表中，在后续内存分配调用时
// 循环使用。
//
// https://jemalloc.net/
// https://valgrind.org/
//
// malloc() 实现很简单，它首先会扫描之前由 free() 所释放的空闲内存块列表，以求找到尺
// 寸大于或等于要求的一块空闲内存。取决于具体实现，采用的扫描策略会有所不同，例如
// first-fit 或 best-fit）。如果这一内存块的尺寸正好与要求相当，就把它直接返回给调用
// 者。如果是一块较大的内存，那么将其进行分割，在将一块大小相当的内存返回给调用者的同
// 时，把较小的那块空闲内存保留在空闲列表中。如果在空闲内存列表中根本找不到足够大的空
// 闲内存块，那么 malloc() 会调用 sbrk() 分配更多的内存。为减少对 sbrk() 的调用次数，
// malloc() 并未只是严格按照所需字节数来分配内存，而是以内存页大小的倍数来增加 brk，
// 并将超出部分置于空闲内存列表中。对于 free()，当它将内存块置于空闲列表之上时，是如何
// 知晓内存块大小的？这是通过一个小技巧来实现的。当 malloc() 分配内存块时，会额外分配
// 几个字节来存放记录这块内存大小的值，该整数值位于内存块的起始处，而实际返回给调用者的
// 内存地址恰好位于这一字段之后。当讲内存块置于空闲内存列表时（双向链表），free() 会使
// 用内存块本身的空间来存放链表指针，并将相邻的空闲块合并。
//
// 使用 alloca() 可以在栈上分配内存，不需要也绝不能调用 free() 来释放由 alloca() 分
// 配的内存，同样也不能调用 realloc() 来调整由 alloca() 分配的内存大小。虽然 alloca()
// 不是 SUSv3 的一部分，但大多数 UNIX 实现都提供了此函数，因而也具备可移植性。请注意，
// 不能在一个函数的参数列表中调用 alloca()，例如 func(x, alloca(size), z)，这会使其
// 分配的栈空间出现在当前函数参数的空间内，而因该单独的调用 alloca(size)。使用该方式
// 分配的内存相对于 malloc() 有一定的优势，例如分配速度很快，此外也不需要维护额外的空
// 闲内存块列表。另一个优点是，alloc() 分配的内存随着栈帧的移除而自动释放，由于在函数
// 的所有返回路径中都无需确保去释放所有的已分配内存，一些函数的编码也变得简单很多。在信
// 号处理程序中调用 longjmp() 或 siglongjmp() 以执行非局部跳转时，alloca() 的作用也
// 尤其突出。此时，在起跳函数和落地函数之间的函数中，如果使用 malloc() 分配内存，要想
// 避免内存泄漏就及其困难，甚至是不可能的。与之相反，alloca() 完全可以避免这一问题，因
// 为非局部跳转会展开调用栈，所以已分配的内存会被自动释放。
//
// 进程的创建和终止。涉及的系统调用 fork() exit() wait() execve()：
//  1.  系统调用 fork() 允许进程（父进程）创建一个新进程（子进程），具体做法是，新的
//      子进程几乎是父进程的复刻，子进程获得父进程的栈、数据段、堆和执行文本段的拷贝。
//      可将此视为把父进程一分为二，术语 fork 也由此得名。当多线程进程调用 fork 时，
//      仅会将发起调用的线程复制到子进程中，子进程中该线程的线程ID与父进程中发起 fork
//      调用的线程ID一致，其他线程均在子进程中消失，也不会为这些线程调用清理函数以及针
//      对线程特有数据的析构。虽然将发起调用的线程复制到子进程中，但全局变量的状态以及
//      所有 pthreads 对象，如互斥量、条件变量等，都会在子进程中得以保留。因为在父进
//      程中为这些 pthreads 对象分配了内存，而子进程则获得了该内存的一份拷贝。因为并
//      未执行清理函数和针对线程持有数据的析构，多线程程序的 fork() 调用会导致子进程
//      内存泄露。因此复制的子进程线程除特殊情况几乎不能做原有线程的任何事，因此常常在
//      紧随其后，子进程直接调用 exec 加载新程序。
//  2.  系统调用 execve(path, argv, envp) 加载一个新程序（路径为 path，参数列表
//      argv，环境变量列表 envp）到当前进程的内存。只要一线程调用了 exec() 系列函数
//      之一，调用程序将被完全替换，除了调用 exec() 的线程外，其他所有线程都立即消失。
//      现存的程序文本段也会被丢弃，并为新程序重新创建栈、数据段、以及堆。通常将这一动
//      作称为执行（executing）一个新程序。执行一个新程序有多种实用的变体，将此类函数
//      统称为 exec()。其他一些操作系统将 fork() 和 exec() 的功能合二为一，形成单一
//      的 spawn 操作，创建一个新进程并执行指定程序。SUSv3 规定的 posix_spawn() 就
//      将 fork() 和 exec() 的功能结合起来，但规范并未对实现此函数做强制要求。Linux
//      的 glibc 函数库实现了该函数以及 SUSv3 中的其他相关函数。posix_spawn() 函数
//      的引入，意在为缺乏交换（swap）设施或内存管理单元的硬件架构（如大多嵌入式系统）
//      编写具备可移植性的应用程序，在此类架构上实现传统意义的 fork()，即便存在可能
//      性，难度也很大。
//  3.  系统调用 wait(&status) 的目的有二：其一，如果子进程尚未使用 exit() 终止，那
//      么 wait() 会挂起父进程直至子进程终止；其二，子进程的终止状态通过 wait() 的
//      status 参数返回。
//  4.  库函数 exit(status) 终止一进程，将进程占用的所有资源归还内核，参数 status 表
//      示进程的退出状态。父进程可使用系统调用 wait() 获取该状态。库函数 exit() 创建
//      于系统调用 _exit() 之上。这二者之间存在一些差异，这里强调的是，在调用 fork()
//      之后，父子进程中一般只有一个会通过调用 exit() 退出，而另一个进程则应使用
//      _exit() 终止。对于多线程程序，任一线程调用了exit()，或者主线程执行了 return，
//      那么所有线程都将消失，也不会执行清理函数和线程特有数据的析构。
//
// 对于那些只调用 for() 的程序，提供了 pthread_atfork 函数添加清理函数，每一次调用
// pthread_atfork(prepare_func, parent_func, child_func) 会将 prepare_func 添加
// 到一个函数列表中，在调用 fork 创建新的子进程之前，会按注册次序相反的顺序自动执行该
// 函数列表中的函数。与之类似，会将 parent_func 和 child_func 添加到一函数列表中，在
// fork() 返回前，将分别在父、子进程中按注册顺序自动运行。调用 fork() 所产生的子进程
// 从调用 fork() 的线程处继承 fork 处理函数。执行 exec() 期间，fork 处理函数将不再保
// 留，因为处理函数的代码会在执行 exec() 的过程中遭到覆盖。在 Linux 上，如果使用 NPTL
// 线程库的程序执行了 vfork()，那么将不再调用 fork 处理函数。不过在使用 LinuxTHreads
// 程序的同一种情况下却有效。
//
// 子进程对 exec() 的调用比非必须，特殊情况下让子进程继续执行与父进程相同的程序反而会
// 有妙用。最终两种情况殊途同归，总是要通过调用 exit() 或接收一个信号来终止子进程，而
// 父进程可调用 wait() 来获取其终止状态。同样对 wait() 的调用也属于可选项，父进程可以
// 对子进程不闻不问，继续我行我素。不过，由后续内容可知，对 wait() 的使用通常也是不可
// 或缺的，每每在 SIGCHLD 信号的处理函数中使用。当子进程终止时，内核会为其父进程产生此
// 类信号，但默认的处理方式是忽略 SIGCHLD 信号。
//
// 创建新进程 fork()。在诸多应用中，创建多个进程是任务分解时行之有效的方法。理解 fork
// 的诀窍是，要意识到完成对 fork() 调用后将存在两个进程，且每个进程都会从 fork() 的返
// 回处继续执行。但系统将率先垂青于哪个进程（即调度其使用 CPU），是无法确定的，意识到
// 这一点极为重要。在设计拙劣的程序中，这种不确定性可能会导致所谓竞争条件错误。这两个进
// 程将执行相同的程序文本段，但却各自拥有不同的栈、数据段、以及堆的拷贝。子进程的栈、数
// 据以及堆在开始时是对父进程内存相应各部分的完全复制。执行 fork 之后，每个进程均可修
// 改各自的数据，而并不影响另一进程。程序代码则可通过 fork() 的返回值来区分父子进程。
// fork() 在父进程中返回子进程 ID，而在子进程中返回 0，子进程可以调用 getpid() 和
// getppid() 获取自己和父进程的进程ID。
//
// #include <unistd.h>
// pid_t fork(void);
//
// 当无法创建子进程时，fork() 将返回 -1，失败的原因可能在于，进程数量要么超出系统针对
// 此真实用户（real user id）在进程数量上的限制（RLIMIT_NPROC），要么是触及允许该系
// 统创建的最大进程数这一系统级上限。
//
// 父子进程间的文件共享。执行 frok() 时，子进程会获得父进程所有文件描述符的副本。这也
// 意味着父子进程中的描述符均指向相同的打开文件描述（open file description）。打开的
// 文件描述包含当前文件的偏移量以及文件状态标志（由 open() 设置，通过 fcntl() F_SETFL
// 操作改变）。一个打开文件的这些属性在父子进程间实现了共享。父子进程可以同时写入一文
// 件，共享文件偏移量会确保二者不会覆盖彼此的输出内容，不过这并不能阻止父子进程的输出随
// 意混杂在一起，要想规避这一现象，需要进行进程间同步。如果不需要这种对文件描述符的共享
// 方式，那么在设计应用程序时，应于 fork() 调用后注意两点：其一，令父子进程使用不同的
// 文件描述符；其二，各自立即关闭不再使用的描述符（亦即那些其他进程使用的描述符）。如果
// 进程之一执行了 exec()，那么文件的执行时关闭功能（close-on-exec）会很有用处。
//
// fork() 的内存语义。从概念上来说，可以将 fork() 认作对父进程程序段、数据段、栈段、
// 堆段创建拷贝。的确，在一些早期的 UNIX 实现中，此类复制确实是原汁原味的，将父进程内
// 存拷贝值交换空间，一次创建新进程映像（image），而在父进程保持自身内存的同时，将换出
// 映像置为子进程。不过，真要是简单将父进程虚拟内存拷贝到新的子进程，那就太浪费了。原
// 因有很多，其中之一是 fork() 之后常常伴随着 exec()，这会用新程序替换进程的代码段，
// 并重新初始化其数据段、堆段和栈段。大部分现代 UNIX 实现（包括 Linux）采用两种技术来
// 避免这种浪费。
//  1.  内核将每一进程的代码段标记为只读，从而使进程无法修改自己的代码，这样父子进程
//      可以共享同一代码段。系统调用 fork() 在为子进程创建代码段时，其所构建的一系列
//      进程级页表项均指向与父进程相同的物理内存页帧。
//  2.  对于父进程数据段、堆段和栈段中的各页，内核采用写时复制（copy-on-write）技术来
//      处理。最初，内核做了一些设置，令这些段的页表项指向与父进程相同的物理内存页，并
//      将这些页面自身标记为只读。调用 fork() 之后，内核会捕获所有父进程或子进程针对这
//      些页面的修改企图，并为要修改的（about-to-be-modified）页面创建拷贝。系统将新
//      的页面拷贝分配给遭内核捕获的进程，还会堆子进程的相应页表项做适当调整。从这一刻
//      起，父子进程可以分别修改各自的页拷贝，不再相互影响。
//
// 控制进程的内存需求。通过将 fork() 与 wait() 组合使用，可以控制一个进程的内存需求。
// 进程的内存需求量，亦即进程所使用的虚拟内存页范围，受到多种因素的影响。例如调用函数
// 和从函数返回时的栈变动，对 exec() 的调用，以及因 malloc() 和 free() 的调用对堆所
// 做的修改。当在子进程中嗲用函数 func()，由于所有可能的变化都发生在子进程，故而从对
// func() 调用之前开始，父进程的内存使用量将保持不变，若已知 func() 导致内存泄漏，或
// 是引发堆内存的过度碎片化，该技术则可以避免这些问题，因为所的影响都局限在子进程中。
// 而当父进程等待子进程执行完毕后，所有的影响都将消除。另外一种用处是，在子进程中只调
// 用 malloc() 分配内存，为了避免复杂的 free() 操作，可以简单的不进行任何释放，只等回
// 到父进程一次性将所有资源都还给系统。
//
// 系统调用 vfork()。在早期的 BSD 实现中，fork() 会对父进程的数据段、堆和栈实施严格
// 的复制。如前所述，这是一种浪费，尤其是在调用 fork() 后立即执行 exec() 的情况下。出
// 于这一原因，BSD 的后期版本引入了 vfork() 系统调用，尽管其运作含义稍微有些不同，实
// 则有些怪异，但效率要远高于 BSD fork()。现代 UNIX 采用写时复制技术来实现 fork()，
// 其效率较之于早期的 fork() 实现要高出许多，进而将对 vfork() 的需求剔除殆尽。虽然如
// 此，Linux（如同许多其他 UNIX 实现一样）还是提供了具有 BSD 语义的 vfork() 系统调
// 用，以期为程序提供尽可能快的 fork 功能。不过，鉴于 vfork() 的怪异语义可能会导致一
// 些难以察觉的程序缺陷，除非能给性能带来重大提升，这种情况发生的概率极小，否则应当尽
// 量避免使用。
//
// #include <unistd.h>
// pid_t vfork(void);
//
// vfork() 是为子进程立即执行 exec() 的程序而专门设计的。vfork() 因为如下两个特性而
// 更具效率，这也是其与 fork() 的区别所在：
//  1.  无需为进程复制虚拟内存页或页表，相反子进程共享父进程的内存，直至其成功执行了
//      exec() 或是调用 _exit() 退出。
//  2.  在子进程调用 exec() 或 _exit() 之前，将暂停执行父进程。
//
// 这两点还另有深意，由于子进程使用父进程的内存，因此子进程对数据段、堆或栈的任何改变
// 将在父进程中体现。此外，如果子进程在 vfork() 与后续的 exec() 或 _exit() 之间执行
// 了函数返回，这同样会影响到父进程，这与试图以 longjmp() 跳转到函数返回处类似。这将
// 可能引发父进程经典的场景，以段错误（SIGSEGV）而告终。在不影响父进程的情况下，子进
// 程在 vfork() 和 exec() 之间所做的操作屈指可数。其中包括堆打开文件标书费进行操作，
// 因为系统是在内核空间为每个进程维护文件描述符表，且在 vfork() 调用期间将复制该表，所
// 以子进程对文件描述符的操作不会影响到父进程。
//
// SUSv3 指出，在如下情况下程序行为未定义：a) 修改了除用于存储 vfork() 返回值的pid_t
// 之外的任何数据；b) 从调用 vfork() 的函数中返回；c) 在成功地调用 _exit() 或执行
// exec() 之后，调用了任何其他函数。后面介绍系统调用 clone() 时将会提及，由 fork()
// 或 vfork() 创建的子进程还具有少量其他进程属性的自有拷贝。vfork() 的语义在于执行该
// 调用后，系统将保证子进程先于父进程获得调度。
//
// SUSv3 将 vfork() 标记为已过时，SUSv4 则进一步将其从规范中删除。对于 vfork() 运作
// 的诸多细节，SUSv3 颇有些语焉不详，因而可能将其实现为对 fork() 的调用。Linux 在内
// 核 2.0 及其之前的版本也是如此。在使用时，一般应立即在 vfork() 之后调用 exec()。如
// 果 exec() 执行失败，子进程应调用 _exit() 退出。vfork() 产生的子进程不应调用 exit
// 退出，因为这回导致对父进程标志输入输出缓冲区的刷新和关闭。vfork() 的其他用法，尤其
// 将其当作内存共享或进程调度方面的独特语义时，将可能破坏程序的可移植性，其中尤以将
// vfork() 实现为简单调用 fork() 的情况为甚。
//
// fork()之后的竞争条件。调用 fork() 后，无法确定父子进程间谁将率先调度，有可能系统默
// 认先执行其中一个进程，但即使这样，这个进程也可能刚执行其时间片已经结束马上就切到另一
// 进程。对于 fork() 之后先调度子进程，该行为的理由可考虑当 fork() 产生的子进程立即执
// 行 exec() 时写时复制所发生的情况。此时，一方面父进程在 fork() 之后继续修改数据页和
// 栈页，另一方面内核要为子进程复制那些将要修改的页。由于子进程一旦获得调度会立即执行
// exec()，故而这一页复制动作纯属浪费。基于这一点，先调度子进程有一些优势，如此一来，
// 等到下次调度到父进程时，就无需复制内存页了。但 Linux 2.6.32 默认是先调度父进程，但
// 有相关的配置文件 /proc/sys/kernel/sched_child_runs_first 是否配置子进程先调度。
// 先调度父进程的依据是，fork() 之后，父进程在 CPU 中正处于活跃状态，并且其内存管理信
// 息也被置于硬件内存管理单元的转译后备缓存（TLB, translation look-aside buffer）
// 中。所以，先运行父进程将提供性能。总之，值得强调的是，两种行为间的性能差异很小，对于
// 大部分应用程序并无影响。若确需保证父子进程的某一特定执行顺序，则必须采用某种同步技
// 术。包括信号量、文件锁、进程间经由管道的消息发送、信号等等。例如使用信号，调用
// fork() 之后，如果进程甲需等待进程乙完成某一动作，那么乙可以在动作完成后项甲发送信
// 号。此时进程甲只需在进程乙触发动作之前，先阻塞对应的信号，然后触发乙做动作，然后调用
// sigsuspend() 或 sigwait() 等待信号即可。
//
// 进程的终止。通常进程有两种终止方式，其一是异常终止，由信号引起，此外进程可使用 _exit
// 系统调用终止。_exit() 的 status 参数定义了进程的终止状态，父进程可调用 wait() 获取
// 该状态。虽然将其定义为 int 类型，但仅有低8位可为父进程所用。SUSv3 规定了两个常量，
// EXIT_SUCCESS 0 和 EXIT_FAILURE 1。虽然可将 0 ~ 255 之间的任意值赋给 _exit() 的
// status 参数，并传递给父进程，不过如取值大于128将在shell脚本中引发混乱。原因在于当以
// 信号终止时，shell 会将变量 $? 置为 128 与信号值之和，以表征这一事实。如果这与进程
// 调用 _exit() 时所用的相同 status 值混杂在一起，将令 shell 无法区分。
//
// 程序一般不会直接调用 _exit()，而是调用库函数 exit()，它会在调用 _exit() 之前执行
// 一些动作。exit() 会执行的动作包括：调用 atexit() on_exit() 注册的退出处理函数，其
// 执行顺序与注册顺序相反；刷新 stdio 流缓冲区；使用由 status 提供的值执行 _exit()
// 系统调用。程序另一种终止方式是从 main() 函数中执行 return，或者或明或暗一直执行到
// main() 函数的结尾处。执行 return n 等同于执行 exit(n) 的调用，因为调用 main() 的
// 运行时函数会将 main() 的返回值作为 exit() 的参数。如果没有返回值，或无声无息执行到
// main() 函数结尾，同样会导致 main() 的调用者执行 exit() 函数，不过视不同的C语言标准
// 版本，以及所使用的不同编译器选项，其结果也有所不同。C89 标准未就上述情况下的行为进行
// 定义，程序可以返回任意的 status 值。Linux GCC 默认行为就是如此，程序的退出状态取自
// 于栈或特定CPU寄存器的随机值，应避免这一方式终止程序。C99标准则要求如同执行exit(0)，
// 如果使用 gcc -std=c99 在 Linux 中编译程序，也会获得这个结果。
//
// 无论进程是否正常终止，都会发现如下的进程终止细节：
//  1.  关闭所有打开文件描述符、目录流、信息目录描述符（catopen(3) catgets(3)），以
//      及字符集转换描述符（iconv_open(3)）。
//  2.  作为文件描述符关闭的后果之一，将释放进程所有的任何文件锁。
//  3.  分离（detach）任何已连接的System V共享内存段，且对应于各段的shm_nattch计数值
//      将减一。
//  4.  进程为每个System V信号量所设置的 semadj 值将会加到信号量值中。
//  5.  如果该进程是一个管理终端（terminal）的管理进程，那么系统会向该终端前台进程组中
//      的每个进程发送 SIGHUP 信号，接着终端会与会话脱离。
//  6.  将关闭该进程打开的任何 POSIX 有名信号量，类似于调用 sem_close()。
//  7.  将关闭该进程打开的任何 POSIX 消息队列，类似于调用 mq_close()。
//  8.  作为进程组退出的后果之一，如果某进程组成为孤儿，且该组中存在任何已停止进程
//      （stopped processes），则组中所有进程都会收到 SIGHUP 信号，随之为 SIGCONT
//      信号。
//  9.  移除该进程通过 mlock 或 mlockall() 所建立的任何内存锁。
//  10. 取消该进程调用 mmap() 所创建的任何内存映射。
//
// #include <unistd.h>
// #include <stdlib.h>
// void _exit(int status);
// void exit(int status);
// int atexit(void (*func)(void));
// int on_exit(void (*func)(int, void*), void *arg); 可以传递退出码和一个用户指定参数
//
// 有时，应用程序需要在进程终止时自动执行一些操作。例如对于一个库程序，如果进程使用了该
// 库程序，那么在进程前该库需要自动执行一些清理动作。因为库本身对于进程何时以及如何退出
// 并无控制权，也无法要求主程序在退出前调用库中特定的清理函数，故而也不能保证一定会执行
// 这些清理函数。解决这一问题的方法之一是使用退出处理函数，退出函数由 exit() 函数执行。
// 然而，如果程序直接调用 _exit() 或者因信号而异常终止，将不会调用退出处理函数。当进程
// 收到信号而终止时，将不会调用退出处理函数，这一事实一定程度上限制了他们的效用。此时最
// 佳的应对方式是为可能发送给进程的信号建立信号处理函数，并于其中设置标志位，令主程序据
// 此来调用 exit()，因为 exit() 不属于异步信号安全函数。即便如此，还是无法处理SIGKILL
// 信号，因为无法改变SIGKILL的默认行为。这也是应该避免使用SIGKILL来终止进程的另一原
// 因。建议使用SIGTERM，这也是kill命令默认发送的信号。
//
// SUSv3 要求系统实现应允许一个进程能够注册至少 32 个退出处理函数，使用系统调用
// sysconf(_SC_ATEXIT_MAX）可以获取这个上限值，但是并无法获知有多少已注册的处理函数。
// 通过运用动态分配链表来添加已注册的处理程序，glibc 允许注册近乎任意数量的退出处理函
// 数。通过 fork() 创建的子进程会继承父进程注册的退出处理函数，而进程调用 exec() 时，
// 会移除所有已注册的退出处理函数。无法取消经由 atexit() 或 on_exit() 注册的退出处理
// 函数。不过，可以令退出处理程序在执行动作之前检查全局执行标志释放置位，或者清除该标志
// 来屏蔽退出处理程序。
//
// fork() exit() 以及 stdio 缓冲区。当下面的程序正常执行输出到终端时行为正常，但当将
// 输出重定向到文件时（./program > a.txt），Ciao 出现在 Hello world 之前，并且Hello
// world 打印了两次。
//      printf("Hello world\n");
//      write(STDOUT_FILENO, "Ciao\n", 5);
//      fork();
//      exit(0);
//
// 要理解为什么 printf() 输出会出现两次，首先要记住stdio缓冲区是维护在进程用户空间内
// 存中，当标志输出定向终端时，因为默认时行缓冲，所以会立即显式输出。不过，当标志输出定
// 向到文件时，由于默认是块缓冲，所以在本例中，当调用 fork() 时，printf() 输出的字符串
// 仍在父进程的stdio缓冲区中，并随子进程的创建而产生一份副本。父子进程调用exit()会刷新
// 各自的stdio缓冲区，从而导致重复的输出结果。而 write() 的输出并未出现两次，这是因为
// write() 会将数据直接传递给内核传冲区，fork() 不会复制这一缓冲区。另外，write() 的
// 输出要先于 printf() 是因为 write() 会立即将数据传给内核高速缓存，而 printf() 则需
// 要等到调用 exit() 刷新 stdio 缓冲区时才传递。通常在混合使用 stdio 函数和系统调用对
// 同一文件进行I/O处理时，需要特别谨慎。可以采用以下两种方法之一来避免重复输出问题：
//  1.  针对stdio缓冲区的特定解决方案，可以在调用fork()之前使用函数flush()来刷新缓冲
//      区，作为另一种选择，也可以使用 setvbuf() 和 setbuf9) 来关闭标准流的缓冲功能。
//  2.  子进程可以调用_exit()而非exit()，以便不再刷新缓冲区，这一技术例证了一个更为
//      通用的原则：在创建子进程的应用中，典型情况下仅有一个进程（一般为父进程）应调用
//      exit() 终止，而其他进程调用 _exit() 终止，从而确保只有一个进程做清理工作。
//
// 执行新程序 execve()。系统调用 execve() 可以将新程序加载到某一进程的内存空间。在这
// 一操作过程中，将丢失旧有程序，而进程的栈、数据以及堆段会被新程序替换。在执行了各种C
// 语言函数库的运行时启动代码以及程序的初始化代码后，新程序从 main() 函数处开始执行。
// 由 fork() 生成的子进程对 execve() 的调用最为频繁，不以 fork() 调用为先导而单独调
// 用 execve() 的做法在应用中实属罕见。基于系统调用 execve()，还提供了一系列冠以exec
// 来命名的上层库函数。
//
// #include <unistd.h>
// int execve(const char *path, char *const argv[], char *const envp[]);
// int fexecve(int fd, char *const argv[], char *const envp[]);
//
// 参数 path 包含准备载入当前进程空间的新程序的路径名，既可以是绝对路径，也可以是相对
// 于调用进程当前工作目录的相对路径。参数 argv 指定了传递给新进程的命令行参数，argv[0]
// 是新程序的程序名，通常是 path 路径中的基本名称部分（即路径的最后部分）。参数 envp
// 指定了新程序的环境变量列表，其元素指向“name=value"格式的字符串。Linux 所特有的文件
// /proc/PID/exe 是一个符号链接，包含PID对应进程中正在运行可执行文件的绝对路径名。
//
// 调用execve()之后，因为同一进程依然存在，所以进程ID仍保持不变，还有少量其他的进程属
// 性也未发生变化。如果对 path 所指定的程序文件设置了 set-user-id set-group-id 权限
// 位，那么系统调用会在执行此文件时将进程的有效用户或组ID设置为程序文件的属主或组ID。
// 利用这一机制，可令用户在运行特定程序时临时获取特权。无论是否更改了有效ID，也不管这一
// 变化是否生效，execve() 都会以进程的有效用户ID去覆盖已保存的set-user-id，以进程的有
// 效组ID去覆盖保存的set-group-id。
//
// glibc 自版本2.3.2开始提供函数 fexecve()，其行为与 execve() 类似，只是指定将要执行
// 的程序是以打开文件描述符 fd 的方式，而非通过路径名。有些应用程序需要打开某个程序文
// 件，通过执行校验和来验证文件内容，然后再运行该文件，这一场景就较为适宜使用该函数。
// fexecve() 的设计初衷是让调用者在执行一个可执行文件之前，先对其内容做校验（例如计算
// 校验和）。仅仅打开文件、计算校验和，然后再调用 execve(2) 是不够的，因为在两个步骤
// 之间，文件名或路径中的某个目录前缀可能被替换（例如通过修改符号链接的目标）。不过，
// fexecve() 并不能避免“文件内容在校验之后、调用 fexecve() 之前被改动”这一问题；要解
// 决这个问题，需要确保文件权限能阻止恶意用户修改该文件。使用 fexecve() 时的惯用做法
// 是：把 fd 设为 close-on-exec，这样文件描述符就不会泄漏给即将执行的程序。一方面避免
// 无谓地占用描述符；另一方面，如果 fexecve() 被递归使用，可防止每一步都把一个新的描述
// 符传给子程序，最终导致耗尽描述符。但是，若 fd 指向脚本（即以 #! 开头、指定解释器的
// 可执行文本文件），且已为 fd 设置了 close-on-exec 标志，则 fexecve() 会因 ENOENT
// 失败。原因是，当脚本解释器开始执行时，fd 已被 close-on-exec 关闭，解释器找不到脚本
// 文件。因此，当fd指向脚本时，不能为其设置 close-on-exec 标志，否则会触发上述问题。
//
// 由于是将调用程序取而代之，对execve()的成功调用将永远不返回，而且也无需检查execve()
// 的返回值，因为该值总是雷打不动地等于-1。实际上，一旦函数返回，就表明发生了错误，通常
// 可以通过errno来判断错误原因，可能返回以下错误：
//      EACCESS - 参数 path 没有指向一个常规文件，未对该文件赋予可执行权限，或者因为
//          path 中某一级目录不可搜索（即关闭了该目录的可执行权限）。还有一种可能，是
//          以 MS_NOEXEC 标志挂载（mount）文件的文件系统，从而导致这一错误。
//      ENOENT - path 指向的文件不存在。
//      ENOEXEC - 尽管对 path 指向的文件赋予了可执行权限，但系统却无法识别其文件格
//          式。一个脚本文件，如果没有包含用于指定脚本解释器的起始行，就可能导致这一
//          错误。
//      ETXTBSY - 存在一个或多个进程已经以写入方式打开 path 所指代的文件。
//      E2BIG - 参数列表和环境变量列表所需空间总和超出了允许的最大值。
//
// ELF 是一种广为实现的可执行文件格式，描述了可执行文件的布局。在执行期间，进程映像通
// 常是由可执行文件的各段构造而成。不过，ELF规格也允许定义一个解释器（PT_INTERP）来
// 运行程序。如果定义了解释器，内核则基于指定解释器可执行文件的各段来构建进程映像，转
// 而由解释器负责加载和执行程序。
//
// #include <unistd.h>
// int execle(const char *path, const char *arg, ... /*, NULL, char *const envp[] */);
// int execlp(const char *path, const char *arg, ... /*, NULL */);
// int execvp(const char *path, char *const argv[]);
// int execv(const char *path,  char *const argv[]);
// int execl(const char *path, const char *arg, ... /*, NULL */);
//
// 以上库函数为执行 exec() 提供了多种选择，所有这些库函数均构建于 execve() 调用之上，
// 只是在为新程序指定程序名、参数列表以及环境变量的方式上有所不同。各函数名称的最后一个
// 字母为区分这些函数提供了线索：
//  1.  大部分 exec() 函数要求提供欲加载新程序的路径名，而 execlp 和 execvp 则允许只
//      提供程序的文件名。系统会在由环境变量PATH所指定的目录列表中寻找相应的执行文件。
//      这与shell对键入命令的搜索方式一致。这些函数名都包含字母p（表示path），以示在
//      操作上有所不同。如果没有PATH路径，那么会采用默认路径 ".:/usr/bin:/bin"，开始
//      的点表示进程的当前工作目录。如果文件名中包含了字符"/"，则将其视为相对或绝对路
//      径名，不再使用变量PATH来搜素文件。
//  2.  函数 execle() execlp() execl() 要求开发者在调用中以字符串列表形式指定参数，
//      而不适用数组来描述 argv 列表。这可以方便已知个数的参数列表的传入。首个参数对
//      应于新程序 main() 函数的 argv[0]，必须以NULL指针来终止参数列表，以便于各调用
//      定位列表的尾部，上述各原型注释中的NULL部分透露了这一要求。这些函数的名称都包含
//      字母l（表示list），以便与以NULL结尾的数组作为参数列表的函数有所区别，这些函数
//      中的v表示的是数组（vector）。
//  3.  函数 execve() execle() 则允许开发者通过 envp 为新程序显式指定环境变量，其中
//      envp 是一个以NULL结束的字符串指针数组。这些函数以字母e结尾，表示环境变量。其他
//      不带e的exec()函数将使用调用者的当前环境作为新程序的环境。
//
// 出于安全方面的考虑，通常会将当前目录排除在超级用户的PATH之外。这是为了防止root用户
// 发生如下意外情况：执行当前工作目录下与标准命令同名的程序（事先由恶意用户故意放置），
// 或者将常用命令拼错而执行了当前工作目录下的其他程序，例如sl而非ls。一些Linux发行版还
// 将当前工作目录排除在非特权用户的PATH之外。应该避免在设置了 set-user-id 或
// set-group-id 的程序中调用 execvp() 和 execlp()，至少应当慎用。需要特别谨慎地控制
// PATH 环境变量，以防运行恶意程序。在实际操作中，这意味着应用程序应该使用已知安全的目
// 录列表来覆盖之前定义的任何PATH值。
//
// 解释器脚本。所谓解释器（interpreter），就是能够读取并执行文本格式命令的程序。各种
// UNIX shell，以及诸如 awk sed perl python ruby 之类的程序都属于解释器。除了能够
// 交互地读取和执行命令之外，解释器通常还具备这样一种能力，从被称为脚本的文本文件中读
// 取和执行命令。UNIX 内核运行解释器脚本的方式与二进制程序无异，前提是脚本必须满足两点
// 要求。首先，必须赋予脚本文件可执行权限。其次，文件的起始行必须指定运行脚本解释器的路
// 径名，格式为 #! interpreter-path [optional-arg]。字符 #! 必须置于改行起始处，这
// 两个字符与解释器路径名之间可以以空格分隔。在解释该路径名时不会使用环境变量PATH，因
// 而一般采用绝对路径。使用相对路径固然可行，但很少见。对其解释则相对于启动解释器进程的
// 当前工作目录。作为例子，UNIX shell 脚本通常以下面的行开始：#!/bin/sh。
//
// 解释器脚本文件首行中可以指定参数，但参数不应包含空格，因为空格所起的作用完全取决于
// 实现。Linux 不会对参数中的空格做特殊解释，将从参数起始直至行尾的所有文本视为一个单
// 词，再将其作为一整个参数传递给解释器。注意，对空格的这种处理方式，与shell的做法形
// 成鲜明的对比，后者总是将其视为命令行中各单词的界定符。其他UNIX实现在处理参数的空格
// 时，其做法与Linux有同有异。在 6.0 版本之前的 FreeBSD 上，可在解释器之后跟随多个以
// 空格分隔的可选参数，并作为多个独立的单词传递给解释器。而在这之后，其行为又转而与
// Linux 趋同。而 Solaris 8 则使用空格来表征参数的结束，同时忽略之后的任何剩余部分。
// Linux 内核要求脚本的起始行不得超过127各字符，其中不包括行尾换行符，超出部分会被忽
// 略。SUSv3 并未对脚本解释器的#!行加以规范，不过大多数UNIX实现都支持这一特性。不同的
// UNIX实现对于起始行长度的限制有所不同，例如 OpenBSD 3.1 的限制为 64 个字节，而
// Tru64 5.1 则为 1024 个字节。
//
// 解释器脚本的执行。exec() 如果检测到传入的文件以#!开始，就会解析该行，然后按如下参
// 数列表来执行解释器程序：
//      interpreter-path [optional-arg] script-path arg...
// 例如脚本文件：necho.script
//      #!/home/bin/necho some argument
// 再使用以下程序执行该脚本：./program necho.script
//      argvec[0] = argv[1];
//      argvec[1] = "hello world";
//      argvec[2] = "goodbye";
//      argvec[3] = NULL;
//      execve(argv[1], argvec, NULL);
// 那么解释器 necho 得到的命令行参数为：
//      argv[0] = /home/bin/necho 或者 necho
//      argv[1] = some argument
//      argv[2] = necho.script
//      argv[3] = hello world
//      argv[4] = goodbye
//
// 对于 execlp() 和 execvp()，其行为方式有些不同，它们会通过PATH路径来查找要执行的程
// 序。如果在路径中找到匹配的程序，且该程序具有可执行权限，但不是一个二进制格式文件，且
// 其并没有包含 #! 起始行，execlp() 和 execvp() 将该文件当作 shell 脚本来处理。Linux
// 中，会将这类文件是同于包含 #!/bin/sh 起始行的文件来进行处理。
//
// 文件描述符与exec()。默认情况下，调用 exec() 的进程打开的文件描述符，在 exec() 执行
// 过程中会保持打开状态。shell 利用这一特性为其所执行的程序处理I/O重定向。例如，假设
// 键入如下命令：ls /tmp > dir.txt。shell 运行该命令时，执行以下几个步骤：
//  1.  调用fork()创建子进程，子进程会运行shell的一份拷贝，因此命令行也有一份拷贝。
//  2.  子shell以描述符1（标准输出）打开文件dir.txt用于输出，可能会采取以下任一方式：
//      a)  子shell关闭描述符1（STDOUT_FILENO）后，随即打开文件dir.txt。因为open()
//          在位描述符取值时总是取最小值，而标准输入（描述符0）又仍出于打开状态，所以
//          会以描述符1来打开文件。
//      b)  shell打开文件dir.txt，获取一个新的文件描述符。之后，如果该文件描述符不是
//          标准输出，那么shell会使用dup2()强制将标准输出赋值为新描述符的副本，并将此
//          时已然无用的新描述符关闭。这种方法较前者更为安全，因为它并不依赖于打开文件
//          描述符的低值取数原则。
//          fd = open("dir.txt", O_WRONLY|O_CREAT, S_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP|S_IROTH|S_IWOTH);
//          if (fd != STDOUT_FILENO) { // rw-rw-rw- */
//              dup2(fd, STDOUT_FILENO);
//              close(fd);
//          }
//  3.  子shell执行程序ls，ls将其结果输出到标准输出，亦即文件dir.txt中。
//
// 此处对shell处理I/O重定向的解释有所简化。特别是，某些命令即所谓shell内置命令，是由
// shell直接运行的，并未调用fork()或者exec()。在处理I/O重定向时，针对这样的命令必须
// 进行特殊处理。将某一shell命令实现为内建命令，不外乎如下两个目的：效率以及会对shell
// 产生副作用。一些频繁使用的命令（如pwd、echo、test）逻辑都很简单，放在shell内部实现
// 效率会更高。将其他命令内置于shell实现，则时希望命令对shell本身产生副作用：更改shell
// 所存储的信息，修改shell进程的属性，亦或是影响shell进程的运行。例如cd命令必须改变
// shell自身的工作目录，故而不应在一个独立进程中执行。产生副作用的内建命令还包括exec、
// exit、read、set、source、ulimit、wait以及shell的作业控制命令（jobs fg bg）。想
// 了解shell支持的全部的内建命令，可参考shell手册页。
//
// 执行时关闭标志（FD_CLOEXEC）。在执行exec()之前，程序有时需要确保关闭某些特定的文件
// 描述符。尤其时在特权进程中调用exec()来启动一个未知程序时，异或是启动程序并不需要使
// 用这些已打开的文件描述符时，从安全编程的角度出发，应当在加载程序之前确保关闭那些不必
// 要的文件描述符。对所有此类描述符施以close()调用可以达到目的，然而这一做法存在如下局
// 限性：
//  1.  某些描述符可能是由库函数打开的。但库函数无法使主程序在执行exec()之前关闭相应的
//      文件描述符。作为即便原则，库函数应总是为其打开的文件设置执行时关闭标志。
//  2.  如果exec()因某种原因而调用失败，可能还需要使描述符保持打开状态。如果这些描述符
//      依然关闭，将它们重新打开并指向相同文件的难道很大，基本上不太可能。
//
// 为此，内核为每个文件描述符提供了执行时关闭标志，如果是fork()子进程然后调用exec()，
// 关闭的是子进程的描述符副本。如果设置了这一标志，那么在成功执行exec()时，会自动关闭
// 该文件描述符，如果调用exec()失败文件描述符会保持打开状态。可以通过 fcntl() F_GETFD
// F_SETFD 操作来获取和设置该标志。
//
// 调用fork()创建的子进程继承了父进程当前已打开的文件描述符集合的一份副本。子进程中的
// 每个描述符指向与父进程中对应描述符相同的“打开文件描述”（参见 open(2)）。因此，这两
// 个描述符共享：打开文件状态标志，文件偏移量，信号驱动的 I/O 属性（参见 fcntl(2)）。
// 另外，子进程中的描述符标志也应该保持跟父进程中的一样。
//
// 信号与exec()。exec()在执行时会将现有进程的文本段丢弃，该文本段可能包含了由调用进程
// 创建的信号处理程序。既然处理处理函数丢弃，内核会将对所有已设信号的处置重置为默认行为
// SIG_DFL，而对所有其他信号（将处置设置为SIG_IGN或SIG_DFL的信号）的处置保持不变。这
// 符号SUSv3的要求。不过，遭忽略的SIGCHLD信号属于SUSv3的特例，调用exec()之后，是继续
// 让遭忽略的SIGCHLD信号保持被忽略状态，还是将其处置重置为SIG_DFL，SUSv3对此不置可
// 否。Linux的操作采取前者，而其他一些UNIX实现可能采用后者。这就意味着，对于忽略
// SIGCHLD信号的程序而言，要最大限度的保持可移植性，就应该在调用exec()之前将SIGCHLD
// 的处置设置为默认SIG_DFL。此外，程序也不应当假设对SIGCHLD初始的初始设置时SIG_DFL
// 之外的其他值。老程序的数据段、堆以及栈悉数被毁，这也意味着通过sigaltstack()所创建
// 的任何备选信号栈都会丢失。由于exec()在调用期间不会保护备选信号栈，故而也会将所有信
// 号的SA_ONSTACK位清除掉。
//
// 在调用exec()期间，进程信号掩码以及挂起（pending）的信号的设置均得以保存。这一特性允
// 许对新程序的信号进行阻塞和排队处理。不过，SUSv3指出，许多现有应用程序的编写都基于如
// 下的错误假设：程序启动时将某些特定信号的处置设置为SIG_DFL，又或者并未阻塞这些信号。
// 特别是，C语言标准对信号的规范很弱，对信号阻塞也未置一词，所有为非UNIX系统所编写的 C
// 程序也不可能去解除对信号的阻塞。为此，SUSv3建议，在调用exec()执行任何程序的过程中，
// 不应当阻塞或忽略信号。这里的任何程序是指并非由exec()的调用者自己编写的程序。至于说
// 如果执行和被执行的程序均出自一人之手，又或者对允许程序处理信号的手法知根知底，那自然
// 又另当别论。
//
// 执行shell命令（system()）。程序可以通过调用system()函数来执行任意的shell命令。另
// 外，popen() 和 pclose() 函数同样可以用来执行shell命令，而且还允许调用程序向命令发
// 送输入信息，或是读取命令的输出。函数system()创建一个子进程来运行shell，并以执行对
// 应的命令。system()的主要优点是简便：无需处理对fork() exec() wait() exit()的调用
// 细节；system()会代为处理错误和信号；因为system()使用shell来执行命令，所以会在执行
// 命令之前对其进程所有的常规shell处理、替换以及重定向操作。但这些优点是以低效率为代价
// 的。使用system()运行命令需要创建至少两个进程，一个用于运行shell，另外一个或多个用
// 于shell所执行的命令，执行每个命令都会调用一次 exec()。如果对效率或者速度有所要求，
// 最好还是直接调用fork()和exec()来执行既定程序。
//
// 当设置了用户ID和组ID的程序在特权模式下运行时，绝不能调用system()。即便此类程序并未
// 允许用户指定需要执行的命令文本，鉴于shell对操作的控制有赖于各种环境变量，故而使用
// system()会不可避免地给系统带来安全隐患。例如，在较老的bourne shell中，环境变量 IFS
// 定义了用于将命令行拆分成为独立单词的内部字段分隔符，就引发了若干起对系统入侵的成功案
// 例。如果将IFS定义为a，那么shell会将字符串shar视为带有参数r的单词sh，并启动另一shell
// 进程来执行当前工作目录下名为r的脚本，这就一改命令的愿意，执行名为shar的命令。对这一
// 安全漏洞的修复举措是，将IFS只应用于shell扩展所产生的单词。此外，现代shell会在启动时
// 重置IFS为由空格、Tab以及换行3个字符组成的字符串，以确保即使IFS的继承值很奇怪，脚本
// 的行为也会保持一致。作为进一步的安全举措，当从设置用户或组ID的程序中调用时，bash会
// 回转为实际用户或组ID的真身。应用需要加载其他程序时，为确保安全过关，应当直接调用
// fork() 和 exec() 函数（execlp() execvp() 除外）。
//
#endif // POSIX END
#endif // PRH_ALLOC_IMPLEMENTATION
#endif // PRH_ALLOC_INCLUDE

// https://gcc.gnu.org/wiki/SplitStacks
//
// 分段栈（Split Stacks），分段栈的目标是允许一个不连续的栈，该栈会根据需要自动增长。这
// 意味着你可以运行多个线程，每个线程都从一个较小的栈开始，并且栈会根据程序的需求自动增长
// 和收缩。因此，在编写多线程程序时，不再需要考虑栈的大小。典型的多线程程序的内存使用量可
// 以显著减少，因为每个线程不需要最坏情况下的栈大小。在 32 位地址空间中，可以运行数百万个
// 线程（无论是完整的 NPTL 线程还是协程）。目前，分段栈已在运行 GNU/Linux 的 32 位和
// 64 位 x86 目标上实现，适用于 gcc 4.6.0 及更高版本。要获得完整功能，你必须使用 gold
// 链接器，可以通过使用 binutils 2.21 或更高版本并带有 --enable-gold 选项来构建。
//
// 栈将有一个始终可用的保证区域（guaranteed zone），保证区域的大小将因目标平台而异。它
// 将包含足够的栈空间来实际分配更多的栈空间，每个函数都必须验证当前栈是否有足够的空间来
// 执行。基本验证是栈指针与当前栈底部加上保证区域大小之间的比较，这必须是函数中的第一个
// 操作，并且也是目标特定的。它必须快速执行，因为每个被调用的函数都会执行它。有两种情况，
// 对于需要小于保证区域大小的栈帧的函数，我们可以简单地比较栈指针和栈限制。对于需要更大
// 栈帧的函数，我们必须进行包括栈帧大小的比较。
//
// 可能的策略：（一）保留一个寄存器来保存栈底加保证区大小，这必须是一个由被调用者保护的寄
// 存器。每个需要小栈帧的函数都以两条指令序列开始：
//          cmp     %sp,%reg    // 大部分情况多两条指令
//          bg      1f
//          expand stack
//      1:
// （二）使用 TLS 变量。在共享库的一般情况下，这将需要调用 __tls_get_addr 函数。这意味
// 着该函数必须在不需要任何额外栈空间的情况下工作。除非整个系统都使用分段栈编译，否则这是
// 不可行的。它需要设置 LD_BIND_NOW，以便在程序启动时解析 __tls_get_addr 函数。即使这
// 样，除非我们能够确保变量的空间完全分配，否则这可能也不够。一般来说，我认为我们不能确保
// 这一点，因为 dlopen 可能会导致线程请求更多的空间用于 TLS 变量，而这些空间需要在第一次
// 调用 __tls_get_addr 时分配，因此我认为这种方法通常无法工作。
// （三）让栈始终在 N 位边界结束。例如，如果我们总是以 4K（0x1000）的倍数分配栈段，那么
// 将每个栈段对齐，使栈始终在 12 位边界结束。然后栈上剩余的空间是 SP & 0xfff，栈底地址
// 值最大 0x1000，栈顶地址值最小 0x0000，32位栈指针的合法范围 [0x0ffc, 0x0000]，栈指
// 指针指向当前合法的栈顶元素。0x0000 & 0xfff = 0x0000 表示已经没有空间，0x0ffc &
// 0x0fff = 0x0ffc 表示只使用了 4 字节空间，还有 0x0ffc 大小的空间可用。
//          mov     %sp,%junkreg    // 大部分情况多四条指令
//          and     $0xfff,%junkreg
//          cmp     $framesize plus slop,%junkreg
//          bg      1f
//          expand stack
//      1:
// （四）引入一个新的函数调用来处理栈指针和栈扩展的比较。这个函数调用将是线程库的一部分，
// 并且可以使用特殊知识——例如，快速定位当前帧的栈信息的能力。这个函数调用将使用一个特殊
// 的调用约定序列，带有一个参数，即栈帧的大小。然后每个函数都以调用这个函数开始。在某些
// 目标上，这个函数调用可以与PIC代码所需的函数调用结合，例如 __i686.get_pc_thunk.bx。
// （五）重用栈保护器（stack protector）支持字段。当使用 glibc 时，每个线程描述符都有
// 一个字段用于栈保护器。我们可以重用该字段来保存栈限制。当然，然后就不可能将分段栈与栈
// 保护器一起使用。
// （六）至少在 x86 上，安排在 TCB 头中分配一个新字段，可以通过 %fs 或 %gs 访问。这可
// 能是最好的解决方案，也是为 i386 和 x86_64 实现的解决方案。
//
// 扩展栈：扩展栈需要分配额外的内存。这些额外的内存必须仅使用仅由的栈空间余量（stack
// space slop）来分配。所有用于分配额外栈空间的函数都必须编译为不使用分段栈。因此引入一
// 个新的函数属性 no_split_stack，表示栈不能被分段。也可以确保栈足够大，以至于在分配函
// 数调用期间不需要分段栈。
// 扩展栈后，函数将把任何基于栈的参数从旧栈复制到新栈。幸运的是，所有需要复制或移动构造
// 函数的 C++ 对象都是隐式地通过引用传递的，因此在栈上复制参数是可以的。对于可变参数函
// 数，这在一般情况下是不可能的，因此我们将以不同的方式编译可变参数函数：它们将使用一个
// 参数指针，参数指针不需要基于帧指针。对于返回栈上对象的函数，对象将在旧栈上返回。这通
// 常会自动发生，因为初始隐藏参数将自然地指向旧栈。
// 扩展栈时，函数的返回地址将被篡改，指向一个释放分配的栈块并重置栈指针到调用者的函数。
// 旧栈块的地址和旧栈指针将被保存在新栈块的某个位置。
//
// 向后兼容性：我们希望能够在预编译的库（这些库没有使用分段栈编译）的系统上使用分段栈程
// 序。这意味着我们需要确保在调用任何此类函数之前有足够的栈空间。
// 每个以分段栈模式编译的对象文件都将被注释以表明函数使用分段栈，但 GNU as 没有创建任意
// 注释的一般支持。因此，每个以分段栈模式编译的对象文件将有一个特殊名称的空节：
// .note.GNU-split-stack。如果以分段栈模式编译的对象文件包含一些带有 no_split_stack
// 属性的函数，那么该对象文件也将有一个 .note.GNU-no-split-stack 节。这将告诉链接器有
// 些函数可能没有预期的分段栈前序代码。
// 当链接器链接可执行文件或共享库时，它将寻找从分段栈代码到非分段栈代码的调用。这将包括
// 对非分段栈共享库的调用（因此，一个链接到分段栈共享库的程序如果在运行时动态链接器发现
// 了一个非分段栈共享库，可能会失败；可能希望使用一个新的段类型来检测这种情况）。
// 对于从分段栈代码到非分段栈代码的调用，链接器将更改分段栈（调用者）函数的初始指令。这
// 意味着链接器将需要对编译器发出的指令有特殊了解。这些更改的效果将是将所需的帧大小增加
// 一个足够大的数字，以合理地适用于非分段栈。这将是一个目标依赖的数字；默认值将是类似
// 64K 的东西。请注意，当分段栈函数返回时，这个大的栈将被释放。请注意，我忽略了在共享库
// 中的分段栈代码调用主可执行文件中的非分段栈代码的情况，这似乎是一个不太可能的问题。
// 函数指针是一个棘手的情况。一般来说，我们不知道函数指针是否指向分段栈代码。因此，所有
// 通过函数指针的调用都将被修改为调用（或跳转到）一个特殊的函数 __fnptr_morestack。这
// 将使用目标特定的函数调用约定序列，并且将被实现为好像它本身是一个函数调用指令。也就是
// 说，所有参数都将被设置好，然后代码将跳转到 __fnptr_morestack。__fnptr_morestack
// 函数接受两个参数：要调用的函数指针和推送到栈上的参数字节数。（这尚未实现。）
//
// 调试：调试器将需要了解分段栈模式。有两个主要问题：展开栈和查找可变参数函数的参数。幸
// 运的是，DWARF 足够复杂，可以表示分段栈函数使用的不寻常的返回序列。因此，唯一的主要问
// 题是 gdb 期望所有栈地址单调递减。需要某种标记来告诉 gdb 禁用这个合理性检查（sanity
// check）。对于可变参数函数，可变参数将通过一个参数指针而不是在栈上访问。gdb 可能需要
// 调整以理解这一点。
//
// 实现步骤：
// 添加一个新的目标平台函数 bool supports_split_stack() 以及 TARGET_SUPPORTS_SPLIT_STACK。
// 在 gcc 中添加 -fsplit-stack 选项。只有当 targetm.supports_split_stack() 返回 true 时，才允许使用此选项。
// 添加 no_split_stack 函数属性。如果使用 -fno-split-stack，则忽略此属性。
// 如果使用 -fsplit-stack，则在对象文件中生成分段栈注释。
// 编写 __generic_morestack 常规函数。它必须在不自己分段栈的情况下分配所需的内存量。这可能是操作系统依赖的。
// alloca 和动态数组必须改变以检查可用的栈空间。如果没有足够的可用空间，它们必须调用堆分配例程。空间必须在函数退出时释放。
// 对于每个目标平台：
//      定义小栈帧函数和大栈帧函数的函数入口序列。
//      定义 __morestack 常规函数的调用约定。
//      当使用 -fsplit-stack 且未使用 no_split_stack 属性时，在前序代码中实现此序列。
//      如果需要，以不同的方式实现可变参数，使用一个单独的参数指针。
//      定义 __fnptr_morestack 常规函数的调用约定。更改 call define_expands 以使用新的调用约定来调用 REG。
//      编写 __morestack 常规函数。它必须以目标依赖的方式获取其参数。它必须保存寄存器并切换到一个备用栈。然后它可以调用
//      __generic_morestack。它必须将调用函数的返回值更改为指向 __releasestack。函数入口序列必须允许可靠地完成此操作。
//      编写 __releasestack 常规函数。它必须从分配的栈中检索原始栈指针和原始返回地址，释放分配的栈，并将栈指针调整为指向旧栈。
//      编写 __morestack_nosplit 常规函数。当分段栈代码调用非分段栈代码时，将调用此函数。它类似于 __morestack，但使用目标依赖的大栈大小。
//      编写 __fnptr_morestack 常规函数。在某些情况下，直接检查函数指针处的代码以查看它是否检查分段栈。如果它这样做，代码可以直接
//      跳转到被调用的函数。否则，它必须像 __morestack_nosplit 一样分配栈，然后将参数字节复制到新栈上。
//      如果分段栈对象中的代码调用非分段栈对象中的代码，则更改代码的初始启动序列，始终调用 __morestack_nosplit。
//      在包含分段栈对象的链接中，如果以非调用方式引用非分段栈对象中的函数（如获取其地址），则改为获取链接器生成的存根函数（stub
//      function）的地址。存根函数将调用 __morestack_nosplit，如果需要，将参数复制到新栈上，然后跳转到真正的函数。复制参数将不得
//      不对参数数量做出假设，因此如果传递的参数过多，这将失败。我不确定如何最好地处理这个不太可能的情况。我们只应在一个调用来源于
//      分段栈函数时才分配新栈。
// 更改链接器以查找新的分段栈注释。
// 如果使用 ld -r 将带有分段栈注释的对象与没有分段栈注释的对象链接，发出错误。
// 调整 gdb 以理解新代码。
// 想出将此高效地整合到 glibc 的最佳方法。可能需要将 glibc 既编译成分段栈，也编译成非分段栈，并以某种方式安排分段栈代码在运行时获取
// 分段栈的 glibc。如果程序链接器和动态链接器都能达成一致，或者程序链接器能够以某种方式知道在运行时将使用分段栈的 glibc，那将最好。
// 理想情况下，glibc 动态链接器应该知道程序是否期望共享库的分段栈版本，并拒绝将其与该库的非分段栈版本链接。
//
// 实现协程栈自动增长的第二种方法，预先分配很大一块虚拟地址空间，但按需进行 commit 和
// uncommit，初始时 commit 很小一块，但这应该只能按内存页大小进行 commit，而内存页大小
// 一般为 4KB，对于一般的协程来信，可能还是浪费空间。
#ifdef PRH_CORO_INCLUDE
typedef struct prh_impl_coro prh_coro;
#define prh_coro_proc prh_fastcall(void)
prh_fastcall_typedef(void, prh_coroproc_t)(prh_coro *);

typedef struct prh_impl_soro prh_soro;
#define prh_soro_proc prh_fastcall(void)
prh_fastcall_typedef(void, prh_soroproc_t)(prh_soro *);

typedef struct prh_impl_coro_main prh_impl_coro_main;
typedef struct prh_impl_coro_struct prh_coro_struct;

prh_fastcall(void) prh_impl_asm_coro_yield(prh_coro *coro, prh_coro *next);
prh_coro *prh_impl_next_resume_coro(void);
int prh_coro_self_id(prh_coro *coro);
int prh_soro_self_id(prh_soro *soro);

prh_inline void prh_coro_yield(prh_coro *coro) {
    prh_impl_asm_coro_yield(coro, prh_impl_next_resume_coro());
}

prh_inline void prh_soro_yield(prh_soro *soro) {
    extern prh_thread_local prh_impl_coro_main *PRH_IMPL_CORO_MAIN;
    prh_impl_asm_coro_yield((prh_coro *)soro, (prh_coro *)PRH_IMPL_CORO_MAIN);
}

prh_inline void *prh_coro_data(prh_coro *coro) {
    return *(void **)((prh_byte *)coro + 8);
}

prh_inline void *prh_soro_data(prh_soro *soro) {
    return *(void **)((prh_byte *)soro + 8);
}

prh_coro_struct *prh_coro_init(int start_id, int maxcoros);
void prh_coro_create(prh_coro_struct *s, prh_coroproc_t proc, int stack_size, void *userdata);
void *prh_coro_creatx(prh_coro_struct *s, prh_coroproc_t proc, int stack_size, int maxudsize);
bool prh_coro_cycle_start(prh_coro_struct *s);
bool prh_coro_start(prh_coro_struct *s, int index);
void prh_coro_reload(prh_coro_struct *s, int index, prh_coroproc_t proc); // udata is not reset
void prh_coro_finish(prh_coro_struct **s);

typedef struct {
    prh_i32 start_id; // 1st field dont move
    prh_coro *coro; // last field dont move, only used by soro_struct
} prh_soro_struct;

prh_inline int prh_soro_main_id(prh_soro_struct *s) {
    return s->start_id;
}

prh_inline int prh_coro_main_id(prh_coro_struct *s) {
    return prh_soro_main_id((prh_soro_struct *)s);
}

void prh_soro_init(prh_soro_struct *s, int start_id);
void prh_soro_create(prh_soro_struct *s, prh_soroproc_t proc, int stack_size, void *userdata);
void *prh_soro_creatx(prh_soro_struct *s, prh_soroproc_t proc, int stack_size, int maxudsize);
bool prh_soro_start(prh_soro_struct *s);
void prh_soro_reload(prh_soro_struct *s, prh_soroproc_t proc); // udata is not reset
void prh_soro_finish(prh_soro_struct *s);

#ifdef PRH_CORO_STRIP_PREFIX
#define coro_t                  prh_coro
#define soro_t                  prh_soro
#define coro_struct_t           prh_coro_struct
#define soro_struct_t           prh_soro_struct
#define coro_proc_func          prh_coro_proc
#define soro_proc_func          prh_soro_proc
#define coro_get_data           prh_coro_data
#define soro_get_data           prh_soro_data
#define coro_self_id            prh_coro_self_id
#define soro_self_id            prh_soro_self_id
#define coro_main_id            prh_coro_main_id
#define soro_main_id            prh_soro_main_id
#define coro_yield              prh_coro_yield
#define soro_yield              prh_soro_yield
#define coro_init               prh_coro_init
#define coro_create             prh_coro_create
#define coro_creatx             prh_coro_creatx
#define coro_cycle_start        prh_coro_cycle_start
#define coro_start              prh_coro_start
#define coro_reload             prh_coro_reload
#define coro_finish             prh_coro_finish
#define soro_init               prh_soro_init
#define soro_create             prh_soro_create
#define soro_creatx             prh_soro_creatx
#define soro_start              prh_soro_start
#define soro_reload             prh_soro_reload
#define soro_finish             prh_soro_finish
#endif // PRH_CORO_STRIP_PREFIX

#ifdef PRH_CORO_IMPLEMENTATION
#ifndef PRH_CORO_DEBUG
#define PRH_CORO_DEBUG PRH_DEBUG
#endif

#define prh_lower_guard_word 0x5a5a5a5a
#define prh_upper_guard_word 0xa5a5a5a5

struct prh_impl_coro_guard {
    prh_u32 lower_guard_word;
    prh_u32 upper_guard_word;
};

prh_fastcall(int) prh_impl_asm_stack_init_depth(void);
prh_fastcall(void) prh_impl_asm_coro_call(void);
prh_fastcall(void) prh_impl_asm_soro_call(void);

void prh_impl_coro_stack_segmentation_fault(prh_coro *coro) {
    printf("coro %p stack segmentation fault\n", (void *)coro);
    abort();
}

// coroutine stack layout:
//  lower memery address
//  [prh_impl_coro_guard    ]
//  [       ...             ]
//  [       ...             ]          ^
//  [       ...             ]          ^
//  [stack memory data      ] <-- rsp  | <-- stack top
//  [stack memory data      ]
//  [stack memory data      ] <-- stack bottom
//  [prh_coro: rspoffset    ] <-- coro
//  [prh_coro: ...          ]
//  [coroutine userdata area]
//  upper memory address
struct prh_impl_coro {
    prh_i32 rspoffset; // 1st field dont move
    prh_i32 loweraddr;
    void *userdata;
};

// prh_coro_struct layout:
//  [prh_coro_struct]
//  [prh_coro *]
//  [prh_coro *]
struct prh_impl_coro_struct {
    prh_i32 start_id; // 1st field dont move
    prh_i32 real_cnt;
    prh_i32 maxcoros;
    prh_i32 coro_cnt;
};

typedef struct prh_impl_coro_main {
    prh_i32 rspoffset; // 1st field dont move
    prh_i32 start_id; // 2nd field dont move
    struct prh_impl_coro_main *next; // 3rd field dont move
    prh_i32 curr_index; // coro index start from 1
    prh_u32 end_count: 31, yield_cycle: 1;
    prh_coro **coro_list;
} prh_impl_coro_main;

typedef struct {
    prh_i32 rspoffset; // 1st field dont move
    prh_i32 start_id; // 2nd field dont move
    prh_impl_coro_main *next; // 3rd field dont move
} prh_impl_soro_main;

prh_inline int prh_impl_coro_struct_alloc_size(int maxcoros) {
    assert(maxcoros >= 1);
    assert(sizeof(prh_coro_struct) % sizeof(void *) == 0);
    return (int)(sizeof(prh_coro_struct) + maxcoros * sizeof(void *));
}

prh_coro_struct *prh_coro_init(int start_id, int maxcoros) {
    int alloc_size = prh_impl_coro_struct_alloc_size(maxcoros);
    prh_coro_struct *s = (prh_coro_struct *)prh_calloc(alloc_size);
    s->start_id = start_id;
    s->maxcoros = maxcoros;
    return s;
}

prh_inline struct prh_impl_coro_guard *prh_impl_coro_guard(prh_coro *coro) {
    return (struct prh_impl_coro_guard *)((char *)coro - coro->loweraddr);
}

void prh_impl_coro_guard_verify(prh_coro *coro) {
    struct prh_impl_coro_guard *g = prh_impl_coro_guard(coro);
    if (g->lower_guard_word != prh_lower_guard_word || g->upper_guard_word != prh_upper_guard_word) {
        prh_impl_coro_stack_segmentation_fault(coro);
    }
}

#define prh_impl_coro_size 16
prh_static_assert(sizeof(prh_coro) <= prh_impl_coro_size);

prh_inline int prh_impl_coro_extend_size(int coro_extend_size) {
    return prh_impl_coro_size + (int)prh_round_16_byte(coro_extend_size);
}

int prh_impl_coro_cache_line_aligned_alloc_size(int stack_size, int coro_extend_size, int maxudsize) {
    assert(coro_extend_size >= 0 && maxudsize >= 0);
    int coro_size = (int)prh_round_cache_line_size(prh_impl_coro_size + coro_extend_size);
    int data_size = (int)prh_round_cache_line_size(maxudsize);
    int stack_size = (int)prh_round_cache_line_size(stack_size);
    prh_real_assert(stack_size > coro_size + data_size + (int)sizeof(struct prh_impl_coro_guard) + prh_impl_asm_stack_init_depth());
    return stack_size;
}

prh_coro *prh_impl_coro_cache_line_aligned_init(void *stack, int stack_size, int coro_extend_size, int maxudsize) {
    assert(coro_extend_size >= 0 && maxudsize >= 0);
    int coro_size = (int)prh_round_cache_line_size(prh_impl_coro_size + coro_extend_size);
    int data_size = (int)prh_round_cache_line_size(maxudsize);
    int stack_size = (int)prh_round_cache_line_size(stack_size);
    prh_real_assert(stack_size > coro_size + data_size + (int)sizeof(struct prh_impl_coro_guard) + prh_impl_asm_stack_init_depth());

    prh_coro *coro = (prh_coro *)((prh_byte *)stack + stack_size - coro_size - data_size);
    memset(coro, 0, coro_size + data_size);
    coro->loweraddr = (prh_i32)((char *)coro - (prh_byte *)stack);
    coro->userdata = (char *)coro + coro_size;

    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    guard->lower_guard_word = prh_lower_guard_word;
    guard->upper_guard_word = prh_upper_guard_word;
    return coro;
}

prh_coro *prh_impl_coro_alloc(int stack_size, int coro_extend_size, int maxudsize) {
    assert(maxudsize >= 0);
    int coro_size = prh_impl_coro_extend_size(coro_extend_size);
    int data_size = (int)prh_round_16_byte(maxudsize);
    prh_real_assert(stack_size > coro_size + data_size + (int)sizeof(struct prh_impl_coro_guard) + prh_impl_asm_stack_init_depth());

    int stackallocsize = (int)prh_round_16_byte(stack_size);
    char *p = (char *)prh_16_byte_aligned_malloc(stackallocsize);
    prh_coro *coro = (prh_coro *)(p + stackallocsize - coro_size - data_size);
    memset(coro, 0, coro_size + data_size);
    coro->loweraddr = (prh_i32)((char *)coro - p);
    coro->userdata = (char *)coro + coro_size;

    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    guard->lower_guard_word = prh_lower_guard_word;
    guard->upper_guard_word = prh_upper_guard_word;
    return coro;
}

prh_coro *prh_impl_coro_alloc_set(prh_coro **slot, int stack_size, int coro_extend_size, int maxudsize) {
    assert(*slot == prh_null);
    prh_coro *coro = prh_impl_coro_alloc(stack_size, coro_extend_size, maxudsize);
    *slot = coro;
    return coro;
}

void prh_impl_coro_load_stack(prh_coro *coro, prh_ptr proc, prh_ptr coro_call_func) {
    prh_impl_coro_guard_verify(coro);
    // [32-bit architecture]
    // pstack + alloc <-- 00 <-- 16字节对齐
    //           proc <-- 12
    //                <-- 08 prh_impl_asm_coro_call
    // [64-bit architecture]
    // pstack + alloc <-- 00 <-- 16字节对齐
    //           proc <-- 08
    //                <-- 00 prh_impl_asm_coro_call
    assert((prh_unt)coro % 16 == 0); // initial rsp shall 16-byte aligned
    void **rsp = (void **)coro;
    *(--rsp) = (void *)proc;
    *(--rsp) = (void *)coro_call_func;
    coro->rspoffset = (prh_i32)((char *)coro - (char *)rsp);
}

prh_inline void prh_impl_coro_load(prh_coro *coro, prh_coroproc_t proc) {
    prh_impl_coro_load_stack(coro, (prh_ptr)proc, (prh_ptr)prh_impl_asm_coro_call);
}

prh_inline void prh_impl_soro_load(prh_coro *coro, prh_soroproc_t proc) {
    prh_impl_coro_load_stack(coro, (prh_ptr)proc, (prh_ptr)prh_impl_asm_soro_call);
}

prh_coro *prh_impl_soro_create(prh_soroproc_t proc, int stack_size, int coro_extend_size, void *userdata) {
    prh_coro *coro = prh_impl_coro_alloc(stack_size, coro_extend_size, 0);
    prh_impl_soro_load(coro, proc);
    coro->userdata = userdata;
    return coro;
}

prh_coro *prh_impl_soro_creatx(prh_soroproc_t proc, int stack_size, int coro_extend_size, int maxudsize) {
    prh_coro *coro = prh_impl_coro_alloc(stack_size, coro_extend_size, maxudsize);
    prh_impl_soro_load(coro, proc);
    return coro;
}

prh_coro **prh_impl_coro_list(prh_coro_struct *s) {
    return (prh_coro **)(s + 1);
}

prh_coro **prh_impl_coro_find_free_slot(prh_coro_struct *s) {
    assert(s->coro_cnt >= 0 && s->coro_cnt < s->maxcoros);
    prh_coro **coro_list = prh_impl_coro_list(s);
    for (int i = s->coro_cnt; i < s->maxcoros; i += 1) {
        if (coro_list[i] == prh_null) {
            s->coro_cnt = i + 1;
            return coro_list + i;
        }
    }
    return prh_null;
}

void prh_coro_create(prh_coro_struct *s, prh_coroproc_t proc, int stack_size, void *userdata) {
    prh_coro **slot = prh_impl_coro_find_free_slot(s);
    prh_coro *coro = prh_impl_coro_alloc_set(slot, stack_size, 0, 0);
    prh_impl_coro_load(coro, proc);
    coro->userdata = userdata;
#if PRH_CORO_DEBUG
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[coro %02d] %p create -- lower %p (left %d) rsp %p coro %p (size %d) data %p (size %d) -- stack %d\n",
        s->start_id + s->coro_cnt, (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, prh_impl_coro_extend_size(0), coro->userdata, 0, stack_size);
#endif
}

void *prh_coro_creatx(prh_coro_struct *s, prh_coroproc_t proc, int stack_size, int maxudsize) {
    prh_coro **slot = prh_impl_coro_find_free_slot(s);
    prh_coro *coro = prh_impl_coro_alloc_set(slot, stack_size, 0, maxudsize);
    prh_impl_coro_load(coro, proc);
#if PRH_CORO_DEBUG
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[coro %02d] %p create -- lower %p (left %d) rsp %p coro %p (size %d) data %p (size %d) -- stack %d\n",
        s->start_id + s->coro_cnt, (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, prh_impl_coro_extend_size(0), coro->userdata, (int)prh_round_16_byte(maxudsize), stack_size);
#endif
    return coro->userdata;
}

prh_coro *prh_impl_coro_get(prh_coro_struct *s, int index) {
    assert(index > 0 && index <= s->coro_cnt);
    return prh_impl_coro_list(s)[index - 1];
}

void prh_coro_reload(prh_coro_struct *s, int index, prh_coroproc_t proc) {
    prh_coro *coro = prh_impl_coro_get(s, index);
    assert(coro && coro->rspoffset == 0); // only finished coro can reload
    prh_impl_coro_load(coro, proc);
#if PRH_CORO_DEBUG
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[coro %02d] %p reload -- lower %p (left %d) rsp %p coro %p (size %d) data %p --\n",
        s->start_id + index, (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, prh_impl_coro_extend_size(0), coro->userdata);
#endif
}

// 跨线程协程在每个线程中都有一个主协程，每个线程可以有多个主协程，不管是线程主动创建多
// 个主协程，还是一个主协程涉及的子协程创建了主协程，一个线程同一时间只会处理一个主协程
// 及其关联的子协程组合，而且只有当最深层的组合处理完毕才会处理浅层的组合。
prh_thread_local prh_impl_coro_main *PRH_IMPL_CORO_MAIN;

int prh_coro_self_id(prh_coro *coro) {
    struct prh_impl_coro_main *m = PRH_IMPL_CORO_MAIN;
    return m->start_id + m->curr_index;
}

int prh_soro_self_id(prh_soro *coro) {
    struct prh_impl_coro_main *m = PRH_IMPL_CORO_MAIN;
    return m->start_id + 1;
}

void prh_impl_coro_main_yield(prh_impl_coro_main *m, prh_coro *next) {
    m->next = PRH_IMPL_CORO_MAIN;
    PRH_IMPL_CORO_MAIN = m;
    prh_impl_asm_coro_yield((prh_coro *)m, next);
    PRH_IMPL_CORO_MAIN = m->next;
}

prh_coro *prh_impl_get_next_resume(prh_impl_coro_main *m) {
    for (int i = m->curr_index; i < (int)m->end_count; i += 1) {
        prh_coro *next = m->coro_list[i];
        if (next && next->rspoffset) {
            m->curr_index = i + 1;
            return next;
        }
    }
    m->curr_index = 0;
    return (prh_coro *)m;
}

prh_coro *prh_impl_next_resume_coro(void) {
    struct prh_impl_coro_main *m = PRH_IMPL_CORO_MAIN;
    if (m->yield_cycle == 0) return (prh_coro *)m;
    prh_coro *next = prh_impl_get_next_resume(m);
    return next;
}

prh_fastcall(void *) prh_impl_asm_coro_finish(prh_coro *coro) {
    coro->rspoffset = 0;
    prh_impl_coro_guard_verify(coro);
    return prh_impl_next_resume_coro();
}

prh_fastcall(void *) prh_impl_asm_soro_finish(prh_coro *coro) {
    coro->rspoffset = 0;
    prh_impl_coro_guard_verify(coro);
    return PRH_IMPL_CORO_MAIN;
}

#ifndef PRH_CONO_IMPLEMENTATION
prh_fastcall(void *) prh_impl_asm_cono_finish(prh_coro *coro) {
    return prh_impl_asm_soro_finish(coro);
}
#endif

bool prh_coro_cycle_start(prh_coro_struct *s) {
    prh_impl_coro_main mainstack;
    mainstack.coro_list = prh_impl_coro_list(s);
    mainstack.start_id = s->start_id;
    mainstack.end_count = s->coro_cnt;
    mainstack.curr_index = 0;
    mainstack.yield_cycle = 1;
    prh_coro *next = prh_impl_get_next_resume(&mainstack);
    if (next == (prh_coro *)&mainstack) {
        return false;
    }
#if PRH_CORO_DEBUG
    printf("[coro %02d] %p start %02d\n", s->start_id, (void *)&mainstack, s->start_id + mainstack.curr_index);
#endif
    prh_impl_coro_main_yield(&mainstack, next);
    return true;
}

bool prh_coro_start(prh_coro_struct *s, int index) {
    prh_impl_coro_main mainstack;
    mainstack.coro_list = prh_impl_coro_list(s);
    mainstack.start_id = s->start_id;
    mainstack.end_count = s->coro_cnt;
    mainstack.yield_cycle = 0;
    prh_coro *next = prh_impl_coro_get(s, index);
    if (next == prh_null || next->rspoffset == 0) {
        return false;
    }
    mainstack.curr_index = index;
#if PRH_CORO_DEBUG
    printf("[coro %02d] %p start %02d\n", s->start_id, (void *)&mainstack, s->start_id + mainstack.curr_index);
#endif
    prh_impl_coro_main_yield(&mainstack, next);
    return true;
}

prh_inline void prh_impl_coro_free(prh_coro *coro) {
    prh_aligned_free(prh_impl_coro_guard(coro));
}

void prh_coro_finish(prh_coro_struct **main) {
    prh_coro_struct *s = *main;
    if (s == prh_null) return;
    prh_coro **start = prh_impl_coro_list(s);
    for (int i = 0; i < s->maxcoros; i += 1) {
        prh_coro *coro = start[i];
        if (coro) {
            prh_impl_coro_free(coro);
            start[i] = prh_null;
        }
    }
    *main = prh_null;
    prh_free(s);
}

void prh_soro_init(prh_soro_struct *s, int start_id) {
    s->start_id = start_id;
    s->coro = prh_null;
}

void prh_soro_create(prh_soro_struct *s, prh_soroproc_t proc, int stack_size, void *userdata) {
    assert(s->coro == prh_null);
    s->coro = prh_impl_soro_create(proc, stack_size, 0, userdata);
#if PRH_CORO_DEBUG
    prh_coro *coro = s->coro;
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[coro %02d] %p create -- lower %p (left %d) rsp %p coro %p (size %d) data %p (size %d) -- stack %d\n",
        s->start_id + 1, (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, prh_impl_coro_extend_size(0), coro->userdata, 0, stack_size);
#endif
}

void *prh_soro_creatx(prh_soro_struct *s, prh_soroproc_t proc, int stack_size, int maxudsize) {
    assert(s->coro == prh_null);
    prh_coro *coro = prh_impl_soro_creatx(proc, stack_size, 0, maxudsize);
    s->coro = coro;
#if PRH_CORO_DEBUG
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[coro %02d] %p create -- lower %p (left %d) rsp %p coro %p (size %d) data %p (size %d) -- stack %d\n",
        s->start_id + 1, (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, prh_impl_coro_extend_size(0), coro->userdata, (int)prh_round_16_byte(maxudsize), stack_size);
#endif
    return coro->userdata;
}

void prh_soro_reload(prh_soro_struct *s, prh_soroproc_t proc) {
    prh_coro *coro = s->coro;
    assert(coro && coro->rspoffset == 0); // only finished coro can reload
    prh_impl_soro_load(coro, proc);
#if PRH_CORO_DEBUG
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[coro %02d] %p reload -- lower %p (left %d) rsp %p coro %p (size %d) data %p --\n",
        s->start_id + 1, (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, prh_impl_coro_extend_size(0), coro->userdata);
#endif
}

void prh_impl_soro_start(int cono_id, prh_coro *coro) {
    assert(coro && coro->rspoffset);
    prh_impl_soro_main mainstack;
#if PRH_CORO_DEBUG
    printf("[thrd %02d] cono %02d launched at stack %p <=> %p\n", prh_thrd_self_id(), cono_id, (void *)&mainstack, coro);
#endif
    prh_impl_coro_main_yield((prh_impl_coro_main *)&mainstack, coro);
}

bool prh_soro_start(prh_soro_struct *s) {
    prh_impl_soro_main mainstack;
    mainstack.start_id = s->start_id;
    prh_coro *next = s->coro;
    if (next == prh_null || next->rspoffset == 0) {
        return false;
    }
#if PRH_CORO_DEBUG
    printf("[soro %02d] %p start %02d\n", s->start_id, (void *)&mainstack, s->start_id + 1);
#endif
    prh_impl_coro_main_yield((prh_impl_coro_main *)&mainstack, next);
    return true;
}

void prh_soro_finish(prh_soro_struct *main) {
    prh_coro *coro = main->coro;
    if (coro == prh_null) return;
    prh_impl_coro_free(coro);
    main->coro = prh_null;
}
#endif // PRH_CORO_IMPLEMENTATION
#endif // PRH_CORO_INCLUDE

// https://en.cppreference.com/w/c/atomic/memory_order
// https://learn.microsoft.com/en-us/cpp/standard-library/atomic
// https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html
// https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync
// https://research.swtch.com/mm
//
// 在串行程序中，程序的不变性比较容易维护，例如队列的元素数量必须小于或等于用来存储元素
// 的数组长度、头节点和尾节点的下标必须在合理范围内等等，我们只要在所有共有方法的入口点
// 和出口点都维持这个不变性，那么就足以保证代码的正确性。
//
// 当在系统中引入并发时，事件将变得非常困难。除非使用了某种特殊方法，否则你将不得不在编
// 写每一行代码时都要保证这些不变性。然而，即便如此也往往还不够，因为有时候一行代码（无
// 论你采用何种高级编程语言）会被编译为多条机器语言指令。而且，如果在操作中涉及多个变量，
// 那么这项任务将几乎不可能完成，这就需要某种特别形式的状态管理方式，例如彼此独立、不可
// 修改、或者保持同步。
//
// 当然最简单的方法是完全避免对数据进行共享或者更新。但不幸的是，即使采用这种方法，在有
// 些情况下仍然需要使用同步。例如，你需要将状态的中间变化过程局限在某个线程中，直到所有
// 操作完成。然后，当需要将状态向外公开时，你必须通过某种机制将这些变化通知到全局内存空
// 间，其他线程则需要从全局内存空间读取这些状态，这两个动作必须是单一的和不可分割的原子
// 操作。要实现这种方式并不容易，由于目前的硬件并不支持以原子的方式来读取和写入任意数量
// 的内存空间，因此在软件中必须通过临界区来模拟这一过程。临界区能够保证每次只有一个线程
// 执行某段特定的代码，这就消除了在多个线程之间发生相互干扰的问题，并且强制实施依次执行
// 的顺序。这意味着系统中的一些线程必须等到其他线程完成工作之后，才能开始执行它自己的工
// 作。
//
// 一个简单的数据竞争示例。int *a = ...; (*a)++; 这里 a 是一个指向某个共享内存位置的
// 指针，(*a)++ 是对这个共享位置的数据进行加一操作，当编译成机器代码时将包含多条机器指
// 令： 读取 mov eax, [a]   更新 inc eax    写入 mov [a], eax 。实际上，这一步骤类
// 似于将代码改为：int *a = ...; int tmp = *a; tmp++; *a = tmp; 。
//
// 任何需要多条机器指令的运算都是非原子的，此外还有一些非原子的操作并非像上面代码那样明
// 显。在现代处理器中通常能够保证：如果在递增运算中对内存的读写操作是以机器字长大小单位
// （即 CPU 的内存寻址单位），那么将以原子方式来执行这些操作，例如在 32 位机器上执行 32
// 位值的递增，在 64 位机器上执行 64 位值的递增。相反，如果在读写数据时使用的字节数要大
// 于 CPU 的内存寻址单位，那么这些操作是非原子的。例如，如果在 32 位机器上写入一个 64
// 位的值，那么这个操作就需要两条 mov 指令将这个值从处理器的私有内存移动动到共有内存，其
// 中每条指令复制 4 各字节。同样，如果在未对齐的地址，即地址的范围至少跨越了一个内存寻址
// 单位，上执行读写操作，那么也需要执行多次内存操作，此外还可能需要一些位掩码操作和移动
// 操作，即使这个值所占的内存空间小于或者等于机器的内存寻址单位也是如此。对齐是一个非常
// 复杂的主题。
//
// 那么，为什么在并发执行非原子运算时会出现问题？虽然加载寄存器和保存寄存器本身都是原子
// 的，但是将加载、递增、保存这三条指令放在一起组成的操作却是非原子的。每个线程都在单独
// 的处理器上运行，这意味着每个处理器都拥有自己的私有 eax 寄存器，但所有线程看到的 a 都
// 指向相同的并且访问同一块共享内存，我们可以通过时间刻度来分析这个并发指向行为。这三条
// 指令不会真正地同时执行，虽然处理器可以同时执行多条指令，但有一点非常重要，即带有缓存
// 一致性机制的内存系统将确保一致的内存全局视图。因此，我们可以以一种简单的、串行的时间
// 刻度来描述程序的执行流程。
//
// 执行以下流程我们编写的算法仍然是安全的：
//      t1 -> t1 -> t1 -> t3 -> t3 -> t3 -> t2 -> t2 -> t2
//      t2 -> t2 -> t2 -> t1 -> t1 -> t1 -> t3 -> t3 -> t3
//      t2 -> t2 -> t2 -> t3 -> t3 -> t3 -> t1 -> t1 -> t1
//      t3 -> t3 -> t3 -> t1 -> t1 -> t1 -> t2 -> t2 -> t2
//
// 这些执行流程都将产生正确的结果，因为每个线程的操作都不会与其他线程的操作发生相互干扰，
// 在每个执行流程中，第一个线程都将一直运行到结束，然后是第二个第三个线程依次执行完成。
// 在这些执行流程中，所有线程都是串行执行的，或者说执行流程是串行的。
//
// 然而，这个示例的正确运行完全是出于偶然，在程序中没有采取任何措施防止在多个线程的操作
// 之间发生干扰，这将使得多个线程的执行时间相互重叠并导致竟态条件的发生。让我们暂时先忽
// 略 t3：  t1 -> t2 -> t2 -> t2 -> t1 -> t1 。如果 *a 最开始的值为 0，由于执行了两
// 次递增运算，我们期待结果是 2，但实际上最终结果为 1。这很明显违背了算法的第一个正确性
// 条件：每个线程在执行了递增运算之后，全局的计数器都将增加 1。这是一个典型的竟态条件问
// 题，或者更准确地说是一个数据竞争问题，这个问题是由于缺乏对数据进行同步而导致的。之所
// 以被称为 “竞争”，是因为代码执行的正确性完全依赖于多个线程之间的竞争结果。每个线程都
// 试图最先执行完代码，并且根据哪个线程最先执行完成，程序将产生不同的结果，这些结果有时
// 候是正确的，有时候是错误的。竞争只是在涉及共享状态时出现的众多问题之一，它可能对程序
// 的正确性造成严重的危害。
//
// 注意，在单处理器的机器上同样可能出现这个问题，如果 t1 刚刚将 a 的值移入 eax 或者 t1
// 刚刚执行完递增操作时就发生了上下文切换。发生切换的原因可能是 t1 的执行时间片已经使用
// 完，或者由于 t2 是一个更高优先级的线程，那么都会导致同样的问题。
//
// 我们将 t3 加入到执行流程示意图中，那么将可能违背递增运算的第二个正确性条件：
//      t3 -> t1 -> t1 -> t1 -> t2 -> t2 -> t2 -> t3 -> t3
//
// 第二个正确性条件是这个值只能单调地增长，当 t1 和 t2 执行完时，从系统其他线程的角度，
// 一切似乎都在正确的运行，因为值从 0 递增到了 1 和 2。但是此时 t3 继续执行时，它将覆盖
// t1 和 t2 的执行结果，重新将值设置为 1。此时如果 t2 再次运行，它所看到的值将比前一次
// 看到的值（2）要小。这很明显是一个问题，并且这个问题将破坏整个算法。
//
// 一个重要的问题是，程序中的许多操作都不是原子操作，因为在这些操作中包含了多个逻辑步骤，
// 而每个逻辑步骤又可能包含多个物理步骤等。简单来说，原子性就是指单个操作或者一组操作能
// 够一次性执行完成，并且不会被打断。任何状态修改以及相应的操作都是快速执行完成的，系统
// 中的所有其他线程将看不到在原子操作中出现的中间状态。同样，原子操作一定不能在更新状态
// 的过程中发生故障，如果发生故障，那么必须通过相应的回滚机制恢复到之前的状态。
//
// 根据这个定义，我们很难在实际编程中实现原子性。虽然处理器能够在对对齐的内存执行写入操
// 作时保证原子性，但一些更高级别的逻辑操作（例如调用对象的某个方法）则并非如此简单。事
// 实上，有时候我们希望在执行一些跨越机器物理边界的操作时也能实现原子性，这些操作可能需
// 要与 Web 服务或者数据库交互，此时保证原子性的难度将更大。在实现原子性时，除了简单的
// 读写操作外，我们还必须使用系统提供的各种控制机制。比如已提到的临界区可以模拟内存更新
// 操作的原子性。当涉及多个资源或者持久化的资源时，数据库中的事务、COM+ 以及 .NET 中的
// System.Transactions 命名空间等，都是一些颇具吸引力的解决方案。Win32 和 .NET 框架
// 平台提供了一组工具通过数据同步来实现原子性。熟悉关系数据库的开发人员可能会在其中发现
// 一些相似之处：数据库通过事务来实现串行化的操作，并为程序员提供了一个接口来使用原子性、
// 一致性、独立性、和持久性（Atomicity Consistency Isolation Durabiliry, ACID）。
//
// 当程序需要使用共享的可变状态时，同步时唯一能够保证程序正确的技术。目前，同步这个术语
// 已经被过度地使用，这使得它的含义变得非常模糊。我们应该对两种不同但却紧密相关的同步进
// 行区别：数据同步和控制同步。
//
// 数据同步，我们必须对共享资源（包括内存）进行保护，这一当多个线程以并行方式使用相同的
// 资源时不会发生相互干扰。控制同步，在多个线程之间，一个线程通常需要等待其他线程执行到
// 程序中的某个特定点，例如由于在执行完算法的某个步骤之后需要汇总和交换数据，或者由于线
// 程需要协调其他的线程并且告诉它们接下来需要做什么。这两种技术并不是相互排斥的，我们通
// 常需要将它们结合起来使用。例如，我们可能希望生产者线程向共享缓冲区中写入一些数据后，
// 能够通知消费者线程，此时就需要使用控制同步，我们同样还需要确保生产者和消费者能够安全
// 访问这个数据，这就需要使用数据同步。
//
// 所有的同步操作大致上都可以归类到这两种类型种。在实际情况种，我们可以通过多种方式来实
// 现程序种的数据同步和控制同步。实现方式的选择对于能否成功地使用并发来说是非常重要的。
// 在这个选择过程种需要考虑很多因素。比如正确性，即所选择的实现方式能否带来正确的代码；
// 性能，即对算法串行性能的影响；可伸缩性，即如果提供更多的处理器，那么系统的吞吐量能否
// 相应的提升，或者至少不会降低。
//
// 对于一般性的数据竞争问题，解决方案之一就是将共享状态的并发访问串行化。互斥是最常使用
// 的一种技术，用来保证每次只有一个线程能够执行那些容易发生并发问题的指令区域。涉及的技
// 术有锁（Lock），互斥量（Mutex），临界区（Critical Section），监视器（Monitor），
// 二值信号量（Binary Semaphore），读写锁（R/W Lock），以及事务。信号量是临界区思想的
// 一种扩展，它允许一定数量的线程同时出现在临界区中。
//
// 程序在临界区中执行的时间要尽量可能少，这是为了提高程序的执行性能。另外，最令人注意的
// 问题就是如何对临界区中抛出的异常进行处理。通常，程序希望确保正确的退出临界区，即使临
// 界区在异常环境中被终止。然而，如果在发生故障时只是简单地释放锁，那么往往还不够。还记
// 得原子性的定义中：原子操作要么完全完成，要么完全不完成。如果在发生故障后立即释放锁，
// 那么可能会在程序的剩余部分造成数据破坏。
//
// 当使用临界区时，你必须确定哪些数据需要在临界区中保护。有两种方式来组织临界区：粗粒度
// 和细粒度。粗粒度通过单个临界区来保护程序中的所有数据，这使得程序以单线程形式运行，因
// 为每次只有一个线程能够执行操作。这是保持程序正确性的最简单的方式，只有一个锁需要管理，
// 并且只有一个锁需要获取和释放，这种方式减少了在实现同步时需要的空间和时间，我们只需要
// 非常少的工作就可以确保程序的安全性。然而，这种过程保守的方法可能会由于伪共享（false
// sharing）问题而对程序的可伸缩性带来负面影响。伪共享不必要地阻止对某些数据的并发访问，
// 即通过对访问施加一些不必要的保护来确保程序执行的正确性。为了提高程序的可伸缩性，我们
// 可以对每一部分数据都使用一个锁，这使得多个线程能够同时访问不相交的数据部分。这种方式
// 能够减少或消除伪共享，使线程实现更高程度的并发以提高可伸缩性。这种方法的缺点在于需要
// 管理大量的锁，空间时间上的复杂性大大增加，如果使用不当还会导致死锁问题。如果在多个数
// 据结构之间存在着复杂的不变性关系，那么要消除数据竞争问题就会变得更加困难。
//
// 没有任何一种方法能够适用于所有情况，程序通常会将这两种极端情况之间找到某种平衡并且将
// 一些技术结合起来使用。但一条通用的经验法则是，首先从粗粒度的锁定开始以确保程序的正确
// 性，然后再根据可伸缩性的需求来调整更细粒度的区域，通过这种方法将可以实现更可维护的、
// 更易于理解的和错误更少的程序。
//
// 在实际编程中很少会直接将内核对象作为主要的同步机制，理由很简单，直接使用内核对象需要
// 做更多的工作，在访问和管理这些对象时需要执行内核切换操作，这将消耗大量的时钟周期，此
// 外操作系统的各个辅助数据结构也将消耗大量的内存空间。然而，如果程序必须精确地等待某个
// 事件发生，那么你最终还是不得不使用某种形式的内核对象。但即便如此，我们通常还是会优先
// 选择更高层的抽象同步结构，这些结构隐藏了对内核对象的使用和管理。
//
// Win32 和 .NET 框架都提供了一些机制来实现这种抽象，这些机制通常会使用延迟分配（Lazy
// Allocation）技术并且在某些情况下还将使用对象池结构，这样可以将单个内核对象在多个高层
// 并发对象中重用。延迟分配是指将分配操作尽可能地推迟到最晚的时间点，并且只有在绝对必要
// 时才触发内核切换操作，因此既节约了空间又节约了时间。这些抽象层除了确保正确的功能以及
// 提供更优的性能外，还形成了一些常见的编程模式，如果没有这些模式，那么你将需要通过内核
// 对象来手动构造它们，例如共享模式的锁以及条件变量。
//
// Win32 的临界区（Critical Section）为非托管代码提供了更为高效的互斥机制。它们在功能
// 上基本等同于互斥体，并且支持递归获取。进入临界区和离开临界区等操作都是在用户态中执行
// 的，除了在发生锁竞争的很少情况下，需要使用一个真正的内核对象来等待。此时执行获取操作
// 的线程将在这个临界区上等待，这个等待是通过将自旋等待与临界区底层的自动重置内核对象结
// 合起来实现的。可以以任何形式创建 CRITICAL_SECTION，唯一的要求就是，在初始化临界区后，
// 永远都不要复制或者移动临界区的内存。CRITICAL_SECTION 的大小在 32 位系统上大概 24 个
// 字节，在 64 位系统上大概 40 个字节。临界区的初始化和删除操作，必须确保在任何时刻，在
// 任意一个临界区对象上只能有一个线程调用初始化或删除函数，并且只有在没有其他线程拥有这
// 个临界区对象的情况下才可以执行这些操作。如果忽略了这个要求，那么可能导致不可预期的行
// 为。
//
// 临界区通常会通过自旋来避免在多处理器机器上发生阻塞，简单来说，自旋比等待将浪费更少的
// CPU 时钟周期。如果线程在执行自旋等待时临界区变得可用，那么线程就不需要在内部事件上发
// 生阻塞。对于获取这个锁的线程来说，阻塞操作至少需要两次上下文切换，每次切换都将消耗数
// 千个时钟周期：当线程开始等待时发生一次切换，当锁被释放时线程必须醒来获得这个锁，此时
// 将发生第二次切换。在执行等待时至少需要一次内核切换操作。如果在自旋上所花的时间小于在
// 切换操作中所花的时间，那么通过避免阻塞将极大地提高吞吐量。另一方面，如果在执行自旋等
// 待时临界区依然没有变得可用，那么线程将由于自旋而浪费一定的 CPU 时钟周期，这些时钟周
// 期本可以用于上下文切换操作，并且让其他的线程运行。因此，在使用自旋等待时必须非常小心
// 和谨慎。在默认情况下，EnterCriticalSection 不会执行任何自旋等待，每个临界区都有一个
// 默认的自旋计数值 0。在单处理器机器上通常会忽略自旋计数值，因为在这种情况下自旋操作是
// 没有意义的。最优的自旋计数值并不是唯一的，在不同的机器之间可能有着不同的值。根据堆管
// 理器开发团队提供的经验，MSDN 文档推荐的最优值为 4000。对平均情况而言，1500 左右的值
// 是一个更为合理的起始点，但应该根据实际测试的可伸缩性来进行调节。虽然在初始化临界区之
// 后还可以通过 SetCriticalSectionSpinCount 修改，并且根据执行过程中收集的统计信息进
// 行调整，但自旋计数通常是一个在性能测试期间确定的常量值。
//
// Windows Vista 有一个新功能可以动态地调节自旋计数。虽然在操作系统内部使用了这个功能，
// 但它并没有被公开。在将来的 Windows SDK 中可能会正式地公开和支持这个功能，但也可能不
// 会公开，因此我建议不要依赖它。如果使用了 InitializeCriticalSectionEx，并且在 Flags
// 值中指定 RTL_CRITICAL_SECTION_FLAG_DYNAMIC_SPIN，那么生成的临界区将会使用过一种动
// 态的自旋算法。这个值是在 WinNT.h 中定义的，而不是在 Windows.h 中。当通过这种方式来
// 初始化临界区，那么指定的自旋计数将被忽略。相反，自旋计数值在开始时将是某个默认的数值，
// 并且操作系统将根据之前的自旋操作与阻塞的比较来对其进行动态调整。这种动态调整算法的目
// 的是将自旋计数稳定下来，并且如果自旋并不能在统计上减少上下文切换的发生次数，那么将停
// 止自旋。虽然这个功能很有意思，但它只是一个实验性的功能，这也就是为什么它没有被公开的
// 原因，并且我们也不清楚在程序中使用这个功能是否会带来任何重要的价值。
//      #include <windows.h>
//      #include <winnt.h>
//      InitializeCriticalSectionEx(&cs, 0, RTL_CRITICAL_SECTION_FLAG_DYNAMIC_SPIN);
//
// Windows 增加了一种新的内核对象类型来处理低资源情况，称之为键值事件（Keyed Event）。   *** 键值事件是隐藏在内核中，并没有直接公开出来
// 键值事件是隐藏在内核中，并没有直接公开出来，尽管我们将在新的 Windows Vista 同步原语
// 中看到大量地使用了它（与轻量读写锁以及条件变量一样）。当内存不足以分配一个真正的事件
// 时，EnterCriticalSection 将使用键值事件。此时进程的所有临界区之间将共享一个键值事件，
// 称之为 \KernelObjects\CritSecOutOfMemoryEvent。每个进程都有一个指向键值事件的句柄，
// 在调试器中执行 !handle 命令将会看到这个句柄。在程序代码中不需要初始化或者创建这个对
// 象，它总是存在的和可用的，而不管机器上的资源处于何种情况。
//
// 键值事件的工作原理是什么？键值事件使得多个线程能够在同一个事件上执行设置或者等待操作。
// 但只有一个全局的事件并不足以解决临界区问题，事实上，每个临界区都需要有一个事件。为了
// 解决这种困境，当线程在这个事件上执行等待或者设置等操作时，它必须指定一个键值，这个键
// 值是一个指针大小的值，它代表对事件的某种抽象和唯一标识。当线程使用某个键值 K 设置了
// 事件，那么将唤醒一个在 K 上等待的线程。然而，只有当前进程中的等待线程会被唤醒，因此
// 不同进程之间的 K 相互是独立的。内存地址通常被用作 K 值，这也是临界区、轻量读写锁、条
// 件变量使用键值事件的方式。你可以在进程中获取任意数量的抽象事件，并且不需要为每个地址
// 分配一个真正的事件对象。
//
// 如果有 N 个等待线程必须被唤醒，那么同样的键值 K 必须被设置 N 次。因此，要模拟一个手
// 动重置的事件，需要通过一个辅助数据结构来记录等待线程列表。当然临界区并不需要这个功能，
// 但对于读写锁和条件变量需要这种功能。Windows XP 中的键值事件实现并不是高效的，键值事
// 件以链表形式来维护等待列表，因此在查找和设置一个键值是遍历性能为 O(N)。这里的 N 是在
// 事件上等待的线程数量，并不区分不同的键值。Windows Vista 对键值事件做出了较大的改进，
// 现在，键值事件不是将等待者放入到链表中，而是使用一个散列表并以键值 K 为散列键（Hash
// Key），虽然这种方式增加了发生散列冲突的概率（因此将出现一定程度的竞争不可预测性），但
// 却提升了查找的性能。这种改进带来的性能提升足以使得键值事件在 Vista 的轻量读写锁、条件
// 变量、单次初始化（One-Time Initialization）等 API 中用作唯一的事件机制。在这些新的
// 功能中都没有使用传统的事件，它们只使用键值事件，这就是为什么新的同步原语都是轻量级的，
// 经常只占据一个指针大小的空间，并且不需要使用任何专门的内核对象。键值事件不仅提升了系统
// 的可靠性，而且还减轻了句柄和非分页等资源的压力，这种改进在整体上是非常受欢迎的。键值
// 事件可以通过条件变量来直接访问，因为它们在内部封装了对键值事件对象的访问。

#ifdef PRH_THRD_INCLUDE
#ifdef PRH_THRD_IMPLEMENTATION
#if defined(prh_plat_windows)
#include <winnt.h> // RTL_CRITICAL_SECTION_FLAG_DYNAMIC_SPIN
prh_inline void prh_impl_critical_section_init(void *critical_section) {
    // VOID InitializeCriticalSection(LPCRITICAL_SECTION); // Windows XP Server 2003 may raise STATUS_NO_MEMORY exception, Windows Vista always succeeds
    // BOOL InitializeCriticalSectionAndSpinCount(LPCRITICAL_SECTION, DWORD Spin); // Windows XP Server 2003 may return FALSE, Windows Vista always succeeds
    // BOOL InitializeCriticalSectionEx(LPCRITICAL_SECTION, DWORD Spin, DWORD Flags); // Windows Vista Windows Server 2008
    // 可传入的旋转次数是从 0 到 0xff_ffff 之间的一个值，注意，如果是在单处理器上调用这个函数那么函数会忽略旋转计数
    // 在临界区中包含了大量的可用调试信息，基本的信息包括所有者线程的标识、递归计数、用于等待的内核对象句柄，以及其他一些信息。如果
    // 在初始化临界区时没有指定 CRITICAL_SECTION_NO_DEBUG_INFO，那么还将包含更多信息，例如临界区被进入的次数、所经历的竞争等。这
    // 些信息会被调试器、性能分析器等工具访问。在调试器中（WinDbg）输入 !locks 命令将输出进程中所有被持有的锁，或 !locks-v 打印所
    // 有的锁，而不考虑它们的所有权状态。
    //      typedef struct _RTL_CRITICAL_SECTION_DEBUG {
    //          WORD Type, CreatorBackTraceIndex;
    //          struct _RTL_CRITICAL_SECTION *CriticalSection;
    //          LIST_ENTRY ProcessLocksList;
    //          DWORD EntryCount, ContentionCount, Flags;
    //          WORD CreatorBackTraceIndexHigh, Identifier;
    //      } RTL_CRITICAL_SECTION_DEBUG;
    //      typedef struct _RTL_CRITICAL_SECTION { // 六个指针（24-byte）或五个指针（40-byte）
    //          PRTL_CRITICAL_SECTION_DEBUG DebugInfo;
    //          LONG LockCount, RecursionCount;
    //          HANDLE OwningThread;
    //          HANDLE LockSemaphore;
    //          ULONG_PTR SpinCount;
    //      } RTL_CRITICAL_SECTION
    DWORD SpinCount = 1000, Flags = CRITICAL_SECTION_NO_DEBUG_INFO; // | RTL_CRITICAL_SECTION_FLAG_DYNAMIC_SPIN;
    prh_boolret(InitializeCriticalSectionEx(critical_section, SpinCount, Flags));
}
#endif
#endif
#endif

// 通常互斥行为只是一种更强的保证，而并不是绝对必要的。如果将一个代码区域都标记为临界区，
// 毫无疑问它确实可以简化工作，并使得代码更容易理解维护和调试。但有时候，我们也会考虑到
// 读/读冲突（多个线程同时读取）是一种安全的行为，我们可以运行多个并发的读取操作访问共享
// 数据，只要在同时不存在写入操作即可。因为读取操作的数量通常大于写入操作的数量（在 mscorlib.dll
// 中，这个比值大约为 2.5 比 1），因此同时进行多个读取操作可以极大地提高代码的可伸缩性。
// 虽然情况并非总是如此，但大多数情况都是这样的。这正是读写锁（RWL）发挥作用的地方。虽然
// 各种 RWL 在具体实现细节上可能有所不同，但基本上都满足以下需求：
//      1.  当线程获取锁时，必须指定这是一个读取操作还是写入操作
//      2.  在任何时刻，最多只有一个写入操作可以持有这个锁，即互斥模式
//      3.  只要存在一个写入操作，那么所有的读取操作都不能持有这个锁
//      4.  在任何时刻，任意数量的读取操作可以同时持有这个锁，即共享模式
//
// Win32 的 “轻量级” 读写锁（Slim R/W Lock）是在 Windows Vista 和 Server 2008 中新
// 引入的，它提供了互斥（Exclusive）和共享（Shared）两种模式，后者可用于只读操作中。共
// 享模式可以是多个执行读操作的线程同时获得锁。这种行为是安全的，并且通常会带来更高程度
// 的并发性以及更好的可伸缩性。SRWL 是比临界区更轻量级的原语，它基本上都是在用户态中执行
// 的并且等于指针的大小，此外在 SRWL 内部也不会使用标准的内核对象来实现等待。这二者之间
// 也存在一些功能差异，例如 SRWL 是不可递归的。在使用 SRWLOCK 之前，必须通过初始化函数
// 进行初始化。由于 SRWL 在内部并没有使用任何动态分配的事件或者内存，因此在使用完之后不
// 需要进行删除。
//
// 如果锁被另一个线程持有，并且持有模式与试图获取的模式不兼容，那么试图获取锁的线程将被
// 阻塞。阻塞是通过一个非警觉等待来实现的，当锁被释放时，如果有读取操作和写入操作同时在
// 等待，那么锁将优先唤醒等待中的写入操作，当没有写入操作时所有的读取操作都将被唤醒。SRWL
// 能够在低资源情况下运行的原因，与临界区能够在低资源情况下运行的原因是一样的，因为都使
// 用了键值事件。在 Windows Vista 中，键值事件的性能得到了极大的提升，这使得可以在 SRWL
// 中可以将键值事件用作唯一的等待机制。事实上，你更希望通过 SRWL 而不是临界区来实现独占   *** 其实可以使用 SRWL 的独占模式来实现 mutex
// 模式的获取操作和释放操作，因为 SRWL 有着轻量级特性。对于小规模的竞争情况，SRWL 确实
// 比临界区更优越。SRWL 也使用了自旋等待，并且自旋操作的数量是固定的，这个数值即不可配置
// 也不是动态的，而是根据平均性能来选择的。还要注意的是，Vista SRWL 并不支持在锁已经被
// 获取之后再修改锁的模式，例如从共享模式升级为独占模式，或者从独占模式降级为共享模式，
// 等由于它的轻量级特性，Vista 并不支持这些功能。
//
// SRWL 并不支持递归的独占锁获取操作。如果线程已经获取了某个 SRWL 的读取锁或者写入锁，
// 那么在同一个线程上再次获取读取锁或者写入锁将导致死锁。这种行为是可以理解的，因为在前
// 面已经提到过，递归地获取操作将导致脆弱的设计。然而，这种行为仍会给一些需要递归的设计
// 带来困难。此外，还有另外一层微妙的含义。由于 SRWL 不需要支持递归获取，因此它也就不需
// 要记录所有权信息。后一个原因使得 SRWL 非常轻量级，但同样也使得它更难以调试：与临界区
// 结构不同的是，SRWLOCK 并没有维护操作系统线程 ID，当然你可以在调试时自行记录，这使得
// 调式工作更为困难。
//
// 如果在一个不属于当前线程的 SRWLOCK 上调用 ReleaseSRWLockExclusive/Shared，那么将
// 引发一个异常。这个异常的类型没有被公开，在 NtStatus.h 中被定义为 STATUS_RESOURCE_NOT_OWNED，
// 值为 0xC0000264。这种处理方式是很好的，你很少会希望捕获到这个异常，因为它表示在程序
// 中存在错误。但当你在调试中遇到一个未处理异常时，知道这个异常码是有帮助的。因为 SRWL
// 并不记录所有权信息，因此即使不持有锁的线程也可以对另一个线程的锁执行释放操作。这个锁
// 并不能将这种情况与正确的锁释放操作区分开来，最终当某个线程试图释放锁时，却发现锁已经
// 不再被持有了，这将导致一个异常。此时，异常错误发生的源头信息已经丢失了，因此必须通过
// 分析将错的情况重构出来。
//
// 条件变量是一种常见的控制同步，线程通常需要等待某些程序特定的条件建立起来之后再运行。
// 在确认条件是否满足时通常需要对某个谓词进行求值，而在求值过程中又涉及对共享状态的读取。
// 由于涉及共享状态，因此需要使用数据同步。而且，如果条件还没有满足，那么其他线程将需要
// 通过数据同步来确保安全地修改求值过程中与条件相关的状态。在退出临界区以及等待一个事件
// 发生的过程中，存在着一个内在的条件竞争，SignalObjectAndWait 可应对这种情况，它以原
// 子的方式触发一个对象并且在另一个对象上等待。但在使用了临界区或者 SRWL 之后，将不能使
// 用这个功能，因为同步机制被隐藏起来了，你不能通过触发一个内核对象来释放这个锁，用户态
// 锁本身控制了所有这些行为。这正是为什么 Windows Vista 中引入条件变量的原因。条件变量
// 与临界区或 SRWL 一起来实现在于特定锁相关的逻辑条件变量上执行等待和触发等操作。与临界
// 区一样，条件变量的作用范围是在进程之内，与 SRWL 一样它也是非常轻量级的，每个条件变量
// 和指针一样大小，并且将键值事件作为唯一的等待和触发机制，这意味着它不需要分配任何内核
// 事件对象。条件变量是在用户态中实现的，并且执行等待或触发操作时会导致内核切换发生。在
// 实现条件变量时考虑了尽量将内核切换发生次数降至最低。同样需要注意的是，条件变量是最接
// 近于 Windows 键值事件的对象。
//
// Win32 通过 CONDITION_VARIABLE 来支持条件变量，条件变量可以使一个或多个线程等待同一
// 个事件的发生，并且通过与临界区或 SRWL 结合，使得能够以原子方式来释放一个锁并且在一个
// 条件变量上开始等待，这样就消除了复杂的竟态条件问题。这些原语都是在 Windows Vista 和
// Server 2008 中新引入的。与 SRWL 一样，它们的大小也是和指针一样的，并且不会通过传统
// 的内核对象来实现等待。在单个锁上可以有任意数量的条件变量，并且每个条件变量都表示一种
// 不同的抽象条件。与 SRWL 一样，条件变量没有相关的资源需要释放。
//
// 当线程激活一个或多个线程等待的条件时，必须唤醒这些线程，可以唤醒其中一个或唤醒所有。
// 调用这些唤醒函数时不需要持有一个锁，尽管这么做是更安全的。如果没有持有锁，那么被唤醒
// 的线程可以重新获得锁醒来。如果持有锁唤醒，那么被唤醒的线程在尝试重新获取唤醒线程持有
// 的锁时会失败，因此唤醒的线程会立即在这个锁上进行等待。另外，条件变量在进行等待之前，
// 对于临界区来说必须锁定一次，但必须要小心的是必须确保不能递归锁定多次，因为条件变量进
// 入等待状态之前仅会释放一次锁定，如果锁定多次条件变量就不能释放这个锁，其他线程再也不
// 能更新条件导致死锁。
//
// 有几种线程间的加载和存储操作不需要借助临界区形式进行同步，要正确地实现这种操作，通常
// 需要对编译器和硬件架构有深刻的理解，尤其要清楚在加载和存储等操作中的原子性和执行顺序。
// 在理解这些内容后，我们在编写代码时不仅可以避免一些开销，而且还提高程序的可伸缩性和活
// 跃性。但付出的代价是代码理解起来将更为复杂和困难。这种方法通常称为无锁编程（Lock Free
// Programming）。代码通过利用内存模型提供的各种保证（Memory Model Guarantee）来避免
// 在主要代码路径上使用全功能的锁，此外在一些较少执行的代码路径中可以使用硬件原子指令或
// 者硬件锁。在某些情况下可以彻底不使用锁，这就是所谓的无阻塞编程（Nonblocking Programming）。
// 这些内容看起来有些困难，实际情况也确实如此，在大部分并发程序中，低锁编程（Low Lock
// Programming）是一种不成熟的优化。它很容易破坏程序的正确性，因此不能轻易地采用这种方
// 式。更糟糕的是，对并发算法的测试仍然是一项复杂的工作，即使在涉及锁的情况下，如果要彻
// 底避免使用锁，那么将会使工作变得更为困难。然而，如果能够理解为什么这些技术是可行的，
// 那么带来非常大的启发意义，它至少将加深你对并发的理解，因此值得研究。
//
// 内存加载与存储操作的重排序。如果正确地构建了临界区，那么它可以在不同线程上运行的各个
// 代码之间确保原子性和串行性。这是一个重要的正确性属性，着保证了，如果在某个临界区 A 中
// 对内存位置 x 执行存储操作之后，那么其他线程随后从相同临界区 A 中加载 x 时将看到这个
// 存储操作的结果。人们通常很容易接受这个属性，但更重要的是理解它。
//
// 在临界区之外，这些假设将不再成立。我们可能会认为在临界区之外执行多变量的更新操作是不
// 安全的，因为一个线程可能会看到更新操作的中间状态，但令许多人感到奇怪的是，单变量的更
// 新操作同样并非总是安全的。在执行程序时，软件和硬件通常会对内存操作进行重排序。程序顺
// 序 -> 1. 编译器优化 -> 汇编代码 -> 2. 处理器 ILP 重排 -> 执行指令 -> 3. 处理器缓
// 存作用 => 实际顺序。
//
//  1.  在将源代码编译为机器指令的过程中，编译器执行的优化操作通常会移动、消除或增加读写
//      等内存操作。这成为代码移动（Code Motion），目的是通过一些措施来提升性能，这些
//      措施包括：执行更少的指令、优化寄存器的使用、将相关内存的访问尽量放在接近的位置
//      上以获得空间局部性、更少地访问内存。在移动代码时，编译器必须保持串行行为，单当
//      代码运行在多线程的环境中时，重新对代码进行排序将改变代码的行为。
//  2.  现代处理器都采用了指令级别的并行技术（Instruction Level Parallelism，ILP），
//      例如流水管道（Pipeline）、超标量执行（Superscalar Execution）、以及分支预测
//      （Branch Prediction）等来将多条指令重叠执行。这种技术的目的是减少指令集合执行
//      的总时钟周期数。例如，在处理器的指令管道中，在不同位置 a 和 b 上的内存加载操作
//      可以同时执行，即使源代码中 a 是在 b 之前，单在实际执行时 b 可以在 a 之前完成。
//      如果处理器认为这种交换顺序不会产生错误，那么这种交换就是合法的，即在二者之间不
//      存在依赖性。
//  3.  在运行 Windows 的计算机架构上采用了一种层次式的快速缓存来分摊对主存的访问开销。
//      一些层次的缓存可以在处理器之间被共享，而其他层次中的缓存则不可以。许多处理器还
//      采用了写缓冲区（Write Buffer）来延迟存储操作。虽然可以很方便地将内存视作一个
//      大型数组以直接进行读取和写入，但缓存打破了这种模型。它们必须通过一种硬件功能来
//      保持全局一致性，这种功能称为缓存一致性（Cache Coherency）。不同的架构采用了不
//      同的一致性策略，这些策略精确地控制写入操作在何时才会到达主存，以及加载操作在何时
//      必须刷新本地的处理器缓存。这些因素都使得加载和存储等操作看上去是乱序执行的。
//
// 通常，上面三种情况都属于 “指令重排（Instruction Reordering）”。大多数程序员并不需
// 要关心指令重排，但对底层并非程序感兴趣的人们经常需要思考它。需要理解三种不同的“顺序”
// 概念。程序顺序，各种操作在源代码中出现的顺序。实际执行顺序，这些操作在程序实际执行时
// 的发生顺序，源代码中出现的一些操作甚至可能不会执行。可能的执行顺序，注意这里的顺序有
// 多个，某个执行顺序是多个可能出现的执行顺序中的一个，这取决于不同的因素，例如编译器中
// 打开的优化选项的变化、处理器的数量、缓存布局、目标机器上的缓存一致性策略。这对于理解
// 并发程序来说是非常重要的，如果可能出现导致任何错误的执行顺序，那么不管这种顺序是否会
// 在实际情况中发生，都是一个错误。指令重排并不是一个只在学术上或者理论上存在的问题，它
// 出现得非常频繁。串行代码和使用了锁的并行代码不会受到这个问题的影响。由于这些代码都是
// 你最常看到的代码，因此在日常工作中很少会出现重排导致的问题。然而，系统级别的代码以及
// 高度并行的代码则需要考虑这个问题。只有在使用一些常见的模式时，例如双重检查锁定（Double
// Checked Locking），系统高层开发人员才会第一次发现这种类型的问题。
//
// 实际执行的顺序并非总是编写的顺序。例如下面出现指令重排导致的出错情况，假设两个共享变
// 量 x 和 y，这两个变量的初始值为 0，两个线程 t0 和 t1 分别执行不同的指令序列。在 t0
// t1 都运行一次之后，是否可能出现 a==b==0 的情况？尽管这个问题可能令人感到困惑，但如果
// 答案为是，那么乍一看将是不可思议的，因为好像只有下面五种可能的执行结果。
//      t0: x=1;        t1: y=1;
//          a=y;            b=x;
//      t0 -> t0 -> t1 -> t1        a==0 b==1
//      t0 -> t1 -> t0 -> t1        a==1 b==1
//      t0 -> t1 -> t1 -> t0        a==1 b==1
//      t1 -> t0 -> t1 -> t0        a==1 b==1
//      t1 -> t1 -> t0 -> t0        a==1 b==0
//
// 但是由于指令重排的原因，这个程序可能被重排为这四条指令的任意排列组合，或者静态的（通
// 过编译器）、或者动态地（通过处理器或者内存系统）。这使得程序在实际运行时可能会像下面
// 这样，当前还有其他排列顺序。这种问题行为的出现可能涉及多个处理器，在优化代码时可能导
// 致这种有问题的代码移动。在实际情况中，由于大量地使用了存储缓冲，因此这种指令重排会经
// 长发生。例如，上面的第一种 a==0 b==1 的情形，如果 t0 执行完 x=1 之后在 t1 执行 b=x
// 时 t1 所在的处理器并没有看到这个 x=1 的更新就会出现 a==0 b==0 的情况。
//      t0: a=y;        t1: b=x;
//          x=1;            y=1;
//      t0 -> t1 -> t0 -> t1        a==0 b==0
//
// 还有一些更为复杂的示例，这些示例并不遵循关于代码如何执行的一些基本假设。假设一种情况，
// 其中三个线程 t0 t1 t2，以及三个变量 x y z，这些变量在最开始时的值都为 0。在所有线程
// 运行结束后，最终的结果是否可能是 x==1 y==1 z==0 呢？这看上去太不可思议了。由于 t1
// 将 1 写入到 y，它看到的 x 一定等于 1，同时如果 t2 看到 y 等于 1，那么它应该看到 x
// 也应该等于 1 才是，这是可传递的因果关系（Transitive Causality）。事实上，这个问题
// 答案还是是。在运行 Windows 的现代处理器中，都不允许违背这种可传递的因果关系，尽管在
// 一些老的处理器架构中允许这么做（例如 Pentium 4 SMP）。如果在处理器上遇到这种问题，那
// 么很可能是处理器的一个错误，但这个事实也并非是关键因素，因为编译器执行的一些代码移动
// 也可能破坏下面的算法。
//      t0: x = 1;      t1: while (x == 0) ;    t2: while (y == 0) ;
//                          y = 1;                  z = x;
//
// 尽管所有这些问题都非常依赖于编译器和处理器，但要解决它们却并非没有希望。有三个因素可
// 以使程序员实现低锁编程。
//
//  1.  无论如何，任何影响指令顺序的组件都不会破坏代码的串行求值操作，我们只需关心在线程
//      间通信中出现的加载和存储等操作。
//  2.  数据依赖性限制了可以被重排的操作，这使得推断代码的所有可能执行顺序变得稍微简单
//      一些。
//  3.  所有平台都提供了一个内存一致性模型（Memory Consistency Model），或者简称为内
//      存模型，这个模型明确定义了哪些重排操作才是允许发生的。这种更抽象的机器模型可以
//      用来编写可移值性更高的代码，这些代码能够在多种平台上工作。
//
// 后续部分，我们将分析与 Windows 编程相关的内存模型，以及控制程序所有可能执行顺序的各
// 种方式，从而确保任何一个执行顺序都会使程序正确的执行。这包括使用原子互锁指令（Interlocked
// Instruction）来替代普通的加载指令和存储指令，volatile 关键字、内存栅栏（Memory Fence）
// 等等。
//
// 临界区可以防止所有重排问题的发生，这是因为临界区可以与编译器、CPU 以及内存系统等结合
// 在一起以防止在指令重排中产生问题。所有编写正确的同步原语都具备这种功能。如果在上面的
// 示例中使用临界区，那么任何指令重排都不会影响最终的并行执行结果。我们后面可以看到，进
// 入临界区相当于设置了一个栅栏，在栅栏之后的所有代码都不会被移动到临界区之外。同样，离
// 开临界区可以确保在释放锁之前的代码不会被移动到临界区之外。锁的实现者需要确定是否使用
// 完全栅栏（Full Fence），因为将代码从临界区之外移入进来通常是没有问题的。使用完全栅栏
// 有助于实现一个更公平的系统，例如，如果在锁释放中没有使用栅栏，那么可能导致释放操作被
// 推迟到一个存储缓冲中，如果执行释放操作的线程试图再次获取这个锁，那么与系统中的其他线
// 程相比，它将获得一种不公平的优势。大多数编写并发软件的开发人员都应该坚持使用 Windows
// 提供的同步原语，这样就可以完全无需关心内存重排问题。
//
// 数据依赖性对重排的影响。在实际程序的指令重排中存在着一些基本的限制，这些限制不需要对
// 程序进行修改。在移动数据时，编译器和处理器将小心地维持操作之间的数据依赖性，如果不这
// 么做，那么一些编写正确的算法即使在串行执行的情况下也会变得不正确。在这种情况中，数据
// 依赖性仅作用于在单个处理器或单个线程执行的一系列指令操作。换句话说，在不同处理器上运
// 行的代码之间的依赖性将不被考虑。数据依赖性共有三种类型：真实依赖性（True Dependence），
// 也称为先写后读冲突（Load-After-Store）；输出依赖性（Output Dependence），或者叫做
// 写写冲突（Store-After-Store）；反向依赖性（Anti Dependence），也称为先读后写（Store
// After Load）。数据依赖同样是可传递的：x = 1; /*S0*/ y = x; /*S1*/ z = y; /*S2*/。
// 这里，S2 对 S1 有着真实依赖性，S1 对 S0 有着真实依赖性，因此 S2 同样对 S0 存在真实
// 依赖性。
//
//  1.  先写后读依赖性，首先对某个位置执行存储操作，然后执行加载操作，这个加载操作不能
//      被移动到存储操作之前，否则程序将看到原来没有修改的值。
//  2.  写写依赖性，对同一个变量执行多次写入操作，我们不能对这些指令重排，否则前面的写
//      入操作会越过后面的写入操作，因此错误地覆盖已写入的值。编译器经常会将多个写入操
//      作合并为一个，删除第一个写入操作，但这种行为能够保证最终的结果是正确的，它并不
//      同于对这些指令进行重排。
//  3.  先读后写依赖性，一个值先被读取然后被写入，这个写操作不能被移动到读操作之前。
//
// 硬件原子性，现代处理器能够以很细的粒度来提供物理原子性。前面提到的临界区的基本作用就
// 是在更高级别上提供逻辑原子性。临界区通常是由软件和硬件组合实现，其中利用了我们将要看
// 到的原子操作，这些原子操作是编写低锁代码的基本构件。
//
// 首先要清楚的是，普通的读写指令是否拥有某种类型的原子性？在运行 Windows 代码的处理器
// 上，如果对指针大小的值进行读写操作并且这些操作都是内存对齐的，那么它们将是原子操作。
// 在这里，指针大小意味着在 32 位处理器上是 4 个字节，而在 64 位处理器上是 8 个字节。
// 因此，读写操作的原子性直接依赖于内存的分配以及目标架构的位数。当判断内存访问操作是否
// 是原子操作时，还需要考虑值的大小，例如如果某个值只占 2 个字节，那么只有它是位于一个
// 对齐的边界上，那么这个值的读写操作都是原子的，但这些操作可能会影响周围的内存。
//
// 如果读写操作不满足这些标准，那么在操作中可能包含多条指令，这就可能发生破裂读取（Torn
// Read）的情况。破裂读取是由于在读取操作和写入操作之间存在竞争而导致的。在读取操作中，
// 一部分值是在写入操作之前读取的，而其他部分则是在写入操作之后读取的。在串行程序中几乎
// 不会发生破裂读取问题，但对于并发程序来说，破裂读取是一种非常棘手的情况，因为它们非常
// 难以诊断。例如当 a 没有对齐或者它指向的值超过指针大小，在最简单的语句中都会出现破裂
// 读取问题，例如 r0 = *a; *a = r0; 。超过指针大小的情况要更为常见，因为大多数语言都
// 支持在单条语句中读写大型数据类型，例如 64 位的 Int64 Double、128 位的 Decimal、
// Win32 的 LONGLONG FILETIME 等数据结构、以及自定义的按值赋值的其成员累加大小超过指
// 针的结构体。例如在 32 位机器上，Int64 x = 0x1111222233334444; 将被编译成两条指令：
//      MOV [x], 0x33334444     MOV [x+4], 0x11112222
//
// 在处理未对齐的访问时，编译器可以采取两种方式，识别出未对齐的情况并且生成多个指令，或
// 者尝试使用单条指令。后者是一个非对齐的内存访问，根据处理器架构的不同，所采取的措施也
// 不同：或者由硬件来自动修复，或者由操作系统付出高开销来修复，或者表现为一个错误。如果
// 数据的大小超过了一个字，那么就有必要生成多条指令，但这些指令中的任何一条同样可能是未
// 对齐的。一些新的处理器能够保证，未对齐的读写操作也可以原子地执行，只要它们能够在缓存
// 行（Cache Line）的边界上对齐，然而依赖这种条件将会带来麻烦。
//
// 破裂读取还可能违背类型安全性，如果你获得了一个未对齐的指针，那么在读取这个指针时可能
// 出现破裂读取问题，随后对解引用时将访问随机的内存。如果幸运的话，这种操作将触发一个内
// 存访问违规。如果不幸运，那么将破坏某个随机的内存区域。
//
// 单字长内存的原子读写操作是非常有用的，对于这种情况，处理器专门为原子的读写提供了特殊
// 的原语指令，以及更为复杂的比较并交换操作（Compare and Swap, CAS）可以基于某种条件来
// 原子的修改。在这些特殊的原子互锁指令上可以构建其他同步原语，例如临界区、事件、以及无
// 锁代码。互锁操作还意味着某种类型的内存栅栏，这种内存栅栏将与系统的内存模型直接交互，
// 实际上栅栏的一些变化形式可以控制使用哪些类型的内存模型。互锁指令使用了硬件中的处理器
// 间同步功能，在 Pentium Pro 之前的架构中，如果要引发一个互锁指令，那么将使得在整个系
// 统总线上维持一个锁。现在，互锁操作将在缓存一致性硬件中执行，并且在获得缓存行时将使用
// 一种特殊的互斥模式。这极大地降低了互锁指令的开销。然而，这些指令的开销仍然较大，并且
// 在竞争程度很高或者访问未对齐的地址时，仍将锁住总线。一个常见的误解就是，互锁操作不能
// 在未对齐的地址上运行，但尽管在这种情况下互锁操作可能是低效的（由于总线锁定问题），并
// 且在 IA64（Intel 安腾 Itanium 处理器）上将导致异常，但操作的原子性却不会被破坏。
//
// 在所有情况中，互锁操作通常会消耗数百个指令周期，在单插槽（Single Socket）架构上（整
// 台主板只提供一个 CPU 插槽，所有 CPU 核心、内存通道、PCIe 通道都归这些核心独享，NUMA
// 因子为 1，访存延迟一致，软件无需考虑跨 Socket 调度），通常是 50 ~ 150 个指令周期。
// 而多插槽（Multi-Socket 双路、四路、八路等）架构上（主板提供多个 CPU 插槽，通过高速
// 总线 Intel UPI、AMD Infinity Fabric 等互连，形成 NUMA 拓扑，每个 Socket 拥有本地
// 内存和远程内存，跨 Socket 访存延迟高，由于性能或容量可线性扩展，常用于高并发数据库、
// 大型虚拟化、HPC），可能高达 500 个指令周期。在非一致内存访问（Non-Uniform Memory
// Access, NUMA）机器上的开销更大，因为在 NUMA 拓扑节点之间需要同步。通常来说，目标机
// 器上内存层次结构越复杂和越庞大，那么同步操作的开销就越大，并且对系统可伸缩性的影响也
// 越大。因此，在构建底层软件时，很重要的一点是将互锁操作的数量降至最低。
//
// 交换（XCHG）。最基本的互锁原语是交换（Exchange），在一个原子操作中读取一个值并且将其
// 与一个新值交换。在 x86 指令集中，这将被转换为一个 XCHG 指令。我们将要看到的大多数其
// 他指令要加上一个 LOCK 前缀，从而在多个处理器之间实现原子性，但 XCHG 有所不同，使用这
// 个指令本身就意味着这一个 LOCK 前缀。我们大多数人都不会使用汇编语言来编写程序，因此在
// Windows.h 中定义了以下 API 来实现 XCHG 原语。使用这个函数就好像是直接使用对应指令的
// 汇编代码。函数返回目标位置上的旧值，并将一个新值放入这个位置，这两个操作之间不会存在
// 其他的值。从这种意义上看，这个指令实现的原子操作中包含了一个读和一个写操作。注意非托
// 管代码要求用 volatile 来修饰内存位置参数，在 .NET 中没有这个要求，并且如果你指定的
// 引用是一个指向 volatile 的位置，编译器还会给出警告错误。在这两种情况中，除了讨厌的
// 编译器警告之外，使用 volatile 通常是一种好做法，但并非完全必要。
//      LONG InterlockedExchange(LONG volatile *Target, LONG Value);
//
// 在 Win32 中有一些函数来处理以 64 位和指针表示的内存位置。在 32 位架构上必须模拟这个
// 64 位的函数，虽然你可能会奇怪为什么要在 32 位系统上支持 64 位的原子操作，我们在随后
// 将会看到，它依赖于还没有介绍的 CMPXCHG8B 指令。这些 Exchange 函数还有一些变体，后缀
// 为 Acquire（如 InterlockedExchangeAcquire64），我们将在后面讨论栅栏时说明 Acquire
// 的含义。
//      LONGLONG InterlockedExchange64(LONGLONG volaitile *Target, LONGLONG Value);
//      PVOID InterlockedExchangePointer(PVOID volatile *Target, PVOID Value);
//
// 为了简单说明 XCHG 的使用，我们来创建一个简单的自旋锁。这段代码并不具备产品级质量，因
// 为在一个 XCHG 指令上执行自旋操作将付出很高的开销。硬件需要确保实现原子性保证，这将增
// 加缓存一致性通信量，并且在多插槽机器上将导致更多的开销。但无论如何，这段代码是有意义
// 的。每当 a 被赋值为 0 时，总有一个线程将看到这个值并且将其修改为 1。由于只有单一进入
// 临界区的线程才会调用 exit，因此就保证了互斥行为。这或许有些令人奇怪，因为即使当 exit
// 执行一个普通的写操作，互锁操作函数仍然正确地实现功能。
//      void enter(void) { while (InterlockedExchange(&a, 1) != 0) ; }
//      void exit(void) { a = 0; }
//
// XCHG 指令可以用于简单的原子读然后写的操作，但有些算法要求更为复杂的读-比较-写操作序
// 列。在这个操作中包含了三个独立的步骤，if (a == expected) a = value; 。处理器在
// XCHG 指令上提供了一个变化形式 CMPXCHG，这个指令的参数不仅包含目标位置以及需要写入的
// 值，还包括一个比较操作数，仅当目标位置上的值等于比较操作数时，新的值才会放入目标位置
// 中，否则这个位置上的值将保持不变，在这两种情况中，锁观察到的值将被返回给调用者。这是
// 一个真正的比较并交换（CAS）操作，并且硬件将确保当使用 LOCK 前缀时，整个操作序列都是
// 原子的。注意，即使在 32 位处理器上，仍然可以使用 64 位的比较交换操作，因为在现代 Intel
// 和 AMD 处理器上都普遍支持 CMPXCHG8B 指令。CMPXCHG 比 XCHG 的效率要略低，很明显它需
// 要做更多的工作，包括执行一次比较和一次写入。此外，还有一个不太明显的原因，在获取缓存
// 行之后，CMPXCHG 可能发现它需要放回缓存行，并且在大多数时候软件需要重新计算一些状态并
// 再次尝试这个操作，所有这些导致缓存行在处理器之间反复变动，这将表现出高度竞争行为。互
// 锁操作将以独占模式获得目的地址的缓存行，可能使进程中其他处理器的缓存行无效，并导致缓
// 存一致性通信量的增加以及竞争的出现。
//
// 有些 64 位架构支持 128 位的互锁操作，与 CMPXCHG8B 指令非常类似，几乎所有 X64 处理器
// 提供了 CMPXCHG16B，这个指令与 LOCK CMPXCHG 一样都是原子的。有些早期的 64 位 AMD
// 芯片并没有像 X64 芯片那样提供相同级别的支持，这意味着你需要通过一个 CPUID 来测试是否
// 提供了这种支持。这使得编写可移值的 64 位代码更加困难，这也是为什么很难找到 128 位互锁
// 操作以及在 .NET 中根本不支持 128 位互锁操作的原因。除了编写汇编代码之外，目前访问
// CMPXCHG16B 的唯一方式是使用 _InterlockedCompareExchange128 这个内置函数。另外有
// 一个鲜为人知的秘密，即一些特定的 SSE 指令（例如 MOVDQU）在某些架构上提供了原子的 128
// 位操作。处理器并不保证这种原子性，因此任何提供这种原子性的实现在将来可能发生变化。
//
// 位测试并置位（BTS, Set）位测试并复位（BTR, Reset），即将某一位置 1 或清 0，然后返回
// 这一位原来的值，如果加上 LOCK 前缀，那么这些指令将以原子方式执行。注意参数 Offset
// 并非一个位掩码，而是位的索引值（例如 0 ~ 31）。如果在修改前发现这个位是 1 那么返回
// TRUE，否则返回 FALSE。无论返回值是什么，这个指令将修改位上的值。在支持这些指令的处理
// 器上，对这些函数的调用将被编译为一个内置函数，否则将通过 CMPXCHG 指令来模拟这个调用。
// 另外 BTS/BTR 指令比 XCHG 等指令要略微更高效一些，如果你需要设置或者清除某一位上的值，
// 那么你应该优先选择使用这些函数。
//      BOOLEAN InterlockedBitTestAndSet(LONG *Base, LONG Offset);
//      BOOLEAN InterlockedBitTestAndReset(LONG *Base, LONG Offset);
//
// 还有一些其他的互锁操作可以处理常见的更新模式，每一种互锁操作都可以通过一个普通的 CAS
// 操作来实现，但如果完全在硬件中实现这个操作，那么将更为高效。这些操作包括 XADD 指令，
// 当带有 LOCK 前缀时原子的将一个特定值与每一地址位置的数值相加。当带有 LOCK 前缀时，
// INC DEC NOT NEG 等但操作数逻辑指令都将以原子方式执行。当带有 LOCK 前缀时，ADD SUB
// AND OR XOR 等二元逻辑运算同样以原子方式执行。
//
// 内存一致性模型，即内存模型。内存模型严格规定了哪些类型的读写操作可以移动，在什么条件    *** 内存模型
// 下可以移动，以及它们可以移动到哪些地方。内存模型可以按从弱到强的程度来划分：Intel
// IA64 HW MM -> Intel EM64T HW, AMD64 HW, Intel/AMD X86 HW MM -> CLI ECMA MM,
// Java 5 MM -> CLR 2.0 MM -> Sequential Consistency MM。内存模型越弱，性能越好，
// 编程易理解性最差。在最弱的内存模型中可以对所有的读写进行重排，并仍然保持最初程序在串
// 行执行时的正确性（不违背数据依赖性）。在最强的内存模型中，也被称为串行一致性（Sequential
// Consistency, SC）将禁止所有的重排动作，代码的实际执行顺序与程序源代码本身保持完全一
// 致。在弱内存模型中可以实现更多的优化，但实现起来却更为困难，强内存模型提供了一个更易
// 于理解和编程的模型，但可优化性却不高。任何比串行一致性更弱的模型通过都称为松散内存模
// 型（Relaxed Memory Model）。
//
// 在理想情况中，我们都将遵循串行一致性来编程，也就是说如果串行一致性不会对性能产生巨大
// 的影响。在未来的架构中，有序执行（In-Order Execution）将变得越来越普及（为减少能耗
// 以及复杂性），此时串行一致性的架构或者或变得更加有吸引力。但就目前而言，开发内存模型
// 的人们需要与他们的目标用户一起分析这些权衡，并且制定一些能够为用户代码最大价值的规则。
// 由于重排可能在多个地方发生（编译器重排以及处理器重排），因此内存模型的定义是一个分层
// 的过程，这个过程将分别影响硬件和编译器。所有的硬件架构都必须定义一个内存模型，模型的
// 规范定义必须清晰无误，这样底层的软件开发人员才可以在机器上编程，尤其时编译器和操作系
// 统的开发人员。如果某个高层软件依赖于硬件的内存模型，那么通常是有问题的，因为在多种处
// 理器实现之间存在着许多差异，并且编译器所支持的排序类型也可能有所不同。硬件供应商规定
// 的模型通常比实际实现的模型要更弱，这是为了避免受到更强模型的限制。换句话说，他们希望
// 保留一些控制权，以便在将来通过弱化已实现的模型来实现更智能的优化。
//
// 有些编译器则进一步定义了一个内存模型，而不考虑运行时的硬件。CLR 定义了一个强内存模型，
// 不管目标架构是什么，这个模型都将保持一致，从而更容易编写出可移值性更高的代码。这需要
// 在特定的架构上生成一些特殊的指令，并且尽量限制编译器所能实现的优化类型。这个模型的优
// 势在于，它使得程序员可以安全地依赖于这个内存模型，因为它永远都不会被弱化，并且它也不
// 需要知道关于硬件模型的任何信息。而另一方面，VC++ 并没有这么做，尽管它提供了一些手动
// 方式来限制代码重排操作。
//
// 一些处理器对读写指令的重排情况如下，该表格展示了某种类型的重排，例如一个读操作是否会
// 移动到另一个读操作之后，或者被移动到另一个写操作之后。表中的每一项表示某个架构是否允
// 许改行中的重排，允许的重排越多，那么内存模型就越弱，可以看到 X86 Intel64 ADM64 都
// 是比较强的，而 IA64 则是最弱的。如果你希望更全面地从理论上了解内存模型，那么可以阅读
// Jave JSR-133 内存模型规范中的一些资料，这些文档使用了一种称为 “Happens-Before and
// Synchronizes-With” 的机制，通过因果性和可见性来描述合法的排序。注意，这里没有给出
// 一些更弱的模型，例如 Alpha 和 PowerPC，因为当前 Windows 不能在这些架构上运行。根据
// 最新的 Intel 和 AMD 处理器文档，X86 Intel64 AMD64 的内存模型都禁止大多数形式的 Load-Load
// 重排，但对于一些情况，特别是在本地处理器写缓存中存在满足的未决写入操作时，它们允许对
// 读操作进行重排。这可能导致读操作看上去被重排了（抽象地），尽管在物理上并没有发生任何
// 重排。由于需要从非常具体的条件来思考，因此情况将变得复杂，这样当存在疑问时，更安全的
// 回答就是：是的，这些处理器允许 Load-Load 重排。在某些情况下，你可以利用这种特殊的规
// 则，但这将为编写和维护可移植的并且正确的代码增加困难。
//                                              X86     Intel64     AMD64   IA64（安腾处理器）
//  一个读操作和随后另一个读操作（Load-Load）       否*     否*         否*         是
//  一个读操作和随后另一个写操作（Load-Store）      否      否         (是)         是
//  一个写操作和随后另一个写操作（Store-Store）     否      否          否          是
//  一个写操作和随后另一个读操作（Store-Load）     (是)    (是)        (是)         是
//      否*：除了写缓存或转发等一些情况（except for store buffer/forwarding）
//
// 在表格中有一些值得注意的地方。有些处理器在指令缓存和数据缓存中分别采用了不同的策略，
// 尤其是在读操作和写操作的执行顺序，这里的内容仅限于普通的数据缓存。开发编译器的人员在
// 实现自我更新代码（Self Modifying Code）的功能时最关心指令缓存，例如支持代码清理（Code
// Pitching）或者代码重写的 JIT 编码器，比如 Java HotSpot VM。请参考相关处理器文档以
// 了解详细内容。
//  1.  其中没有提到栅栏的影响，尽管栅栏将禁止表格中给出的部分重排操作。通常，栅栏的目的
//      就是为了避免表格中的某一种重排。
//  2.  处理器必须维持单处理器的一致性，因此如果任何移动可能对内存位置产生影响，那么都将
//      会由于数据依赖而被禁止。
//  3.  只有在 IA64 上才允许对读操作进行任意重排，这是为了乱序执行以及允许猜测的和缓存
//      命中的读操作尽量以最优的顺序执行。X86 Intel64 AMD64 只允许由于在本地对存储操作
//      进行缓存而导致对加载操作进行重排。
//  4.  所有四种架构都允许将写操作移动到读操作之后，这是因为在之前提到，所有处理器中都
//      大量地使用了存储缓存。
//  5.  除了 IA64 之外，其他架构都实现了在全局范围内对写操作的排序，即写操作的执行顺序
//      是可见的。由于在 IA64 上缺乏全局的写操作排序，因此可能导致一些严重的可移植性问
//      题。
//  6.  所有上述处理器都确保因果关系是可传递的。
//
// 基于多个原因，我们有必要禁止对读和写操作进行重排，栅栏的最大作用是，无论是何种目标架    *** 内存栅栏
// 构，以及这个架构允许哪些重排操作，内存栅栏都可以用来禁止对读和写操作进行重排。然而，
// 在使用栅栏的同时需要付出一定代价，因为它们禁止了一些优化操作。许多栅栏都是很常见的，
// 但只有一种类型在我们需要注意的所有架构上都被支持，被称为完全栅栏（Full Fence）。它
// 确保不会有任何读写指令被移动超过栅栏，无论是哪个方向。换句话说，在栅栏之前的指令将不
// 会被移动到栅栏之后，而栅栏之后的指令也不会被移动到栅栏之前。大多数架构都通过一个专门    *** 完全栅栏（Full Fence）MFENCE，任何读和写指令都不能跨越栅栏
// 的指令（例如 MFENCE）来实现这个功能。完全栅栏是唯一一个在所有架构上都要求支持的栅栏，
// 这种要求是正确的，但其他的栅栏则通过允许特定类型的读写指令移动超过栅栏，从而避免不必
// 要的优化限制。
//
// 我们来看一些与架构特定的栅栏。首先是双路栅栏（Two-Way Fence），这些栅栏要么仅应用于   *** 完全栅栏和双路栅栏，对于起作用的指令，两个方向跨越栅栏都禁止
// 写指令，要么仅用于读指令。在 X86 和 X64 中支持这些栅栏，但在 IA64 中不支持。其中写        写栅栏（Store Fence）SFENCE，写指令不能跨越栅栏
// 栅栏（Store Fence），类似于完全栅栏，只不过它只应用于写指令，而读指令可以自由地在任        读栅栏（Load Fence）LFENCE，读指令不能跨越栅栏
// 何方向上跨越栅栏，对应的指令为 SFENCE。读栅栏（Load Fence），应用于读指令，而写指令
// 可以自由地在任何地方跨越栅栏，对应的指令为 LFENCE。这些指令作为一种优化措施是非常有
// 用的。例如，读栅栏将禁止特定类型的猜测执行，但不会影响处理器对写操作进行缓存的功能。
// 同样，写栅栏可以禁止对写操作进行缓冲，但允许处理器猜测执行。
//
// 接下来的两个栅栏用于 IA64 以及在编译器的优化中，它们有时候被称为单路栅栏（One-Way     *** 单路栅栏，对于起作用的指令，仅单方向禁止跨越栅栏
// Fence），因为它们只允许在单一方向上的移动。获取栅栏（Acquire Fence）确保在栅栏之后        获取栅栏（Acquire Fence），读或写操作不会移动到栅栏之前
// 的读或写指令不会被移动到栅栏之前，在栅栏之前的指令仍然可以被移动到栅栏之后。释放栅栏        释放栅栏（Release Fence），读或写操作不会移动到栅栏之后
// （Release Fence）确保在栅栏之后的读或者写指令不会被移动到栅栏之后，在栅栏之后的指令
// 仍然可以被移动到栅栏之前。注意，这两种栅栏并不是只能作用于读写指令，而是只允许向某一
// 方向移动。这些栅栏使得一些特定的优化被保留下来，尤其是那些需要在特定方向上将指令移动
// 超过栅栏的情况。
//
// 在使用更弱的栅栏时，要推断无锁编程的正确性将变得更为困难，因为此时一些特定的重排操作
// 是合法的。尽管通过放松栅栏的限制可以为那些被反复调用的底层代码，例如操作系统中某个常
// 用的中断例程，带来显著的性能提升，但从以往的经验来看，这种优化并非是关键的。如果你对
// 是否使用栅栏还有疑问，或者并不希望写特定于某个架构的代码，那么通常可以通过完全栅栏来
// 禁止重排。需要指出的是，在编译器级别上的完全栅栏，在处理器级别上的完全栅栏，以及同时   *** 存在编译器级别、处理器级别、两种级别都生效的三种级别栅栏
// 适用于这两种级别的栅栏之间存在着一个显著的差异。在软件栈的每个层次上都可能出现大量的
// 重排，如果某个完全栅栏只能作用于编译器，那么它并不能禁止在处理器上的重排操作，反之亦
// 然。如果需要绝对确保某个读或者写指令不会移动，那么就需要一个在两种级别上都能起作用的
// 栅栏。认识到这种差异是很关键的，因此我们将在可适用的地方使用它。
//
// 你可能希望知道如何在代码中实现栅栏，事实上我们刚才看到的所有互锁操作都会产生一个处理器
// 级别上的完全栅栏，除了那些前缀为 Acquire 和 Release 的操作。在 C++ 中要求你传递一个
// 指向 volatile 变量的指针，这基本上可以确保在编译器级别生成一个完全栅栏，当然有一些
// 情况也并非一定如此。而 .NET 的 JIT 编译器也将互锁操作编译为一个完全栅栏。因此这是实
// 现栅栏的一种最简单方式，并且也是为什么大多数锁，基于互锁操作构建的，能够保证正确的行
// 为并且禁止可能破坏临界区串行性的重排操作的原因。
//
// 在 VC++ 中创建栅栏要更为复杂，因为编译器是高度可控的。而且，你可以使用多种类型的栅栏，
// 这与 .NET 不同，因此你可以编写特定于处理器的代码来使用某种栅栏。与 .NET 类似的是，在
// VC++ 中，对 volatile 变量执行读操作和写操作将分别产生获取栅栏和释放栅栏，并且同样可
// 以防止编译器将这些操作提升到循环之外。然而，VC++ 和 .NET 之间存在一个巨大的差异，这    *** VC++ 与 .NET 不同，volatile 生成的栅栏无法在处理器级别上起作用
// 些栅栏只能适用于编译器级别，而无法在处理器级别上发挥作用。当人们第一次听到这种情况时，
// 往往都会感到吃惊。类似地，在 Windows.h 中有一个 MemoryBarrier 宏，这个宏将在处理器
// 级别上生成一个双向栅栏，但不能在编译器级别上保证同样的作用。
//
// 在 VC++ 中有如下一组编译器内置函数，可以在编译器级别和处理器级别上同时实现栅栏。另外，
// 你可以通过 Win32 的 InterlockedXxxAcquire 以及 InterlockedXxxRelease 系列函数来
// 生成特定类型的获取栅栏和释放栅栏，这些函数在为 IA64 架构编译代码时使用，在所有其他架
// 构上，它们还是使用完全栅栏。
//      _ReadWriteBarrier 生成一个完全栅栏
//      _ReadBarrier 生成一个只读栅栏
//      _WriteBarrier 生成一个只写栅栏
//
// 注意，释放栅栏之后紧接着获取栅栏（Release Followed by Acquire Fence）中的危险。最    *** 释放栅栏（Release Fence）后面紧跟另一个获取栅栏（Acquire Fence）的问题
// 复杂并且最容易被忽视的一种重排情况是，当有两个紧邻的栅栏，特别是一个释放栅栏，后面紧
// 跟一个获取栅栏。例如，在 VC++ 和 .NET 中，当在写一个 volatile 变量之后紧接着读另一
// 个 volatile 变量，就会出现这种情况。为了说明这种情况，我们回到前面给出的一个示例。
// 在这段代码中，x 和 y 都是共享变量，每个线程都将 1 写入到一个变量中，然后将另一个变量
// 读取到一个局部变量 a 和 b 中。有人可能会通过将 x 和 y 标记为 volatile 来修复这个问
// 题。然而，这种修复方式不会起作用，因为这两个写操作将生成一个释放栅栏，会阻止这个写操
// 作 x = 1 或 y = 1 不会向后移动，但不能阻止后面的写操作 a = y 或 b = x 移动到释放
// 栅栏之前。解决方案是在这些指令之间放置一个完全栅栏。
//      t0: x = 1;                  t1: y = 1;
//          a = y;                      b = x;
//      t0: x = 1;                  t1: y = 1;
//          _ReadWriteBarrier()         _ReadWriteBarrier()
//          a = y;                      b = x;
//
// 无锁编程（Lock Free Programming），从名字可以看出，就是在编写并发安全的代码中不使用
// 锁。这听起来很简单，但确实一个很容易发生错误的过程，在使用这项技术时需要对底层有深入
// 理解。无锁编程在学术论文等资料中通常称为无阻塞算法（Nonblocking），我们需要了解三种
// 类型的无阻塞算法。
//
//  1.  无障碍算法（Obstruction Freedom），在系统中的其他线程被挂起的情况下，线程仍然
//      可以通过这个算法继续执行。换句话说，系统中的其他线程都不会持有这个线程需要的锁
//      或共享资源。
//  2.  无锁算法，这个算法比无障碍算法更强，它意味着每当某个线程无法继续执行时，我们要
//      确保这是因为系统中有另一个线程已经执行了。尽管任何一个线程都可能饥饿，但系统在
//      整体上的执行将取得进展。
//  3.  无等待算法（Wait Freedom），这个算法是三者中最强的，它意味着系统中的任意线程都
//      将在有限数量的步骤中执行完成。换句话说，线程不会像无锁算法一样出现饥饿情况。
//
// 在许多实际的系统中，这些差异并不重要，并且很多时候只是在理论上才会引起人们的注意。因
// 此，当我们提到无阻塞时，通常所有这些算法都成为无锁算法。这其中包含了重要的一点，在实
// 现无锁算法时仍然可以使用原子的硬件指令。有些人可能会发现这有一些误导的含义，因为互锁
// 操作的开销可能像锁的开销一样大，有几种无锁算法并不要求互锁操作，但它们使用得很少。在
// 某些情况下，我们甚至将曲解无锁算法的含义，例如双检查锁定可以要求获取一个锁。
//
// 无锁算法的主要好处在于它的无阻塞特性，由于没有任何线程会阻塞，以及任何一个线程都不会
// 阻碍其他线程的执行，因此将获得非常高的可伸缩性。上下文切换将减少，吞吐量将上升。尽管
// 如此，但无锁算法经常遇到活锁（Live Lock）问题，有一段时间陷入空忙的状态。无锁的另一
// 个好处（不太明显）就是可靠性，由于执行的粒度必须被压缩到一个原子操作中，因此单个线程
// 的失败将不会破坏无锁数据结构的一致性。例如，在重要的操作系统数据结构中将注意这个问题，
// 但在用户态的数据结构中则更少注意，其中在更新数据结构时出现的失败通常是灾难性的，并且
// 会导致整个进程被破坏。
//
// 无锁数据结构需要非常小心才能正确地实现，由于不能防止其他线程并发地看到这个结构处于不
// 一致的状态，因此这个数据结构绝不能进入到不一致的状态。从某种意义上来说，这使得编码实
// 现它们将更为简单，如果没有其他要求，算法的作用域将更小和更简单，因为每个更新操作都必
// 须被归结为一个原子操作（通常是一个互锁操作）。这单个操作时线性化点，在这个点上，更新
// 操作将发挥作用并且变得可见。如果我们注意数据结构的不变性或者检查它们，那么会发现无锁
// 代码的一个通常需求就是，永远都不要违背这些不变性，每个原子更新必须将这个结构从一个合
// 法的状态移动到另一个合法的状态。
//
// 延迟初始化与双重检查锁定。在延迟初始化中使用的双重检查锁定模式是一种声名狼藉的模式，
// 这不仅是因为它被广泛地用作为一种有效的初始化机制，而且还因为它在多种常见的硬件内存模
// 型中会失败。这些硬件架构包括 Alpha 和 IA64。值得指出的是，这种模式的大多数变化形式
// 都可以在 X86 Intel64 AMD64 上工作，CLR 2.0 的内存模型同样确保了双重检查锁定能够正
// 确地工作。
//
// 延迟初始化的一个简单的（但性能不高）示例如下。延时初始化，在许多情况下被用于尽可能地
// 延迟开销很大的资源的分配。下面的代码有它的缺点，由于只有第一次才需要对值进行初始化，
// 没必要每次访问这个值都进行锁定，只要确保在初始化时锁定就好了。
//      struct lazy_init { void *value; }
//      void *get_value(struct lazy_init *p) {
//          void *value;
//          mutex.enter();
//          if (p->value == prh_null) {
//              p->value = create_object();
//          }
//          value = p->value;
//          mutex.exit();
//          return value;
//      }
//
// 解决这个问题的通常方式就是使用双重检查锁定模式。首先在锁的外面进行一次检查看这个值是
// 否已经被初始化了，如果已被初始化那么就需要使用锁，如果还没有被初始化那么就需要获取锁
// 并且初始化这个值。这种模式的一个微妙的地方在于，有一次检查是在锁的内部完成，这与可以
// 确保另一个线程不会并发地初始化这个值。因为可能有多个线程同时进入到 mutex.enter() 这
// 一行，但只有一个线程真正的去执行初始化操作。注意，在允许 store-store 乱序的机器上，
// 例如安腾处理器 IA64，这里存在一个隐藏的错误。当创建 value 这个对象时，一个写操作是
// 将对象的地址写入到 value，但 create_object() 时还存在其他的写操作来初始化对象的成
// 员。在不乱序的情况下，将地址写入到 value 当然最后一个执行。如果产生乱序，当写入地址
// 的时候，可能指向的对象并没有完全初始化。这样，当一个线程判断 p->value 不为空的时候，
// 这个对象可能是一个未完全初始化的垃圾数据。你需要添加一个 _WriteBarrier()，当然这个
// _WriteBarrier() 在 X86 Intel64 AMD64 平台上不需要。
//      void *get_value(struct lazy_init *p) {
//          if (p->value == prh_null) {
//              mutex.enter();
//              if (p->value == prh_null) {                 if (p->value == prh_null) {
//                  p->value = create_object();                 void *ptr = create_object(); _WriteBarrier(); p->value = ptr;
//              }                                           }
//              mutex.exit();
//          }
//          return p->value;                                _ReadBarrier(); return p->value;
//      }
//
// 对象成员的读取操作也存在着相同的问题，因为上面介绍的所有处理器平台，以及包括 .NET 内
// 存模型，都允许在某些情况进行 Load-Load 重排，因此读取 value 的操作可能被移动到用户
// 调用 get_value() 之后读取对象成员的操作之后。对于某些读者来说，这看上去有些不可思议，
// 在获得一个指向对象本身的指针之前，如果读取对象的成员呢？这看上去违背了数据依赖性，但
// 其实不然。一些新的处理器（例如 IA64）采用了值猜测的方法来提前执行读取操作，如果处理器
// 碰巧猜对了指针和字段在指针写入之前一样的值，推测读取可能会失效并产生问题。解决的方法
// 是像上面一样添加一个 _ReadBarrier()，然而需要指出的是，在 X86 Intel64 AMD64 处理器
// 上将不需要这个栅栏。一些弱处理器如 IA64 则需要这个栅栏，但如果你希望编写完全特定于处
// 理器的代码，那么可以考虑添加这个栅栏或者使用 #ifdef IA64 宏包起来。另外，可以使用单
// 次初始化（One-Time Initialization）API 来编写可移植的延迟初始化代码，而无须关系具
// 体的内存模型。
// （If the processor happens to guess the correct value of the pointer and field
// as it was before the pointer was written, the speculative read could retire
// and create a problem. It's unfortunate that we need this read barrier because
// the only dangerous period of time is immediately after construction. Because
// there's no fixed length on this window of time, it is generally not possible
// to remove the barrier. This is surprisingly needed for processors like IA64
// that do pointer and value speculation.）
//
// 另外，如果需要初始化的值不仅仅是一个指针，可以添加一个 initialized 成员来辅助初始化。
// 但我们必须非常小心，因为需要确保初始化标志（initialized）与需要初始化的数据写操作不
// 会被重排。
//      void *get_value(struct lazy_init *p) {
//          if (p->initialized == false) {
//              mutex.enter();
//              if (p->initialized == false) {
//                  p->value = create_object();
//                  _WriteBarrier();
//                  p->initialized = true;
//              }
//              mutex.exit();
//          }
//          _ReadBarrier();
//          return p->value;
//      }
//
// 是否可以实现一个无锁的版本呢，我们可以对上面的算法做一些细微的改动以放松算法的要求，
// 下面提供了第一个真正的无等待算法示例。由于互锁操作的限制，需要初始化的值必须是一个指
// 针。
//      void *get_value(struct lazy_init *p) {
//          if (p->value == prh_null) {
//              void *obj = create_object();
//              if (InterlockedCompareExchange(p->value, obj, prh_null) != prh_null) { // 返回的是旧值
//                  release_object(obj); // 释放写失败的线程创建的垃圾对象
//              }
//          }
//          _ReadBarrier();
//          return p->value;
//      }
//
// 无阻塞栈和ABA问题。有几种已知的无阻塞容器数据结构，例如栈、队列、优先队列、双向队列、
// 集合、散列表等，这在后面将介绍。但就目前而言，我们将分析如何实现一个无阻塞栈（Nonblocking
// Stack），尽管这听起来复杂，但其实很简单，除了一个叫做 ABA 的问题。在托管代码中更可以
// 很容易避免 ABA 问题，但在 VC++ 中不行。Windows 提供了 SList 数据结构，这是一个无阻
// 塞数据结构并且可以避免 ABA 问题，在非投管代码中很容易使用它。
//
// 我们构建一个新的节点对象 new_node 来存放被压入的值，并且在循环中将新节点的 next 指向
// 头节点，尽管头节点这个值可能立即失效，但设置操作时安全的，因为我们还没有公开新节点，
// 因此其他任何线程都不可能看到这个值。然后我们通过 InterlockedCompareExchange 来使得
// 新节点变得可见。如果这个函数调用失败，那么将继续重新尝试执行。
//      void push(prh_data_snode *stack, void *value) {
//          prh_data_snode *new_node = malloc(sizeof(prh_data_snode));
//          new_node->data = value;
//          prh_data_snode *head;
//      label_retry:
//          _ReadBarrier(); // 确保循环迭代中正确地重新读取 stack->next 的值
//          head = stack->next;
//          new_node->next = head;
//          if (InterlockedCompareExchange(&stack->next, new_node, head) != head) {
//              // 添加一定数量的自旋等待
//              goto label_retry;
//          }
//      }
//
// Pop 操作的工作原理类型，我们将头节点读入到一个局部变量 head 中，然后用 head->next
// 去交换这个头节点。如果扎个操作失败，那么将将循环继续再次尝试。这类循环尝试没有使用锁，
// 但却需要使用等待，某个线程执行失败的原因是被另一个线程竞争而被抢夺了执行权。在实际的
// 实现中，当某个线程无法进一步执行时，我们可能会增加一定数量的自旋等待时间，这将减少在
// 共享变量上的竞争，并且对那些在多处理器机器上访问非常频繁的栈来说将带来显著的性能提升。
//      void *pop(prh_data_snode *stack) {
//          prh_data_snode *head;
//      label_retry:
//          _ReadBarrier(); // 确保循环迭代中正确地重新读取 stack->next 的值
//          head = stack->next;
//          if (head == prh_null) return prh_null;
//          if (InterlockedCompareExchange(&stack->next, head->next, head) != head) {
//              // 添加一定数量的自旋等待
//              goto label_retry;
//          }
//          return head->data;
//      }
//
// ABA 问题将导致 CAS 操作在本应该失败时却执行成功，这使得上面给出的算法被彻底破坏，托
// 管代码不会出现这个问题。下面是一些可能引起 ABA 问题的情况：
//  1.  如果使用一个节点池并且重用那些从栈中弹出的节点，那么在多个并发操作中可能会使用
//      相同的节点对象。
//  2.  释放的节点内存将返回到内存分配器，而这块内存可能被重用。
//
// ABA 问题的来源是，我们通过头节点 stack->next 来判断这个栈是否已经发生了变化，但如果
// 节点可以重用，那么可能出现这种情况：当第一个线程在判断头节点有没有变化时，另一个线程
// 抢先弹出了该节点，并被该线程或其他线程重用作为头节点重新插入到了栈中。执行比较交换的
// 第一个线程将在这个时候发现头节点并没有什么变化，可以执行它的操作，CAS 操作将成功。但
// 实际上栈已经发生了变化，CAS 应该失败。
//
// 为什么这会是一个问题，我们来看一个示例，假设栈中有两个节点，X 位于栈顶，随后是节点 Y，
// 假定一个线程试图弹出 X 并将下一个节点 Y 读取到局部变量中。但是它还没来得及执行 CAS
// 操作，另一个线程首先弹出了 X 然后继续弹出了 Y，使得栈为空。此时，又来了一个线程，压
// 入一个新节点 Z，并且随后再次压入 X（无论是什么原因）。此时，X 的 next 指针指向 Z，但
// 当第一个线程恢复执行并且执行 CAS 时，发现头节点没变，CAS 操作将成功：它把 Y 作为栈
// 新的头节点，即使 Y 已经消失了，然后 Z 将完全被丢弃。这种情况的复杂性将令人感到非常沮
// 丧。
//
// 要避免这个问题，通常需要在 CAS 操作中使用额外的状态，例如一个版本号，在每次压入或者
// 弹出节点时都递增这个版本号。换句话说，现在不是更新一个值，而是同时更新两个：指针以及
// 新的整数版本号。如果要实现这个操作，那么就需要额外的间接层，例如使用一个独立的对象，
// 或者将 CAS 操作数量翻倍，例如在 32 位机器上执行 64 位的 CAS，或者在 64 位机器上执行
// 128 位的 CAS。由于后一种方式并非在所有架构上都是可用的，这就使得编写高效的、可移植的、
// 并且不出现 ABA 问题的结构变得非常困难。在托管代码中不会出现这种情况（除非我们明确地
// 将节点放入对象池中），因为 .NET 与 VC++ 不同，只要指向某个对象的引用依然存在，那么这
// 个对象的内存就不会被重用，这种行为以及互锁操作和执行 GC 的代码一起确保了不会出现 ABA
// 问题。
//
// ABA 问题是很难发现和修复的，然而你不需要编写自己的 ABA 安全机制，Win32 提供了一个无
// 锁栈，称为互锁单向链表（Interlocked Singly Linked List, SList），虽然这个这个链表
// 使用了前面介绍的相同算法，但在内部可以防止 ABA 问题的发生。Windows 内核大量地使用了
// SList。SList 通过 LIST_HEADER 数据结构来表示，要创建一个空的 SList，只要在某个地方
// 分配链表内存，并且调用初始化函数。LIST_HEADER 由操作系统来管理，你不能自行管理，并且
// 在不同的架构之间很有可能发生变化。
//      VOID InitializeSListHead(PSLIST_HEADER ListHead); // Windows XP Server 2003
//
// 链表元素类型为 SLIST_ENTRY 数据结构，通常这些元素将被作为成员嵌入到其他数据结构中，
// 用来在 SList 中将所有节点链接起来。所有节点元素都必须对齐了 MEMORY_ALLOCATION_ALIGNMENT
// （16 字节或 8 字节）边界，没有对齐的元素将导致不可预期的结果。使用以下函数从栈中压入
// 或弹出元素。如果编译时 NTDDI_VERSION >= NTDDI_WIN8，InterlockedPushListSList 版
// 本会被替换为 InterlockedPushListSListEx。 InterlockedPushListSListEx 函数版本不
// 使用 __fastcall 调用约定。
//      PSLIST_ENTRY InterlockedPushEntrySList(PSLIST_HEADER, PSLIST_ENTRY); // 返回原来的头节点，Windows XP Server 2003
//      PSLIST_ENTRY FASTCALL InterlockedPushListSList(PSLIST_HEADER, PSLIST_ENTRY first last, ULONG Count); // Windows Vista Server 2008
//      PSLIST_ENTRY InterlockedPushListSListEx(PSLIST_HEADER, PSLIST_ENTRY first last, ULONG Count); // 插入多个元素，Windows 8 Server 2012
//      PSLIST_ENTRY InterlockedPopEntrySList(PSLIST_HEADER ListHead);
//
// 在 SList 中还有两个其他操作，清空这个链表，以及统计链表中元素的数量。当清空链表时，将
// 返回一个指向原来头节点的指针，然后当你需要处理这些元素或者释放它们相关的内存时，可以
// 通过头节点来遍历这个链表。链表插入的元素个数没有限制，但是 QueryDepthSList 返回的最
// 大值为 65535，它返回的是元素个数的低 16 位，例如元素个数为 65536 将返回 0。在多线程
// 程序中，不能依赖返回的元素个数，因为随时可能被其他线程更新。
//      PSLIST_ENTRY InterlockedFlushSList(PSLIST_HEADER ListHead);
//      USHORT QueryDepthSList(PSLIST_HEADER ListHead);
//
// 互锁单链表（SList）简化了从链表中插入和删除的任务。SList 使用非阻塞算法实现，以提供
// 原子同步，提高系统性能，并避免诸如优先级反转和锁护送等问题（avoid problems such as
// priority inversion and lock convoys）。优先级反转问题，是指优先级顺序被颠倒，高优
// 先级被低优先级间接堵住，高优先级任务反而跑不动的问题。高优先级任务 H 所需资源被低优先
// 级任务 L 占有，而 L 又抢不到 CPU（被一堆中优先级任务 M 抢占），导致 H 被间接饿死。
// 关键：H 与 M 并不共享任何锁，但调度结果却是 M 先跑、H 阻塞，优先级顺序被“反转”。主流
// 解决方法有，优先级继承（PI）：L 临时升到 H 的优先级，尽快放锁。优先级天花板（PCP）：
// 资源本身带一个 “天花板” 优先级，拿锁就升到天花板，避免 M 插进来。
//
// 锁护送/锁车队问题，是当多个优先级相同的线程反复争夺同一个锁时出现的现象，时间片被锁切
// 成碎片，大家轮流抢锁，集体频繁阻塞和唤醒，唤醒执行很短的时间片又被阻塞。即锁刚被释放，
// 就被下一个线程获取只跑一小会儿又释放锁继续阻塞进行下一次枪锁，导致系统不断做上下文切
// 换，像 “车队” 一样集体慢下来。关键：纯粹是调度粒度被锁切成碎片，CPU 大量花在切换上。
// 危害：吞吐量骤降，且 “不参与抢锁” 的同级线程反而能拿到完整时间片，出现调度不公平。缓
// 解：让线程先自旋或 try lock 若干次，失败再阻塞；使用分段锁、RCU 等降低竞争；提高锁持
// 有粒度或改用无锁算法。
//
// 分段锁（Segmented Locking）与 RCU（Read-Copy-Update）是两种把 “大锁” 拆成 “小锁”
// 或直接 “无锁” 的并发策略，目标都是降低锁竞争，但适用场景和实现方式完全不同。分段锁是
// 把共享数据结构（通常是哈希表）逻辑划分成若干段（segment/bucket），每一段配一把独立锁。
// 写线程只锁定目标段，其余段可继续被读写，冲突范围从 “整张表” 缩小到 “一个段”。读线程
// 在多数实现里仍要拿段锁（或使用 RW Lock 读锁），但并发程度已随段数线性提高。段数一般
// 固定（JDK1.7 ConcurrentHashMap 默认 16），扩容时需对整个段重新哈希，段内仍可能阻塞。
// 适用于哈希表、缓存等可天然分区且写操作相对均匀的场景。优点：实现直观、锁粒度可控；缺
// 点：段数固定导致热点段依旧竞争激烈，跨段操作（如全局统计）需一次性拿多把锁。
//
// RCU（Read-Copy-Update）读操作完全无锁，写操作通过 “副本+指针切换+延迟回收” 保证一
// 致性。读线程直接取指针即可进入临界区，架构层保证指针读原子。写线程先复制一份新数据，
// 在副本上修改，再用原子写操作把全局指针指向新副本；旧数据不会立即释放，而是登记一个回
// 调。当内核确认 “所有 CPU 都经历了一次上下文切换”（即宽限期 Grace Period），才执行回
// 调把旧副本真正 kfree。适用于链表、路由表、 dentry 缓存等读多写极少且元素通过指针链接
// 的结构。优点：读侧开销接近零，可扩展性最好；缺点：写侧代价高（复制+等待 GP）、只能保
// 护 “指针可见” 的数据结构，对数组/环形缓冲区不直观；内存占用暂时翻倍。宽限期（Grace
// Period）：在写者完成数据更新并切换指针后，并不会立即释放旧数据的内存空间。这是因为可
// 能还有一些读者线程在写操作开始前就已经进入临界区，正在访问旧数据。只有当所有在写操作
// 开始前进入临界区的读者都退出临界区后，旧数据才会被安全地释放。从写者完成更新到旧数据
// 被释放的这段时间，就称为宽限期。宽限期的实现依赖于内核中对 CPU 上下文切换等事件的监
// 测，当所有 CPU 都经历了一次上下文切换（表示之前的读操作都已完成），宽限期结束，旧数
// 据可以被回收。
//
// 在 32 位代码中，SList 的实现和使用相对简单。然而，在 64 位代码中实现它们是一个挑战，
// 因为它不像 32 位代码那样，原生互锁交换原语可交换的数据量能达到地址大小的两倍。因此，
// 使用 SList 将使得高端可扩展算法移植到 Windows 成为可能。从 Windows 8 开始，为 64
// 位代码提供了适当的原生互锁交换原语，例如 InterlockedCompare64Exchange128。
//
// 重新回顾 Dekker 互斥算法。这段代码一个常见问题是，enter 函数的内部循环中可能被认为
// 带有循环不变性（turn == j），那么编译器可能将 turn 的读取操作提升到循环之外，这将
// 导致线程永远处于自旋状态，可以将 turn 标记为 volatile 避免这个问题。同样，一个聪明
// 的编译器可能会推断，i 应该永远都不能等于 1-i，因此在循环中读取的 enter_req[j] 元素
// 将不会在循环体内部被写入，编译器可以把读操作再次提升到循环之外，也导致无限自旋的情况。
// 同样我们需要将 enter_req 标记为 volatile。
//      static volatile bool enter_req[2] = {false};
//      static volatile int turn = 0;
//      void enter(int i) {         // i 表示当前线程的索引，0 或者 1
//          int j = 1 - i;          // j 表示另一个线程
//          enter_req[i] = true;    // 当前线程请求进入临界区
//          while (enter_req[j]) {  // 等待直到另一个线程不不希望进入临界区
//              if (turn == j) {    // 还没有轮到我们，因此必须后退并且等待
//                  enter_req[i] = false;
//                  while (turn == j) ;
//                  enter_req[i] = true;
//              }
//          }
//      }
//      void leave(int i) {
//          turn = 1 - i;           // 让出当前线程的轮次
//          enter_req[i] = false;   // 退出临界区
//      }
//
// 如果没有将这些变量标记为 volatile，那么我们需要注意其他一些问题。将 false 写入到
// enter_req[i] 的操作可能被移动到 turn 读取操作之后，并且与将 true 写入 enter_req[i]
// 的操作合并起来。结果就是，我们永远都不会让出标记，这导致了其他线程永远的自旋以等待看
// 到标志变为 false。一个更基本的问题是，如果没有 volatile 变量，那么 enter 将不会产生
// 任何栅栏。假设调用者在进入临界区之后立即读取一个变量，这个读取操作可能被移动到写入
// enter_req[i] 之前以及读取 enter_req[j] 之前，因为写入操作可以跨越到读取操作之后。
// 这种情况的后果就是破坏了互斥行为，在临界区内读取的变量可能被并发地改变，这可能带来灾
// 难性的结果。另外，VC++ 的 volatile 生成的栅栏无法在处理器级别上起作用。
//
// 并行容器与普通容器的区别主要体现在以下几个方面：
//  1.  并行容器能够提供可伸缩的访问。在并发访问中，普通容器通常并不安全，即使是安全的，
//      对于大多数为并发访问提供安全容器的通用库来说，它们的重点都放在提升单线程的性能
//      上，而不是实现可伸缩性。.NET 1.0 中的非泛型集合类型就是这种情况，它们只是在底层
//      串行容器上提供一个同步包装。尽管这种方式能够保证正确性，并且也简单，但却不能充分
//      利用许多容器内在的可伸缩性。
//  2.  并行容器可以提供更高效的并行遍历。许多并行算法都需要对数据源进行分割，这样多个线
//      程可以对数据源同时执行某个操作（即数据并行）。这个数据源通常是某种并行容器，因此
//      通过可伸缩的方式来访问它将实现高效的并行遍历。
//  3.  有些容器（但并非所有容器）提供了并发的协作机制，这种机制在一种并行容器中是最为常
//      见的，即生产者消费者容器。这些容器通过一些结构化模式使多个线程能够彼此写作，这些
//      模式将复杂的同步操作隐藏在简单易用的容易接口后面，例如阻塞队列或者有界队列。
//
// 并行容器的实现有多种方法选择，粗粒度锁定是最容易实现的模式，而当数据可以被拆分为多个    *** 粗粒度锁定
// 不同的段（Piece）时细粒度锁定将更有优势，而无阻塞技术或无锁技术可以彻底避免使用锁。只
// 有当多个线程同时访问同一段数据时，才会出现竞争。细粒度锁定这种模式可以采取两种形式，    *** 细粒度分段锁定
// 将锁与数据结构的各个段关联起来，例如链表中的每个节点，或者通过某种映射机制将每一段映
// 射到集合中的一组锁中。第一种方式很容易理解，一些低开销的锁变得更为重要，例如以字为单
// 位的自旋锁。第二种方法可能不太明显，条带映射（Striping）是一种最常用的技术，它使实际
// 需要的锁比数据的分段数量要少。为了说明条带映射，假设一个数据结构被拆分为 P 段，并且有
// L 个锁，这样当一个线程需要访问该结构中的某一段 Pn 时，需要获取锁的编号为 Pn%L。L 的
// 大小可以根据并发级别来选择，合理的大小可以有效地消除瓶颈并减少竞争。假设有一个数值，
// 其中包含 2048 个元素，并且由 16 个锁来保护。如果要访问第 1077 个元素，那么就需要获取
// 编号为 5 的锁。其他一些分配锁的模式也可以降低伪竞争（False Contention）的情况，如果
// 数据结构中两个逻辑上不相交的段使用了同一个锁，那么当两个线程分别访问这两个段时将会出
// 现伪竞争的情况。虽然细粒度锁定能够提供更好的可伸缩性，但在单个容器中拥有多个锁将增加
// 代码的复杂性。它不仅增加单个实例中操作系统资源的存储空间和管理工作，还是得锁的实现将
// 变得复杂，因为我们必须小心地以正确顺序来获取锁，这样才不会出现死锁。在执行一些对全局
// 产生影响的操作之前，例如调整容器的大小以及清除容的元素等，通常需要获取多个锁，此外枚
// 举操作也是很复杂的。如果这些操作被频繁使用，那么所导致的开销将远远高于粗粒度锁定带来
// 的开销。
//
// 如果在数组中，元素的大小都是一个字长，并且被正确地对齐（任何一个元素都不会跨越一块指
// 针大小的内存），那么程序可以安全地读取或者写入这个数组，因为硬件确保了这些操作的原子
// 性。如果元素的大小超过了一个字长或者没有被正确对齐，那么就需要使用锁定机制。在数组中
// 增加细粒度的锁并不困难，我们只需将这个数组划分为多个段，并且为每一段分配一个唯一的锁，
// 或者使用条带映射。这种设计方法非常类似于同队对数据进行分割来实现数据并行。
//
// 在栈中使用细粒度锁几乎没有任何意义，栈通常不支持随机访问，栈的头节点在本质上限制了并
// 发，栈必须在头节点上进行压入或者弹出。而队列则不同，它有两个端口，入队操作在一端进行，  *** 使用两个锁的细粒度锁定队列
// 出队操作在另一端进行。一种通过细粒度锁来提高并发的方式是，使用两个锁，每端一个。这种
// 方式是正确的，但却容易造成死锁。在实现队列时可以采用多种方式，但一种常见的方式是使用
// 链表。在队列中存在两个成员，一个指向头节点，一个指向尾节点，在大多数时间里，这些操作
// 是完全独立的。但当队列变小时，可能需要获取两个锁，事实上队列的操作逻辑很快会变得复杂。
// 例如当第一个节点进入队列时，头节点和尾节点都必须指向它，而当最后一个节点离开队列时，
// 头节点和尾节点都必须为空。要确保这两个线程都注意到彼此的进展情况很困难，以下是容易出
// 现死锁的地方。例如，入队操作首先获取了它的锁，然后发现它必须获取另外一个锁；同样，出队
// 操作获取它的第一个锁，然后也发现它必须获得另外一个锁；此时，这两个操作都无法取得进展。
// 我们可以绕开这个问题，让其中一个线程首先后退，然后获得另一个锁，这样在需要持有两个锁
// 的情况下，所有线程都将以相同顺序来获取这个锁。但还有一种更简单的方法，就是使用一个哨
// 兵（Sentinel）节点来表示空队列，这样我们就不用担心两个线程在不同的共享位置上操作。要
// 创建一个通过数组来存储数组的细粒度锁定队列将更复杂一些，但肯定是可以实现的，它看上去
// 非常像使用链表的队列，但要求当数组被填满时能够正确地调整队列的大小。在这里存在一个良
// 性竞争，它会导致在并非绝对必要的情况下重新调整数组的大小。在看到对满之后，可能其他线
// 程在当前线程调用 resize 之前从队列中取出元素，此时当前线程将仍然扩充数组的大小，但从
// 技术上看，数组其实已经有了可用的空间。为了避免这种情况，我们在 resize 获取出队锁之后，
// 需要再次检查完整的条件。但这只是一个很小的优化，它会增加代码的复杂度，因此是否采用这
// 个优化值得商榷。
//
// 无锁队列的实现，它维持头节点和尾节点两个指针，在入队新节点时将插入到尾部，而出队操作
// 将在头部进行。当 head 等于 tail 时，这意味着 head->next 为空，队列也被认为空。当入
// 队一个新节点时，我们必须更新尾节点的 next 指针，将它指向这个新节点。在尾节点插入之后，
// q->tail 实际处于不同步状态，因为其他线程随时又插入了新的尾节点。这就是为什么在插入时
// 要先调用 catch_up_tail 的原因，每个插入线程都需要尽可能抓住最新的尾节点去插入。另外，
// view_iterator() 提供了队列在特定时刻的快照（snapshot），对容器内容进行遍历的线程将
// 不会观察到随后的更新，它是通过在调用开始记住尾节点来实现的，当遍历链表时，将在到达这
// 个尾节点时停止遍历动作。
//      struct lock_free_que { prh_data_snode *head, *tail; };
//      void lock_free_que_init(struct lock_free_que *q) {
//           q->head = q->tail = malloc(sizeof(prh_data_snode));
//           _WriteBarrier();
//      }
//      prh_data_snode *catch_up_tail(struct lock_free_que *q) {
//           prh_data_snode *tail = q->tail;
//           prh_data_snode *tail_next = tail->next;
//           while (tail_next != prh_null) {
//               InterlockedCompareExchange(&q->tail, tail_next, tail);
//               tail = q->tail;
//               tail_next = tail->next;
//           }
//           return tail;
//      }
//      void enqueue(struct lock_free_que *q, void *data) {
//          prh_data_snode *new_node = malloc(sizeof(prh_data_snode));
//          new_node->data = data;
//          new_node->next = prh_null;
//          prh_data_snode *tail;
//      lable_retry:
//          _ReadBarrier();
//          tail = catch_up_tail(q);
//          if (InterlockedCompareExchange(&tail->next, new_node, prh_null) != prh_null) {
//              goto label_retry;
//          }
//          // 这个操作失败不要紧，因为表示其他线程又插入了新的节点（以 catch_up_tail 看到的包含了不管是当前
//          // 还是其他线程插入后的队列的尾节点为基准插入），尾节点已经指向了其他线程插入的新节点
//          InterlockedCompareExchange(&q->tail, new_node, tail);
//      }
//      prh_data_snode *dequeue(struct lock_free_que *q) {
//          prh_data_snode *head = (prh_data_snode *)q;
//          prh_data_snode *head_next;
//          for (; ;) {
//              _ReadBarrier();
//              head_next = head->next;
//              if (head_next == prh_null) return prh_null;
//              if (InterlockedCompareExchange(&head->next, head_next->next, head_next) == head_next) {
//                  return head_next;
//              }
//          }
//      }
//      prh_data_snode *view_iterator(struct lock_free_que *q) {
//          _ReadBarrier(); // 仅托管代码有效，因为托管代码只要有引用存在内存就不会释放
//          prh_data_snode *curr = q->head->next; // 如果是 VC++，头部节点可能被其他线程释放掉，导致内存访问违规
//          prh_data_snode *tail = catch_up_tail(q);
//          while (curr != prh_null) {
//              yield curr;
//              if (curr == tail) break;
//              curr = curr->next;
//          }
//      }
//
// 工作密迁队列（Work Stealing Queue）。大多数调度器，例如 CLR 线程池，在运行时都是基
// 于一个全局工作队列。这个队列由一个锁保护，所有的入队操作和出队操作都必须被串行化。池
// 中的每个工作线程在完成当前任务之后，都要回到这个队列并取出一个新的工作项。这种方式虽
// 然简单，但却会导致在队列种发生大量竞争。对于执行时间很短的细粒度任务来说，随着处理器
// 数量的增加，线程在竞争种所耗费的时间也将增加。另一种数据结构称为工作密迁队列，这个队
// 列可以极大地减少这种竞争并且提高可伸缩性。这个队列使得线程在自己的私有端（Private
// End）执行压入和弹出操作非常简单，并且允许其他线程从另一端执行弹出（密迁）操作，但是
// 从外部执行压入操作是不被允许的。每个处理器自己产生的任务都压入自己本地的私有端，当每
// 个处理器查找需要执行的任务时，首先从自己的私有端弹出任务，如果私有端已经没有任务，将
// 从其他处理器队列的外部端获取任务执行。这对于分而治之的算法，以及任务时从其他任务派生
// 出来的情况，带来非常大的性能提升。而且，它还可以通过细粒度的分解来降低开销。以下实现
// 的队列是基于数组的，并且是一个带有头索引和尾索引的循环队列。local_push 和 local_pop
// 由拥有这个队列的线程调用，在线程的私有端进行压入和弹出。try_steal 是外部线程从队列的
// 另外一段执行弹出操作，这个方法是线程安全的，因此多个外部线程可以同时执行这个操作。
//      struct work_steal_que {
//          void **array;
//          int size_minus_one;
//          int head;
//          int tail;
//          lock foreign_lock;
//      };
//      bool is_empty(struct work_steal_que *q) {
//          _ReadBarrier();
//          return q->head == q->tail;
//      }
//      int count(struct work_steal_que *q) {
//          _ReadBarrier();
//          return q->tail - q->head;
//      }
//      void local_push(struct work_steal_que *q, void *data) { // 压入到尾部，只有 local_push 才能扩展数组大小
//          _ReadBarrier();
//          int tail = q->tail;
//          int size_minus_one = q->size_minus_one;
//          void **array = q->array;
//          if (tail - q->head < size_minus_one) { // 队列未满，队列满时只能保持 size - 1 个元素
//              array[tail & size_minus_one] = data;
//              q->tail = tail + 1;
//              _WriteBarrier();
//              return;
//          }
//          lock(q->foreign_lock);
//          if (tail - q->head < size_minus_one) {
//              array[tail & size_minus_one] = data;
//              q->tail = tail + 1;
//          } else { // 扩充数组容量
//              int new_size_minus_one = (size_minus_one << 1) | 1;
//              void **new_array = malloc(new_size_minus_one + 1);
//              for (int i = 0; i <= new_size_minus_one; i += 1) {
//                  new_array[i] = array[(i + q->head) & size_minus_one];
//              }
//              q->head = 0;
//              new_array[size_minus_one] = data;
//              q->tail = size_minus_one + 1;
//              q->size_minus_one = new_size_minus_one;
//          }
//          unlock(q->foreign_lock);
//      }
//      void *local_pop(struct work_steal_que *q) { // 从尾部弹出
//          void *data = prh_null;
//          _ReadBarrier();
//          int tail = q->tail - 1;
//          q->tail = tail; // 占有一个元素
//          _ReadWriteBarrier();
//          if (q->head <= tail) { // 元素占有成功
//              data = q->array[tail & q->size_minus_one];
//          } else {
//              lock(&q->foreign_lock);
//              if (q->head <= tail) { // 占有失败的元素被 try_steal 回退了
//                  data = q->array[tail & q->size_minus_one];
//              } else {
//                  q->tail = tail + 1; // 占有失败
//              }
//              unlock(&q->foreign_lock);
//          }
//          return data;
//      }
//      void *try_steal(struct work_steal_que *q) { // 从头部弹出
//          void *data = prh_null;
//          if (try_lock(&q->foreign_lock)) { // 只有当队列中元素很少时才会 lock 失败
//              int head = q->head;
//              q->head = head + 1; // 占有头部元素
//              _ReadWriteBarrier();
//              if (head < q->tail) {
//                  data = q->array[head & q->size_minus_one];
//              } else {
//                  q->head = head; // 占有失败恢复头节点
//              }
//              unlock(&q->foreign_lock);
//          }
//          return data;
//      }
//
// 生产者消费者关系是在两个或多个任务之间形成的一种常见关系，在这种情况中，一个或多个生
// 产者通过某种通信机制与一个或多个消费者关联起来。生产者负责生成数据项，而消费者则通过
// 某种方式来处理数据项。生产者和消费者的比率可以在很大范围内变动，最优的吞吐量的比率取
// 决于在生产元素和消费元素中包含的开销：如果消费一个元素的开销是生产一个元素开销的 10
// 倍，那么当生产者与消费者的比率为 1:10 时，可以在生产者和消费者之间达到最佳平衡。如果
// 将这种情况扩展为包含多个阶段，那么将形成一个流水线（Pipeline）。流水线是多个生产者消
// 费者关系组合成的一个更大数据流。
//
// 容器是一种为生产者消费者模式实现通信的常见方式，但已介绍的容器都没有包含内置的协作机   *** 实现协作式容器
// 制。对于容器本身来说，它们并不需要考虑调用者会对返回值做出何种响应，但如果调用者希望
// 等待一个元素到来，那么该怎么办？构建一个阻塞队列（Blocking Queue）来提供这种行为是
// 非常简单的，只需要将现有的队列用某种同步机制包装起来。另一个相关的情况是，如果我们估
// 计生产者的速率有时候会超过消费者的速率，那么该怎么办？我们可能希望限制新元素的入队速
// 率，从而限制对内存的消耗。要实现这个功能，我们需要通过某种逻辑来阻塞生产者，这称为有
// 界缓冲区（Bounded Buffer）。我们现在来看一些构建这两种容器的方法，通常，在单个类型
// 中实现阻塞和有界等功能是非常有用的，在实现时必须要考虑三个基本的因素：
//  1.  容器必须支持安全的并发访问
//  2.  当消费者试图从空队列中取走一个元素时，它必须被阻塞（Blocking）值得生产一个元素
//  3.  当生产者试图将一个元素放入已满的队列时，它必须阻塞，直到消费者取走一个元素为新
//      元素腾出空间，这也称为有界（Bounding）
//
// 还有一种常见的协作方式，从严格意义上来看它并不是一个容器，这种协作方式称为栅栏（Barrier）。
// 使用栅栏的计算通常被称为分阶段计算（Phased Computation）。使用栅栏的算法被拆分为多个   *** 通过线程栅栏协作方式来实现分阶段计算
// 独立的阶段并且有时候时循环的，所有线程都将等待每个参与者到达当前阶段的末尾后，再一起
// 进入下一阶段进行处理。例如，CLR 中的 GC 就是hi用了这种方法来对线程进行同步：执行标记
// （Marking）、重定位（Relocating）、以及紧缩（Compacting）等操作。在某个阶段中，各个
// 参与线程通常会产生一些数据并将它们存储在某个共享位置，例如线程 n 将数据存在在数组 a[n]
// 位置，所有参与线程在下一阶段中可以安全地访问这些数据。这个数据结构的任务很简单，它必须
// 阻塞所有到达栅栏的线程，直到一个特定的数值到来，此时释放所有的线程。有几种不同的算法
// 可供选择，其中一种算法在拥有大量处理器的机器上表现得很好，并且不需要任何锁定，这个算法
// 称为逆向栅栏（Sense-Reversing Barrier）。
//
// 有时候，自旋等待（Spin Waiting）要好于真正的阻塞，许多同步原语，例如 CLR 监视器和     *** 自旋等待
// Win32 临界区，都使用了一种两阶段锁定协议（Two-phase Locking Protocol），在通过等待
// 来获取某个锁之前，首先会自旋一段时间。为什么自旋是一种合适的方式，原因是上下文切换以
// 及内核切换等操作的开销都是很高的，频繁锁的获取和释放会将线程时间片切得很碎导致线程的
// 执行效率低下（锁护送效应）。在多处理器机器上，自旋可以避免这两种操作。我们来分析在没
// 有使用自旋时出现的情况：
//  1.  线程 T1 获取了锁 L，并且开始执行它的临界区代码
//  2.  线程 T2 试图获取锁 L，然而被 T1 阻塞，这将导致 T2 线程的一次内核切换和一次上下
//      文切换
//  3.  线程 T1 退出临界区，释放锁 L，这将通知 T2 醒来，这个信号本身将同样导致一次内核
//      切换，并且根据优先级提升的结果以及系统的当前状态，还可能出现一些上下文切换
//  4.  线程 T2 醒来，并且再次尝试获取锁 L，这同样会导致一次上下文切换，因为 T2 将被重
//      新调度
//
// 这个示例包含了两次上下文切换，一次是线程 T2 被阻塞时，第二次是 T2 被唤醒时。如果 T1
// 在临界区内执行的时候非常短，那么将浪费两次上下文切换的时间，而且处理器缓存可能失效，
// 因为原来运行 T2 的处理器当 T2 随眠后可能分配给其他线程，或者 T2 线程唤醒后被分配到
// 一个新处理器上执行。自旋锁可以彻底避免上下文切换，通过使用自旋锁，T2 在步骤 2 中将不
// 会阻塞，而是通过自旋来等待 L 被释放，这同样避免了步骤 4 中的切换，因为当 T2 注意到
// L 被释放就可以直接执行。由于大量的竞争通常时很常见的，并且锁的平均持有时间通常是很短
// 的，因此自旋等待可以带来一定的好处。
//
// 然而，要实现通用的自旋锁却非常困难，在确保自旋锁在 Windows 上正确地工作，需要考虑许
// 多细节问题，这些问题与线程调度器、Intel 超线程技术（HT）、以及缓存等都是相关的。此外，
// 在最坏的情况下，大多数资源最终都将执行真正的等待，例如实现自旋锁的复杂性超过了上下文
// 切换带来的开销。即使最坏的情况看上去是不太可能的，但当线程正在临界区中执行时被中断，
// 或者当某个锁上的到达率非常高时，仍然会出现这种情况。我们将分析两种自旋锁方法，一种方
// 法是在共享遍历上自旋，并且不会执行真正的等待，不过在一定时间后，它会让出线程的时间片。
// 第二种方法被称为 “Mellor-Crummey-Scott MCS” 锁，它能够减少在共享内存位置上的竞争。
// MCS 锁在采用非均匀内存访问（NUMA）的多处理器机器上能够实现非常高的可伸缩性。
//
// 如何在 Windows 上正确地自旋，在分析自旋锁具体细节之前，我们必须考虑一些如何在 Windows
// 上使用自旋等待的基本规则。
//  1.  在自旋等待循环中的每次迭代中调用 YieldProcessor，该函数将在启动 Intel 超线程
//      技术（HT）的处理器上生成 YIELD 或者 PAUSE 指令，在不支持超线程技术的处理器上
//      则产生 NOP 指令。在 .NET 中的 Thread.Yield 带有一个数值参数，表示在循环中生成
//      这些指令的数量。这确保了处理器能够知道当前运行的代码正在执行自旋等待，因此将执行
//      单元提供给其他逻辑处理器使用。
//  2.  在大多数自旋等待情况中，每次迭代都将读取一些工作状态，这可能导致内存通信量以及
//      缓存竞争的增加。因此，一种明智的做法就是在每次自旋迭代中使用逐渐增长的延迟，称
//      为指数衰减（Exponential Backoff）。有时候，可以通过等待一段随机的时间来避免线
//      程执行同一种自旋策略，因为这可能导致严重的活锁问题。
//  3.  如果使用了纯粹的自旋等待（而不是两阶段自旋等待），那么有时候需要通过相应的 API
//      来执行显式的上下文切换。原因是，如果线程自旋的时间超过了执行一个完成上下文切换
//      所需的时间，那么更合适的做法就是允许其他的线程执行，而不是持续使用处理器资源（可
//      能会妨碍其他正在等待的线程执行）。
//  4.  当主动引发上下文切换时，最合适使用的 Win32 函数是 SwitchToThread，它将交出调
//      用线程的时间片，并且由另一个可允许的线程来取代它执行。如果函数返回 TRUE，表示
//      切换操作成功了，否则将返回 FALSE。从 Windows Vista 和 Server 2008 开始，这个
//      函数将不会考虑系统中所有的线程。
//  5.  因为 SwitchToThread 在切换时不会考虑系统中所有的线程，一种明智的做法就是偶尔
//      调用 Sleep 或者 SleepEx 并将参数指定为 0，因为当不存在优先级相同并且就绪的可
//      运行线程时，将不会导致上下文切换。然而，有时候将参数指定为 1 同样有用，如果你遇
//      到的情况是，某个高优先级的线程正在自旋等待一个低优先级的线程，那么这将有助于避免
//      产生饥饿问题。
//
// 纯自旋锁（Spin Only Lock）仅适合于当临界区极小的情况，判断是否可以采用纯自旋锁的一个
// 经验法则是：临界区中不超过 10 条指令，并且执行时间不超过 50 个时钟周期。这排除了许多
// 操作，包括内存分配、任何高延迟资源的访问，例如文件系统。构建一个纯自旋锁很简单，我们
// 将使用一个标志，其中 0 表示锁是可用的，并且线程将通过互锁操作来比较并交换（CAS）一个
// 非 0 值。线程通过它们自己的 ID 来标识所有权，在构建纯自旋锁时最困难的地方在于，如何
// 根据具体的负载来调整自旋逻辑。
//
// MCS 锁（Mellor-Crummey Scott）是基于 TATAS 锁构建的，目的在于减少锁状态所在缓存行
// 上的内存竞争。唯一的差异在于，线程不是在读取共享锁状态的操作上自旋，而是在一个线程私
// 有的锁状态标识上自旋。每个检测竞争的线程都将分配一个新的本地标志，并将它放入一个共享
// 的等待队列中。线程将在它自己的标志上自旋，当锁的持有者退出这个锁时，它将唤醒一个等待
// 中的线程，而这个醒来的线程将尝试获取锁。
//
// LOCK 前缀（F0H）用于强制执行一个操作，确保在多处理器环境中对共享内存的独占访问。LOCK   *** LOCK 前缀
// 前缀的作用是在执行伴随的指令时，使处理器的 LOCK# 信号使能（将指令转换为原子指令）。
// 在多处理器环境中，LOCK# 信号确保在信号使能期间，处理器对任何共享内存拥有独占使用权。
// 在大多数 IA-32 处理器和所有 Intel 64 处理器中，锁定操作并不通过使能 LOCK# 信号来实
// 现，见下面 “IA-32 架构兼容性” 部分。
//
// LOCK 前缀只能添加到以下指令，并且只能用于这些指令的目标操作数为内存操作数的形式：ADD、
// ADC、AND、BTC、BTR、BTS、CMPXCHG、CMPXCH8B、CMPXCHG16B、DEC、INC、NEG、NOT、OR、
// SBB、SUB、XOR、XADD 和 XCHG。如果使用 LOCK 前缀的指令中源操作数为内存操作数，可能会
// 生成未定义操作码异常（#UD）。如果 LOCK 前缀用于上述列表之外的任何指令，也会生成未定义
// 操作码异常。XCHG 指令无论是否带有 LOCK 前缀，都会使能 LOCK# 信号。
//
// LOCK 前缀通常与 BTS 指令一起使用，以在共享内存环境中对内存位置执行读-改-写操作。LOCK
// 前缀的完整性不受内存字段对齐方式的影响。对于任意未对齐的字段，都会进行内存锁定。该指令
// 在非 64 位模式和 64 位模式下的操作是相同的。
//
// IA-32 架构兼容性，从 P6 家族处理器开始，当 LOCK 前缀添加到指令中，并且正在访问的内存
// 区域在处理器内部被缓存时，通常不会使能 LOCK# 信号。相反，只会锁定处理器的缓存。处理器
// 的缓存一致性机制确保与内存相关的操作以原子方式执行。更多关于缓存锁定的信息，见第3A卷
// 第 10 章中的 “锁定操作对内部处理器缓存的影响”。
//
// 保护模式异常，如果 LOCK 前缀用于除以下列表之外的任何指令：ADD、ADC、AND、BTC、BTR、
// BTS、CMPXCHG、CMPXCH8B、CMPXCHG16B、DEC、INC、NEG、NOT、OR、SBB、SUB、XOR、XADD、
// XCHG，都将产生 #UD 异常。当使用 LOCK 前缀时，指令可能产生与指令相关的其他异常。
//
// Intel 64 和 IA-32 架构提供了用于管理和提高连接到同一系统总线的多个处理器性能的机制。
// 这些机制包括：
//  1.  总线锁定（Bus Locking）或缓存一致性管理：用于在系统内存上执行原子操作。
//  2.  串行化指令。
//  3.  高级可编程中断控制器（APIC）：位于处理器芯片上，见第 12 章 “高级可编程中断控制
//      器”。此功能由 Pentium 处理器引入。
//  4.  二级缓存（L2 缓存）：对于 Pentium 4、Intel Xeon 和 P6 家族处理器，L2 缓存包
//      含在处理器封装内，并与处理器紧密耦合。对于 Pentium 和 Intel486 处理器，提供了
//      支持外部 L2 缓存的引脚。
//  5.  三级缓存（L3 缓存）：对于 Intel Xeon 处理器，L3 缓存包含在处理器封装内，并与
//      处理器紧密耦合。
//  6.  英特尔超线程技术：这是对 Intel 64 和 IA-32 架构的扩展，使单个处理器核心能够同
//      时执行两个或多个线程，见第 10.5 节 “英特尔®超线程技术和英特尔®多核技术”。
//
// 这些机制在对称多处理（SMP）系统中特别有用。然而，当一个 Intel 64 或 IA-32 处理器和
// 一个专用处理器（如通信、图形或视频处理器）共享系统总线时，也可以使用这些机制。这些多
// 处理机制具有以下特点：
//  1.  维护系统内存一致性（System Memory Coherency）：当两个或多个处理器同时尝试访问
//      系统内存中的同一地址时，必须有一种通信机制或内存访问协议来促进数据一致性，并且
//      在某些情况下，允许一个处理器暂时锁定一个内存位置。
//  2.  维护缓存一致性（Cache Consistency）：当一个处理器访问另一个处理器上缓存的数据
//      时，它不能收到错误的数据。如果它修改了数据，所有访问该数据的其他处理器必须收到修
//      改后的数据。
//  3.  允许对写入内存的顺序进行可预测的排序：在某些情况下，重要的是外部观察到的内存写入
//      顺序必须与编程顺序完全相同。
//  4.  在一组处理器之间分配中断处理：当几个处理器在系统中并行运行时，拥有一个集中机制来
//      接收中断并将它们分配给可用处理器进行处理是有用的。
//  5.  通过利用现代操作系统和应用程序的多线程和多进程特性来提高系统性能。
//
// Intel 64 和 IA-32 处理器的缓存机制和缓存一致性在第 13 章中讨论。APIC 架构在第 12
// 章中描述。总线和内存锁定、串行化指令、内存排序以及英特尔超线程技术在以下各节中讨论。
//
// 锁定的原子操作（Locked Atomic Operations），32 位 IA-32 处理器支持对系统内存中的位
// 置执行锁定的原子操作。这些操作通常用于管理共享数据结构（如信号量、段描述符、系统段或
// 页表），其中两个或多个处理器可能同时尝试修改同一字段或标志。处理器使用三种相互依赖的    *** 处理器的三种原子操作机制
// 机制来执行锁定的原子操作：
//  1.  保证的原子操作（Guaranteed Atomic Operations）
//  2.  总线锁定（Bus Locking），使用 LOCK# 信号和 LOCK 指令前缀
//  3.  缓存一致性协议（Cache Coherency Protocols），确保可以在缓存的数据结构上执行原
//      子操作（缓存锁定，Cache Lock）；此机制存在于 Pentium 4、Intel Xeon 和 P6 家
//      族系列处理器中
//
// 这些机制以以下方式相互依赖。某些基本内存事务（如读取或写入系统内存中的一个字节）总是
// 保证以原子方式处理。也就是说，操作一旦开始，处理器保证在允许另一个处理器或总线代理访
// 问内存位置之前完成操作。处理器还支持总线锁定，用于执行某些内存操作（如在共享内存区域
// 中的读-改-写操作），这些操作通常需要以原子方式处理，但不会自动以这种方式处理。由于经
// 常使用的内存位置通常缓存在处理器的 L1 或 L2 缓存中，原子操作通常可以在处理器的缓存内
// 执行，而无需使能总线锁定。在这里，处理器的缓存一致性协议确保在执行缓存内存位置的原子
// 操作时，缓存相同内存位置的其他处理器得到适当管理。
//
// 注意：在存在竞争锁访问的情况下，软件可能需要实现确保公平访问资源的算法，以防止锁饥饿。
// 硬件没有提供保证参与代理公平性的资源。软件有责任管理信号量和互斥锁函数的公平性。
//
// 处理锁定的原子操作的机制随着 IA-32 处理器的复杂性而发展。较新的 IA-32 处理器（如 Pentium
// 4、Intel Xeon 和 P6 家族处理器）和 Intel 64 提供了比早期处理器更精细的锁定机制。这
// 些机制在以下各节中描述。
//
// 保证的原子操作。Intel486 处理器（以及后续的处理器）保证以下基本内存操作始终以原子方    *** 处理器确保的原子操作
// 式执行：
//  1.  读取或写入一个字节
//  2.  读取或写入对齐在 16 位边界上的字
//  3.  读取或写入对齐在 32 位边界上的双字
//
// Pentium 处理器（以及后续的处理器）保证以下额外的内存操作始终以原子方式执行：
//  4.  读取或写入对齐在 64 位边界上的四字
//  5.  对位于 32 位数据总线上的未缓存的内存位置的 16 位访问
//
// P6 家族处理器（以及后续的处理器）保证以下额外的内存操作始终以原子方式执行：
//  6.  对位于缓存行中的缓存内存的未对齐的 16 位、32 位和 64 位访问
//
// 支持英特尔® AVX 的处理器（通过设置 CPUID.01H:ECX.AVX[28] 特性标志）保证以下指令执
// 行的 16 字节内存操作始终以原子方式执行。注意，这些指令要求其内存操作数的线性地址对齐
// 在 16 字节边界上。
//  7.  MOVAPD、MOVAPS 和 MOVDQA
//  8.  VMOVAPD、VMOVAPS 和 VMOVDQA，使用 VEX.128 编码
//  9.  VMOVAPD、VMOVAPS、VMOVDQA32 和 VMOVDQA64，使用 EVEX.128 编码且 k0（掩码禁用）
//
// 对于英特尔酷睿 2 双核、英特尔凌动、英特尔酷睿双核、奔腾 M、奔腾 4、英特尔至强、P6 家
// 族、奔腾和英特尔 486 处理器，跨缓存行和页面边界的对缓存内存的访问不能保证以原子方式执
// 行。英特尔酷睿 2 双核、英特尔凌动、英特尔酷睿双核、奔腾 M、奔腾 4、英特尔至强和 P6
// 家族处理器提供了总线控制信号，它允许外部内存子系统使这种分裂的内存访问以原子方式执行
// （make split accesses atomic）；然而，访问非对齐数据会严重影响处理器性能，应避免。
//
// 除上述情况外，访问大于四字的数据的 x87 指令或 SSE 指令可能使用多次内存访问来实现。如
// 果这样的指令写入内存，一些内存访问可能会完成（写入内存），而另一个访问可能会因架构原
// 因导致操作出现故障，例如由于一个页表项被标记成了 “不存在（not present）”。在这种情况
// 下，即使整体指令导致故障，已完成访问的效果也可能对软件可见。如果 TLB 无效化被延迟（见
// 第 5.10.4.4 节），即使所有访问都在同一页面上，也可能发生此类页面故障（page faults）。
//
// 总线锁定。Intel 64 和 IA-32 处理器提供一个 LOCK# 信号，该信号在某些关键内存操作期间   *** 总线锁定（bus locking）
// 自动使能，以锁定系统总线或等效链路（equivalent link）。使能此信号被称为一个总线锁定
// （a bus lock）。当此输出信号被使能时，来自其他处理器或总线代理的总线控制请求被阻塞。
// 软件可以通过在指令前添加 LOCK 前缀来指定其他需要遵循 LOCK 语义的场合。
//
// 在 Intel386、Intel486 和 Pentium 处理器的情况下，明确锁定的指令会导致 LOCK# 信号的
// 使能。硬件设计人员有责任在系统硬件中提供 LOCK# 信号，以控制处理器之间的内存访问。对于
// P6 及更新的处理器家族，如果正在访问的内存区域在处理器内部被缓存，通常不会使能 LOCK#    *** 新处理器可能的缓存内存的缓存行锁定（cache locking）
// 信号；相反，锁定仅应用于处理器的缓存。这些处理器会在以下两种情况下才为锁定访问使能总
// 线锁定：
//  (1) 访问跨越多个缓存行（一个分裂锁定，a split lock）。
//  (2) 访问 WB 内存类型之外的内存时（一个 UC 锁定，a UC lock），“UC 锁” 这个术语的使
//      用是因为最常见的场景涉及对 UC（不可缓存）内存的访问。尽管名称如此，对 WC（写合
//      并）、WP（写保护）和 WT（写通）内存的锁定访问也会导致总线锁定。
//
// LOCK 操作对内部处理器缓存的影响。对于英特尔 486 和奔腾处理器，即使在处理器中缓存了被
// 锁定的内存区域，LOCK 操作期间 LOCK# 信号也始终会在总线上被断言。对于 P6 和更新的处
// 理器家族，如果在 LOCK 操作期间被锁定的内存区域在处理器中被缓存为写回内存，并且完全包
// 含在缓存行中，处理器可能不会断言总线上的 LOCK# 信号。相反，它会在内部修改内存位置，
// 并允许其缓存一致性机制确保操作以原子方式执行。此操作称为 “缓存锁定（cache locking）”。
// 缓存一致性机制自动防止缓存相同内存区域的两个或多个处理器同时修改该区域中的数据。
//
// 自动锁定。处理器自动遵循 LOCK 语义的操作如下：                                      *** 自动锁定的操作
//  1.  执行引用内存的 XCHG 指令时。
//  2.  当切换到一个任务时（switching to a task），处理器会测试并设置 TSS 描述符类型
//      字段中的忙标志。为了确保两个处理器不会同时切换到同一任务，处理器在测试和设置此
//      标志时遵循 LOCK 语义。
//  3.  在加载段描述符时，处理器会在段描述符中设置已访问标志（如果未设置）。在此操作期
//      间，处理器遵循 LOCK 语义，以防止描述符在更新时被另一个处理器修改。为了使此操作
//      有效，更新描述符的操作系统程序应使用以下步骤：
//      -   使用锁定操作修改访问权限字节来指示段描述符不存在，并给类型字段指定一个值表
//          明描述符正在被更新。
//      -   更新段描述符的字段（此操作可能需要多次内存访问，因此不能使用锁定操作）
//      -   使用锁定操作修改访问权限字节，以指示段描述符有效且存在
//      -   英特尔 386 处理器始终会更新段描述符中的已访问标志，无论该标志是否已设置。
//          Pentium 4、Intel Xeon、P6 家族、奔腾和英特尔 486 处理器仅在该标志尚未设
//          置时更新此标志。
//  4.  处理器使用锁定周期（locked cycles）来设置分页结构条目中的已访问标志和脏标志。
//  5.  在中断请求之后，中断控制器可能会使用数据总线将中断向量发送给处理器。在此期间，
//      处理器遵循 LOCK 语义，以确保在传输向量时数据总线上不会出现其他数据。
//
// 软件控制的总线锁定。为了明确强制 LOCK 语义，软件可以在以下指令用于修改内存位置时使用   *** 特定指令在修改内存位置时可以手动添加 LOCK 前缀
// LOCK 前缀。当 LOCK 前缀与任何其他指令一起使用或未对内存进行写操作（例如目标操作数在
// 寄存器中）时，会生成无效操作码异常（#UD）。
//  1.  位测试和修改指令（BTS、BTR 和 BTC）。
//  2.  交换指令（XADD、CMPXCHG、CMPXCHG8B 和 CMPXCHG16B）。
//  3.  XCHG 指令自动添加 LOCK 前缀。
//  4.  以下单操作数算术和逻辑指令：INC、DEC、NOT 和 NEG。
//  5.  以下双操作数算术和逻辑指令：ADD、ADC、SUB、SBB、AND、OR 和 XOR。
//
// 锁定指令保证仅锁定由目标操作数定义的内存区域，但系统可能会将其解释为对更大内存区域的
// 锁定。软件应使用相同的地址和操作数长度访问信号量，信号量是一种共享内存，用于多个处理
// 器之间信号触发（used for signaling between multiple processors）。例如，如果一个
// 处理器使用字访问（a word access）信号量，其他处理器不应使用字节访问（a byte access）
// 信号量。注意：不要使用 WC（写合并）内存类型实现信号量。不要对用于实现信号量内存位置
// 的缓存行执行非临时存储（non-temporal stores）。
//
// 总线锁定的完整性不受内存字段对齐的影响。LOCK 语义在更新整个操作数期间都遵循，不管其    *** LOCK 的原子性不受内存对齐影响，但对齐的内存访问可以获得更好的系统性能
// 所需多少总线周期数。然而，为获得更好的系统性能，建议锁定访问对齐在其自然边界上：
//  -   8 位访问任何边界（锁定或其他）
//  -   锁定字（WORD）访问的 16 位边界
//  -   锁定双字（DWORD）访问的 32 位边界
//  -   锁定四字（QWORD）访问的 64 位边界
//
// 锁定操作（Locked Operations）相对于所有其他内存操作和所有外部可见事件是原子的。只有
// 指令获取（instruction fetch）和页表访问（page table accesses）可以穿越锁定指令。
// 锁定指令可以用于同步由一个处理器写入并由另一个处理器读取的数据。
//
// 对于 P6 家族处理器，锁定操作会串行化所有未完成的加载和存储操作（即，等待它们完成）。
// 此规则也适用于 Pentium 4 和 Intel Xeon 处理器，但有一个例外。引用弱有序（weakly
// ordered）内存类型（如 WC 内存类型）的加载操作可能不会被串行化。
//
// 锁定指令（Locked Instructions）不应用于确保写入的数据可以作为指令获取。注意：当前版
// 本的 Pentium 4、Intel Xeon、P6 家族、奔腾和英特尔 486 处理器的锁定指令允许写入的数
// 据作为指令获取。然而，英特尔建议需要使用自修改代码（self-modifying code）的开发人员
// 使用一种不同的同步机制，将在以下各节中描述。
//
// 禁用总线锁定的功能。由于总线锁定在某些情况下可能对性能产生不利影响，处理器可能支持两    *** 禁用总线锁定
// 个功能，系统软件可以使用这些功能来禁用总线锁定。这些功能称为分裂锁定禁用（split-lock
// disable）和 UC 锁定禁用（UC-lock disable）。
//
// 分裂锁定禁用的支持由 IA32_CORE_CAPABILITIES[5] 列举。软件通过设置 MSR_MEMORY_CTRL[29]
// 来启用分裂锁定禁用。当设置此位时，对多个缓存行的锁定访问会导致总线锁定违规，从而引发
// 对齐检查异常（#AC），且锁定访问不会发生。其他对齐检查异常仅在 CR0.AM=1、EFLAGS.AC=1
// 和 CPL=3 时发生。由于分裂锁定禁用导致的对齐检查异常即使在 CR0.AM=0、EFLAGS.AC=0 或
// CPL<3 的情况下也可能发生。对于这些总线锁定违规，错误代码为空（null），即错误代码的第
// 31:2 位被清零；第 0 位（EXT）可能正常设置。
//
// 处理器通过设置 IA32_CORE_CAPABILITIES MSR（MSR 索引 CFH）bit4 或列举 CPUID.07H.02H:EDX[6]
// 为 1，来支持 UC 锁定禁用功能。后者架构形式的枚举（CPUID）从基于 Sierra Forest 微架
// 构的处理器开始使用；早期处理器可能会使用旧的模型特定形式（IA32_CORE_CAPABILITIES）。
// 注意：没有处理器会同时设置 IA32_CORE_CAPABILITIES[4] 和枚举 CPUID.07H.02H:EDX[6]
// 为 1。
//
// 如果处理器以任一方式枚举对 UC 锁定禁用的支持，软件可以通过设置 MSR_MEMORY_CTRL[28]
// 来启用 UC 锁定禁用。当设置此位时，使用除 WB（写回）以外的内存类型的锁定访问会导致总线
// 锁定违规，从而引发故障，且锁定访问不会发生。发生的具体故障取决于如何枚举 UC 锁定禁用：
//  1.  如果 IA32_CORE_CAPABILITIES[4] 读取为 1，则 UC 锁定会导致一般保护异常（#GP），
//      错误代码为零。
//  2.  如果 CPUID.07H.02H:EDX[6] 枚举为 1，则 UC 锁定会导致 #AC，错误代码值为 4。第
//      0 位（EXT）可能正常设置。如果设置了 EXT 位，则错误代码的值为 5。
//
// UC 锁定禁用不适用于 VMCS 中指定的物理地址的锁定访问。此类访问包括对 EPT 的已访问标志
// 和脏标志的更新以及对发布中断描述符（posted-interrupt descriptors）的访问。如果 CR0.CD = 1
// 或启用 PRMRR 时 MSR_PRMRR_BASE_0[2:0] ≠ 6（WB），则 UC 锁定禁用未启用。如果这些条
// 件中的任何一个成立，处理器将忽略 MSR_MEMORY_CTRL[28] 的值。虽然 MSR_MEMORY_CTRL 不
// 是架构 MSR，但上述行为在 IA32_CORE_CAPABILITIES 或 CPUID 枚举支持的处理器模型中是
// 一致的。
//
// 请注意，由于分裂锁定禁用或对齐检查导致的 #AC(0) 比由于 UC 锁定禁用导致的 #GP(0) 或
// #AC(4) 具有更高的优先级。如果启用了这两个功能，则对多个缓存行的锁定访问会导致 #AC(0)，
// 无论正在访问的内存类型如何。
//
// 除了这些禁用总线锁定的功能外，还有一些功能允许软件检测何时发生了总线锁定。有关 OS 总
// 线锁定检测的信息，请参见第 19.3.1.6 节，有关 VMM 总线锁定检测的信息，请参见第 27.2
// 节。
//
// 处理自修改（Self-Modifying Code）和交叉修改代码（Cross-Modifying Code）。处理器将   *** 自修改代码的同步规则
// 数据写入当前正在执行的代码段，并打算将该数据作为代码执行的行为称为自修改代码。IA-32
// 处理器在执行自修改代码时表现出模型特定行为，这取决于被修改代码位于当前执行指针之前多
// 远。随着处理器微架构变得越来越复杂，并开始提前推测性地执行（speculatively execute）
// 代码（如在 P6 和更新的处理器家族中），关于应该执行修改前还是修改后的代码的规则变得模
// 糊。要编写自修改代码并确保其符合当前和未来的 IA-32 架构版本，请使用以下编码选项之一。
// 这些选项的使用对于打算在奔腾或英特尔 486 处理器上运行的程序不是必需的，但建议使用以
// 确保与 P6 和更新的处理器家族兼容。自修改代码的执行性能将低于非自修改或正常代码。性能
// 下降的程度将取决于修改的频率和代码的具体特性。
//      (* 选项 1 *)
//      将修改后的代码（作为数据）存储到代码段；
//      跳转到新代码或中间位置；
//      执行新代码；
//
//      (* 选项 2 *)
//      将修改后的代码（作为数据）存储到代码段；
//      执行串行化指令；（* 例如，CPUID 指令 *）
//      执行新代码；
//
// 一个处理器将数据写入第二个处理器当前正在执行的代码段，并打算让第二个处理器将该数据作    *** 交叉修改代码的同步规则
// 为代码执行的行为称为交叉修改代码（Cross-Modifying Code）。与自修改代码一样，IA-32
// 处理器在执行交叉修改代码时表现出模型特定行为，这取决于被修改代码位于执行处理器当前执
// 行指针之前多远。要编写交叉修改代码并确保其符合当前和未来的 IA-32 架构，必须实现以下
// 处理器同步算法。此选项的使用对于打算在英特尔 486 处理器上运行的程序不是必需的，但建
// 议使用以确保与奔腾 4、英特尔至强（Xeon）、P6 家族和奔腾处理器兼容。与自修改代码一样，
// 交叉修改代码的执行性能将低于非交叉修改（正常）代码，这取决于修改的频率和代码的具体特
// 性。自修改代码和交叉修改代码的限制也适用于英特尔 64 架构。
//      (* 修改处理器的操作 *)
//      Memory_Flag := 0; (* 将 Memory_Flag 设置为除 1 以外的值 *)
//      将修改后的代码（作为数据）存储到代码段；
//      Memory_Flag := 1;
//
//      (* 执行处理器的操作 *)
//      WHILE (Memory_Flag ≠ 1)
//          等待代码更新；
//      ELIHW;
//      执行串行化指令；（* 例如，CPUID 指令 *）
//      开始执行修改后的代码；
//
// 内存排序（Memory Ordering）指的是处理器将读取（加载）和写入（存储）操作通过系统总线
// 发送到系统内存的顺序。Intel 64 和 IA-32 架构根据架构实现支持几种内存排序模型。例如，   *** Intel386 执行程序排序或强排序
// Intel386 处理器强制执行程序排序（program ordering），通常称为强排序（strong ordering），
// 在所有情况下，读取和写入操作都会按照指令流中出现的顺序在系统总线上执行。
//
// 为了优化指令执行的性能，IA-32 架构允许偏离强排序模型，这种模型在 Pentium 4、Intel
// Xeon 和 P6 家族处理器中被称为处理器排序（processor ordering）。这些处理器排序变体，
// 在这里称为内存排序模型（memory-ordering model），允许执行一些性能增强操作，例如允许   *** 新处理执行较弱的内存排序模型（Memory Ordering Model），称为处理器排序
// 读取操作优先于缓冲写入操作。这些变体的目标是在保持内存一致性的同时，提高指令执行速度，
// 即使在多处理器系统中也是如此。
//
// 第 10.2.1 节和第 10.2.2 节描述了 Intel486、Pentium、Intel Core 2 Duo、Intel Atom、
// Intel Core Duo、Pentium 4、Intel Xeon 和 P6 家族处理器实现的内存排序。第 10.2.3
// 节通过示例说明了 IA-32 和 Intel-64 处理器上内存排序模型的行为。第 10.2.4 节讨论了字
// 符串操作的特殊存储处理，第 10.2.5 节讨论了如何通过特定指令修改内存排序行为。
//
// Intel® Pentium® 和 Intel486™ 处理器中的内存排序。Pentium 和 Intel486 处理器遵循处   *** Intel486 和 Pentium 除一种情况之外，始终执行强排序
// 理器排序内存模型；然而在大多数情况下，它们作为强排序处理器运行。读取和写入操作始终以
// 编程顺序出现在系统总线上，除了以下情况一表现出处理器排序。
//  1.  当所有缓冲写入（buffered write）都是缓存命中的情况下，也因此缓存命中的写入操作    *** 缓存未命中的读取操作，可以优先于缓存命中的写入操作出现在系统总线上
//      不会与缓存未命中的读取操作共享相同的内存，缓存未命中的读取操作（read misses）
//      允许优先于缓冲写入出现在系统总线上。
//  2.  在 I/O 操作的所有情况下，读取和写入操作始终以编程顺序出现。
//
// 在处理器排序处理器（如 Pentium 4、Intel Xeon 和 P6 家族处理器）上正确运行的软件不应
// 依赖于 Pentium 或 Intel486 处理器的相对强排序。相反，它应该通过使用适当的锁定或序列
// 化操作确保对控制处理器之间并发执行的共享变量的访问明确遵循程序排序（见第 10.2.5 节，
// “加强或削弱内存排序模型”）。P6 及更新的处理器家族中的内存排序。Intel Core 2 Duo、     *** Pentium 4 和 P6 及更新的处理器使用处理器排序，
// Intel Atom、Intel Core Duo、Pentium 4 和 P6 家族处理器也使用了处理器排序内存排序        其可进一步称为 “基于存储缓冲区转发的写入排序”
// 模型，其可进一步定义为 “存储缓冲区转发形式的写入操作排序（write ordered with
// store-buffer forwarding）”，该模型可以描述如下。
//
// 在单处理器系统中，对于定义为写回可缓存（write-back cacheable）的内存区域，内存排序
// 模型遵循以下原则。注意，单处理器和多处理器系统的内存排序原则，是以处理器上执行软件的
// 视角编写的，其中 “处理器” 一词指的是逻辑处理器。例如，支持多个核心或英特尔超线程技术
// 的物理处理器被视为多处理器系统。
//  1.  读取操作不会与其他读取操作重新排序。
//  2.  读取操作不会与之后的写入操作重新排序。
//  3.  写入内存的操作不会与其他写入操作重新排序，以下情况除外：
//      -   使用非临时移动指令（MOVNTI、MOVNTQ、MOVNTDQ、MOVNTPS 和 MOVNTPD）执行的
//          流式写入（streaming writes）操作
//      -   字符串操作，见第 10.2.4.1 节
//  4.  写入内存的操作不会与 CLFLUSH 指令重新排序。本手册的早期版本规定，写入内存的操作   *** 写入操作与 CLFLUSH/CLFLUSHOPT
//      可能会与 CLFLUSH 指令的执行重新排序。然而，实现 CLFLUSH 指令的处理器不允许这种
//      重新排序。写入操作可以与 CLFLUSHOPT 指令重新排序，当该指令刷新一个缓存行，而该
//      缓存行不是写入操作写入的那个缓存行的时候。
//      CLFLUSH 指令的执行不会相互重新排序，CLFLUSHOPT 的执行可以与访问不同缓存行的     *** CLFLUSH 和 CLFLUSH
//      CLFLUSH 指令的执行重新排序，访问不同缓存行的 CLFLUSHOPT 指令的执行可以相互重        CLFLUSHOPT 和 CLFLUSH
//      新排序。                                                                        CLFLUSHOPT 和 CLFLUSHOPT
//  5.  写入操作可以与之后对不同位置的读取操作重新排序，但如果是同一位置则不能重新排序。
//  6.  读写操作不能与 I/O 指令、锁定指令或串行化指令重新排序。
//  7.  读取操作不能越过较早的 LFENCE 和 MFENCE 指令。
//  8.  写入操作以及 CLFLUSH 和 CLFLUSHOPT 的执行不能越过较早的 LFENCE、SFENCE 和
//      MFENCE 指令。
//  9.  LFENCE 指令不能越过较早的读取操作。
//  10. SFENCE 指令不能越过较早的写入操作或 CLFLUSH 和 CLFLUSHOPT 的执行。
//  11. MFENCE 指令不能越过较早的读取、写入操作或 CLFLUSH 和 CLFLUSHOPT 的执行。
//
// 在多处理器系统中，适用以下排序原则：
//  1.  各个处理器使用与单处理器系统相同的排序原则。
//  2.  单个处理器的多个写入操作，在所有处理器的视角看来，都是以相同的顺序执行。
//  3.  单个处理器的多个写入操作，不会相对其他处理器的写入操作进行排序。
//  4.  内存排序遵循因果关系（causality），即内存排序尊重传递可见性（transitive visibility）。
//  5.  多个处理器的任何两个存储操作，会以一致的顺序（in a consistent order）被其他处理器观察到。
//  6.  锁定的指令有一个总顺序（a total order）。
//
// 如下图的示例，考虑一个系统中的三个处理器，每个处理器执行三次写入操作，分别写入三个定
// 义的位置（A、B 和 C）。单独来看，处理器以相同的程序顺序执行写入操作，但由于总线仲裁
// 和其他内存访问机制，三个处理器写入各个内存位置的顺序，在每次处理器执行相应代码序列的
// 过程中都可能不同。位置 A、B 和 C 的最终值在每次执行写入序列时可能都会有所不同。
//
//      单个处理器的写入顺序（Order of Writes From Individual Processors）
//      Processor #1        Processor #2        Processor #3
//      Write A.1           Write A.2           Write A.3   ---.    每个单独的处
//      Write B.1           Write B.2           Write B.3      |--> 理器保证以程序
//      Write C.1           Write C.2           Write C.3   ---'    顺序执行写操作
//          |                   |                   |
//          '-----------.       |       .-----------'
//                      |       |       |
//                      V       V       V
//          写入操作实际写入内存的顺序示例（Example of order
//          of actual writes from all processors to memory）
//                     .--- Write A.1 ---.
//         单个处理器遵 |--- Write B.1    |      所有处理器的写入操作不保证以特定的
//         循的程序顺序 |    Write A.2    |--->  顺序写入（Writes from all processors
//                     |    Write A.3    |      are not guaranteed to occur in
//                     '--- Write C.1    |      a particular order）
//                          Write B.2    |
//                          Write C.2    |
//                          Write B.3    |
//                          Write C.3 ---'
//
// 本节描述的处理器排序模型与 Pentium 和 Intel486 处理器使用的模型几乎相同。Pentium 4、
// Intel Xeon 和 P6 家族处理器的唯一增强功能是：
//  1.  增加了对推测性读取（speculative reads）的支持，同时仍然遵循上述排序原则
//  2.  当读取操作跳过对同一内存位置的写入操作时的存储缓冲区转发（store-buffer forward），
//      注意，在 P6 处理器家族中，由于内容勘误（errata），从流式存储（streaming stores）
//      到同一地址的 WC（写合并）内存的读取不会发生存储缓冲区转发
//  3.  长字符串存储和字符串移动操作的乱序存储，见 “快速字符串操作和乱序存储”
//
// 内存排序原则说明示例。本节提供了一组示例，说明了上文介绍的内存排序原则。它们旨在让软
// 件编写者了解内存排序如何影响不同指令序列的结果。这些示例仅限于对定义为写回缓存（WB）
// 的内存区域的访问。示例仅涉及软件可见行为，当后续部分做出 “两个存储操作被重新排序” 等
// 陈述时，其含义只是 “从软件的角度来看，两个存储操作似乎被重新排序了”。逻辑处理器可能会
// 重新排序两个访问，即使其中一个示例表明它们可能并没有被重新排序。这样的示例只是表明软件
// 无法检测到这种重新排序的发生。同样，一个逻辑处理器可能执行一个内存访问多次，只要软件
// 可见行为与这个内存访问的单次执行一致。
//
// 如上所述，本节的示例仅限于对定义为写回缓存（WB）的内存区域的访问。它们仅适用于普通加
// 载存储和锁定的读-改-写指令。它们不一定适用于以下情况：
//  1.  字符串指令的乱序存储
//  2.  带有非时态提示的访问
//  3.  处理器作为地址翻译的一部分从内存读取（如页面遍历）
//  4.  以及处理器对分段和分页结构的更新（如更新 “已访问” 位）
//
// 本节示例背后的原理适用于单个内存访问指令，和锁定的读-改-写指令。Intel-64 内存排序模
// 型保证，对于以下每个内存访问指令，其组成的内存操作表现为单次内存访问：
//  1.  读取或写入单个字节的指令
//  2.  读取或写入地址对齐在 2 字节边界上的字（2 字节）的指令
//  3.  读取或写入地址对齐在 4 字节边界上的双字（4 字节）的指令
//  4.  读取或写入地址对齐在 8 字节边界上的四字（8 字节）的指令
//  5.  任何锁定指令（无论是 XCHG 指令还是带有 LOCK 前缀的其他读-改-写指令）表现为一个
//      不可分割且不可中断的加载序列，后跟存储序列，无论对齐如何
//
// 其他指令可能使用多次内存访问来实现。从内存排序的角度来看，不能保证组成的内存访问的相
// 对顺序。也不能保证存储的组成操作的执行顺序与加载的组成操作的执行顺序相同。
//
// 示例前一部分使用的是 MOV 指令，其背后的原理适用于一般的加载和存储访问，以及其他从内
// 存加载或存储到内存的指令。后面部分使用 XCHG 指令提供示例，这些示例背后的原理适用于其
// 他锁定的读-改-写指令。本节使用的 “处理器” 一词指代逻辑处理器，示例使用 Intel-64 汇
// 编语言语法，并使用以下符号约定：
//  1.  以 “r” 开头的参数，如 r1 或 r2，指的是仅对正在考虑的处理器可见的寄存器（如 EAX）
//  2.  内存位置用 x、y、z 表示
//  3.  存储操作写为 mov [_x], val，这意味着 val 正在被存储到内存位置 x
//  4.  加载操作写为 mov r, [_x]，这意味着内存位置 x 的内容正在被加载到寄存器 r 中
//
// 加载和存储操作不会与同类操作重新排序。Intel-64 内存排序模型不允许加载或存储与同类操
// 作重新排序。也就是说，它确保加载操作按程序顺序被看到，并且存储操作按程序顺序被看到。
// 这通过以下示例进行说明：
//
//      示例 10-1. 存储操作不会与其他存储操作重新排序
//      处理器 0            处理器 1
//      mov [_x], 1        mov r1, [_y]
//      mov [_y], 1        mov r2, [_x]
//      初始值：x = y = 0
//      最终结果不允许出现：r1 = 1 且 r2 = 0
//
// 只有在处理器 0 的两个存储操作被重新排序（两个加载操作发生在它们之间）或处理器 1 的两
// 个加载操作被重新排序（两个存储操作发生在它们之间）时，才会出现不允许的返回值。如果
// r1 = 1，则对 y 的存储操作发生在从 y 的加载操作之前。由于 Intel-64 内存排序模型不允
// 许存储操作被重新排序，对 x 的较早存储操作发生在从 y 的加载操作之前。由于 Intel-64
// 内存排序模型不允许加载操作被重新排序，对 x 的存储操作也发生在从 x 的较晚加载操作之前，
// 因此，r2 = 1。
//
// 存储操作不会与较早的加载操作重新排序。Intel-64 内存排序模型确保处理器的存储操作不会
// 发生在同一处理器的先前加载操作之前。
//
//      示例 10-2. 存储操作不会与较早的加载操作重新排序
//      处理器 0            处理器 1
//      mov r1, [_x]        mov r2, [_y]
//      mov [_y], 1         mov [_x], 1
//      初始值：x = y = 0
//      最终结果不允许出现：r1 = 1 且 r2 = 1
//
// 因为 r1 = 1 时，必定加载操作 mov r2, [_y] 和存储操作 mov [_x], 1 执行完毕，且此时
// 存储操作 mov [_y], 1 一定还没有执行，因此 r2 一定是 0。
//  1.  由于 r1 = 1，处理器 1 对 x 的存储操作发生在处理器 0 从 x 加载之前
//  2.  由于 Intel-64 内存排序模型防止每个存储操作与同一处理器的较早加载操作重新排序，
//      处理器 1 从 y 的加载操作发生在其对 x 的存储操作之前
//  3.  同样，处理器 0 从 x 的加载操作发生在其对 y 的存储操作之前
//  4.  因此，处理器 1 从 y 的加载操作发生在处理器 0 对 y 的存储操作之前，意味着 r2=0
//
// 加载操作可以与对不同位置的较早存储操作重新排序。Intel-64 内存排序模型允许加载操作与
// 对不同位置的较早存储操作重新排序。然而，加载操作不会与对同一位置的存储操作重新排序。
//
//      示例 10-3. 加载操作可以与较早的存储操作重新排序
//      处理器 0            处理器 1
//      mov [_x], 1         mov [_y], 1
//      mov r1, [_y]        mov r2, [_x]
//      初始值： x = y = 0
//      最终结果允许出现：r1 = 0 且 r2 = 0
//
// 在每个处理器上，加载和存储操作针对不同位置，因此可以重新排序。因此，任何操作的交错都
// 是允许的。一种这样的交错是两个加载操作发生在两个存储操作之前。这将导致每个加载操作返
// 回值 0。
//
// 以下示例说明了加载操作不会与对同一位置的较早存储操作重新排序的事实。Intel-64 内存排
// 序模型不允许加载操作与较早的存储操作重新排序，因为访问是针对同一位置。因此，必须保持
// r1 = 1。
//
//      示例 10-4. 加载操作不会与对同一位置的较早存储操作重新排序
//      处理器 0
//      mov [_x], 1
//      mov r1, [_x]
//      初始值：x = 0
//      最终结果不允许出现：r1 = 0
//
// 允许处理器之间转发（intra-processor forwarding）。内存排序模型允许两个处理器的并发
// 存储操作被这两个处理器以不同的顺序看到；具体来说，每个处理器可能会感知到自己的存储操
// 作发生在另一个处理器的存储操作之前。
//
//      示例 10-5. 允许处理器内转发
//      处理器 0            处理器 1
//      mov [_x], 1         mov [_y], 1
//      mov r1, [_x]        mov r3, [_y]
//      mov r2, [_y]        mov r4, [_x]
//      初始值：x = y = 0
//      最终结果允许出现：r2 = 0 和 r4 = 0
//
// 内存排序模型对两个处理器看到的两个存储操作执行顺序没有限制。这一事实允许处理器 0 在看
// 到处理器 1 的存储操作之前看到自己的存储操作，而处理器 1 也在看到处理器 0 的存储操作之
// 前看到自己的存储操作，因此允许 r2 = 0 且 r4 = 0。
//
// 在实践中，这种重新排序可能是存储缓冲区转发（store buffer forwarding）的结果。当存储
// 操作暂时保留在处理器的存储缓冲区中时，它可以满足处理器自己的加载操作，但对其他处理器
// 不可见（无法满足其他处理器的加载操作）。
//
// 存储操作具有传递可见性。内存排序模型确保存储操作的传递可见性，因果相关的存储操作对所
// 有处理器来说似乎以与因果关系一致的顺序发生。
//
//      示例 10-6. 存储操作具有传递可见性
//      处理器 0            处理器 1        处理器 2
//      mov [_x], 1         mov r1, [_x]
//                          mov [_y], 1     mov r2, [_y]
//                                          mov r3, [_x]
//      初始值：x = y = 0
//      最终结果不允许出现：r1 = 1, r2 = 1, r3 = 0
//
// 因为，当 r2 = 1 时，处理器 1 两个操作已执行完，因为 r1 是 1，则处理器 0 的存储操作
// 发生在处理器 1 的操作之前，另外处理器 2 的两个加载操作按顺序发生，因此 r3 = 1。
//  1.  由于 r1 = 1，处理器 0 的存储操作发生在处理器 1 的加载操作之前
//  2.  由于内存排序模型防止存储操作与较早的加载操作重新排序，处理器 1 的加载操作发生在
//      其存储操作之前，因此处理器 0 的存储操作因果上先于处理器 1 的存储操作
//  3.  由于处理器 0 的存储操作因果上先于处理器 1 的存储操作，内存排序模型确保处理器 0    *** 因果相关的存储操作，对所有处理器都以相同的因果顺序发生
//      的存储操作从所有处理器的角度来看似乎发生在处理器 1 的存储操作之前
//  4.  由于 r2 = 1，处理器 1 的存储操作发生在处理器 2 的加载操作之前
//  5.  由于 Intel-64 内存排序模型防止加载操作重新排序，处理器 2 的加载操作按顺序发生
//  6.  上述项目意味着处理器 0 对 x 的存储操作发生在处理器 2 从 x 的加载操作之前，这意
//      味着 r3 = 1
//
// 存储操作被其他处理器以一致顺序看到。内存排序模型允许两个处理器的存储操作被这两个处理
// 器以不同的顺序看到。然而，任何两个存储操作必须对除执行存储操作的两个处理器之外的所有
// 处理器似乎以相同的顺序执行。
//
//      示例 10-7. 存储操作被其他处理器以一致顺序看到
//      处理器 0            处理器 1        处理器 2        处理器 3
//      mov [_x], 1         mov [_y], 1     mov r1, [_x]    mov r3, [_y]
//                                          mov r2, [_y]    mov r4, [_x]
//      初始值：x = y = 0
//      最终不允许出现：r1 = 1, r2 = 0, r3 = 1, r4 = 0
//
// 由于内存排序模型确保任何两个存储操作对所有其他处理器（执行存储操作的处理器除外）似乎
// 以相同的顺序执行，因此不允许这组返回值。r1 = 1 和 r2 = 0 说明处理器 1 在处理器 0
// 执行完之后才执行，当处理器 3 看到 r3 = 1 时，r4 一定是 1。
//  1.  处理器 2 的第一和第二次加载不能被重新排序
//  2.  处理器 3 的第一和第二次加载不能被重新排序
//  3.  如果 r1 = 1 且 r2 = 0，处理器 0 的存储操作相对于处理器 2 似乎发生在处理器 1
//      的存储操作之前
//  4.  同样，r3 = 1 且 r4 = 0 意味着处理器 1 的存储操作相对于处理器 3 似乎发生在处理
//      器 0 的存储操作之前，与处理 2 看到的矛盾
//
// 锁定指令具有总顺序（have a total order）。内存排序模型确保所有处理器对所有锁定指令
// 的单一执行顺序达成一致，包括那些大于 8 字节或未自然对齐的指令。
//
//      示例 10-8. 锁定指令具有总顺序
//      处理器 0            处理器 1        处理器 2        处理器 3
//      xchg [_x], r1       xchg [_y], r2
//                                          mov r3, [_x]    mov r5, [_y]
//                                          mov r4, [_y]    mov r6, [_x]
//      初始值：r1 = r2 = 1, x = y = 0
//      最终不允许出现：r3 = 1, r4 = 0, r5 = 1, r6 = 0
//
// 处理器 2 和处理器 3 必须在两个 XCHG 执行顺序上达成一致。因为 r3 = 1 r4 = 0，处理器
// 0 的 XCHG 先发生。
//  1.  如果 r5 = 1，处理器 1 对 y 的 XCHG 发生在处理器 3 从 y 的加载之前
//  2.  由于 Intel-64 内存排序模型防止加载操作被重新排序，处理器 3 的加载操作按顺序发
//      生，因此处理器 1 的 XCHG 发生在处理器 3 从 x 的加载之前
//  3.  由于处理器 0 对 x 的 XCHG 发生在处理器 1 的 XCHG 之前，它发生在处理器 3 从 x
//      的加载之前，因此 r6 = 1
//
// 加载和存储操作不会与锁定指令重新排序。内存排序模型防止加载和存储操作与较早或较晚执行
// 的锁定指令重新排序。本节中的示例仅说明了锁定指令在加载或存储操作之前执行的情况。如果
// 锁定指令在加载或存储操作之后执行，重新排序也会被阻止。
//
//      示例 10-9. 加载操作不会与锁定指令重新排序
//      处理器 0            处理器 1
//      xchg [_x], r1       xchg [_y], r3
//      mov r2, [_y]        mov r4, [_x]
//      初始值：x = y = 0, r1 = r3 = 1
//      最终结果不允许出现：r2 = 0 和 r4 = 0
//
// 锁定指令的执行有一个总顺序。因为 r2 = 0，处理器 0 的 XCHG 先发生。由于 Intel-64 内
// 存排序模型防止处理器 1 的加载与其较早的 XCHG 重新排序，处理器 0 的 XCHG 发生在处理
// 器 1 的加载之前，因此 r4 = 1。
//
//      示例 10-10. 存储操作不会与锁定指令重新排序
//      处理器 0            处理器 1
//      xchg [_x], r1       mov r2, [_y]
//      mov [_y], 1         mov r3, [_x]
//      初始值：x = y = 0, r1 = 1
//      最终结果不允许出现：r2 = 1 和 r3 = 0
//
//  1.  由于 r2 = 1，处理器 0 对 y 的存储操作发生在处理器 1 从 y 的加载操作之前
//  2.  由于内存排序模型防止存储操作与较早的锁定指令重新排序，处理器 0 对 x 的 XCHG 发
//      生在其对 y 的存储操作之前。因此，处理器 0 对 x 的 XCHG 发生在处理器 1 从 y 的
//      加载操作之前
//  3.  由于内存排序模型防止加载操作被重新排序，处理器 1 的加载操作按顺序发生，因此处理
//      器 1 对 x 的 XCHG 发生在处理器 1 从 x 的加载操作之前，因此 r3 = 1
//
// 快速字符串操作和乱序存储。《Intel® 64 和 IA-32 架构软件开发人员手册》第 1 卷第 7.3.9.3   *** 快速字符串操作的乱序存储（Out-of-Order Stores）
// 节描述了一种称为快速字符串操作（fast-string operation）的对重复字符串操作的优化。如
// 该节所述，快速字符串操作产生的存储操作可能看起来乱序执行。依赖于顺序存储排序（sequential
// store ordering）的软件不应使用字符串操作来存储整个数据结构。数据和信号量应分离。顺序
// 依赖代码应在任何字符串操作后写入一个离散的信号量变量（a discrete semaphore variable），
// 以允许所有处理器正确看到排序的数据。加载和存储操作的原子性仅对具有原生数据大小（native
// data size）的字符串数据元素保证，而且仅当它们包含在单个缓存行中时才成立。下文提供了
// 进一步的解释和示例。
//
// 写回（WB）内存上字符串操作的内存排序模型。本节讨论 Intel 64 架构上写回（WB）内存的
// 字符串操作的内存排序模型。内存排序模型遵循以下原则：
//  1.  单个字符串操作内的存储操作可能乱序执行。
//  2.  来自不同字符串的存储操作（例如连续字符串操作中的存储操作）不会乱序执行，所有较
//      早字符串操作的存储操作将在任何较晚字符串操作的存储操作之前完成。
//  3.  字符串操作不会与其他存储操作重新排序。
//
// 快速字符串操作（例如以 MOVS/STOS 指令和 REP 前缀启动的字符串操作）可能被异常或中断    *** 字符串操作的不乱序保证，可能被异常或中断破坏
// 中断。中断是精确的但可能会被延迟，例如中断可能在缓存行边界处、每循环的几次迭代后、
// 或每操作几个字节之后发生。不同的实现可能选择不同的选项，甚至可能选择不延迟中断处理，
// 因此软件不应依赖于延迟。当达到中断/陷阱处理程序时，源/目标寄存器指向要操作的下一个字
// 符串元素，而堆栈中存储的 EIP 指向字符串指令，ECX 寄存器保存最后一次成功迭代后的值。
// 从该陷阱/中断处理程序返回应导致字符串指令从被中断的点恢复。
//
// 字符串操作内存排序原则（上述第 2 和第 3 项）应通过考虑快速字符串操作的不可破坏性来解
// 释。例如，如果一个快速字符串操作在执行 k 次迭代后被中断，那么中断处理程序执行的存储操
// 作将在快速字符串从第 0 次到第 k 次迭代的存储操作之后可见，并且在快速字符串从第 (k+1)
// 次迭代开始的存储操作之前可见。单个字符串操作内的存储操作可能乱序执行（上述第 1 项），   *** 单个字符串操作内部的存储乱序，只有开始快速字符串操作时才发生
// 仅当启用快速字符串操作时才发生。快速字符串操作通过 IA32_MISC_ENABLE 模型特定寄存器
// 启用/禁用。
//
// 字符串操作内存排序原则的说明示例。在示例 10-11 中，处理器 0 通过 rep:stosd 执行一轮
// （128 次迭代）双字字符串存储操作，将值 1（EAX 中的值）写入从位置 _x（保存在 ES:EDI
// 中）开始的 512 字节块中，按升序排列。由于每个操作存储一个双字（4 字节），因此操作重
// 复 128 次（ECX 中的值）。内存块最初包含 0。处理器 1 从处理器 0 正在更新的内存块中读
// 取两个内存位置，即从范围 _x 到 (_x+511) 中的位置读取。处理器 1 可能会察觉到处理器 0
// 中的重复字符串存储操作乱序发生。假设处理器 0 上启用了快速字符串操作。
//
//      示例 10-11. 字符串操作内的存储操作可能重新排序
//          处理器 0                处理器 1
//          rep:stosd [_x]          mov r1, [_z]
//                                  mov r2, [_y]
//          处理器 0 上的初始值： EAX=1, ECX=128, ES:EDI=_x
//          [_x] 到 511[_x] 的初始值： 全 0， _x <= _y < _z < _x+512
//          最终结果允许出现： r1=1 且 r2=0
//
// 在示例 10-12 中，处理器 0 执行两轮单独的 rep stosd 操作，每轮 128 次双字存储，将值
// 1（EAX 中的值）写入从位置 _x（保存在 ES:EDI 中）开始的第一个 512 字节块中，按升序排
// 列。然后它将 1 写入从 (_x+512) 到 (_x+1023) 的第二个内存块中。所有内存位置最初都包
// 含 0。处理器 1 从这两个内存块执行两次加载操作。处理器 1 不可能看到第二块内存被写入 1
// 之后，第一块内存中的内容还是 0。该示例假设对第二个块（_x+512 到 _x+1023）的写入不会
// 在处理器 0 对第一个块的字符串操作被中断时执行。如果处理器 0 对第一个块的字符串操作被
// 中断，并且中断处理程序执行了对第二个内存块的写入，那么第二个内存块的更改将在字符串操
// 作对第一个内存块恢复之前可见。
//
//      示例 10-12. 字符串操作之间的存储操作不会重新排序
//          处理器 0                处理器 1
//          rep:stosd [_x]          mov r1, [_z]
//          mov ecx, $128           mov r2, [_y]
//          rep:stosd 512[_x]
//          处理器 0 上的初始值： EAX=1, ECX=128, ES:EDI=_x
//          [_x] 到 1023[_x] 的初始值： 全 0， _x <= _y < _x+512 < _z < _x+1024
//          最终结果不允许出现： r1=1 且 r2=0
//
// 在示例 10-13 中，处理器 0 通过 rep:stosd 执行一轮（128 次迭代）双字字符串存储操作，
// 将值 1（EAX 中的值）写入从位置 _x（保存在 ES:EDI 中）开始的 512 字节块中，按升序排
// 列。然后它写入第二个内存位置，该位置在前一个字符串操作的内存块之外。处理器 1 执行两次
// 读取操作，第一次读取来自 512 字节块之外的地址，它由处理器 0 更新，第二次读取来自字符
// 串操作内存块内。处理器 1 在看到字符串操作的所有存储操作之前，不能看到处理器 0 的较晚
// 存储操作。该示例假设处理器 0 对 [_z] 的存储操作不会在字符串操作被中断时执行。如果字
// 符串操作被中断，并且处理器 0 对 [_z] 的存储操作由中断处理程序执行，那么对 [_z] 的更
// 改将在字符串操作恢复之前可见。
//
//      示例 10-13. 字符串操作不会与较晚的存储操作重新排序
//          处理器 0                处理器 1
//          rep:stosd [_x]          mov r1, [_z]
//          mov [_z], $1            mov r2, [_y]
//          处理器 0 上的初始值： EAX=1, ECX=128, ES:EDI=_x
//          [_x] 到 511[_x] 的初始值：全 0， [_y] = [_z] = 0， _x <= _y < _x+512
//          最终结果不允许出现： r1=1 且 r2=0
//
// 示例 10-14 说明了字符串操作被中断时的可见性原则。该示例中，处理器 0 开始一个字符串操
// 作，写入从地址 _x 开始的 512 字节内存块中。处理器 0 在执行 k 次存储操作后被中断。当
// 处理器 0 被中断时，地址 _y 尚未被处理器 0 更新。接管处理器 0 的中断处理程序写入地址
// _z。处理器 1 可能会在看到字符串操作恢复时执行的 512 字节内存块的剩余存储操作之前，看
// 到来自中断处理程序的对 _z 的存储操作。
//
//      示例 10-14. 被中断的字符串操作
//          处理器 0                                          处理器 1
//          rep:stosd [_x] // 在 es:edi 到达 _y 之前被中断      mov r1, [_z]
//          mov [_z], $1   // 中断处理程序                      mov r2, [_y]
//          处理器 0 上的初始值： EAX=1, ECX=128, ES:EDI=_x
//          [_x] 到 511[_x] 的初始值：全 0， [_y] = [_z] = 0， _x <= _y < _x+512
//          最终的结果允许出现： r1=1 且 r2=0
//
// 示例 10-15 说明了字符串操作与较早存储操作的排序。字符串操作中的任何存储操作都不能在
// 所有前面的存储操作可见之前可见。
//
//      示例 10-15. 字符串操作不会与较早的存储操作重新排序
//          处理器 0                处理器 1
//          mov [_z], $1            mov r1, [_y]
//          rep:stosd [_x]          mov r2, [_z]
//          处理器 0 上的初始值： EAX=1, ECX=128, ES:EDI=_x
//          [_x] 到 511[_x] 初始值： 全 0， [_y] = [_z] = 0， _x <= _y < _x+512
//          最终结果不允许出现： r1=1 且 r2=0
//
// 加强或削弱内存排序模型。Intel 64 和 IA-32 架构提供了几种机制来加强或削弱内存排序模
// 型，以处理特殊的编程情况。这些机制包括：
//  1.  I/O 指令、锁定指令、LOCK 前缀和串行化指令对处理器施加更强的排序。
//  2.  SFENCE 指令（在 Pentium III 处理器中引入 IA-32 架构）和 LFENCE 和 MFENCE 指
//      令（在 Pentium 4 处理器中引入）为特定类型的内存操作提供内存排序和串行化功能。
//  3.  内存类型范围寄存器（MTRRs）可用于加强或削弱特定物理内存区域的内存排序，见第 13.11
//      节 “内存类型范围寄存器（MTRRs）”。MTRRs 仅在 Pentium 4、Intel Xeon 和 P6 家
//      族处理器中可用。
//  4.  页面属性表（Page Attribute Table, PAT）可用于加强特定页面或页面组的内存排序，
//      见第 13.12 节 “页面属性表”。PAT 仅在 Pentium 4、Intel Xeon 和 Pentium III
//      处理器中可用。
//
// 这些机制可以如下使用：总线上的内存映射设备（Memory Mapped Devices）和其他 I/O 设备
// 通常对写入其 I/O 缓冲区的顺序敏感。I/O 指令可以用于（IN 和 OUT 指令）对此类访问施加
// 强写入排序，如下所示。在执行 I/O 指令之前，处理器等待程序中的所有先前指令完成，并且
// 所有缓冲写入操作排出到内存。只有指令获取（instruction fetch）和页表遍历（page tables
// walks）可以穿透 I/O 指令。后续指令的执行直到处理器确定 I/O 指令已完成时才开始。
//
// 多处理器系统中的同步机制可能依赖于强内存排序模型。在这里，程序可以使用锁定指令，如 XCHG
// 指令或 LOCK 前缀，以确保对内存的读-改-写操作以原子方式执行。锁定指令通常像 I/O 指令
// 一样运行，它们等待所有先前的内存访问完成，并且所有缓冲写入操作排出到内存，见第 10.1.2
// 节 “总线锁定”。与 I/O 操作不同，锁定指令不等待所有先前指令完成执行。
//
// 程序同步也可以使用串行化指令来执行。这些指令通常在关键过程或任务边界处使用，以在跳转
// 到新代码段或上下文切换发生之前强制完成所有先前指令。与 I/O 指令一样，处理器等待所有先
// 前指令已完成，并且所有缓冲写入操作已排出到内存，然后才执行串行化指令。
//
// SFENCE、LFENCE 和 MFENCE 指令提供了一种性能高效的方式，确保在产生弱排序结果的例程和
// 使用这些数据的例程之间的加载和存储内存排序。SFENCE、LFENCE 和 MFENCE 指令提供了一种
// 比 CPUID 指令更有效的控制内存排序的方法。这些指令的功能如下：
//  1.  SFENCE — 串行化所有程序指令流中在 SFENCE 指令之前发生的存储（写入）操作，但不
//      影响加载操作。
//  2.  LFENCE — 串行化所有程序指令流中在 LFENCE 指令之前发生的加载（读取）操作，但不
//      影响存储操作。具体来说，LFENCE 指令在所有先前指令在本地完成后才会执行，而后续指
//      令的执行会在 LFENCE 完成之前被阻塞。因此，一个在 LFENCE 之前的从内存加载数据的
//      指令会在 LFENCE 完成之前从内存接收数据。一个在将数据存储到内存的指令之后的 LFENCE
//      可能在被存储的数据对全局可见之前完成。尽管 LFENCE 之后的指令可能在 LFENCE 之前
//      从内存中预取，但它们会在 LFENCE 完成之前被阻塞。
//  3.  MFENCE — 串行化所有程序指令流中在 MFENCE 指令之前发生的存储和加载操作。
//
// MTRRs 在 P6 家族处理器中引入，用于为指定的物理内存区域定义缓存特性。以下是两个示例，
// 说明如何使用 MTRRs 设置的内存类型来加强或削弱 Pentium 4、Intel Xeon 和 P6 家族处理
// 器的内存排序：
//  1.  强未缓存（Strong Uncached，UC）内存类型对内存访问强制执行强排序模型。在这里，
//      对 UC 内存区域的所有读取和写入操作都会出现在总线上，并且不会执行乱序或推测性访
//      问。这种内存类型可以应用于专用于内存映射 I/O 设备的地址范围，以强制强内存排序。
//  2.  对于可以接受弱排序的内存区域，可以选择写回（WB）内存类型。在这里，读取操作可以
//      推测性地执行，写入操作可以被缓冲和合并。对于这种类型的内存，原子（锁定）操作在
//      不分跨缓存行的情况下执行缓存锁定。这有助于减少与典型同步指令（如 XCHG）相关的性
//      能损失，这些指令在整个读-改-写操作期间锁定总线。使用 WB 内存类型，如果内存访问
//      包含在缓存行内，XCHG 指令锁定缓存而不是总线。
//
// PAT 在 Pentium III 处理器中引入，以增强可以分配给页面或页面组的缓存特性。PAT 机制
// 通常用于在页面级别加强缓存特性，这些特性是相对于 MTRRs 建立的缓存特性。
//
// 英特尔建议为 Intel Core 2 Duo, Intel Atom（英特尔凌动）, Intel Core Duo（英特尔
// 酷睿双核）, Pentium 4, Intel Xeon（英特尔至强）和 P6 家族处理器编写的软件假设处理
// 器排序模型或更弱的内存排序模型。Intel Core 2 Duo, Intel Atom, Intel Core Duo,
// Pentium 4, Intel Xeon 和 P6 家族处理器没有实现强内存排序模型，在使用 UC 内存类型时
// 除外。尽管 Pentium 4, Intel Xeon 和 P6 家族处理器支持处理器排序，但英特尔不保证未
// 来的处理器将支持此模型。为了使软件可移植到未来的处理器，建议操作系统提供关键区域和资
// 源控制构造和 API，这些 API 基于 I/O、锁定、串行化指令，用于在多处理器系统中同步对共
// 享内存区域的访问。此外，软件不应依赖于处理器排序，当系统硬件不支持此内存排序模型的情
// 况下。
//
// 串行化指令（Serializing Instructions）。Intel 64 和 IA-32 架构定义了几种串行化指
// 令。这些指令强制处理器完成所有先前指令对标志、寄存器和内存的修改，并在获取和执行下一
// 条指令之前，将所有缓冲的写入操作排出到内存。例如，当使用 MOV 指令将新值加载到控制寄
// 存器 CR0 中以启用保护模式时，处理器必须在进入保护模式之前执行串行化操作。这种串行化
// 操作确保了在处理器从实地址模式切换到保护模式之前，所有在实地址模式下启动的操作都已完
// 成。串行化指令的概念是随着 Pentium 处理器引入 IA-32 架构的，以支持并行指令执行。对
// 于不实现并行指令执行的 Intel486 及更早处理器，串行化指令没有意义。
//
// 需要注意的是，在 P6 及更新的处理器家族上执行串行化指令会限制推测性执行（speculative
// execution），因为推测性执行的指令结果会被丢弃。以下是串行化指令：
//  1.  特权串行化指令：INVD、INVEPT、INVLPG、INVVPID、LGDT、LIDT、LLDT、LTR、MOV
//      （到控制寄存器，MOV CR8 除外，MOV CR8 在架构上不被定义为串行化指令）、MOV（到
//       调试寄存器）、WBINVD 和 WRMSR。对任何非串行化 MSR 的 WRMSR 执行都不会被串行
//      化。非串行化 MSR 包括以下内容：IA32_SPEC_CTRL MSR（MSR 索引 48H）、IA32_PRED_CMD
//      MSR（MSR 索引 49H）、IA32_TSX_CTRL MSR（MSR 索引 122H）、IA32_TSC_DEADLINE
//      MSR（MSR 索引 6E0H）、IA32_PKRS MSR（MSR 索引 6E1H）、IA32_HWP_REQUEST MSR
//      （MSR 索引 774H），或任何 x2APIC MSR（MSR 索引 802H 到 83FH）。
//  2.  非特权串行化指令：CPUID、IRET、RSM 和 SERIALIZE。
//
// 当处理器对指令执行进行串行化时，它确保在执行下一条指令之前，所有待处理的内存事务都已
// 完成（包括存储在存储缓冲区中的写入）。没有任何指令可以越过串行化指令，串行化指令也不
// 能越过任何其他指令（读取、写入、指令获取或 I/O）。例如，CPUID 可以在任何特权级别执行，
// 以串行化指令执行，除了修改 EAX、EBX、ECX 和 EDX 寄存器外，对程序流程没有其他影响。
//
// 以下指令是内存排序指令（memory ordering instructions），而不是串行化指令。这些指令
// 清空数据内存（drain the data memory）子系统。它们不对指令执行流进行串行化，LFENCE
// 在指令排序方面确实提供了一些保证，它在所有先前指令在本地完成后才会执行，后续指令的执
// 行会在 LFENCE 完成之前被阻塞。SFENCE、LFENCE 和 MFENCE 指令在控制内存加载和存储的
// 串行化方面提供了更多的粒度。
//  3.  非特权内存排序指令：SFENCE、LFENCE 和 MFENCE。
//
// 关于串行化指令，还有以下额外信息值得关注：
//  1.  处理器在对指令执行进行串行化时，不会将其数据缓存中修改的数据内容写回到外部内存。
//      软件可以通过执行 WBINVD 指令（这是一个串行化指令）来强制修改数据写回。WBINVD
//      完成所需的时间或周期会因不同缓存层次结构的大小和其他因素而有所不同。因此，使用
//      WBINVD 指令可能会影响中断/事件响应时间。
//  2.  当执行一条启用或禁用分页的指令时（即，更改控制寄存器 CR0 中的 PG 标志），该指令
//      后面应该跟一个跳转指令。跳转指令的目标指令是使用 CR0 的新设置（即分页启用或禁用）
//      获取的，但跳转指令本身是使用之前的设置获取的。Pentium 4、Intel Xeon 和 P6 家
//      族处理器不需要在写入 CR0 后执行跳转操作（因为在 Pentium 4、Intel Xeon 或 P6
//      家族处理器中，使用 MOV 指令写入 CR0 是完全串行化的）。然而，为了与在其他 IA-32
//      处理器上运行的代码保持向后和向前兼容性，建议执行跳转操作。
//  3.  每当执行一条更改 CR3 内容的指令时，分页启用的情况下，下一条指令是使用与 CR3 新
//      值对应的转换表获取的。因此，下一条指令及其顺序后续指令应该基于 CR3 的新值进行映
//      射。TLB 中的全局条目不会失效，见第 5.10.4 节 “TLB 和分页结构缓存的无效化”。
//  4.  Pentium 处理器及更新的处理器家族使用分支预测（branch prediction）技术，通过在
//      分支指令执行之前预取分支指令的目标来提高性能。因此，当执行分支指令时，指令执行不
//      是确定串行化的。
//
// AMD64 Architecture Programmer's Manual Volume 2: System Programming
// 7 Memory System
//
// 本章描述：缓存一致性（Cache coherency）机制，缓存控制机制，内存类型划分，内存映射
// I/O，内存排序规则，串行化指令。下图给出处理器与存储系统的概念视图，展示数据与指令在
// 各部件之间的流动。该图并不对应任何具体微架构实现，仅用于说明本章所涵盖的主要存储系统
// 部件。
//
//      [主存，Main Memory]     处理器与存储系统
//             ^
//      .------|------------------------------.
//      |      v                              |
//      | [系统总线接口，System Bus Interface] |
//      |      ^                    ^         |
//      |      |                    |         |
//      |      v                    |         |
//      |   [L2 U-Cache]            |         |
//      |    |      ^               |         |
//      |    |      |           [WC Buffers]  |
//      |    |      v               ^         |
//      |    |     [L1 D-Cache]     |         |
//      |    v           ^   ^      |         |
//      |   [L1 I-Cache] |   |      |         |
//      |       |        |   |      |         |
//      |       |        | [Write Buffers]    |
//      |       |        |     ^              |
//      |       |        |     |              |
//      |       |        v     |              |
//      |       |     [加载存储单元]           |
//      |       |           ^                 |
//      |       |           |                 |
//      |       v           v                 |
//      |   [执行单元，Execution Units]        |
//      |                                     |
//      |                           处理器芯片 |
//      '-------------------------------------'
//
// 主存位于处理器芯片外部，是离执行单元最远的存储层级。缓存是离执行单元最近的存储层级，
// 容量远小于主存但速度更快，可位于片内或片外。缓存保存最常用的指令与数据副本，使软件无
// 需访问主存即可获得高速访问。
//  . L1 数据缓存，保存软件最近读写的数据
//  . L1 指令缓存，与 L1 数据缓存类似，但仅保存最近执行的指令，某些实现可将二者合并为统
//    一 L1 缓存
//  . L2 缓存，通常比 L1 大数倍且更慢，常见为统一缓存，同时缓存指令与数据，最近使用但超
//    出 L1 容量的指令与数据可存放于 L2，L2 可为排他策略（不含 L1 副本），也可为包含策
//    略（含 L1 副本）
//
// 对可缓存存储区的读操作首先检查缓存，若信息存在则为读命中，否则为读缺失。写操作同理。
// 缓存被划分为固定大小的块，称为缓存行。缓存行的大小与对齐边界一致；例如 32 字节行按
// 32 字节边界对齐，地址 0007h 与 001Eh 落在同一行。行大小实现相关，常见 32 或 64 字
// 节，由 CPUID Fn8000_0005 与 Fn8000_0006 报告。
//
// 把数据装入缓存的过程称为缓存行填充（cache line fill），即使只请求一个字节，也会加载
// 整行。填充通常需替换现有行，称为缓存行替换（cache line replacement）。若被替换行已
// 被修改，则先执行缓存行写回（cache line writeback）主存。
//
// 缓存行写回保持缓存与主存一致。在芯片内部，处理器通过内部探查（internally probing）
// 其他缓存与写缓冲获取请求数据的最新版来维持缓存一致性；外部设备也可通过对处理器缓存的
// 外部探查（externally probing）获取最新数据。本文中 “探查” 指外部探查，内部探查则明
// 确标注 “内部”。
//
// 写缓冲在主线或缓存忙碌时暂存写数据，其实现与否视具体型号而定。若对非缓存写的次序与大
// 小无严格要求，实现可使用写合并缓冲，把多次写合并为更少总线事务。
//
// 单处理器内存访问排序。内存访问可被重新排序的灵活度，与处理器实现执行和退役（retire）
// 指令的灵活度密切相关。指令执行产生结果和状态，并决定指令是否引发异常；指令退役按程序
// 顺序将执行结果提交到软件可见的资源（内存、缓存、写合并缓冲、寄存器），或在执行产生异
// 常时触发异常。
//
// AMD64 架构的实现按程序顺序退役指令，但实现可以以任意顺序执行指令，只要满足数据依赖性。
// 实现也可在确定指令是否需要之前进行推测执行（speculative execute）。在内部，实现会管
// 理读写，使指令有序完成。然而，由于允许乱序和推测执行，硬件实际发出的内存访问序列可能
// 看起来与程序顺序不同。以下各节描述处理器实现必须遵守的访问规则，根据所访问内存类型的
// 不同，这些规则可能被进一步限制。本节规则仅适用于单处理器，多处理器规则见 “多处理器内
// 存访问排序” 部分。
//
// 读排序。通常，读操作不影响程序顺序，因为它们不改变除寄存器外的软件可见资源的状态。但
// 某些系统设备可能对读敏感，此时软件可将该设备映射到强制强读取排序的内存类型，或使用读
// 写屏障指令强制强读取排序。
//
// 对于可缓存内存类型，适用以下读排序规则：
//  1.  允许乱序读，只要对软件透明且保持顺序执行的外观，乱序读可由指令乱序执行或推测执行
//      引起，处理器可乱序读取内存并完成缓存行填充，以支持乱序执行继续推进。
//  2.  允许推测读，推测读是指处理器在确认指令实际完成前就开始执行内存读指令。例如，处理
//      器可预测分支会发生，并在确认预测是否正确前就开始执行预测分支后的指令，若其中一条
//      推测指令读取内存数据，则该读操作即为推测读，缓存行填充也可推测进行。
//  3.  读可重排到写之前，处理器通常赋予读高于写的优先级，避免指令执行所需读数据若未立即
//      可用导致的停顿，允许读先于写通常能最大化软件性能。
//  4.  若读地址与之前写地址相同，则读不能重排到该写之前，此时读指令将停顿直到写指令执行
//      完成，因为读指令需要写指令的结果才能正确运行，对于可缓存类型，写数据可在真正写回
//      内存前被转发（forward）给读指令。
//  5.  指令获取（instruction fetching）构成一条并行的异步读取流，并与该指令流的加载
//      操作执行的读访问，相对其独立且无序（independent from and unordered with）。
//
// 写排序。写影响程序顺序，因为它们改变软件可见资源的状态。以下是写排序的规则：
//  1.  一般而言，不允许乱序写。乱序执行的写指令必须等到前面所有指令按程序顺序完成后，才
//      能将其结果提交到内存。不过，处理器可以将乱序写指令的结果先保存在私有缓冲（对软件
//      不可见）中，直到可以提交时再写入内存。
//  2.  对于写合并内存类型的写操作，它们相对于其他内存类型的写操作，可能看起来会以乱序完
//      成。见 “内存类型” 和 “写合并” 部分。
//  3.  不允许推测写。与乱序写类似，推测写指令也必须等到前面所有指令按程序顺序完成后，才
//      能将其结果提交到内存。处理器可将结果保存在私有缓冲（对软件不可见）中，直到结果可
//      以提交时再写入内存。
//  4.  允许写缓冲。当写指令完成并提交其结果时，该结果可被缓冲，直到按程序顺序真正写回系
//      统内存。尽管写缓冲本身对软件不可直接访问，但缓冲的内容对后续访问同一位置的内存操
//      作可见，包括仅部分字节与缓冲重叠的读操作。例如，一个双字读若与写缓冲中的单个修改
//      字节重叠，可在该写尚未提交前返回该字节的缓冲值。总体而言，任何对可缓存内存的读操
//      作，都会返回按程序顺序完成的前面所有全局和局部可见写操作对这些字节的综合结果。具
//      体实现既可以从写缓冲提供数据以满足这一要求，也可以暂停读操作，直到所有重叠的缓冲
//      写都已提交到内存。对于可缓存内存类型而言，写缓冲（write buffer）就像内存一样被
//      乱序和推测地读取。
//  5.  允许写合并。在某些情况下，软件可通过使用写合并内存类型或非临时存储指令来放松写
//      排序规则，使多次写操作合并为更少次数的内存写。使用写合并时，只要地址不同，其他内
//      存类型的写可能会跑到写合并写之前（发生乱序）完成。写合并应仅在写顺序不影响程序语
//      义时使用（例如对图形帧缓冲的写）。
//
// 读写屏障（Read/Write Barriers）。当必须严格保证访问顺序时，软件可用读写屏障指令强制
// 按程序顺序执行。LFENCE、SFENCE、MFENCE 分别提供读、写、读写屏障，串行化指令、I/O 指
// 令、加锁指令（含隐式加锁的 XCHG）也可用作屏障。见内存一致性和协议部分 “特殊一致性考
// 虑”，以及下文表格汇总了 AMD64 架构支持的各种内存类型允许的访问顺序。
//
// 多处理器内存访问排序。“内存排序” 指所有处理器或程序观察到的内存访问序列。为提升性能，
// AMD64 处理器可有违程序顺序推测性地执行指令并暂存乱序执行结果，但对自然对齐的回写内存
// 类型（WB）的正常缓存访问仍遵守以下规则（示例内存初值为 0）。从程序视角来看，按优先级
// 由低到高排列如下：
//  1.  单个处理器发出的所有加载、存储和 I/O 操作，在该处理器上运行的代码看来均按程序顺
//      序发生，所有指令也表现为按程序顺序执行。
//  2.  同一处理器发出的连续存储，按程序顺序提交到系统内存，并且以程序顺序对其他处理器可
//      见。某处理器的存储操作不能排序到前面已获取数据的加载操作之前提交到内存。换言之，
//      存储不能被重排到其前面的加载操作之前。
//      – 加载不会越过前面的加载（加载不被重排），存储不会越过前面的存储（存储不被重排）。
//        当加载 B 读到 1 时，加载 A 不能读到 0。但是，属于字符串操作部分的加载可能例
//        外，因为字符串存储不是简单的一次操作，可能在一次迭代中加载 A 读取到 0，而在另
//        一次迭代种加载 B 读取到 1）。
//              处理器 0            处理器 1
//              存储 A <- 1         加载 B
//              存储 B <- 1         加载 A
//      – 存储不会越过前面的加载，加载 A 和加载 B 不能都读到 1。
//              处理器 0            处理器 1
//              加载 A              加载 B
//              存储 B <- 1         存储 A <- 1
//  3.  处理器的存储按程序顺序提交到内存系统，但可被存储缓冲（store buffering）导致存
//      储被任意延迟。因此，来自一个处理器的存储可能表现为顺序不一致。下例加载 A 和加载
//      B 都可能读到 1，并且由于写合并，其中一个处理器或两个处理器都可能实际并未在目标
//      内存位置写入 1。
//              处理器 0            处理器 1
//              存储 A <- 1         存储 B <- 1
//              ...                 ...
//              存储 A <- 2         存储 B <- 2
//              ...                 ...
//              加载 B              加载 A
//  4.  非重叠加载可以越过前面的存储操作。以下处理器 0 和 1 可观察到所有值组合（00、01、
//      10、11）。
//              处理器 0            处理器 1
//              存储 A <- 1         存储 B <- 1
//              加载 B              加载 A
//      – 若需顺序一致（如 Dekker 互斥算法），应在存储与后续加载间插入 MFENCE，或使用
//        加锁存储（如 XCHG）。下例加载 A 与加载 B 不能都读到 0。
//              处理器 0            处理器 1
//              存储 A <- 1         存储 B <- 1
//              MFENCE              MFENCE
//              加载 B              加载 A
//      – 若加载与前面存储部分重叠，加载可能从存储缓冲（store buffer）返回已修改部分，
//        把全局可见字节与仅局部可见字节混合。要保证加载只返回全局可见值，应在存储与后面
//        依赖的加载操作之间插入 MFENCE 或加锁操作，或者存储或加载必须使用加锁操作（如
//        XCHG）。
//      – 处理器间内存不同位置的存储操作，从其他处理器的角度观察的观察顺序必须全局一致。
//        不允许处理器 X 先看到处理器 0 的存储 A 后看到处理器 1 的存储 B，而处理器 Y
//        顺序相反。
//              处理器 0            处理器 1        处理器 X        处理器 Y
//              存储 A <- 1         存储 B <- 1
//                                                  加载 A(1)       加载 B(1)
//                                                  加载 B(0)       加载 A(0) 矛盾
//  5.  不同处理器间的依赖存储表现为按程序顺序发生。若处理器 1 在读到处理器 0 写入的 A
//      新值后再写 B，且处理器 2 读到 B 的新值，则其后续对 A 的读也必须得到新值。
//              处理器 0            处理器 1        处理器 2
//              存储 A <- 1
//                                  加载 A(1)
//                                  存储 B <- 1
//                                                  加载 B(1)
//                                                  加载 A(1)
//  6.  内存操作的局部可见性（处理器内部）可能与全局可见性（其他处理器视角）不同。通过
//      数据旁路（data bypass），局部加载可在存储操作尚未全局可见前，从存储缓冲读到该
//      存储操作的结果。此时（当使用该旁路时）仍保持程序顺序。例如，处理器 0 的加载 A
//      可通过旁路读到 1，而处理器 1 的加载 A 读到 0；同理，处理器 1 的加载 B 可读到
//      1，而处理器 0 的加载 B 读到 0，因此可能出现 r1=1、r2=0、r3=1、r4=0 的结果。
//      对处理器 0 的存储 A 何时被处理器 1 可见，与处理器 1 的存储 B 何时被处理器 0
//      可见的相对顺序，无任何约束。
//              处理器 0            处理器 1
//              存储 A <- 1         存储 B <- 1
//              加载 r1 A           加载 r3 B
//              加载 r2 B           加载 r4 A
//      若需要强排序模型不允许局部存储及之后的加载旁路，应在存储与后续加载间使用 MFENCE
//      或同步指令（如 XCHG 或加锁的读-改-写操作），这可强制比全存储排序（total store
//      ordering）更强的内存序。
//              处理器 0            处理器 1
//              存储 A <- 1         存储 B <- 1
//              MFENCE              MFENCE
//              加载 r1 A           加载 r3 B
//              加载 r2 B           加载 r4 A
//      在本例中，MFENCE 指令确保所有被缓冲的存储全局可见后，才允许后续加载执行，从而不
//      会出现 r1=1、r2=0、r3=1、r4=0 的结果。

#ifdef PRH_ATOMIC_INCLUDE
// 当多个线程访问一个原子对象时，所有的原子操作都会针对该原子对象产生明确的行为：在任
// 何其他原子操作能够访问该对象之前，每个原子操作都会在该对象上完整地执行完毕。这就保
// 证了在这些对象上不会出现数据竞争，而这也正是定义原子性的关键特征。
//
// https://devblogs.microsoft.com/cppblog/c11-atomics-in-visual-studio-2022-version-17-5-preview-2/
//
// Once you’ve installed Visual Studio 2022 17.5 Preview 2 you can try out C11
// atomics by adding /experimental:c11atomics and /std:c11 or /std:c17 to your
// compile options. Note that we still define __STDC_NO_ATOMICS__ so if your
// build system is testing for that you will need to add a special case or
// change to checking if compiling a translation unit including <stdatomic.h>
// succeeds.
//
// At the moment only lock-free atomics are supported, but in an upcoming
// release we will extend this support to include locking atomics as well.
// Atomics of all the usual built-in C types are lock-free, including long
// long on 32-bit x86. We will continue to define the __STDC_NO_ATOMICS__ macro
// even under /experimental:c11atomics until locking atomics are implemented.
#include <stdatomic.h>

// 这里的原子类型不需要声明成 volatile，因为它们总是通过变量的地址进行访问，而不是直接
// 访问变量的值。如果传一个变量的地址给函数，那么函数必须从内存中读取它的值，变量值不会
// 被优化到寄存器中，因此编译器优化不会对此产生影响。
typedef prh_byte prh_atom_bool;
typedef prh_i08 prh_atom_i08;
typedef prh_u08 prh_atom_u08;
typedef prh_i16 prh_atom_i16;
typedef prh_u16 prh_atom_u16;
typedef prh_i32 prh_atom_i32;
typedef prh_u32 prh_atom_u32;
typedef prh_int prh_atom_int;
typedef prh_unt prh_atom_unt;
typedef prh_unt prh_atom_ptr;

prh_static_assert(prh_alignof(prh_atom_bool) == prh_alignof(atomic_bool));
prh_static_assert(prh_alignof(prh_atom_i08) == prh_alignof(atomic_schar));
prh_static_assert(prh_alignof(prh_atom_u08) == prh_alignof(atomic_uchar));
prh_static_assert(prh_alignof(prh_atom_i16) == prh_alignof(atomic_short));
prh_static_assert(prh_alignof(prh_atom_u16) == prh_alignof(atomic_ushort));
prh_static_assert(prh_alignof(prh_atom_i32) == prh_alignof(atomic_int));
prh_static_assert(prh_alignof(prh_atom_u32) == prh_alignof(atomic_uint));
prh_static_assert(prh_alignof(prh_atom_int) == prh_alignof(atomic_intptr_t));
prh_static_assert(prh_alignof(prh_atom_unt) == prh_alignof(atomic_uintptr_t));
prh_static_assert(prh_alignof(prh_atom_ptr) == prh_alignof(atomic_uintptr_t));

prh_static_assert(sizeof(prh_atom_bool) == sizeof(atomic_bool));
prh_static_assert(sizeof(prh_atom_i08) == sizeof(atomic_schar));
prh_static_assert(sizeof(prh_atom_u08) == sizeof(atomic_uchar));
prh_static_assert(sizeof(prh_atom_i16) == sizeof(atomic_short));
prh_static_assert(sizeof(prh_atom_u16) == sizeof(atomic_ushort));
prh_static_assert(sizeof(prh_atom_i32) == sizeof(atomic_int));
prh_static_assert(sizeof(prh_atom_u32) == sizeof(atomic_uint));
prh_static_assert(sizeof(prh_atom_int) == sizeof(atomic_intptr_t));
prh_static_assert(sizeof(prh_atom_unt) == sizeof(atomic_uintptr_t));
prh_static_assert(sizeof(prh_atom_ptr) == sizeof(atomic_uintptr_t));

// Initializes an existing atomic object.
// The function is not atomic: concurrent access from another thread, even
// through an atomic operation, is a data race.
// Calling this function on an atomic object that has already been initialized
// (either on construction or by calling this function earlier) causes
// undefined behavior.
// atomic_init is the only way to initialize dynamically-allocated atomic
// objects. For example:
//      _Atomic int *p = malloc(sizeof(_Atomic int));
//      atomic_init(p, 42);
prh_inline void prh_atom_bool_init(prh_atom_bool *a, bool b) { atomic_init((atomic_bool *)a, b); }
prh_inline void prh_atom_i08_init(prh_atom_i08 *a, prh_i08 b) { atomic_init((atomic_schar *)a, b); }
prh_inline void prh_atom_u08_init(prh_atom_u08 *a, prh_u08 b) { atomic_init((atomic_uchar *)a, b); }
prh_inline void prh_atom_i16_init(prh_atom_i16 *a, prh_i16 b) { atomic_init((atomic_short *)a, b); }
prh_inline void prh_atom_u16_init(prh_atom_u16 *a, prh_u16 b) { atomic_init((atomic_ushort *)a, b); }
prh_inline void prh_atom_i32_init(prh_atom_i32 *a, prh_i32 b) { atomic_init((atomic_int *)a, b); }
prh_inline void prh_atom_u32_init(prh_atom_u32 *a, prh_u32 b) { atomic_init((atomic_uint *)a, b); }
prh_inline void prh_atom_int_init(prh_atom_int *a, prh_int b) { atomic_init((atomic_intptr_t *)a, b); }
prh_inline void prh_atom_unt_init(prh_atom_unt *a, prh_unt b) { atomic_init((atomic_uintptr_t *)a, b); }
prh_inline void prh_atom_ptr_init(prh_atom_ptr *a, void *b) { atomic_init((atomic_uintptr_t *)a, (prh_unt)b); }

// Atomically perform load (atomic read) operation and return the value.
// The default memory_order type is memory_order_seq_cst.
prh_inline bool prh_atom_bool_read(const prh_atom_bool *a) { return atomic_load((atomic_bool *)a); } // return read value
prh_inline prh_i08 prh_atom_i08_read(const prh_atom_i08 *a) { return atomic_load((atomic_schar *)a); }
prh_inline prh_u08 prh_atom_u08_read(const prh_atom_u08 *a) { return atomic_load((atomic_uchar *)a); }
prh_inline prh_i16 prh_atom_i16_read(const prh_atom_i16 *a) { return atomic_load((atomic_short *)a); }
prh_inline prh_u16 prh_atom_u16_read(const prh_atom_u16 *a) { return atomic_load((atomic_ushort *)a); }
prh_inline prh_i32 prh_atom_i32_read(const prh_atom_i32 *a) { return atomic_load((atomic_int *)a); }
prh_inline prh_u32 prh_atom_u32_read(const prh_atom_u32 *a) { return atomic_load((atomic_uint *)a); }
prh_inline prh_int prh_atom_int_read(const prh_atom_int *a) { return atomic_load((atomic_intptr_t *)a); }
prh_inline prh_unt prh_atom_unt_read(const prh_atom_unt *a) { return atomic_load((atomic_uintptr_t *)a); }
prh_inline void *prh_atom_ptr_read(const prh_atom_ptr *a) { return (void *)atomic_load((atomic_uintptr_t *)a); }

// Atomically perform write or read-modify-write operation.
// The default memory_order type is memory_order_seq_cst.
prh_inline void prh_atom_bool_write(prh_atom_bool *a, bool b) { atomic_store((atomic_bool *)a, b); }
prh_inline void prh_atom_i08_write(prh_atom_i08 *a, prh_i08 b) { atomic_store((atomic_schar *)a, b); }
prh_inline void prh_atom_u08_write(prh_atom_u08 *a, prh_u08 b) { atomic_store((atomic_uchar *)a, b); }
prh_inline void prh_atom_i16_write(prh_atom_i16 *a, prh_i16 b) { atomic_store((atomic_short *)a, b); }
prh_inline void prh_atom_u16_write(prh_atom_u16 *a, prh_u16 b) { atomic_store((atomic_ushort *)a, b); }
prh_inline void prh_atom_i32_write(prh_atom_i32 *a, prh_i32 b) { atomic_store((atomic_int *)a, b); }
prh_inline void prh_atom_u32_write(prh_atom_u32 *a, prh_u32 b) { atomic_store((atomic_uint *)a, b); }
prh_inline void prh_atom_int_write(prh_atom_int *a, prh_int b) { atomic_store((atomic_intptr_t *)a, b); }
prh_inline void prh_atom_unt_write(prh_atom_unt *a, prh_unt b) { atomic_store((atomic_uintptr_t *)a, b); }
prh_inline void prh_atom_ptr_write(prh_atom_ptr *a, void *b) { atomic_store((atomic_uintptr_t *)a, (prh_unt)b); }

prh_inline bool prh_atom_bool_fetch_write(prh_atom_bool *a, bool b) { return atomic_exchange((atomic_bool *)a, b); } // return old value
prh_inline prh_i08 prh_atom_i08_fetch_write(prh_atom_i08 *a, prh_i08 b) { return atomic_exchange((atomic_schar *)a, b); }
prh_inline prh_u08 prh_atom_u08_fetch_write(prh_atom_u08 *a, prh_u08 b) { return atomic_exchange((atomic_uchar *)a, b); }
prh_inline prh_i16 prh_atom_i16_fetch_write(prh_atom_i16 *a, prh_i16 b) { return atomic_exchange((atomic_short *)a, b); }
prh_inline prh_u16 prh_atom_u16_fetch_write(prh_atom_u16 *a, prh_u16 b) { return atomic_exchange((atomic_ushort *)a, b); }
prh_inline prh_i32 prh_atom_i32_fetch_write(prh_atom_i32 *a, prh_i32 b) { return atomic_exchange((atomic_int *)a, b); }
prh_inline prh_u32 prh_atom_u32_fetch_write(prh_atom_u32 *a, prh_u32 b) { return atomic_exchange((atomic_uint *)a, b); }
prh_inline prh_int prh_atom_int_fetch_write(prh_atom_int *a, prh_int b) { return atomic_exchange((atomic_intptr_t *)a, b); }
prh_inline prh_unt prh_atom_unt_fetch_write(prh_atom_unt *a, prh_unt b) { return atomic_exchange((atomic_uintptr_t *)a, b); }
prh_inline void *prh_atom_ptr_fetch_write(prh_atom_ptr *a, void *b) { return (void *)atomic_exchange((atomic_uintptr_t *)a, (prh_unt)b); }

// Atomically perform read-modify-wirte operation, and return the old value.
// The modify operation can be add (+) sub (-) and (&) or (|) xor (^).
// The default memory_order type is memory_order_seq_cst.

prh_inline prh_i08 prh_atom_i08_fetch_inc(prh_atom_i08 *a) { return atomic_fetch_add((atomic_schar *)a, 1); }
prh_inline prh_u08 prh_atom_u08_fetch_inc(prh_atom_u08 *a) { return atomic_fetch_add((atomic_uchar *)a, 1); }
prh_inline prh_i16 prh_atom_i16_fetch_inc(prh_atom_i16 *a) { return atomic_fetch_add((atomic_short *)a, 1); }
prh_inline prh_u16 prh_atom_u16_fetch_inc(prh_atom_u16 *a) { return atomic_fetch_add((atomic_ushort *)a, 1); }
prh_inline prh_i32 prh_atom_i32_fetch_inc(prh_atom_i32 *a) { return atomic_fetch_add((atomic_int *)a, 1); }
prh_inline prh_u32 prh_atom_u32_fetch_inc(prh_atom_u32 *a) { return atomic_fetch_add((atomic_uint *)a, 1); }
prh_inline prh_int prh_atom_int_fetch_inc(prh_atom_int *a) { return atomic_fetch_add((atomic_intptr_t *)a, 1); }
prh_inline prh_unt prh_atom_unt_fetch_inc(prh_atom_unt *a) { return atomic_fetch_add((atomic_uintptr_t *)a, 1); }

prh_inline prh_i08 prh_atom_i08_fetch_dec(prh_atom_i08 *a) { return atomic_fetch_sub((atomic_schar *)a, 1); }
prh_inline prh_u08 prh_atom_u08_fetch_dec(prh_atom_u08 *a) { return atomic_fetch_sub((atomic_uchar *)a, 1); }
prh_inline prh_i16 prh_atom_i16_fetch_dec(prh_atom_i16 *a) { return atomic_fetch_sub((atomic_short *)a, 1); }
prh_inline prh_u16 prh_atom_u16_fetch_dec(prh_atom_u16 *a) { return atomic_fetch_sub((atomic_ushort *)a, 1); }
prh_inline prh_i32 prh_atom_i32_fetch_dec(prh_atom_i32 *a) { return atomic_fetch_sub((atomic_int *)a, 1); }
prh_inline prh_u32 prh_atom_u32_fetch_dec(prh_atom_u32 *a) { return atomic_fetch_sub((atomic_uint *)a, 1); }
prh_inline prh_int prh_atom_int_fetch_dec(prh_atom_int *a) { return atomic_fetch_sub((atomic_intptr_t *)a, 1); }
prh_inline prh_unt prh_atom_unt_fetch_dec(prh_atom_unt *a) { return atomic_fetch_sub((atomic_uintptr_t *)a, 1); }

prh_inline void prh_atom_i08_inc(prh_atom_i08 *a) { atomic_fetch_add((atomic_schar *)a, 1); }
prh_inline void prh_atom_u08_inc(prh_atom_u08 *a) { atomic_fetch_add((atomic_uchar *)a, 1); }
prh_inline void prh_atom_i16_inc(prh_atom_i16 *a) { atomic_fetch_add((atomic_short *)a, 1); }
prh_inline void prh_atom_u16_inc(prh_atom_u16 *a) { atomic_fetch_add((atomic_ushort *)a, 1); }
prh_inline void prh_atom_i32_inc(prh_atom_i32 *a) { atomic_fetch_add((atomic_int *)a, 1); }
prh_inline void prh_atom_u32_inc(prh_atom_u32 *a) { atomic_fetch_add((atomic_uint *)a, 1); }
prh_inline void prh_atom_int_inc(prh_atom_int *a) { atomic_fetch_add((atomic_intptr_t *)a, 1); }
prh_inline void prh_atom_unt_inc(prh_atom_unt *a) { atomic_fetch_add((atomic_uintptr_t *)a, 1); }

prh_inline void prh_atom_i08_dec(prh_atom_i08 *a) { atomic_fetch_sub((atomic_schar *)a, 1); }
prh_inline void prh_atom_u08_dec(prh_atom_u08 *a) { atomic_fetch_sub((atomic_uchar *)a, 1); }
prh_inline void prh_atom_i16_dec(prh_atom_i16 *a) { atomic_fetch_sub((atomic_short *)a, 1); }
prh_inline void prh_atom_u16_dec(prh_atom_u16 *a) { atomic_fetch_sub((atomic_ushort *)a, 1); }
prh_inline void prh_atom_i32_dec(prh_atom_i32 *a) { atomic_fetch_sub((atomic_int *)a, 1); }
prh_inline void prh_atom_u32_dec(prh_atom_u32 *a) { atomic_fetch_sub((atomic_uint *)a, 1); }
prh_inline void prh_atom_int_dec(prh_atom_int *a) { atomic_fetch_sub((atomic_intptr_t *)a, 1); }
prh_inline void prh_atom_unt_dec(prh_atom_unt *a) { atomic_fetch_sub((atomic_uintptr_t *)a, 1); }

prh_inline prh_i08 prh_atom_i08_fetch_add(prh_atom_i08 *a, prh_i08 b) { return atomic_fetch_add((atomic_schar *)a, b); }
prh_inline prh_u08 prh_atom_u08_fetch_add(prh_atom_u08 *a, prh_u08 b) { return atomic_fetch_add((atomic_uchar *)a, b); }
prh_inline prh_i16 prh_atom_i16_fetch_add(prh_atom_i16 *a, prh_i16 b) { return atomic_fetch_add((atomic_short *)a, b); }
prh_inline prh_u16 prh_atom_u16_fetch_add(prh_atom_u16 *a, prh_u16 b) { return atomic_fetch_add((atomic_ushort *)a, b); }
prh_inline prh_i32 prh_atom_i32_fetch_add(prh_atom_i32 *a, prh_i32 b) { return atomic_fetch_add((atomic_int *)a, b); }
prh_inline prh_u32 prh_atom_u32_fetch_add(prh_atom_u32 *a, prh_u32 b) { return atomic_fetch_add((atomic_uint *)a, b); }
prh_inline prh_int prh_atom_int_fetch_add(prh_atom_int *a, prh_int b) { return atomic_fetch_add((atomic_intptr_t *)a, b); }
prh_inline prh_unt prh_atom_unt_fetch_add(prh_atom_unt *a, prh_unt b) { return atomic_fetch_add((atomic_uintptr_t *)a, b); }

prh_inline prh_i08 prh_atom_i32_fetch_sub(prh_atom_i08 *a, prh_i08 b) { return atomic_fetch_sub((atomic_schar *)a, b); }
prh_inline prh_u08 prh_atom_u32_fetch_sub(prh_atom_u08 *a, prh_u08 b) { return atomic_fetch_sub((atomic_uchar *)a, b); }
prh_inline prh_i16 prh_atom_i32_fetch_sub(prh_atom_i16 *a, prh_i16 b) { return atomic_fetch_sub((atomic_short *)a, b); }
prh_inline prh_u16 prh_atom_u32_fetch_sub(prh_atom_u16 *a, prh_u16 b) { return atomic_fetch_sub((atomic_ushort *)a, b); }
prh_inline prh_i32 prh_atom_i32_fetch_sub(prh_atom_i32 *a, prh_i32 b) { return atomic_fetch_sub((atomic_int *)a, b); }
prh_inline prh_u32 prh_atom_u32_fetch_sub(prh_atom_u32 *a, prh_u32 b) { return atomic_fetch_sub((atomic_uint *)a, b); }
prh_inline prh_int prh_atom_int_fetch_sub(prh_atom_int *a, prh_int b) { return atomic_fetch_sub((atomic_intptr_t *)a, b); }
prh_inline prh_unt prh_atom_unt_fetch_sub(prh_atom_unt *a, prh_unt b) { return atomic_fetch_sub((atomic_uintptr_t *)a, b); }

prh_inline void prh_atom_i08_add(prh_atom_i08 *a, prh_i08 b) { atomic_fetch_add((atomic_schar *)a, b); }
prh_inline void prh_atom_u08_add(prh_atom_u08 *a, prh_u08 b) { atomic_fetch_add((atomic_uchar *)a, b); }
prh_inline void prh_atom_i16_add(prh_atom_i16 *a, prh_i16 b) { atomic_fetch_add((atomic_short *)a, b); }
prh_inline void prh_atom_u16_add(prh_atom_u16 *a, prh_u16 b) { atomic_fetch_add((atomic_ushort *)a, b); }
prh_inline void prh_atom_i32_add(prh_atom_i32 *a, prh_i32 b) { atomic_fetch_add((atomic_int *)a, b); }
prh_inline void prh_atom_u32_add(prh_atom_u32 *a, prh_u32 b) { atomic_fetch_add((atomic_uint *)a, b); }
prh_inline void prh_atom_int_add(prh_atom_int *a, prh_int b) { atomic_fetch_add((atomic_intptr_t *)a, b); }
prh_inline void prh_atom_unt_add(prh_atom_unt *a, prh_unt b) { atomic_fetch_add((atomic_uintptr_t *)a, b); }

prh_inline void prh_atom_i08_sub(prh_atom_i08 *a, prh_i08 b) { atomic_fetch_sub((atomic_schar *)a, b); }
prh_inline void prh_atom_u08_sub(prh_atom_u08 *a, prh_u08 b) { atomic_fetch_sub((atomic_uchar *)a, b); }
prh_inline void prh_atom_i16_sub(prh_atom_i16 *a, prh_i16 b) { atomic_fetch_sub((atomic_short *)a, b); }
prh_inline void prh_atom_u16_sub(prh_atom_u16 *a, prh_u16 b) { atomic_fetch_sub((atomic_ushort *)a, b); }
prh_inline void prh_atom_i32_sub(prh_atom_i32 *a, prh_i32 b) { atomic_fetch_sub((atomic_int *)a, b); }
prh_inline void prh_atom_u32_sub(prh_atom_u32 *a, prh_u32 b) { atomic_fetch_sub((atomic_uint *)a, b); }
prh_inline void prh_atom_int_sub(prh_atom_int *a, prh_int b) { atomic_fetch_sub((atomic_intptr_t *)a, b); }
prh_inline void prh_atom_unt_sub(prh_atom_unt *a, prh_unt b) { atomic_fetch_sub((atomic_uintptr_t *)a, b); }

prh_inline prh_i08 prh_atom_i08_fetch_bit_or(prh_atom_i08 *a, prh_i08 b) { return atomic_fetch_or((atomic_schar *)a, b); }
prh_inline prh_u08 prh_atom_u08_fetch_bit_or(prh_atom_u08 *a, prh_u08 b) { return atomic_fetch_or((atomic_uchar *)a, b); }
prh_inline prh_i16 prh_atom_i16_fetch_bit_or(prh_atom_i16 *a, prh_i16 b) { return atomic_fetch_or((atomic_short *)a, b); }
prh_inline prh_u16 prh_atom_u16_fetch_bit_or(prh_atom_u16 *a, prh_u16 b) { return atomic_fetch_or((atomic_ushort *)a, b); }
prh_inline prh_i32 prh_atom_i32_fetch_bit_or(prh_atom_i32 *a, prh_i32 b) { return atomic_fetch_or((atomic_int *)a, b); }
prh_inline prh_u32 prh_atom_u32_fetch_bit_or(prh_atom_u32 *a, prh_u32 b) { return atomic_fetch_or((atomic_uint *)a, b); }
prh_inline prh_int prh_atom_int_fetch_bit_or(prh_atom_int *a, prh_int b) { return atomic_fetch_or((atomic_intptr_t *)a, b); }
prh_inline prh_unt prh_atom_unt_fetch_bit_or(prh_atom_unt *a, prh_unt b) { return atomic_fetch_or((atomic_uintptr_t *)a, b); }

prh_inline prh_i08 prh_atom_i08_fetch_bit_and(prh_atom_i08 *a, prh_i08 b) { return atomic_fetch_and((atomic_schar *)a, b); }
prh_inline prh_u08 prh_atom_u08_fetch_bit_and(prh_atom_u08 *a, prh_u08 b) { return atomic_fetch_and((atomic_uchar *)a, b); }
prh_inline prh_i16 prh_atom_i16_fetch_bit_and(prh_atom_i16 *a, prh_i16 b) { return atomic_fetch_and((atomic_short *)a, b); }
prh_inline prh_u16 prh_atom_u16_fetch_bit_and(prh_atom_u16 *a, prh_u16 b) { return atomic_fetch_and((atomic_ushort *)a, b); }
prh_inline prh_i32 prh_atom_i32_fetch_bit_and(prh_atom_i32 *a, prh_i32 b) { return atomic_fetch_and((atomic_int *)a, b); }
prh_inline prh_u32 prh_atom_u32_fetch_bit_and(prh_atom_u32 *a, prh_u32 b) { return atomic_fetch_and((atomic_uint *)a, b); }
prh_inline prh_int prh_atom_int_fetch_bit_and(prh_atom_int *a, prh_int b) { return atomic_fetch_and((atomic_intptr_t *)a, b); }
prh_inline prh_unt prh_atom_unt_fetch_bit_and(prh_atom_unt *a, prh_unt b) { return atomic_fetch_and((atomic_uintptr_t *)a, b); }

prh_inline void prh_atom_i08_bit_or(prh_atom_i08 *a, prh_i08 b) { atomic_fetch_or((atomic_schar *)a, b); }
prh_inline void prh_atom_u08_bit_or(prh_atom_u08 *a, prh_u08 b) { atomic_fetch_or((atomic_uchar *)a, b); }
prh_inline void prh_atom_i16_bit_or(prh_atom_i16 *a, prh_i16 b) { atomic_fetch_or((atomic_short *)a, b); }
prh_inline void prh_atom_u16_bit_or(prh_atom_u16 *a, prh_u16 b) { atomic_fetch_or((atomic_ushort *)a, b); }
prh_inline void prh_atom_i32_bit_or(prh_atom_i32 *a, prh_i32 b) { atomic_fetch_or((atomic_int *)a, b); }
prh_inline void prh_atom_u32_bit_or(prh_atom_u32 *a, prh_u32 b) { atomic_fetch_or((atomic_uint *)a, b); }
prh_inline void prh_atom_int_bit_or(prh_atom_int *a, prh_int b) { atomic_fetch_or((atomic_intptr_t *)a, b); }
prh_inline void prh_atom_unt_bit_or(prh_atom_unt *a, prh_unt b) { atomic_fetch_or((atomic_uintptr_t *)a, b); }

prh_inline void prh_atom_i08_bit_and(prh_atom_i08 *a, prh_i08 b) { atomic_fetch_and((atomic_schar *)a, b); }
prh_inline void prh_atom_u08_bit_and(prh_atom_u08 *a, prh_u08 b) { atomic_fetch_and((atomic_uchar *)a, b); }
prh_inline void prh_atom_i16_bit_and(prh_atom_i16 *a, prh_i16 b) { atomic_fetch_and((atomic_short *)a, b); }
prh_inline void prh_atom_u16_bit_and(prh_atom_u16 *a, prh_u16 b) { atomic_fetch_and((atomic_ushort *)a, b); }
prh_inline void prh_atom_i32_bit_and(prh_atom_i32 *a, prh_i32 b) { atomic_fetch_and((atomic_int *)a, b); }
prh_inline void prh_atom_u32_bit_and(prh_atom_u32 *a, prh_u32 b) { atomic_fetch_and((atomic_uint *)a, b); }
prh_inline void prh_atom_int_bit_and(prh_atom_int *a, prh_int b) { atomic_fetch_and((atomic_intptr_t *)a, b); }
prh_inline void prh_atom_unt_bit_and(prh_atom_unt *a, prh_unt b) { atomic_fetch_and((atomic_uintptr_t *)a, b); }

// Atomically perform compare-and-exchange (or compare-and-swap CAS) operation.
//      if read value == *expect value { write newvalue and return true }
//      else { *expect = read value and return false }
// If success it operform atomic read-modify-write operation, otherwise it
// opertion load (load actual content into *expect) operation.
// The weak forms of the functions are allowed to fail spuriously, that is,
// even if `read value == *expect value` it still goes to else and return
// false. On these spurious failures, the function returns false while not
// modifying expected.
// This may be acceptable behavior for certain looping algorithms, and
// may lead to significantly better performance on some platforms.
// For non-looping algorithms, atomic_compare_exchange_strong is generally
// preferred.
// The default memory_order type is memory_order_seq_cst.
prh_inline bool prh_atom_bool_weak_write(prh_atom_bool *a, bool *expect, bool b) { return atomic_compare_exchange_weak((atomic_bool *)a, expect, b); }
prh_inline bool prh_atom_i08_weak_write(prh_atom_i08 *a, prh_i08 *expect, prh_i08 b) { return atomic_compare_exchange_weak((atomic_schar *)a, expect, b); }
prh_inline bool prh_atom_u08_weak_write(prh_atom_u08 *a, prh_u08 *expect, prh_u08 b) { return atomic_compare_exchange_weak((atomic_uchar *)a, expect, b); }
prh_inline bool prh_atom_i16_weak_write(prh_atom_i16 *a, prh_i16 *expect, prh_i16 b) { return atomic_compare_exchange_weak((atomic_short *)a, expect, b); }
prh_inline bool prh_atom_u16_weak_write(prh_atom_u16 *a, prh_u16 *expect, prh_u16 b) { return atomic_compare_exchange_weak((atomic_ushort *)a, expect, b); }
prh_inline bool prh_atom_i32_weak_write(prh_atom_i32 *a, prh_i32 *expect, prh_i32 b) { return atomic_compare_exchange_weak((atomic_int *)a, expect, b); }
prh_inline bool prh_atom_u32_weak_write(prh_atom_u32 *a, prh_u32 *expect, prh_u32 b) { return atomic_compare_exchange_weak((atomic_uint *)a, expect, b); }
prh_inline bool prh_atom_int_weak_write(prh_atom_int *a, prh_int *expect, prh_int b) { return atomic_compare_exchange_weak((atomic_intptr_t *)a, expect, b); }
prh_inline bool prh_atom_unt_weak_write(prh_atom_unt *a, prh_unt *expect, prh_unt b) { return atomic_compare_exchange_weak((atomic_uintptr_t *)a, expect, b); }
prh_inline bool prh_atom_ptr_weak_write(prh_atom_ptr *a, void **expect, void *b) { return atomic_compare_exchange_weak((atomic_uintptr_t *)a, (prh_unt *)expect, (prh_unt)b); }

prh_inline bool prh_atom_bool_strong_write(prh_atom_bool *a, bool *expect, bool b) { return atomic_compare_exchange_strong((atomic_bool *)a, expect, b); }
prh_inline bool prh_atom_i08_strong_write(prh_atom_i08 *a, prh_i08 *expect, prh_i08 b) { return atomic_compare_exchange_strong((atomic_schar *)a, expect, b); }
prh_inline bool prh_atom_u08_strong_write(prh_atom_u08 *a, prh_u08 *expect, prh_u08 b) { return atomic_compare_exchange_strong((atomic_uchar *)a, expect, b); }
prh_inline bool prh_atom_i16_strong_write(prh_atom_i16 *a, prh_i16 *expect, prh_i16 b) { return atomic_compare_exchange_strong((atomic_short *)a, expect, b); }
prh_inline bool prh_atom_u16_strong_write(prh_atom_u16 *a, prh_u16 *expect, prh_u16 b) { return atomic_compare_exchange_strong((atomic_ushort *)a, expect, b); }
prh_inline bool prh_atom_i32_strong_write(prh_atom_i32 *a, prh_i32 *expect, prh_i32 b) { return atomic_compare_exchange_strong((atomic_int *)a, expect, b); }
prh_inline bool prh_atom_u32_strong_write(prh_atom_u32 *a, prh_u32 *expect, prh_u32 b) { return atomic_compare_exchange_strong((atomic_uint *)a, expect, b); }
prh_inline bool prh_atom_int_strong_write(prh_atom_int *a, prh_int *expect, prh_int b) { return atomic_compare_exchange_strong((atomic_intptr_t *)a, expect, b); }
prh_inline bool prh_atom_unt_strong_write(prh_atom_unt *a, prh_unt *expect, prh_unt b) { return atomic_compare_exchange_strong((atomic_uintptr_t *)a, expect, b); }
prh_inline bool prh_atom_ptr_strong_write(prh_atom_ptr *a, void **expect, void *b) { return atomic_compare_exchange_strong((atomic_uintptr_t *)a, (prh_unt *)expect, (prh_unt)b); }

prh_inline bool prh_atom_bool_weak_clear(prh_atom_bool *a) { bool expect = true; return atomic_compare_exchange_weak((atomic_bool *)a, &expect, false); }
prh_inline bool prh_atom_bool_weak_set(prh_atom_bool *a) { bool expect = false; return atomic_compare_exchange_weak((atomic_bool *)a, &expect, true); }
prh_inline bool prh_atom_bool_strong_clear(prh_atom_bool *a) { bool expect = true; return atomic_compare_exchange_strong((atomic_bool *)a, &expect, false); }
prh_inline bool prh_atom_bool_strong_set(prh_atom_bool *a) { bool expect = false; return atomic_compare_exchange_strong((atomic_bool *)a, &expect, true); }

prh_inline bool prh_atom_i08_weak_write_non_zero(prh_atom_i08 *a, prh_i32 b) { prh_i08 expect = 0; return atomic_compare_exchange_weak((atomic_schar *)a, &expect, b); }
prh_inline bool prh_atom_u08_weak_write_non_zero(prh_atom_u08 *a, prh_u32 b) { prh_u08 expect = 0; return atomic_compare_exchange_weak((atomic_uchar *)a, &expect, b); }
prh_inline bool prh_atom_i16_weak_write_non_zero(prh_atom_i16 *a, prh_i32 b) { prh_i16 expect = 0; return atomic_compare_exchange_weak((atomic_short *)a, &expect, b); }
prh_inline bool prh_atom_u16_weak_write_non_zero(prh_atom_u16 *a, prh_u32 b) { prh_u16 expect = 0; return atomic_compare_exchange_weak((atomic_ushort *)a, &expect, b); }
prh_inline bool prh_atom_i32_weak_write_non_zero(prh_atom_i32 *a, prh_i32 b) { prh_i32 expect = 0; return atomic_compare_exchange_weak((atomic_int *)a, &expect, b); }
prh_inline bool prh_atom_u32_weak_write_non_zero(prh_atom_u32 *a, prh_u32 b) { prh_u32 expect = 0; return atomic_compare_exchange_weak((atomic_uint *)a, &expect, b); }
prh_inline bool prh_atom_int_weak_write_non_zero(prh_atom_int *a, prh_int b) { prh_int expect = 0; return atomic_compare_exchange_weak((atomic_intptr_t *)a, &expect, b); }
prh_inline bool prh_atom_unt_weak_write_non_zero(prh_atom_unt *a, prh_unt b) { prh_unt expect = 0; return atomic_compare_exchange_weak((atomic_uintptr_t *)a, &expect, b); }
prh_inline bool prh_atom_ptr_weak_write_non_null(prh_atom_ptr *a, void *b) { prh_unt expect = 0; return atomic_compare_exchange_weak((atomic_uintptr_t *)a, &expect, (prh_unt)b); }

prh_inline bool prh_atom_i08_strong_write_non_zero(prh_atom_i08 *a, prh_i32 b) { prh_i08 expect = 0; return atomic_compare_exchange_strong((atomic_schar *)a, &expect, b); }
prh_inline bool prh_atom_u08_strong_write_non_zero(prh_atom_u08 *a, prh_u32 b) { prh_u08 expect = 0; return atomic_compare_exchange_strong((atomic_uchar *)a, &expect, b); }
prh_inline bool prh_atom_i16_strong_write_non_zero(prh_atom_i16 *a, prh_i32 b) { prh_i16 expect = 0; return atomic_compare_exchange_strong((atomic_short *)a, &expect, b); }
prh_inline bool prh_atom_u16_strong_write_non_zero(prh_atom_u16 *a, prh_u32 b) { prh_u16 expect = 0; return atomic_compare_exchange_strong((atomic_ushort *)a, &expect, b); }
prh_inline bool prh_atom_i32_strong_write_non_zero(prh_atom_i32 *a, prh_i32 b) { prh_i32 expect = 0; return atomic_compare_exchange_strong((atomic_int *)a, &expect, b); }
prh_inline bool prh_atom_u32_strong_write_non_zero(prh_atom_u32 *a, prh_u32 b) { prh_u32 expect = 0; return atomic_compare_exchange_strong((atomic_uint *)a, &expect, b); }
prh_inline bool prh_atom_int_strong_write_non_zero(prh_atom_int *a, prh_int b) { prh_int expect = 0; return atomic_compare_exchange_strong((atomic_intptr_t *)a, &expect, b); }
prh_inline bool prh_atom_unt_strong_write_non_zero(prh_atom_unt *a, prh_unt b) { prh_unt expect = 0; return atomic_compare_exchange_strong((atomic_uintptr_t *)a, &expect, b); }
prh_inline bool prh_atom_ptr_strong_write_non_null(prh_atom_ptr *a, void *b) { prh_unt expect = 0; return atomic_compare_exchange_strong((atomic_uintptr_t *)a, &expect, (prh_unt)b); }

// Atomic singly linked queue for only 1 producer and 1 consumer. Each node has
// a prh_snode header and a data pointer. The node has fixed size and can only
// contain a data pointer. The fixed size node is dynamic alloced by the queue.
typedef struct {
    prh_data_snode *head; // 只由单一消费者读写, only modified by pop thread
    prh_data_snode *tail; // 只由单一生产者读写, only modified by push thread
    prh_data_snode_head free; // 仅由生产者读写，only modified by push thread
    prh_atom_ptr last; // 生产者无条件写，消费者负责读和有条件写
} prh_atom_data_quefix;

void prh_atom_data_quefix_init(prh_atom_data_quefix *q);
void prh_atom_data_quefix_push(prh_atom_data_quefix *s, void *data); // data shall not be null
void *prh_atom_data_quefix_top(prh_atom_data_quefix *s); // return null means empty
void *prh_atom_data_quefix_pop(prh_atom_data_quefix *s); // return null means empty
bool prh_atom_data_quefix_pop_all(prh_atom_data_quefix *q, prh_data_quefit *out);
void prh_atom_data_quefix_free_node(prh_data_quefit *q);

#ifdef PRH_ATOMIC_IMPLEMENTATION
#define PRH_IMPL_ATOM_DYNQUE_BLOCK_SIZE PRH_CACHE_LINE_SIZE // block size shall be power of 2
#define PRH_IMPL_ATOM_DYNQUE_NODE_COUNT (PRH_IMPL_ATOM_DYNQUE_BLOCK_SIZE / sizeof(prh_data_snode))
prh_static_assert(PRH_IMPL_ATOM_DYNQUE_NODE_COUNT >= 2); // 如果不能分配2个或2个以上，间接块分配没有意义
prh_static_assert(PRH_IMPL_ATOM_DYNQUE_BLOCK_SIZE % sizeof(prh_data_snode) == 0);

void prh_impl_atom_data_quefix_more_free(prh_atom_data_quefix *q, prh_data_snode *node) {
    prh_data_snode *last = node + PRH_IMPL_ATOM_DYNQUE_NODE_COUNT - 1;
    prh_data_snode *first = q->free.next;
    q->free.next = node; // add node list to free head
    last->next = first;
    for (; ;) {
        node->next = node + 1;
        node = node + 1;
        if (node == last) {
            break;
        }
    }
}

prh_data_snode *prh_impl_atom_data_quefix_aligned_alloc(prh_atom_data_quefix *q) { // called by push thread
    prh_data_snode *node;
    if (q->free.next == prh_null) {
        assert(prh_is_power_of_2(PRH_IMPL_ATOM_DYNQUE_BLOCK_SIZE));
        prh_impl_atom_data_quefix_more_free(q, prh_cache_line_aligned_malloc(PRH_IMPL_ATOM_DYNQUE_BLOCK_SIZE));
    }
    node = q->free.next; // remove first free node
    q->free.next = node->next;
    node->next = prh_null; // node->data is set by push
    return node;
}

void prh_impl_atom_data_quefix_aligned_free(prh_data_snode *node) { // called by pop thread
    if (((prh_unt)(node + 1) & (prh_unt)(PRH_IMPL_ATOM_DYNQUE_BLOCK_SIZE - 1)) == 0) {
        prh_aligned_free(node + 1 - PRH_IMPL_ATOM_DYNQUE_NODE_COUNT);
    }
}

void prh_atom_data_quefix_init(prh_atom_data_quefix *q) {
    q->free.next = prh_null;
    q->head = q->tail = prh_impl_atom_data_quefix_aligned_alloc(q); // 总是分配一个tail空节点，让非空head永远追不上tail
    prh_atom_ptr_init(&q->last, prh_null);
}

typedef struct {
    prh_atom_data_quefix *queue;
    prh_data_snode *alloc_tail;
#if PRH_DEBUG
    prh_data_snode *queue_tail;
#endif
} prh_impl_atom_data_quefix_allocator;

void prh_impl_atom_data_quefix_alloc_begin(prh_atom_data_quefix *q, prh_impl_atom_data_quefix_allocator *p) {
    p->queue = q;
    p->alloc_tail = q->tail;
#if PRH_DEBUG
    p->queue_tail = q->tail;
#endif
}

prh_data_snode *prh_impl_atom_data_quefix_alloc_node(prh_impl_atom_data_quefix_allocator *p, void *data) {
    assert(data != prh_null);
    prh_data_snode *node = p->alloc_tail;
    p->alloc_tail = prh_impl_atom_data_quefix_aligned_alloc(p->queue);
    node->data = data;
    return node;
}

void prh_impl_atom_data_quefix_alloc_end_and_push_node_back(prh_impl_atom_data_quefix_allocator *p) {
    prh_atom_data_quefix *q = p->queue;
    prh_data_snode *tail = p->alloc_tail;
#if PRH_DEBUG
    assert(q->tail == p->queue_tail);
#endif
    q->tail = tail;
    tail->next = prh_null;
}

void prh_atom_data_quefix_push(prh_atom_data_quefix *q, void *data) {
    assert(data != prh_null); // push不会读写head，也不会读写已经存在的节点
    prh_data_snode *null_tail = prh_impl_atom_data_quefix_aligned_alloc(q);
    prh_data_snode *last = q->tail;
    q->tail = null_tail; // push只会更新tail和tail空节点，且push对应单一生产者，因此tail不需要atom
    last->next = null_tail;
    last->data = data;
    assert(q->tail == null_tail); // 只允许唯一生产者
    prh_atom_ptr_write(&q->last, last); // 此步骤执行完毕以上更新必须对所有cpu生效
}

bool prh_atom_data_quefix_empty(prh_atom_data_quefix *q) {
    return prh_atom_ptr_read(&q->last) == prh_null;
}

void *prh_atom_data_quefix_top(prh_atom_data_quefix *q) {
    if (!prh_atom_ptr_read(&q->last)) return prh_null;
    return q->head->data;
}

void *prh_atom_data_quefix_pop(prh_atom_data_quefix *q) {
    prh_data_snode *last = prh_atom_ptr_read(&q->last);
    if (last == prh_null) return prh_null;
    prh_data_snode *head = q->head;
    prh_data_snode *next = head->next;
    void *data = head->data; // pop不会读写tail，也不会读写tail空节点
    q->head = next; // pop只会更新head和读写已存在的头节点，且pop对应单一消费者，因此head不需要atom
    if (head == last) { // 使用 compare write 是因为 q->last 会随时被 push 更新
        prh_atom_ptr_strong_write(&q->last, (void **)&last, prh_null);
    }
    prh_impl_atom_data_quefix_aligned_free(head);
    assert(q->head == next); // 只允许唯一消费者
    return data;
}

bool prh_atom_data_quefix_pop_all(prh_atom_data_quefix *q, prh_data_quefit *out) {
    prh_data_snode *last = prh_atom_ptr_read(&q->last);
    if (last == prh_null) return false;
    out->tail = last;
    out->head = q->head;
    q->head = last->next; // pop all
    prh_atom_ptr_strong_write(&q->last, (void **)&last, prh_null);
    assert(q->head == last->next); // 只允许唯一消费者
    last->next = prh_null; // quefit最后一个节点指向空，方便遍历和移动
    return true;
}

void prh_atom_data_quefix_free_node(prh_data_quefit *q) {
    prh_data_snode *head = q->head;
    for (; head; head = head->next) {
        prh_impl_atom_data_quefix_aligned_free(head);
    }
}
#endif // PRH_ATOMIC_IMPLEMENTATION

typedef struct prh_hive_quefix_block {
    void **tail; // 初始化时指向当前内存块b+1地址处，当前内存块塞满时指向 prh_impl_ahqf_block_end(b)
    struct prh_hive_quefix_block *next; // 是否有下一个内存块
} prh_hive_quefix_block;

typedef struct {
    prh_hive_quefix_block *fbqh; // 仅由push线程访问（free block queue head）
    prh_int fbqh_index;          // 仅由push线程访问（free block queue head index）
    prh_hive_quefix_block *fbqt; // 仅由pop线程访问（free block queue tail）
    prh_atom_int fbn; // free block num
} prh_atom_hive_fbqfix;

// 单生产者单消费者内存块链队列，每个内存块的大小固定，队列尾永远向前推进，队列头永远追不上队列尾
typedef struct {
    prh_hive_quefix_block *head; // 仅由pop线程访问
    prh_int head_index;          // 仅由pop线程访问
    prh_hive_quefix_block *tail; // 仅由push线程访问
    prh_atom_int len;
    prh_atom_hive_fbqfix *freeq;
} prh_atom_hive_quefix;

prh_inline prh_int prh_atom_hive_quefix_len(prh_atom_hive_quefix *q) { return prh_atom_int_read(&q->len); }
prh_inline bool prh_atom_hive_quefix_empty(prh_atom_hive_quefix *q) { return !prh_atom_int_read(&q->len); }

void prh_atom_hive_quefix_init(prh_atom_hive_quefix *q, prh_atom_hive_fbqfix *freeq);
void prh_atom_hive_quefix_free(prh_atom_hive_quefix *q);
void prh_atom_hive_quefix_push(prh_atom_hive_quefix *q, void *data);
void *prh_atom_hive_quefix_top(prh_atom_hive_quefix *q);
void *prh_atom_hive_quefix_pop(prh_atom_hive_quefix *q);
bool prh_atom_hive_quefix_pops(prh_atom_hive_quefix *q, bool (*cb)(void *priv, void *data), void *priv);

typedef struct { // 仅由生产者线程访问
    prh_hive_quefix_block *queue_tail_block;
    prh_hive_quefix_block *free_block_head;
    prh_hive_quefix_block **free_block_ptr;
} prh_atom_ext_hive_quefix_producer;

typedef struct { // 仅由消费者线程访问
    prh_hive_quefix_block *queue_head_block;
    void **queue_head_block_elem_ptr;
    prh_hive_quefix_block *free_block_tail;
} prh_atom_ext_hive_quefix_consumer;

typedef struct { // 生产者和消费者线程共享访问
    prh_atom_int queue_length;
    prh_atom_int free_block_count;
} prh_atom_ext_hive_quefix_length;

prh_inline prh_int prh_atom_ext_hive_quefix_len(prh_atom_ext_hive_quefix_length *l) { return prh_atom_int_read(&l->queue_length); }
prh_inline bool prh_atom_ext_hive_quefix_empty(prh_atom_ext_hive_quefix_length *l) { return !prh_atom_int_read(&l->queue_length); }

void prh_atom_ext_hive_quefix_init(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l);
void prh_atom_ext_hive_quefix_free(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_consumer *c);
void prh_atom_ext_hive_quefix_push(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_length *l, void *data, prh_ptr extra);
void *prh_atom_ext_hive_quefix_top(prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l);
bool prh_atom_ext_hive_quefix_pop(prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l, void **data, prh_ptr *extra);
bool prh_atom_ext_hive_quefix_pops(prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l, bool (*cb)(void *priv, void *data, prh_ptr extra), void *priv);

#define PRH_ATOM_DYNQUE_BLOCK_END ((void *)(~(prh_ptr)0x02))
#define PRH_ATOM_DYNQUE_ITEM_FREE ((void *)(~(prh_ptr)0x03))

typedef struct prh_atom_dynque_block prh_atom_dynque_block;

typedef struct { // 单生产者单消费者无锁原子队列，队列可以动态增长
    prh_ptr block_end_data;
    prh_atom_dynque_block *next; // 是否有下一个内存块
} prh_atom_dynque_block_end;

typedef struct { // 仅由生产者线程访问
    prh_atom_dynque_block *head_block;
    void **head_block_head_item;
    prh_atom_dynque_block *tail_block;
    void **tail_block_tail_item;
    prh_int free_block_count;
    prh_int block_end_offset;
} prh_atom_dynque_freed_blocks;

typedef struct { // 仅由生产者线程访问
    prh_atom_dynque_block *tail_block;
    void **tail_block_tail_item;
    prh_int block_end_offset;
} prh_atom_dynque_producer;

typedef struct { // 仅由消费者线程访问
    prh_atom_dynque_block *head_block;
    void **head_block_head_item;
} prh_atom_dynque_consumer;

typedef struct { // 生产者和消费者线程共享访问
    prh_atom_int queue_length;
} prh_atom_dynque_length;

typedef struct {
    prh_atom_dynque_consumer *c;
    prh_atom_dynque_length *l;
    prh_int origin_queue_length;
    prh_int queue_length;
    prh_atom_dynque_block *head_block;
    prh_atom_dynque_block *curr_block;
    void **curr_block_head_item;
} prh_atom_dynque_stamp;

typedef void (*prh_atom_dynque_free_block)(prh_atom_dynque_block *free_block);

void prh_atom_dynque_freed_blocks_init(prh_atom_dynque_freed_blocks *q);
void prh_atom_dynque_freed_blocks_free(prh_atom_dynque_freed_blocks *q);
void prh_atom_dynque_freed_blocks_push(prh_atom_dynque_freed_blocks *q, prh_atom_dynque_block *free_block);

prh_inline prh_int prh_atom_dynque_len(prh_atom_dynque_length *l) { return prh_atom_int_read(&l->queue_length); }
prh_inline bool prh_atom_dynque_empty(prh_atom_dynque_length *l) { return prh_atom_int_read(&l->queue_length) <= 0; }

void prh_atom_dynque_init(prh_atom_dynque_producer *p, prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_int queue_block_bytes);
void prh_atom_dynque_free(prh_atom_dynque_producer *p, prh_atom_dynque_consumer *c);
void prh_atom_dynque_push(prh_atom_dynque_producer *p, prh_atom_dynque_length *l, void *data, prh_atom_dynque_freed_blocks *freeq);
void *prh_atom_dynque_top(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l);
void *prh_atom_dynque_pop(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_atom_dynque_free_block deliver_free_block_to_producer);
bool prh_atom_dynque_pops(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, bool (*cb)(void *priv, void *data), void *priv, prh_atom_dynque_free_block deliver_free_block_to_producer);

void prh_atom_dynque_ext_push(prh_atom_dynque_producer *p, prh_atom_dynque_length *l, void *data, prh_ptr extra, prh_atom_dynque_freed_blocks *freeq);
void *prh_atom_dynque_ext_pop(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_ptr *extra, prh_atom_dynque_free_block deliver_free_block_to_producer);
bool prh_atom_dynque_ext_pops(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, bool (*cb)(void *priv, void *data, prh_ptr extra), void *priv, prh_atom_dynque_free_block deliver_free_block_to_producer);

void prh_atom_dynque_pop_stamp(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_atom_dynque_stamp *stamp);
bool prh_atom_dynque_check_next(prh_atom_dynque_stamp *stamp, prh_ptr *data_address);
bool prh_atom_dynque_ext_check_next(prh_atom_dynque_stamp *stamp, prh_ptr *data_address, prh_ptr *extra);
void prh_atom_dynque_pop_items(prh_atom_dynque_stamp *stamp, prh_atom_dynque_free_block deliver_free_block_to_producer);

#ifdef PRH_ATOMIC_IMPLEMENTATION
#define PRH_AHQF_BLOCK_SIZE PRH_CACHE_LINE_SIZE // block size shall be power of 2
#define PRH_AHQF_BLOCK_PTRS (PRH_AHQF_BLOCK_SIZE / sizeof(void *))
#define PRH_AHQF_BHEAD_PTRS (prh_int)(sizeof(prh_hive_quefix_block) / sizeof(void *))
prh_static_assert(PRH_AHQF_BLOCK_PTRS >= 2); // 如果不能分配2个或2个以上，间接块分配没有意义
prh_static_assert(PRH_AHQF_BLOCK_SIZE % PRH_CACHE_LINE_SIZE == 0); // 内存块必须是缓存行大小的倍数
prh_static_assert(PRH_AHQF_BLOCK_PTRS % PRH_AHQF_BHEAD_PTRS == 0); // 内存块可以保存的指针数量必须是 2 的倍数
prh_static_assert(PRH_AHQF_BHEAD_PTRS == 2);
prh_hive_quefix_block *prh_impl_ahqf_free_block_pop(prh_atom_hive_fbqfix *q);
prh_hive_quefix_block *prh_impl_atom_ext_hive_free_block_pop(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_length *l);

prh_inline void **prh_impl_ahqf_block_end(prh_hive_quefix_block *b) {
    return (void **)((prh_byte *)b + PRH_AHQF_BLOCK_SIZE);
}

prh_inline prh_hive_quefix_block *prh_impl_ahqf_init_block(prh_hive_quefix_block *b) {
    b->tail = (void **)(b + 1);
    b->next = prh_null;
    return b;
}

prh_hive_quefix_block *prh_impl_ahqf_alloc_block(prh_atom_hive_fbqfix *q) {
    prh_hive_quefix_block *free_block = prh_impl_ahqf_free_block_pop(q);
    if (free_block == prh_null) {
        free_block = prh_cache_line_aligned_malloc(PRH_AHQF_BLOCK_SIZE);
    }
    return prh_impl_ahqf_init_block(free_block);
}

prh_hive_quefix_block *prh_impl_atom_ext_hive_alloc_block(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_length *l) {
    prh_hive_quefix_block *free_block = prh_impl_atom_ext_hive_free_block_pop(p, l);
    if (free_block == prh_null) {
        free_block = prh_cache_line_aligned_malloc(PRH_AHQF_BLOCK_SIZE);
    }
    return prh_impl_ahqf_init_block(free_block);
}

void prh_atom_hive_fbqfix_init(prh_atom_hive_fbqfix *q) {
    q->fbqh = q->fbqt = prh_null;
    prh_atom_int_init(&q->fbn, 0);
}

void prh_atom_hive_quefix_init(prh_atom_hive_quefix *q, prh_atom_hive_fbqfix *freeq) {
    q->head = q->tail = prh_impl_ahqf_alloc_block(freeq);
    q->head_index = PRH_AHQF_BHEAD_PTRS;
    q->freeq = freeq;
    prh_atom_int_init(&q->len, 0);
}

void prh_atom_ext_hive_quefix_init(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l) {
    prh_hive_quefix_block *free_block_head = prh_cache_line_aligned_malloc(PRH_AHQF_BLOCK_SIZE);
    prh_impl_ahqf_init_block(free_block_head);
    p->free_block_ptr = free_block_head->tail;
    p->free_block_head = c->free_block_tail = free_block_head;
    prh_atom_int_init(&l->free_block_count, 0); // 必须先对 free blcok 进行初始化
    prh_hive_quefix_block *head_block = prh_impl_atom_ext_hive_alloc_block(p, l);
    c->queue_head_block = p->queue_tail_block = head_block;
    c->queue_head_block_elem_ptr = head_block->tail;
    prh_atom_int_init(&l->queue_length, 0);
}

void prh_impl_atom_hive_quefix_free_head_block(prh_hive_quefix_block *head_block) {
    prh_hive_quefix_block *next;
    while (head_block) {
        next = head_block->next;
        prh_aligned_free(head_block);
        head_block = next;
    }
}

void prh_atom_hive_quefix_free(prh_atom_hive_quefix *q) {
    prh_impl_atom_hive_quefix_free_head_block(q->head);
}

prh_hive_quefix_block *prh_impl_atom_hive_fbqfix_free_items_on_block(prh_hive_quefix_block *block, prh_hive_quefix_block **start) {
    prh_hive_quefix_block **item = start;
    for (; (void **)item < block->tail; item += 1) {
        prh_hive_quefix_block *free_block = *item; // 释放内存块内保存的空闲块
        assert(free_block != prh_null);
        prh_aligned_free(free_block);
    }
    prh_hive_quefix_block *next = block->next;
    prh_aligned_free(block);
    return next;
}

void prh_impl_atom_hive_fbqfix_free_head_block(prh_hive_quefix_block *head_block, prh_hive_quefix_block **start) {
    head_block = prh_impl_atom_hive_fbqfix_free_items_on_block(head_block, start);
    while (head_block) {
        head_block = prh_impl_atom_hive_fbqfix_free_items_on_block(head_block, (prh_hive_quefix_block **)(head_block + 1));
    }
}

void prh_atom_hive_fbqfix_free(prh_atom_hive_fbqfix *freeq) {
    prh_impl_atom_hive_fbqfix_free_head_block(freeq->fbqh, (void **)freeq->fbqh + freeq->fbqh_index);
}

void prh_atom_ext_hive_quefix_free(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_consumer *c) {
    prh_impl_atom_hive_quefix_free_head_block(c->queue_head_block);
    prh_impl_atom_hive_fbqfix_free_head_block(p->free_block_head, p->free_block_ptr);
}

void prh_atom_hive_quefix_push(prh_atom_hive_quefix *q, void *data) {
    prh_hive_quefix_block *b = q->tail;
    *b->tail++ = data; assert(data != prh_null);
    assert(*(b->tail - 1) == data); // 仅允许单生产者和单消费者
    if (b->tail >= prh_impl_ahqf_block_end(b)) {
        q->tail = b->next = prh_impl_ahqf_alloc_block(q->freeq);
    }
    prh_atom_int_inc(&q->len); // 此步骤执行完毕以上更新必须对所有cpu生效
}

void prh_atom_ext_hive_quefix_push(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_length *l, void *data, prh_ptr extra) {
    prh_hive_quefix_block *b = p->queue_tail_block;
    *b->tail++ = data; assert(data != prh_null);
    *b->tail++ = (void *)extra;
    assert(*(b->tail - 2) == data); // 仅允许单生产者和单消费者
    if (b->tail >= prh_impl_ahqf_block_end(b)) {
        p->queue_tail_block = b->next = prh_impl_atom_ext_hive_alloc_block(p, l);
    }
    prh_atom_int_inc(&l->queue_length); // 此步骤执行完毕以上更新必须对所有cpu生效
}

void prh_impl_ahqf_free_block_push(prh_atom_hive_fbqfix *q, prh_hive_quefix_block *free_block) {
    assert(free_block != prh_null);
    prh_int fbn = prh_atom_int_read(&q->fbn);
    if (fbn == 0) { // 释放的第一个空闲块，当作空闲队列的第一个内存块
        q->fbqh = q->fbqt = prh_impl_ahqf_init_block(free_block);
        q->fbqh_index = PRH_AHQF_BHEAD_PTRS;
    } else {
        prh_hive_quefix_block *b = q->fbqt;
        if (b->tail >= prh_impl_ahqf_block_end(b)) { // 如果当前内存块已满，将空闲块当作空闲队列的下一个内存块
            q->fbqt = b->next = prh_impl_ahqf_init_block(free_block);
        } else { // 否则当前内存块还有位置，将空闲块插入空闲队列
            *b->tail++ = free_block;
            assert(*(b->tail - 1) == free_block); // 仅允许单生产者和单消费者
        }
    }
    prh_atom_int_inc(&q->fbn); // 可用空闲块加一
}

void prh_impl_atom_ext_hive_free_block_push(prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l, prh_hive_quefix_block *free_block) {
    assert(free_block != prh_null);
    prh_hive_quefix_block *b = c->free_block_tail;
    if (b->tail >= prh_impl_ahqf_block_end(b)) { // 如果当前内存块已满，将空闲块当作空闲队列的下一个内存块
        c->free_block_tail = b->next = prh_impl_ahqf_init_block(free_block);
    } else { // 否则当前内存块还有位置，将空闲块插入空闲队列
        *b->tail++ = free_block;
        assert(*(b->tail - 1) == free_block); // 仅允许单生产者和单消费者
    }
    prh_atom_int_inc(&l->free_block_count); // 可用空闲块加一
}

void *prh_atom_hive_quefix_top(prh_atom_hive_quefix *q) {
    if (!prh_atom_int_read(&q->len)) return prh_null;
    return *((void **)q->head + q->head_index);
}

void *prh_atom_hive_quefix_pop(prh_atom_hive_quefix *q) {
    if (!prh_atom_int_read(&q->len)) return prh_null;
    prh_hive_quefix_block *head = q->head;
    void *data = *((void **)head + q->head_index++);
    assert(*((void **)head + q->head_index - 1) == data); // 仅允许单生产者和单消费者
    if (q->head_index >= PRH_AHQF_BLOCK_PTRS) {
        q->head = head->next;
        q->head_index = PRH_AHQF_BHEAD_PTRS;
        prh_impl_ahqf_free_block_push(q->freeq, head); // 将释放的空闲块，放入空闲队列
    }
    prh_atom_int_dec(&q->len); // 此步骤执行完毕以上更新必须对所有cpu生效
    return data;
}

void *prh_atom_ext_hive_quefix_top(prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l) {
    if (!prh_atom_int_read(&l->queue_length)) return prh_null;
    return *c->queue_head_block_elem_ptr;
}

bool prh_atom_ext_hive_quefix_pop(prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l, void **data, prh_ptr *extra) {
    if (!prh_atom_int_read(&l->queue_length)) return false;
    prh_hive_quefix_block *head = c->queue_head_block;
    *data = *c->queue_head_block_elem_ptr++;
    *extra = (prh_ptr)*c->queue_head_block_elem_ptr++;
    assert(*(c->queue_head_block_elem_ptr - 2) == *data); // 仅允许单生产者和单消费者
    if (c->queue_head_block_elem_ptr >= prh_impl_ahqf_block_end(head)) {
        prh_hive_quefix_block *next = head->next;
        c->queue_head_block = next;
        c->queue_head_block_elem_ptr = (void **)(next + 1);
        prh_impl_atom_ext_hive_free_block_push(c, l, head); // 将释放的空闲块，放入空闲队列
    }
    prh_atom_int_dec(&l->queue_length); // 此步骤执行完毕以上更新必须对所有cpu生效
    return true;
}

prh_hive_quefix_block *prh_impl_ahqf_free_block_pop(prh_atom_hive_fbqfix *q) {
    if (prh_atom_int_read(&q->fbn) <= 1) return prh_null; // 必须维持有一个空闲块作为头节点
    prh_hive_quefix_block *head = q->fbqh;
    prh_hive_quefix_block *free_block;
    if (q->fbqh_index >= PRH_AHQF_BLOCK_PTRS) {
        q->fbqh = head->next; // 如果已到达当前内存块末尾，移动到下一个内存块
        q->fbqh_index = PRH_AHQF_BHEAD_PTRS;
        free_block = head; // 需要释放的当前内存块，就是一个可用的空闲块
    } else {
        free_block = *((void **)head + q->fbqh_index++);
        assert(free_block != prh_null);
        assert(*((void **)head + q->fbqh_index - 1) == free_block); // 仅允许单生产者和单消费者
    }
    prh_atom_int_dec(&q->fbn); // 可用空闲块减一
    return free_block;
}

prh_hive_quefix_block *prh_impl_atom_ext_hive_free_block_pop(prh_atom_ext_hive_quefix_producer *p, prh_atom_ext_hive_quefix_length *l) {
    if (!prh_atom_int_read(&l->free_block_count)) return prh_null;
    prh_hive_quefix_block *head = p->free_block_head;
    prh_hive_quefix_block *free_block, *next_block;
    if (p->free_block_ptr >= prh_impl_ahqf_block_end(head)) {
        p->free_block_head = next_block = head->next; // 如果已到达当前内存块末尾，移动到下一个内存块
        p->free_block_ptr = (void **)(next_block + 1);
        free_block = head; // 需要释放的当前内存块，就是一个可用的空闲块
    } else {
        free_block = *p->free_block_ptr++;
        assert(free_block != prh_null);
        assert(*(p->free_block_ptr - 1) == free_block); // 仅允许单生产者和单消费者
    }
    prh_atom_int_dec(&l->free_block_count); // 可用空闲块减一
    return free_block;
}

bool prh_atom_hive_quefix_pops(prh_atom_hive_quefix *q, bool (*cb)(void *priv, void *data), void *priv) {
    prh_int len = prh_atom_int_read(&q->len), i;
    if (len == 0) return false;
    prh_hive_quefix_block *head = q->head;
    prh_int head_index = q->head_index;
    for (i = 0; i < len; i += 1) {
        if (!cb(priv, *((void **)head + head_index))) {
            break; // 返回 true 表示移除该项，返回 false 表示不移除
        }
        head_index += 1;
        if (head_index >= PRH_AHQF_BLOCK_PTRS) {
            prh_hive_quefix_block *next = head->next;
            head_index = PRH_AHQF_BHEAD_PTRS;
            prh_impl_ahqf_free_block_push(q->freeq, head); // 将释放的空闲块，放入空闲队列
            head = next;
        }
    }
    q->head = head;
    q->head_index = head_index;
    prh_atom_int_sub(&q->len, i);
    assert(q->head == head && q->head_index == head_index); // 仅允许单生产者和单消费者
    return true;
}

bool prh_atom_ext_hive_quefix_pops(prh_atom_ext_hive_quefix_consumer *c, prh_atom_ext_hive_quefix_length *l, bool (*cb)(void *priv, void *data, prh_ptr extra), void *priv) {
    prh_int len = prh_atom_int_read(&l->queue_length), i;
    if (len == 0) return false;
    prh_hive_quefix_block *head = c->queue_head_block;
    void **head_elem_ptr = c->queue_head_block_elem_ptr;
    for (i = 0; i < len; i += 1) {
        if (!cb(priv, *head_elem_ptr, (prh_ptr)*(head_elem_ptr + 1))) {
            break; // 返回 true 表示移除该项，返回 false 表示不移除
        }
        head_elem_ptr += 2;
        if (head_elem_ptr >= prh_impl_ahqf_block_end(head)) {
            prh_hive_quefix_block *next = head->next;
            head_elem_ptr = (void **)(next + 1);
            prh_impl_atom_ext_hive_free_block_push(c, l, head); // 将释放的空闲块，放入空闲队列
            head = next;
        }
    }
    c->queue_head_block = head;
    c->queue_head_block_elem_ptr = head_elem_ptr;
    prh_atom_int_sub(&l->queue_length, i); // 只要减 i 的原因是 ext hive quefix 是插入两个指针计数一次
    assert(c->queue_head_block == head && c->queue_head_block_elem_ptr == head_elem_ptr); // 仅允许单生产者和单消费者
    return true;
}

void prh_atom_dynque_freed_blocks_init(prh_atom_dynque_freed_blocks *q, prh_int block_end_offset) {
    memset(q, 0, sizeof(prh_atom_dynque_freed_blocks));
    q->block_end_offset = block_end_offset;
}

prh_inline prh_atom_dynque_block_end *prh_impl_atom_dynque_block_end(prh_atom_dynque_block *block, prh_int block_end_offset) {
    return (prh_atom_dynque_block_end *)((prh_byte *)block + block_end_offset);
}

prh_atom_dynque_block *prh_impl_atom_dynque_free_items_on_block(prh_atom_dynque_freed_blocks *q, prh_atom_dynque_block *block, prh_atom_dynque_block **start) {
    prh_atom_dynque_block_end *block_end = prh_impl_atom_dynque_block_end(block, q->block_end_offset);
    q->free_block_count -= 1; // 减去 block 本身的计数
    while (q->free_block_count && start < (void **)block_end) {
        prh_atom_dynque_block *free_block = *start++;
        assert(free_block != prh_null);
        assert(free_block != PRH_ATOM_DYNQUE_BLOCK_END);
        prh_aligned_free(free_block); // 释放内存块内保存的空闲块
        q->free_block_count -= 1;
    }
    prh_atom_dynque_block *next = block_end->next;
    prh_aligned_free(block);
    return next;
}

void prh_atom_dynque_freed_blocks_free(prh_atom_dynque_freed_blocks *q) {
    if (q->free_block_count == 0) return;
    prh_atom_dynque_block *block = q->head_block;
    block = prh_impl_atom_dynque_free_items_on_block(q, block, q->head_block_head_item);
    while (block) {
        block = prh_impl_atom_dynque_free_items_on_block(q, block, (void **)block);
    }
    q->free_block_count = 0;
}

void prh_atom_dynque_freed_blocks_push(prh_atom_dynque_freed_blocks *q, prh_atom_dynque_block *free_block) {
    assert(free_block != prh_null);
    if (q->free_block_count == 0) {
        q->head_block_head_item = (void **)q->head_block = free_block;
label_assign_tail_block:
        q->tail_block_tail_item = (void **)q->tail_block = free_block;
        prh_impl_atom_dynque_block_end(free_block, q->block_end_offset)->next = prh_null;
    } else {
        prh_atom_dynque_block_end *block_end = prh_impl_atom_dynque_block_end(q->tail_block, q->block_end_offset);
        if (q->tail_block_tail_item >= block_end) { // 如果当前内存块已满，将空闲块当作空闲队列的下一个内存块
            block_end->next = free_block;
            goto label_assign_tail_block;
        } else { // 否则当前内存块还有位置，将空闲块插入空闲队列
            *q->tail_block_tail_item++ = free_block;
        }
    }
    q->free_block_count += 1; // 可用空闲块加一
}

prh_atom_dynque_block *prh_impl_atom_dynque_freed_blocks_pop(prh_atom_dynque_freed_blocks *q) {
    prh_atom_dynque_block *head_block = q->head_block;
    prh_int free_block_count = q->free_block_count;
    prh_int block_end_offset = q->block_end_offset;
    if (free_block_count == 0) return prh_null;
    if (free_block_count == 1) { // 如果只有一个空闲块，空闲块 next 指针一定是空指针
        prh_atom_dynque_freed_blocks_init(q, block_end_offset);
    } else {
        prh_atom_dynque_block_end *head_block_end = prh_impl_atom_dynque_block_end(head_block, block_end_offset);
        if (q->head_block_head_item >= head_block_end) {
            q->head_block_head_item = (void **)q->head_block = head_block_end->next; // 如果已到达当前内存块末尾，移动到下一个内存块
            head_block_end->next = prh_null;
        } else {
            head_block = *q->head_block_head_item++;
            assert(head_block != prh_null);
            prh_impl_atom_dynque_block_end(head_block, block_end_offset)->next = prh_null;
        }
        q->free_block_count -= 1; // 可用空闲块减一
    }
    return head_block;
}

prh_atom_dynque_block *prh_impl_atom_dynque_aligned_alloc(prh_int block_end_offset, prh_atom_dynque_block *free_block) {
    if (free_block == prh_null) {
        prh_int queue_block_bytes = block_end_offset + 2 * sizeof(void *);
        assert(block_end_offset > 0 && (queue_block_bytes % PRH_CACHE_LINE_SIZE) == 0);
        free_block = prh_cache_line_aligned_malloc(queue_block_bytes);
        memset(free_block, 0, queue_block_bytes);
        prh_impl_atom_dynque_block_end(free_block, block_end_offset)->block_end_data = PRH_ATOM_DYNQUE_BLOCK_END;
    }
    return free_block;
}

prh_atom_dynque_block *prh_impl_atom_dynque_alloc_block(prh_int block_end_offset, prh_atom_dynque_freed_blocks *freeq) {
    prh_atom_dynque_block *free_block = prh_impl_atom_dynque_freed_blocks_pop(freeq);
    return prh_impl_atom_dynque_aligned_alloc(block_end_offset, free_block);
}

void prh_atom_dynque_init(prh_atom_dynque_producer *p, prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_int queue_block_bytes) {
    assert(queue_block_bytes > 0);
    prh_int block_end_offset = prh_round_cache_line_size(queue_block_bytes) - 2 * sizeof(void *);
    prh_atom_dynque_block *block = prh_impl_atom_dynque_aligned_alloc(block_end_offset, prh_null);
    c->head_block_head_item = (void **)c->head_block = block;
    p->tail_block_tail_item = (void **)p->tail_block = block;
    p->block_end_offset = block_end_offset;
    prh_atom_int_init(&l->queue_length, 0);
}

void prh_atom_dynque_free(prh_atom_dynque_producer *p, prh_atom_dynque_consumer *c) {
    prh_atom_dynque_block *head_block = c->head_block;
    prh_atom_dynque_block *next;
    while (head_block) {
        next = prh_impl_atom_dynque_block_end(head_block, p->block_end_offset)->next;
        prh_aligned_free(head_block);
        head_block = next;
    }
}

void prh_atom_dynque_push(prh_atom_dynque_producer *p, prh_atom_dynque_length *l, void *data, prh_atom_dynque_freed_blocks *freeq) {
    assert(data != prh_null && data != PRH_ATOM_DYNQUE_BLOCK_END);
    *p->tail_block_tail_item++ = data;
    assert(*(p->tail_block_tail_item - 1) == data); // 仅允许单生产者和单消费者
    if (*p->tail_block_tail_item == PRH_ATOM_DYNQUE_BLOCK_END) {
        prh_atom_dynque_block *next = prh_impl_atom_dynque_alloc_block(p->block_end_offset, freeq);
        prh_impl_atom_dynque_block_end(p->tail_block, p->block_end_offset)->next = next;
        p->tail_block_tail_item = (void **)p->tail_block = next;
    }
    prh_atom_int_inc(&l->queue_length); // 此步骤执行完毕以上更新必须对所有cpu生效
}

void prh_atom_dynque_ext_push(prh_atom_dynque_producer *p, prh_atom_dynque_length *l, void *data, prh_ptr extra, prh_atom_dynque_freed_blocks *freeq) {
    assert(data != prh_null && data != PRH_ATOM_DYNQUE_BLOCK_END);
    *p->tail_block_tail_item++ = data;
    *p->tail_block_tail_item++ = (void *)extra; // 内存块大小是 PRH_CACHE_LINE_SIZE 的倍数，保证可以插入双数个元素
    assert(*(p->tail_block_tail_item - 2) == data); // 仅允许单生产者和单消费者
    if (*p->tail_block_tail_item == PRH_ATOM_DYNQUE_BLOCK_END) {
        prh_atom_dynque_block *next = prh_impl_atom_dynque_alloc_block(p->block_end_offset, freeq);
        prh_impl_atom_dynque_block_end(p->tail_block, p->block_end_offset)->next = next;
        p->tail_block_tail_item = (void **)p->tail_block = next;
    }
    prh_atom_int_add(&l->queue_length, 2); // 此步骤执行完毕以上更新必须对所有cpu生效
}

void *prh_atom_dynque_top(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l) {
    if (prh_atom_int_read(&l->queue_length) <= 0) return prh_null;
    return *c->head_block_head_item;
}

void *prh_atom_dynque_pop(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_atom_dynque_free_block deliver_free_block_to_producer) {
    if (prh_atom_int_read(&l->queue_length) <= 0) return prh_null;
    void **head_item = c->head_block_head_item++;
    void *data = head_item[0]; assert(data != prh_null);
    assert(*(c->head_block_head_item - 1) == data); // 仅允许单生产者和单消费者
    if (data == PRH_ATOM_DYNQUE_BLOCK_END) {
        prh_atom_dynque_block *head = c->head_block;
        c->head_block_head_item = (void **)c->head_block = head_item[1];
        deliver_free_block_to_producer(head); // 需要将释放的空闲块还给生产者线程
    }
    prh_atom_int_dec(&l->queue_length); // 此步骤执行完毕以上更新必须对所有cpu生效
    return data;
}

void *prh_atom_dynque_ext_pop(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_ptr *extra, prh_atom_dynque_free_block deliver_free_block_to_producer) {
    if (prh_atom_int_read(&l->queue_length) <= 0) return prh_null;
    void *data = *c->head_block_head_item++; assert(data != prh_null);
    void *next = *c->head_block_head_item++; *extra = (prh_ptr)next;
    assert(*(c->head_block_head_item - 2) == data); // 仅允许单生产者和单消费者
    if (data == PRH_ATOM_DYNQUE_BLOCK_END) {
        prh_atom_dynque_block *head = c->head_block;
        c->head_block_head_item = (void **)c->head_block = next;
        deliver_free_block_to_producer(head); // 需要将释放的空闲块还给生产者线程
    }
    prh_atom_int_sub(&l->queue_length, 2); // 此步骤执行完毕以上更新必须对所有cpu生效
    return data;
}

void prh_atom_dynque_pop_stamp(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, prh_atom_dynque_stamp *stamp) {
    stamp->c = c; stamp->l = l;
    stamp->origin_queue_length = stamp->queue_length = prh_atom_int_read(&l->queue_length);
    stamp->head_block = stamp->curr_block = c->head_block;
    stamp->curr_block_head_item = c->head_block_head_item;
}

bool prh_atom_dynque_check_next(prh_atom_dynque_stamp *stamp, prh_ptr *data_address) {
    if (stamp->queue_length <= 0) return false;
    prh_atom_dynque_block *b = stamp->curr_block;
    *data_address = (prh_ptr)stamp->curr_block_head_item++;
    if (*stamp->curr_block_head_item == PRH_ATOM_DYNQUE_BLOCK_END) {
        prh_atom_dynque_block *next = *(stamp->curr_block_head_item + 1);
        stamp->curr_block_head_item = (void **)stamp->curr_block = next;
    }
    stamp->queue_length -= 1;
    return true;
}

bool prh_atom_dynque_ext_check_next(prh_atom_dynque_stamp *stamp, prh_ptr *data_address, prh_ptr *extra) {
    if (stamp->queue_length <= 0) return false;
    prh_atom_dynque_block *b = stamp->curr_block;
    *data_address = (prh_ptr)stamp->curr_block_head_item++;
    *extra = (prh_ptr)*stamp->curr_block_head_item++;
    if (*stamp->curr_block_head_item == PRH_ATOM_DYNQUE_BLOCK_END) {
        prh_atom_dynque_block *next = *(stamp->curr_block_head_item + 1);
        stamp->curr_block_head_item = (void **)stamp->curr_block = next;
    }
    stamp->queue_length -= 2;
    return true;
}

void prh_atom_dynque_pop_items(prh_atom_dynque_stamp *stamp, prh_atom_dynque_free_block deliver_free_block_to_producer) {
    prh_int items = stamp->origin_queue_length - stamp->queue_length;
    if (items == 0) return;
    prh_atom_dynque_block *begin = stamp->head_block;
    prh_atom_dynque_block *curr = stamp->curr_block;
    while (begin != curr) {
        deliver_free_block_to_ producer(begin); // 需要将释放的空闲块还给生产者线程
    }
    prh_atom_dynque_consumer *c = stamp->c;
    prh_atom_dynque_length *l = stamp->l;
    c->head_block = curr;
    c->head_block_head_item = stamp->curr_block_head_item;
    prh_atom_int_sub(&l->queue_length, items); // 此步骤执行完毕以上更新必须对所有cpu生效
}

bool prh_atom_dynque_pops(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, bool (*cb)(void *priv, void *data), void *priv, prh_atom_dynque_free_block deliver_free_block_to_producer) {
    prh_int len = prh_atom_int_read(&l->queue_length), i;
    if (len <= 0) return false;
    prh_atom_dynque_block *head = c->head_block;
    void **head_item = c->head_block_head_item;
    for (i = 0; i < len; i += 1) {
        if (!cb(priv, *head_item)) {
            break; // 返回 true 表示移除该项，返回 false 表示不移除
        }
        head_item += 1;
        if (*head_item == PRH_ATOM_DYNQUE_BLOCK_END) {
            prh_atom_dynque_block *next = *(head_item + 1);
            deliver_free_block_to_producer(head); // 需要将释放的空闲块还给生产者线程
            head_item = (void **)head = next;
        }
    }
    c->head_block = head;
    c->head_block_head_item = head_item;
    prh_atom_int_sub(&l->queue_length, i);
    assert(c->head_block == head && c->head_block_head_item == head_item); // 仅允许单生产者和单消费者
    return true;
}

bool prh_atom_dynque_ext_pops(prh_atom_dynque_consumer *c, prh_atom_dynque_length *l, bool (*cb)(void *priv, void *data, prh_ptr extra), void *priv, prh_atom_dynque_free_block deliver_free_block_to_producer) {
    prh_int len = prh_atom_int_read(&l->queue_length), i;
    if (len <= 0) return false;
    prh_atom_dynque_block *head = c->head_block;
    void **head_item = c->head_block_head_item;
    for (i = 0; i < len; i += 2) {
        if (!cb(priv, *head_item, (prh_ptr)*(head_item + 1))) {
            break; // 返回 true 表示移除该项，返回 false 表示不移除
        }
        head_item += 2;
        if (*head_item == PRH_ATOM_DYNQUE_BLOCK_END) {
            prh_atom_dynque_block *next = *(head_item + 1);
            deliver_free_block_to_producer(head); // 需要将释放的空闲块还给生产者线程
            head_item = (void **)head = next;
        }
    }
    c->head_block = head;
    c->head_block_head_item = head_item;
    prh_atom_int_sub(&l->queue_length, i);
    assert(c->head_block == head && c->head_block_head_item == head_item); // 仅允许单生产者和单消费者
    return true;
}
#endif // PRH_ATOMIC_IMPLEMENTATION

// 单生产者单消费者固定大小的数组队列，数组长度必须是2的幂
typedef struct prh_atom_i32_arrque prh_atom_i32_arrque;
typedef struct prh_atom_u32_arrque prh_atom_u32_arrque;
typedef struct prh_atom_int_arrque prh_atom_int_arrque;
typedef struct prh_atom_unt_arrque prh_atom_unt_arrque;
typedef struct prh_atom_ptr_arrque prh_atom_ptr_arrque;

// fixed size array atomic queue for only 1 producer and 1 consumer, the size must be power of 2
void *prh_impl_atom_arrque_alloc(prh_int size, prh_int alloc);
void prh_impl_atom_arrque_free(void *q);
prh_int prh_impl_atom_arrque_len(void *q);
bool prh_impl_atom_arrque_push_u32(void *q, prh_u32 a);
bool prh_impl_atom_arrque_push_unt(void *q, prh_unt a);
bool prh_impl_atom_arrque_pop_all_begin(void *arrque, void *out);
void prh_impl_atom_arrque_pop_all_end(void *arrque, void *data);
prh_u32 prh_impl_atom_arrque_top_u32(void *q);
prh_unt prh_impl_atom_arrque_top_unt(void *q);
prh_u32 prh_impl_atom_arrque_pop_u32(void *q);
prh_unt prh_impl_atom_arrque_pop_unt(void *q);

prh_inline prh_atom_i32_arrque *prh_atom_i32_arrque_init(prh_int size) { return prh_impl_atom_arrque_alloc(size, sizeof(prh_i32) * size); }
prh_inline prh_atom_u32_arrque *prh_atom_u32_arrque_init(prh_int size) { return prh_impl_atom_arrque_alloc(size, sizeof(prh_u32) * size); }
prh_inline prh_atom_int_arrque *prh_atom_int_arrque_init(prh_int size) { return prh_impl_atom_arrque_alloc(size, sizeof(prh_int) * size); }
prh_inline prh_atom_unt_arrque *prh_atom_unt_arrque_init(prh_int size) { return prh_impl_atom_arrque_alloc(size, sizeof(prh_unt) * size); }
prh_inline prh_atom_ptr_arrque *prh_atom_ptr_arrque_init(prh_int size) { return prh_impl_atom_arrque_alloc(size, sizeof(void *) * size); }

prh_inline void prh_atom_i32_arrque_free(prh_atom_i32_arrque *q) { prh_impl_atom_arrque_free(q); }
prh_inline void prh_atom_u32_arrque_free(prh_atom_u32_arrque *q) { prh_impl_atom_arrque_free(q); }
prh_inline void prh_atom_int_arrque_free(prh_atom_int_arrque *q) { prh_impl_atom_arrque_free(q); }
prh_inline void prh_atom_unt_arrque_free(prh_atom_unt_arrque *q) { prh_impl_atom_arrque_free(q); }
prh_inline void prh_atom_ptr_arrque_free(prh_atom_ptr_arrque *q) { prh_impl_atom_arrque_free(q); }

prh_inline bool prh_atom_i32_arrque_empty(prh_atom_i32_arrque *q) { return prh_impl_atom_arrque_len(q) == 0; }
prh_inline bool prh_atom_u32_arrque_empty(prh_atom_u32_arrque *q) { return prh_impl_atom_arrque_len(q) == 0; }
prh_inline bool prh_atom_int_arrque_empty(prh_atom_int_arrque *q) { return prh_impl_atom_arrque_len(q) == 0; }
prh_inline bool prh_atom_unt_arrque_empty(prh_atom_unt_arrque *q) { return prh_impl_atom_arrque_len(q) == 0; }
prh_inline bool prh_atom_ptr_arrque_empty(prh_atom_ptr_arrque *q) { return prh_impl_atom_arrque_len(q) == 0; }

prh_inline prh_int prh_atom_i32_arrque_len(prh_atom_i32_arrque *q) { return prh_impl_atom_arrque_len(q); }
prh_inline prh_int prh_atom_u32_arrque_len(prh_atom_u32_arrque *q) { return prh_impl_atom_arrque_len(q); }
prh_inline prh_int prh_atom_int_arrque_len(prh_atom_int_arrque *q) { return prh_impl_atom_arrque_len(q); }
prh_inline prh_int prh_atom_unt_arrque_len(prh_atom_unt_arrque *q) { return prh_impl_atom_arrque_len(q); }
prh_inline prh_int prh_atom_ptr_arrque_len(prh_atom_ptr_arrque *q) { return prh_impl_atom_arrque_len(q); }

prh_inline bool prh_atom_i32_arrque_push(prh_atom_i32_arrque *q, prh_i32 a) { return prh_impl_atom_arrque_push_u32(q, a); }
prh_inline bool prh_atom_u32_arrque_push(prh_atom_u32_arrque *q, prh_u32 a) { return prh_impl_atom_arrque_push_u32(q, a); }
prh_inline bool prh_atom_int_arrque_push(prh_atom_int_arrque *q, prh_int a) { return prh_impl_atom_arrque_push_unt(q, a); }
prh_inline bool prh_atom_unt_arrque_push(prh_atom_unt_arrque *q, prh_unt a) { return prh_impl_atom_arrque_push_unt(q, a); }
prh_inline bool prh_atom_ptr_arrque_push(prh_atom_ptr_arrque *q, void *a) { return prh_impl_atom_arrque_push_unt(q, (prh_unt)a); }

prh_inline prh_i32 prh_atom_i32_arrque_top(prh_atom_i32_arrque *q) { return (prh_i32)prh_impl_atom_arrque_top_u32(q); }
prh_inline prh_u32 prh_atom_u32_arrque_top(prh_atom_u32_arrque *q) { return (prh_u32)prh_impl_atom_arrque_top_u32(q); }
prh_inline prh_int prh_atom_int_arrque_top(prh_atom_int_arrque *q) { return (prh_int)prh_impl_atom_arrque_top_unt(q); }
prh_inline prh_unt prh_atom_unt_arrque_top(prh_atom_unt_arrque *q) { return (prh_unt)prh_impl_atom_arrque_top_unt(q); }
prh_inline void *prh_atom_ptr_arrque_top(prh_atom_ptr_arrque *q) { return (void *)prh_impl_atom_arrque_top_unt(q); }

prh_inline prh_i32 prh_atom_i32_arrque_pop(prh_atom_i32_arrque *q) { return (prh_i32)prh_impl_atom_arrque_pop_u32(q); }
prh_inline prh_u32 prh_atom_u32_arrque_pop(prh_atom_u32_arrque *q) { return (prh_u32)prh_impl_atom_arrque_pop_u32(q); }
prh_inline prh_int prh_atom_int_arrque_pop(prh_atom_int_arrque *q) { return (prh_int)prh_impl_atom_arrque_pop_unt(q); }
prh_inline prh_unt prh_atom_unt_arrque_pop(prh_atom_unt_arrque *q) { return (prh_unt)prh_impl_atom_arrque_pop_unt(q); }
prh_inline void *prh_atom_ptr_arrque_pop(prh_atom_ptr_arrque *q) { return (void *)prh_impl_atom_arrque_pop_unt(q); }

typedef struct { prh_i32 *elem; prh_int head; prh_int len; prh_int size_minus_one; } prh_atom_i32_arrque_data;
typedef struct { prh_u32 *elem; prh_int head; prh_int len; prh_int size_minus_one; } prh_atom_u32_arrque_data;
typedef struct { prh_int *elem; prh_int head; prh_int len; prh_int size_minus_one; } prh_atom_int_arrque_data;
typedef struct { prh_unt *elem; prh_int head; prh_int len; prh_int size_minus_one; } prh_atom_unt_arrque_data;
typedef struct { void **elem; prh_int head; prh_int len; prh_int size_minus_one; } prh_atom_ptr_arrque_data;

prh_inline bool prh_atom_i32_arrque_pop_all_begin(prh_atom_i32_arrque *q, prh_atom_i32_arrque_data *data) { return prh_impl_atom_arrque_pop_all_begin(q, data); }
prh_inline bool prh_atom_u32_arrque_pop_all_begin(prh_atom_u32_arrque *q, prh_atom_u32_arrque_data *data) { return prh_impl_atom_arrque_pop_all_begin(q, data); }
prh_inline bool prh_atom_int_arrque_pop_all_begin(prh_atom_int_arrque *q, prh_atom_int_arrque_data *data) { return prh_impl_atom_arrque_pop_all_begin(q, data); }
prh_inline bool prh_atom_unt_arrque_pop_all_begin(prh_atom_unt_arrque *q, prh_atom_unt_arrque_data *data) { return prh_impl_atom_arrque_pop_all_begin(q, data); }
prh_inline bool prh_atom_ptr_arrque_pop_all_begin(prh_atom_ptr_arrque *q, prh_atom_ptr_arrque_data *data) { return prh_impl_atom_arrque_pop_all_begin(q, data); }

prh_inline prh_i32 prh_atom_i32_arrque_get_data(prh_atom_i32_arrque_data *p, prh_int index) { return p->elem[((p->head + index) & p->size_minus_one)]; }
prh_inline prh_u32 prh_atom_u32_arrque_get_data(prh_atom_u32_arrque_data *p, prh_int index) { return p->elem[((p->head + index) & p->size_minus_one)]; }
prh_inline prh_int prh_atom_int_arrque_get_data(prh_atom_int_arrque_data *p, prh_int index) { return p->elem[((p->head + index) & p->size_minus_one)]; }
prh_inline prh_unt prh_atom_unt_arrque_get_data(prh_atom_unt_arrque_data *p, prh_int index) { return p->elem[((p->head + index) & p->size_minus_one)]; }
prh_inline void *prh_atom_ptr_arrque_get_data(prh_atom_ptr_arrque_data *p, prh_int index) { return p->elem[((p->head + index) & p->size_minus_one)]; }

prh_inline void prh_atom_i32_arrque_pop_all_end(prh_atom_i32_arrque *q, prh_atom_i32_arrque_data *data) { prh_impl_atom_arrque_pop_all_end(q, data); }
prh_inline void prh_atom_u32_arrque_pop_all_end(prh_atom_u32_arrque *q, prh_atom_u32_arrque_data *data) { prh_impl_atom_arrque_pop_all_end(q, data); }
prh_inline void prh_atom_int_arrque_pop_all_end(prh_atom_int_arrque *q, prh_atom_int_arrque_data *data) { prh_impl_atom_arrque_pop_all_end(q, data); }
prh_inline void prh_atom_unt_arrque_pop_all_end(prh_atom_unt_arrque *q, prh_atom_unt_arrque_data *data) { prh_impl_atom_arrque_pop_all_end(q, data); }
prh_inline void prh_atom_ptr_arrque_pop_all_end(prh_atom_ptr_arrque *q, prh_atom_ptr_arrque_data *data) { prh_impl_atom_arrque_pop_all_end(q, data); }

// 单生产者多消费者固定大小的数组队列，数组长度必须是2的幂
typedef struct prh_atom_i32_mult_rd_arrque prh_atom_i32_mult_rd_arrque;
typedef struct prh_atom_u32_mult_rd_arrque prh_atom_u32_mult_rd_arrque;
typedef struct prh_atom_int_mult_rd_arrque prh_atom_int_mult_rd_arrque;
typedef struct prh_atom_unt_mult_rd_arrque prh_atom_unt_mult_rd_arrque;
typedef struct prh_atom_ptr_mult_rd_arrque prh_atom_ptr_mult_rd_arrque;
typedef struct prh_atom_ext_mult_rd_arrque prh_atom_ext_mult_rd_arrque;

// fixed size array atomic queue for only 1 producer and n consumer, the size must be power of 2
prh_int prh_atom_mult_rd_arrque_alloc_size(prh_int size, prh_int elem_bytes);
void prh_impl_atom_mult_rd_arrque_init(void *arrque, prh_int size);
bool prh_impl_atom_mult_rd_arrque_push_u32(void *arrque, prh_u32 a);
bool prh_impl_atom_mult_rd_arrque_push_unt(void *arrque, prh_unt a);
bool prh_impl_atom_mult_rd_arrque_push_ext(void *arrque, prh_ptr a, prh_ptr b);
prh_u32 prh_impl_atom_mult_rd_arrque_pop_u32(void *arrque);
prh_unt prh_impl_atom_mult_rd_arrque_pop_unt(void *arrque);
bool prh_impl_atom_mult_rd_arrque_pop_ext(void *arrque, void **out);
prh_u32 prh_impl_atom_mult_rd_arrque_weak_pop_u32(void *arrque, bool *race_condition);
prh_unt prh_impl_atom_mult_rd_arrque_weak_pop_unt(void *arrque, bool *race_condition);

prh_inline void prh_atom_i32_mult_rd_arrque_init(prh_atom_i32_mult_rd_arrque *q, prh_int size) { return prh_impl_atom_mult_rd_arrque_init(q, size); }
prh_inline void prh_atom_u32_mult_rd_arrque_init(prh_atom_u32_mult_rd_arrque *q, prh_int size) { return prh_impl_atom_mult_rd_arrque_init(q, size); }
prh_inline void prh_atom_int_mult_rd_arrque_init(prh_atom_int_mult_rd_arrque *q, prh_int size) { return prh_impl_atom_mult_rd_arrque_init(q, size); }
prh_inline void prh_atom_unt_mult_rd_arrque_init(prh_atom_unt_mult_rd_arrque *q, prh_int size) { return prh_impl_atom_mult_rd_arrque_init(q, size); }
prh_inline void prh_atom_ptr_mult_rd_arrque_init(prh_atom_ptr_mult_rd_arrque *q, prh_int size) { return prh_impl_atom_mult_rd_arrque_init(q, size); }
prh_inline void prh_atom_ext_mult_rd_arrque_init(prh_atom_ext_mult_rd_arrque *q, prh_int size) { return prh_impl_atom_mult_rd_arrque_init(q, size); }

prh_inline prh_int prh_atom_i32_mult_rd_arrque_len(prh_atom_i32_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_len(q); }
prh_inline prh_int prh_atom_u32_mult_rd_arrque_len(prh_atom_u32_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_len(q); }
prh_inline prh_int prh_atom_int_mult_rd_arrque_len(prh_atom_int_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_len(q); }
prh_inline prh_int prh_atom_unt_mult_rd_arrque_len(prh_atom_unt_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_len(q); }
prh_inline prh_int prh_atom_ptr_mult_rd_arrque_len(prh_atom_ptr_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_len(q); }
prh_inline prh_int prh_atom_ext_mult_rd_arrque_len(prh_atom_ext_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_len(q); }

prh_inline prh_int prh_atom_i32_mult_rd_arrque_empty_items(prh_atom_i32_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_empty_items(q); }
prh_inline prh_int prh_atom_u32_mult_rd_arrque_empty_items(prh_atom_u32_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_empty_items(q); }
prh_inline prh_int prh_atom_int_mult_rd_arrque_empty_items(prh_atom_int_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_empty_items(q); }
prh_inline prh_int prh_atom_unt_mult_rd_arrque_empty_items(prh_atom_unt_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_empty_items(q); }
prh_inline prh_int prh_atom_ptr_mult_rd_arrque_empty_items(prh_atom_ptr_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_empty_items(q); }
prh_inline prh_int prh_atom_ext_mult_rd_arrque_empty_items(prh_atom_ext_mult_rd_arrque *q) { return prh_impl_atom_mult_rd_arrque_empty_items(q); }

typedef struct {
    prh_int tail; // tail 仅由 write 单一线程写入
    prh_int empty_items;
} prh_atom_mult_rd_arrque_view;

bool prh_impl_atom_mult_rd_arrque_push_begin(void *arrque, prh_atom_mult_rd_arrque_view *view);
void prh_impl_atom_mult_rd_arrque_push_item_u32(void *arrque, prh_atom_mult_rd_arrque_view *view, prh_u32 a);
void prh_impl_atom_mult_rd_arrque_push_item_unt(void *arrque, prh_atom_mult_rd_arrque_view *view, prh_unt a);
void prh_impl_atom_mult_rd_arrque_push_item_ext(void *arrque, prh_atom_mult_rd_arrque_view *view, prh_ptr a, prh_ptr b);
void prh_impl_atom_mult_rd_arrque_push_end(void *arrque, prh_atom_mult_rd_arrque_view *view);

prh_inline bool prh_atom_i32_mult_rd_arrque_push_begin(prh_atom_i32_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { return prh_impl_atom_mult_rd_arrque_push_begin(q, view); }
prh_inline bool prh_atom_u32_mult_rd_arrque_push_begin(prh_atom_u32_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { return prh_impl_atom_mult_rd_arrque_push_begin(q, view); }
prh_inline bool prh_atom_int_mult_rd_arrque_push_begin(prh_atom_int_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { return prh_impl_atom_mult_rd_arrque_push_begin(q, view); }
prh_inline bool prh_atom_unt_mult_rd_arrque_push_begin(prh_atom_unt_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { return prh_impl_atom_mult_rd_arrque_push_begin(q, view); }
prh_inline bool prh_atom_ptr_mult_rd_arrque_push_begin(prh_atom_ptr_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { return prh_impl_atom_mult_rd_arrque_push_begin(q, view); }
prh_inline bool prh_atom_ext_mult_rd_arrque_push_begin(prh_atom_ext_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { return prh_impl_atom_mult_rd_arrque_push_begin(q, view); }

prh_inline bool prh_atom_i32_mult_rd_arrque_push_item(prh_atom_i32_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view, prh_i32 a) { prh_impl_atom_mult_rd_arrque_push_item_u32(q, view, a); }
prh_inline bool prh_atom_u32_mult_rd_arrque_push_item(prh_atom_u32_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view, prh_u32 a) { prh_impl_atom_mult_rd_arrque_push_item_u32(q, view, a); }
prh_inline bool prh_atom_int_mult_rd_arrque_push_item(prh_atom_int_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view, prh_int a) { prh_impl_atom_mult_rd_arrque_push_item_unt(q, view, a); }
prh_inline bool prh_atom_unt_mult_rd_arrque_push_item(prh_atom_unt_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view, prh_unt a) { prh_impl_atom_mult_rd_arrque_push_item_unt(q, view, a); }
prh_inline bool prh_atom_ptr_mult_rd_arrque_push_item(prh_atom_ptr_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view, void *a) { prh_impl_atom_mult_rd_arrque_push_item_unt(q, view, (prh_unt)a); }
prh_inline bool prh_atom_ext_mult_rd_arrque_push_item(prh_atom_ext_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view, prh_ptr a, prh_ptr b) { prh_impl_atom_mult_rd_arrque_push_item_ext(q, view, a, b); }

prh_inline bool prh_atom_i32_mult_rd_arrque_push_end(prh_atom_i32_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { prh_impl_atom_mult_rd_arrque_push_end(q, view); }
prh_inline bool prh_atom_u32_mult_rd_arrque_push_end(prh_atom_u32_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { prh_impl_atom_mult_rd_arrque_push_end(q, view); }
prh_inline bool prh_atom_int_mult_rd_arrque_push_end(prh_atom_int_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { prh_impl_atom_mult_rd_arrque_push_end(q, view); }
prh_inline bool prh_atom_unt_mult_rd_arrque_push_end(prh_atom_unt_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { prh_impl_atom_mult_rd_arrque_push_end(q, view); }
prh_inline bool prh_atom_ptr_mult_rd_arrque_push_end(prh_atom_ptr_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { prh_impl_atom_mult_rd_arrque_push_end(q, view); }
prh_inline bool prh_atom_ext_mult_rd_arrque_push_end(prh_atom_ext_mult_rd_arrque *q, prh_atom_mult_rd_arrque_view *view) { prh_impl_atom_mult_rd_arrque_push_end(q, view); }

prh_inline bool prh_atom_i32_mult_rd_arrque_push(prh_atom_i32_mult_rd_arrque *q, prh_i32 a) { return prh_impl_atom_mult_rd_arrque_push_u32(q, a); }
prh_inline bool prh_atom_u32_mult_rd_arrque_push(prh_atom_u32_mult_rd_arrque *q, prh_u32 a) { return prh_impl_atom_mult_rd_arrque_push_u32(q, a); }
prh_inline bool prh_atom_int_mult_rd_arrque_push(prh_atom_int_mult_rd_arrque *q, prh_int a) { return prh_impl_atom_mult_rd_arrque_push_unt(q, a); }
prh_inline bool prh_atom_unt_mult_rd_arrque_push(prh_atom_unt_mult_rd_arrque *q, prh_unt a) { return prh_impl_atom_mult_rd_arrque_push_unt(q, a); }
prh_inline bool prh_atom_ptr_mult_rd_arrque_push(prh_atom_ptr_mult_rd_arrque *q, void *a) { return prh_impl_atom_mult_rd_arrque_push_unt(q, (prh_unt)a); }
prh_inline bool prh_atom_ext_mult_rd_arrque_push(prh_atom_ext_mult_rd_arrque *q, prh_ptr a, prh_ptr b) { return prh_impl_atom_mult_rd_arrque_push_ext(q, a, b); }

prh_inline prh_i32 prh_atom_i32_mult_rd_arrque_pop(prh_atom_i32_mult_rd_arrque *q) { return (prh_i32)prh_impl_atom_mult_rd_arrque_pop_u32(q); }
prh_inline prh_u32 prh_atom_u32_mult_rd_arrque_pop(prh_atom_u32_mult_rd_arrque *q) { return (prh_u32)prh_impl_atom_mult_rd_arrque_pop_u32(q); }
prh_inline prh_int prh_atom_int_mult_rd_arrque_pop(prh_atom_int_mult_rd_arrque *q) { return (prh_int)prh_impl_atom_mult_rd_arrque_pop_unt(q); }
prh_inline prh_unt prh_atom_unt_mult_rd_arrque_pop(prh_atom_unt_mult_rd_arrque *q) { return (prh_unt)prh_impl_atom_mult_rd_arrque_pop_unt(q); }
prh_inline void *prh_atom_ptr_mult_rd_arrque_pop(prh_atom_ptr_mult_rd_arrque *q) { return (void *)prh_impl_atom_mult_rd_arrque_pop_unt(q); }
prh_inline bool prh_atom_ext_mult_rd_arrque_pop(prh_atom_ext_mult_rd_arrque *q, void *out) { return prh_impl_atom_mult_rd_arrque_pop_ext(q, (void **)out); }

prh_inline prh_i32 prh_atom_i32_mult_rd_arrque_weak_pop(prh_atom_i32_mult_rd_arrque *q, bool *race_condition) { return (prh_i32)prh_impl_atom_mult_rd_arrque_weak_pop_u32(q, race_condition); }
prh_inline prh_u32 prh_atom_u32_mult_rd_arrque_weak_pop(prh_atom_u32_mult_rd_arrque *q, bool *race_condition) { return (prh_u32)prh_impl_atom_mult_rd_arrque_weak_pop_u32(q, race_condition); }
prh_inline prh_int prh_atom_int_mult_rd_arrque_weak_pop(prh_atom_int_mult_rd_arrque *q, bool *race_condition) { return (prh_int)prh_impl_atom_mult_rd_arrque_weak_pop_unt(q, race_condition); }
prh_inline prh_unt prh_atom_unt_mult_rd_arrque_weak_pop(prh_atom_unt_mult_rd_arrque *q, bool *race_condition) { return (prh_unt)prh_impl_atom_mult_rd_arrque_weak_pop_unt(q, race_condition); }
prh_inline void *prh_atom_ptr_mult_rd_arrque_weak_pop(prh_atom_ptr_mult_rd_arrque *q, bool *race_condition) { return (void *)prh_impl_atom_mult_rd_arrque_weak_pop_unt(q, race_condition); }

#ifdef PRH_ATOMIC_IMPLEMENTATION
typedef struct {
    prh_int head; // 仅由pop线程读写，head永远追不上tail
    prh_int tail; // 仅由push线程读写，tail 指向当前可写入的空位
    prh_int size_minus_one; // 数组固定大小，必须是2的幂，只读
    prh_atom_int len;
} prh_impl_atom_arrque;

typedef struct {
    void *elem;
    prh_int head;
    prh_int len;
    prh_int size_minus_one;
} prh_impl_atom_arrque_data;

void *prh_impl_atom_arrque_alloc(prh_int size, prh_int alloc) {
    assert(size > 0 && prh_is_power_of_2(size));
    prh_impl_atom_arrque *q = prh_malloc(sizeof(prh_impl_atom_arrque) + alloc);
    q->head = q->tail = 0;
    q->size_minus_one = size - 1;
    prh_atom_int_init(&q->len, 0);
    return q;
}

void prh_impl_atom_arrque_free(void *q) {
    prh_free(q);
}

prh_int prh_impl_atom_arrque_len(void *q) {
    return prh_atom_int_read(&((prh_impl_atom_arrque *)q)->len);
}

prh_inline bool prh_impl_atom_arrque_full(prh_impl_atom_arrque *q) {
    return prh_atom_int_read(&q->len) > q->size_minus_one;
}

#define prh_impl_atom_arrque_next_pos(q, pos) (((pos) + 1) & ((q)->size_minus_one))
prh_inline void *prh_impl_atom_arrque_elem(prh_impl_atom_arrque *q) {
    return q + 1;
}

bool prh_impl_atom_arrque_push_u32(void *arrque, prh_u32 a) {
    prh_impl_atom_arrque *q = arrque; // push线程只操作q->tail 永远不读写q->head
    if (prh_impl_atom_arrque_full(q)) return false;
    prh_int tail = q->tail; assert(a != 0);
    ((prh_u32 *)prh_impl_atom_arrque_elem(q))[tail] = a;
    assert(q->tail == tail); // 只允许一个生产者
    q->tail = prh_impl_atom_arrque_next_pos(q, tail);
    prh_atom_int_inc(&q->len);
    return true;
}

bool prh_impl_atom_arrque_push_unt(void *arrque, prh_unt a) {
    prh_impl_atom_arrque *q = arrque; // push线程只操作q->tail 永远不读写q->head
    if (prh_impl_atom_arrque_full(q)) return false;
    prh_int tail = q->tail; assert(a != 0);
    ((prh_unt *)prh_impl_atom_arrque_elem(q))[tail] = a;
    assert(q->tail == tail); // 只允许一个生产者
    q->tail = prh_impl_atom_arrque_next_pos(q, tail);
    prh_atom_int_inc(&q->len);
    return true;
}

prh_u32 prh_impl_atom_arrque_top_u32(void *arrque) {
    prh_impl_atom_arrque *q = arrque;
    if (!prh_impl_atom_arrque_len(q)) return 0;
    return ((prh_u32 *)prh_impl_atom_arrque_elem(q))[q->head];
}

prh_unt prh_impl_atom_arrque_top_unt(void *arrque) {
    prh_impl_atom_arrque *q = arrque;
    if (!prh_impl_atom_arrque_len(q)) return 0;
    return ((prh_unt *)prh_impl_atom_arrque_elem(q))[q->head];
}

prh_u32 prh_impl_atom_arrque_pop_u32(void *arrque) {
    prh_impl_atom_arrque *q = arrque; // push线程只操作q->head 永远不读写q->tail
    if (!prh_impl_atom_arrque_len(q)) return 0;
    prh_int head = q->head;
    prh_u32 a = ((prh_u32 *)prh_impl_atom_arrque_elem(q))[head];
    assert(q->head == head); // 只允许一个消费者
    q->head = prh_impl_atom_arrque_next_pos(q, head);
    prh_atom_int_dec(&q->len);
    return a;
}

prh_unt prh_impl_atom_arrque_pop_unt(void *arrque) {
    prh_impl_atom_arrque *q = arrque; // push线程只操作q->head 永远不读写q->tail
    if (!prh_impl_atom_arrque_len(q)) return 0;
    prh_int head = q->head;
    prh_unt a = ((prh_unt *)prh_impl_atom_arrque_elem(q))[head];
    assert(q->head == head); // 只允许一个消费者
    q->head = prh_impl_atom_arrque_next_pos(q, head);
    prh_atom_int_dec(&q->len);
    return a;
}

bool prh_impl_atom_arrque_pop_all_begin(void *arrque, void *out) {
    prh_impl_atom_arrque *q = arrque; // push线程只操作q->head 永远不读写q->tail
    prh_impl_atom_arrque_data *data = out;
    prh_int len = prh_impl_atom_arrque_len(q);
    if (!len) return false;
    prh_int head = q->head;
    data->elem = prh_impl_atom_arrque_elem(q);
    data->size_minus_one = q->size_minus_one;
    data->head = head;
    data->len = len;
    assert(q->head == head); // 只允许一个消费者
    q->head = ((head + len) & q->size_minus_one);
    return true;
}

void prh_impl_atom_arrque_pop_all_end(void *arrque, void *data) {
    prh_impl_atom_arrque *q = arrque;
    prh_atom_int_sub(&q->len, ((prh_impl_atom_arrque_data *)data)->len);
}

typedef struct {
    prh_atom_int head; // 由多个线程读取，head 不能追上 tail
    prh_atom_int tail; // 仅由 write 线程写入，tail 指向当前可写入的空位（如果下一位置是 head，表示队列满，当前 tail 不可写）
    prh_int size_minus_one; // 数组固定大小，必须是2的幂，只读
} prh_impl_atom_mult_rd_arrque;

prh_inline prh_int prh_impl_atom_mult_rd_arrque_pos(prh_int pos, prh_int size_minus_one) {
    return pos & size_minus_one;
}

prh_inline void *prh_impl_atom_mult_rd_arrque_elem(prh_impl_atom_mult_rd_arrque *q) {
    return q + 1;
}

prh_int prh_impl_atom_mult_rd_arrque_empty_items(void *arrque) {
    prh_int head = prh_atom_int_read(&((prh_impl_atom_mult_rd_arrque *)arrque)->head); // 以此为基点写入，tail 不能等于和超过 head
    prh_int tail = prh_atom_int_read(&((prh_impl_atom_mult_rd_arrque *)arrque)->tail); // tail 仅由 write 单一线程写入
    return ((head - tail - 1) & ((prh_impl_atom_mult_rd_arrque *)arrque)->size_minus_one);
}

prh_int prh_impl_atom_mult_rd_arrque_len(void *arrque) {
    return ((prh_impl_atom_mult_rd_arrque *)arrque)->size_minus_one - prh_impl_atom_mult_rd_arrque_empty_items(arrque);
}

prh_int prh_atom_mult_rd_arrque_alloc_size(prh_int size, prh_int elem_bytes) {
    assert(size > 0 && prh_is_power_of_2(size));
    return sizeof(prh_impl_atom_mult_rd_arrque) + elem_bytes * size;
}

void prh_impl_atom_mult_rd_arrque_init(void *arrque, prh_int size) {
    assert(size > 0 && prh_is_power_of_2(size));
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_atom_int_init(&q->head, 0);
    prh_atom_int_init(&q->tail, 0);
    q->size_minus_one = size - 1;
}

bool prh_impl_atom_mult_rd_arrque_push_begin(void *arrque, prh_atom_mult_rd_arrque_view *view) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_int head = prh_atom_int_read(&q->head); // 以此为基点写入，tail 不能等于和超过 head
    prh_int tail = prh_atom_int_read(&q->tail); // tail 仅由 write 单一线程写入
    prh_int size_minus_one = q->size_minus_one;
    prh_int empty_items = ((head - tail - 1) & size_minus_one);
    view->tail = tail;
    view->empty_items = empty_items;
    return empty_items > 0;
}

void prh_impl_atom_mult_rd_arrque_push_item_u32(void *arrque, prh_atom_mult_rd_arrque_view *view, prh_u32 a) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    assert(view->empty_items > 0);
    assert(a != 0); // 方便区分 pop 的时候返回 0 确切表示队列为空
    prh_int tail = view->tail;
    ((prh_u32 *)prh_impl_atom_mult_rd_arrque_elem(q))[tail] = a;
    view->tail = prh_impl_atom_mult_rd_arrque_pos(tail + 1, q->size_minus_one);
    prh_debug(view->empty_items -= 1);
}

void prh_impl_atom_mult_rd_arrque_push_item_unt(void *arrque, prh_atom_mult_rd_arrque_view *view, prh_unt a) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    assert(view->empty_items > 0);
    assert(a != 0); // 方便区分 pop 的时候返回 0 确切表示队列为空
    prh_int tail = view->tail;
    ((prh_unt *)prh_impl_atom_mult_rd_arrque_elem(q))[tail] = a;
    view->tail = prh_impl_atom_mult_rd_arrque_pos(tail + 1, q->size_minus_one);
    prh_debug(view->empty_items -= 1);
}

void prh_impl_atom_mult_rd_arrque_push_item_ext(void *arrque, prh_atom_mult_rd_arrque_view *view, prh_ptr a, prh_ptr b) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_ptr *elem_ptr = (prh_ptr *)prh_impl_atom_mult_rd_arrque_elem(q);
    assert(view->empty_items > 0);
    assert(a != 0); // 方便区分 pop 的时候返回 0 确切表示队列为空
    prh_int tail = view->tail;
    elem_ptr[tail] = a;
    elem_ptr[tail + 1] = b;
    view->tail = prh_impl_atom_mult_rd_arrque_pos(tail + 2, q->size_minus_one);
    prh_debug(view->empty_items -= 1);
}

void prh_impl_atom_mult_rd_arrque_push_end(void *arrque, prh_atom_mult_rd_arrque_view *view) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_atom_int_write(&q->tail, view->tail); // tail 只由单一生产者更新
}

bool prh_impl_atom_mult_rd_arrque_push_u32(void *arrque, prh_u32 a) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_int head = prh_atom_int_read(&q->head); // 以此为基点写入，tail 不能等于和超过 head
    prh_int tail = prh_atom_int_read(&q->tail); // tail 仅由 write 单一线程写入
    prh_int next = prh_impl_atom_mult_rd_arrque_pos(tail + 1, q->size_minus_one);
    if (next == head) return false; // 队列满
    assert(a != 0); // 方便区分 pop 的时候返回 0 确切表示队列为空
    ((prh_u32 *)prh_impl_atom_mult_rd_arrque_elem(q))[tail] = a;
    assert(q->tail == tail); // 只允许一个生产者
    prh_atom_int_write(&q->tail, next); // tail 只由单一生产者更新
    return true;
}

bool prh_impl_atom_mult_rd_arrque_push_unt(void *arrque, prh_unt a) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_int head = prh_atom_int_read(&q->head); // 以此为基点写入，tail 不能等于和超过 head
    prh_int tail = prh_atom_int_read(&q->tail); // tail 仅由 write 单一线程写入
    prh_int next = prh_impl_atom_mult_rd_arrque_pos(tail + 1, q->size_minus_one);
    if (next == head) return false; // 队列满
    assert(a != 0); // 方便区分 pop 的时候返回 0 确切表示队列为空
    ((prh_unt *)prh_impl_atom_mult_rd_arrque_elem(q))[tail] = a;
    assert(q->tail == tail); // 只允许一个生产者
    prh_atom_int_write(&q->tail, next); // tail 只由单一生产者更新
    return true;
}

bool prh_impl_atom_mult_rd_arrque_push_ext(void *arrque, prh_ptr a, prh_ptr b) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_ptr *elem_ptr = (prh_ptr *)prh_impl_atom_mult_rd_arrque_elem(q);
    prh_int head = prh_atom_int_read(&q->head); // 以此为基点写入，tail 不能等于和超过 head
    prh_int tail = prh_atom_int_read(&q->tail); // tail 仅由 write 单一线程写入
    prh_int next = prh_impl_atom_mult_rd_arrque_pos(tail + 2, q->size_minus_one);
    if (next == head) return false; // 队列满
    assert(a != 0); // 方便区分 pop 的时候返回 0 确切表示队列为空
    elem_ptr[tail] = a;
    elem_ptr[tail + 1] = b;
    assert(q->tail == tail); // 只允许一个生产者
    prh_atom_int_write(&q->tail, next); // tail 只由单一生产者更新
    return true;
}

prh_u32 prh_impl_atom_mult_rd_arrque_pop_u32(void *arrque) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_int size_minus_one = q->size_minus_one;
    prh_int tail, head, next;
    prh_u32 a = 0;
    prh_debug(prh_int race_times = 0);
label_continue:
    tail = prh_atom_int_read(&q->tail); // 以此为基点读取，head 不能超过 tail
    head = prh_atom_int_read(&q->head); // 多个线程可能竞争更新 head
    if (head == tail) goto label_return; // 队列空
    next = prh_impl_atom_mult_rd_arrque_pos(head + 1, size_minus_one);
    a = ((prh_u32 *)prh_impl_atom_mult_rd_arrque_elem(q))[head]; // 必须在更新 q->head 之前先读取元素数据，因为一旦更新 q->head 之后，元素可能立马被生产者线程更新
    if (!prh_atom_int_strong_write(&q->head, &head, next)) {
        prh_debug(race_times += 1);
        goto label_continue; // 被其他线程抢先更新，争夺下一个
    }
label_return:
    prh_debug(if (race_times) printf("atom_mult_rd_arrque race times %d\n", race_times));
    return a;
}

prh_u32 prh_impl_atom_mult_rd_arrque_weak_pop_u32(void *arrque, bool *race_condition) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_int tail = prh_atom_int_read(&q->tail); // 以此为基点读取，head 不能超过 tail
    prh_int head = prh_atom_int_read(&q->head); // 多个线程可能竞争更新 head
    *race_condition = false;
    if (head == tail) return 0; // 队列空
    prh_int next = prh_impl_atom_mult_rd_arrque_pos(head + 1, q->size_minus_one);
    prh_u32 a = ((prh_u32 *)prh_impl_atom_mult_rd_arrque_elem(q))[head]; // 必须在更新 q->head 之前先读取元素数据，因为一旦更新 q->head 之后，元素可能立马被生产者线程更新
    if (!prh_atom_int_strong_write(&q->head, &head, next)) {
        *race_condition = true;
        return 0; // 被其他线程抢先更新
    }
    return a;
}

prh_unt prh_impl_atom_mult_rd_arrque_pop_unt(void *arrque) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_int size_minus_one = q->size_minus_one;
    prh_int tail, head, next;
    prh_unt a = 0;
    prh_debug(prh_int race_times = 0);
label_continue:
    tail = prh_atom_int_read(&q->tail); // 以此为基点读取，head 不能超过 tail
    head = prh_atom_int_read(&q->head); // 多个线程可能竞争更新 head
    if (head == tail) goto label_return; // 队列空
    next = prh_impl_atom_mult_rd_arrque_pos(head + 1, size_minus_one);
    a = ((prh_unt *)prh_impl_atom_mult_rd_arrque_elem(q))[head]; // 必须在更新 q->head 之前先读取元素数据，因为一旦更新 q->head 之后，元素可能立马被生产者线程更新
    if (!prh_atom_int_strong_write(&q->head, &head, next)) {
        prh_debug(race_times += 1);
        goto label_continue; // 被其他线程抢先更新，争夺下一个
    }
label_return:
    prh_debug(if (race_times) printf("atom_mult_rd_arrque unt race times %d\n", race_times));
    return a;
}

prh_unt prh_impl_atom_mult_rd_arrque_weak_pop_unt(void *arrque, bool *race_condition) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_int tail = prh_atom_int_read(&q->tail); // 以此为基点读取，head 不能超过 tail
    prh_int head = prh_atom_int_read(&q->head); // 多个线程可能竞争更新 head
    *race_condition = false;
    if (head == tail) return 0; // 队列空
    prh_int next = prh_impl_atom_mult_rd_arrque_pos(head + 1, q->size_minus_one);
    prh_unt a = ((prh_unt *)prh_impl_atom_mult_rd_arrque_elem(q))[head]; // 必须在更新 q->head 之前先读取元素数据，因为一旦更新 q->head 之后，元素可能立马被生产者线程更新
    if (!prh_atom_int_strong_write(&q->head, &head, next)) {
        *race_condition = true;
        return 0; // 被其他线程抢先更新
    }
    return a;
}

bool prh_impl_atom_mult_rd_arrque_pop_ext(void *arrque, void **out) {
    prh_impl_atom_mult_rd_arrque *q = arrque;
    prh_ptr *elem_ptr = (prh_ptr *)prh_impl_atom_mult_rd_arrque_elem(q);
    prh_int size_minus_one = q->size_minus_one;
    prh_int tail, head, next;
    prh_debug(prh_int race_times = 0);
label_continue:
    tail = prh_atom_int_read(&q->tail); // 以此为基点读取，head 不能超过 tail
    head = prh_atom_int_read(&q->head); // 多个线程可能竞争更新 head
    if (head == tail) goto label_return; // 队列空
    next = prh_impl_atom_mult_rd_arrque_pos(head + 2, size_minus_one);
    out[0] = elem_ptr[head]; // 必须在更新 q->head 之前先读取元素数据，因为一旦更新 q->head 之后，元素可能立马被生产者线程更新
    out[1] = elem_ptr[head + 1];
    if (!prh_atom_int_strong_write(&q->head, &head, next)) {
        prh_debug(race_times += 1);
        goto label_continue; // 被其他线程抢先更新，争夺下一个
    }
label_return:
    prh_debug(if (race_times) printf("atom_mult_rd_arrque ext race times %d\n", race_times));
    return a;
}

#ifdef PRH_TEST_IMPLEMENTATION
void prh_impl_atomic_test(void) {
    atomic_flag f; atomic_bool b; atomic_int i; atomic_uint u;
    atomic_intptr_t ip; atomic_uintptr_t up; atomic_size_t sz; atomic_ptrdiff_t pd;
    atomic_char ch; atomic_schar sc; atomic_uchar uc; atomic_short sh;
    atomic_ushort uh; atomic_long sl; atomic_ulong ul; atomic_llong ll; atomic_ullong ull;
    printf("\n\n[atomic]\n");
    printf("atomic_flag size %d align %d lock free %d\n", (int)sizeof(atomic_flag), (int)prh_alignof(atomic_flag), atomic_is_lock_free(&f));
    printf("atomic_bool size %d align %d lock free %d\n", (int)sizeof(atomic_bool), (int)prh_alignof(atomic_bool), atomic_is_lock_free(&b));
    printf("atomic_int size %d align %d lock free %d\n", (int)sizeof(atomic_int), (int)prh_alignof(atomic_int), atomic_is_lock_free(&i));
    printf("atomic_uint size %d align %d lock free %d\n", (int)sizeof(atomic_uint), (int)prh_alignof(atomic_uint), atomic_is_lock_free(&u));
    printf("atomic_intptr_t size %d align %d lock free %d\n", (int)sizeof(atomic_intptr_t), (int)prh_alignof(atomic_intptr_t), atomic_is_lock_free(&ip));
    printf("atomic_uintptr_t size %d align %d lock free %d\n", (int)sizeof(atomic_uintptr_t), (int)prh_alignof(atomic_uintptr_t), atomic_is_lock_free(&up));
    printf("atomic_size_t size %d align %d lock free %d\n", (int)sizeof(atomic_size_t), (int)prh_alignof(atomic_size_t), atomic_is_lock_free(&sz));
    printf("atomic_ptrdiff_t size %d align %d lock free %d\n", (int)sizeof(atomic_ptrdiff_t), (int)prh_alignof(atomic_ptrdiff_t), atomic_is_lock_free(&pd));
    printf("atomic_char size %d align %d lock free %d\n", (int)sizeof(atomic_char), (int)prh_alignof(atomic_char), atomic_is_lock_free(&ch));
    printf("atomic_schar size %d align %d lock free %d\n", (int)sizeof(atomic_schar), (int)prh_alignof(atomic_schar), atomic_is_lock_free(&sc));
    printf("atomic_uchar size %d align %d lock free %d\n", (int)sizeof(atomic_uchar), (int)prh_alignof(atomic_uchar), atomic_is_lock_free(&uc));
    printf("atomic_short size %d align %d lock free %d\n", (int)sizeof(atomic_short), (int)prh_alignof(atomic_short), atomic_is_lock_free(&sh));
    printf("atomic_ushort size %d align %d lock free %d\n", (int)sizeof(atomic_ushort), (int)prh_alignof(atomic_ushort), atomic_is_lock_free(&uh));
    printf("atomic_long size %d align %d lock free %d\n", (int)sizeof(atomic_long), (int)prh_alignof(atomic_long), atomic_is_lock_free(&sl));
    printf("atomic_ulong size %d align %d lock free %d\n", (int)sizeof(atomic_ulong), (int)prh_alignof(atomic_ulong), atomic_is_lock_free(&ul));
    printf("atomic_llong size %d align %d lock free %d\n", (int)sizeof(atomic_llong), (int)prh_alignof(atomic_llong), atomic_is_lock_free(&ll));
    printf("atomic_ullong size %d align %d lock free %d\n", (int)sizeof(atomic_ullong), (int)prh_alignof(atomic_ullong), atomic_is_lock_free(&ull));
}
#endif // PRH_TEST_IMPLEMENTATION
#endif // PRH_ATOMIC_IMPLEMENTATION
#endif // PRH_ATOMIC_INCLUDE

#ifdef PRH_TIME_INCLUDE
// 1-sec 秒 second
// 1000-msec 毫秒 millisecond
// 1000000-usec 微妙 microsecond
// 1000000000-nsec 纳秒 nanosecond 最大值10亿可以用int32表示，int32最大值为20亿
// 1GHZ 1000MHZ 1000000KHZ 1000000000HZ 相当于 1-nsec per tick
// 一天24小时*3600秒，共86400秒*365天，一年共31536000秒
//
// int64 保持秒可以表示正负2.9千亿年        int32 保存秒可以表示68年
//       如果保存毫秒可以表示2.9亿年              保存毫秒可以表示24天
//       如果保存微妙可以表示29万年               保存微秒可以表示35分钟
//       如果保存纳秒可以表示292年                保存纳秒可以表示2秒
//
// The epoch of system_clock is unspecified, but most implementations use Unix
// Time (i.e., time since 00:00:00 Coordinated Universal Time (UTC), Thursday,
// 1 January 1970, not counting leap seconds).
//
// UTC时间从1970/1/1 00:00:00开始，uint32 只能表示 136 年大约在 2106 年失效。在32位
// Linux系统上，time_t是一个32位有符号整数，可以表示的日期范围从 1901/12/13 20:45:52
// 至 2038/1/19 03:14:07。Windows 上 x86 和 x64 的 time_t 类型大小总是 8 字节。

// Epoch delta from 0000/1/1 to 1970/1/1
#define PRH_EPOCH_DELTA_SECS 0x0000000E79844E00LL // 62168256000-sec
#define PRH_EPOCH_DELTA_MSEC 0x0000388AACD0B000LL // 62168256000000-msec
#define PRH_EPOCH_DELTA_USEC 0x00dcddb30f2f8000LL // 62168256000000000-usec

#define PRH_MSEC_PER_SEC 1000
#define PRH_USEC_PER_SEC 1000000
#define PRH_NSEC_PER_SEC 1000000000

typedef struct {
    prh_i64 secs; // 最大可以表示正负2.9千亿年
    prh_i32 usec;
} prh_timeusec;

typedef struct {
    prh_i64 secs;
    prh_i32 nsec;
} prh_timensec;

typedef struct {
    prh_i32 year;   // 正负20亿年
    prh_i32 usec;   // 0 ~ 999999
    prh_byte month; // 1 ~ 12
    prh_byte mday;  // 1 ~ 31
    prh_byte wday;  // 0 ~ 6 (sunday = 0)
    prh_byte hour;  // 0 ~ 23
    prh_byte min;   // 0 ~ 59
    prh_byte sec;   // 0 ~ 60 since C99
} prh_datetime;

#define prh_abs_sec_to_utc(abs) ((abs) - PRH_EPOCH_DELTA_SECS)
#define prh_utc_sec_to_abs(utc) ((utc) + PRH_EPOCH_DELTA_SECS)

prh_i64 prh_system_secs(void);
prh_i64 prh_system_msec(void);
prh_i64 prh_system_usec(void);
prh_i64 prh_steady_secs(void);
prh_i64 prh_steady_msec(void);
prh_i64 prh_steady_usec(void);
prh_i64 prh_steady_nsec(void);
prh_i64 prh_clock_ticks(void); // 如果精度为纳秒（精度为1000000000每秒，1GHZ）可以表示292年
prh_i64 prh_elapse_secs(prh_i64 ticks);
prh_i64 prh_elapse_msec(prh_i64 ticks);
prh_i64 prh_elapse_usec(prh_i64 ticks);
prh_i64 prh_elapse_nsec(prh_i64 ticks);
prh_i64 prh_thread_time(void); // 当前线程执行时间，包含用户以及内核的执行时间

void prh_system_time(prh_timeusec *t);
void prh_system_date(prh_datetime *utc_date);
void prh_system_date_from(prh_datetime *utc_date, const prh_timeusec *utc_time);
void prh_system_time_from_date(prh_timeusec *utc_time, const prh_datetime *utc_date);
void prh_system_time_from_local_date(prh_timeusec *utc_time, const prh_datetime *local_date);
void prh_local_date(prh_datetime *local_date);
void prh_local_date_from(prh_datetime *local_date, const prh_timeusec *utc_time);

prh_inline prh_i64 prh_system_msec_from(const prh_timeusec *p) {
    return p->secs * PRH_MSEC_PER_SEC + p->usec / PRH_MSEC_PER_SEC;
}

prh_inline prh_i64 prh_system_usec_from(const prh_timeusec *p) {
    return p->secs * PRH_USEC_PER_SEC + p->usec;
}

// https://github.com/adobe/chromium/blob/master/base/time_mac.cc
// https://github.com/adobe/chromium/blob/master/base/time_posix.cc
// https://github.com/adobe/chromium/blob/master/base/time_win.cc
#ifdef PRH_TIME_IMPLEMENTATION
typedef struct {
    prh_i64 ticks_per_sec;
} prh_impl_timeinit;

prh_impl_timeinit PRH_IMPL_TIMEINIT;

// https://github.com/rust-lang/rust/blob/3809bbf47c8557bd149b3e52ceb47434ca8378d5/src/libstd/sys_common/mod.rs#L124
// Computes (value*numer)/denom without overflow, as long as both
// (numer*denom) and the overall result fit into i64 (which is the case
// for our time conversions). 分子（numerator）分母（denominator）
// Decompose value as (value/denom*denom + value%denom):
//      v * n / d = (v / d * d + v % d) * n / d =
//      (v / d * d * n / d) + (v % d * n / d) =
//      v / d * n + v % d * n / d = q * n + r * n / d
prh_i64 prh_impl_mul_div(prh_i64 value, prh_i64 numer, prh_i64 denom) {
    prh_i64 q = value / denom;
    prh_i64 r = value % denom;
    return q * numer + r * numer / denom;
}

#if defined(prh_plat_windows)
// https://learn.microsoft.com/en-us/windows/win32/winmsg/about-timers
//
// High-resolution timer 性能计数器的值是一个单调递增的计数值，其频率可以通过
// QueryPerformanceFrequency 获取。
//
// A counter is a general term used in programming to refer to an incrementing
// variable. Some systems include a high-resolution performance counter that
// provides high-resolution elapsed times.
//
// If a high-resolution performance counter exists on the system, you can use
// the QueryPerformanceFrequency function to express the frequency, in counts
// per second. The value of the count is processor dependent. On some
// processors, for example, the count might be the cycle rate of the processor
// clock.
//
// The QueryPerformanceCounter function retrieves the current value of the
// high-resolution performance counter. By calling this function at the
// beginning and end of a section of code, an application essentially uses
// the counter as a high-resolution timer.
//
// https://learn.microsoft.com/en-us/windows/win32/sysinfo/acquiring-high-resolution-time-stamps
//
// Acquiring high-resolution time stamps
//
// Windows 提供了一些可以用来获取高分辨率时间戳或测量时间间隔的 API。对于本地代码，
// 主要的 API 是 QueryPerformanceCounter（QPC）。对于设备驱动程序，内核模式的 API
// 是 KeQueryPerformanceCounter。对于托管代码，System.Diagnostics.Stopwatch 类
// 使用 QPC 作为其精确时间基础。QPC 是独立的，并且不与任何外部时间参考同步。如果要获
// 取可以与外部时间参考（例如协调世界时，UTC）同步的时间戳（用于高分辨率的时间测量），
// 请使用 GetSystemTimePreciseAsFileTime。时间戳和时间间隔测量是计算机和网络性能测
// 量的重要组成部分。这些性能测量操作包括计算响应时间、吞吐量和延迟，以及对代码执行进
// 行剖析。所有这些操作都涉及对在时间间隔内发生的活动的测量，该时间间隔由开始和结束事
// 件定义，这些事件可以独立于任何外部时间参考。QPC 通常是用于对同一系统或虚拟机上发生
// 的事件进行时间戳标记和测量小时间间隔的最佳方法。如果要在多台机器之间对事件进行时间
// 戳标记，并且每台机器都参与了某种时间同步方案（例如网络时间协议，NTP），请考虑使用
// GetSystemTimePreciseAsFileTime。QPC 帮助你避免使用其他时间测量方法（例如直接读
// 取处理器的时间戳计数器，TSC）时可能遇到的困难。
//
// QPC is available on Windows XP and Windows 2000 and works well on most
// systems. However, some hardware systems' BIOS didn't indicate the hardware
// CPU characteristics correctly (a non-invariant TSC), and some multi-core
// or multi-processor systems used processors with TSCs that couldn't be
// synchronized across cores. Systems with flawed firmware that run these
// versions of Windows might not provide the same QPC reading on different
// cores if they used the TSC as the basis for QPC.
//
// All computers that shipped with Windows Vista and Windows Server 2008 used
// a platform counter (High Precision Event Timer (HPET)) or the ACPI Power
// Management Timer (PM timer) as the basis for QPC. Such platform timers
// have higher access latency than the TSC and are shared between multiple
// processors. This limits scalability of QPC if it is called concurrently
// from multiple processors.
//
// The majority of Windows 7 and Windows Server 2008 R2 computers have
// processors with constant-rate TSCs and use these counters as the basis
// for QPC. TSCs are high-resolution per-processor hardware counters that
// can be accessed with very low latency and overhead (in the order of 10s
// or 100s of machine cycles, depending on the processor type). Windows 7
// and Windows Server 2008 R2 use TSCs as the basis of QPC on single-clock
// domain systems where the operating system (or the hypervisor) is able to
// tightly synchronize the individual TSCs across all processors during
// system initialization. On such systems, the cost of reading the
// performance counter is significantly lower compared to systems that use
// a platform counter. Furthermore, there is no added overhead for concurrent
// calls and user-mode queries often bypass system calls, which further
// reduces overhead. On systems where the TSC is not suitable for timekeeping,
// Windows automatically selects a platform counter (either the HPET timer or
// the ACPI PM timer) as the basis for QPC.
//
// Windows 8, Windows 8.1, Windows Server 2012, and Windows Server 2012 R2
// use TSCs as the basis for the performance counter. The TSC synchronization
// algorithm was significantly improved to better accommodate large systems
// with many processors. In addition, support for the new precise time-of-day
// API was added, which enables acquiring precise wall clock time stamps from
// the operating system. For more info, see GetSystemTimePreciseAsFileTime.
// On Windows RT and Windows 11 and Windows 10 devices using Arm processors,
// the performance counter is based on either a proprietary platform counter
// or the system counter provided by the Arm Generic Timer if the platform
// is so equipped.
//
// Windows 一直在并将继续投资于提供可靠且高效的性能计数器。当你需要具有 1 微秒或更高
// 分辨率的时间戳，并且不需要这些时间戳与外部时间参考同步时，应选择
// QueryPerformanceCounter、KeQueryPerformanceCounter 或
// KeQueryInterruptTimePrecise。当你需要具有 1 微秒或更高分辨率且与协调世界时
// （UTC）同步的时间戳时，应选择 GetSystemTimePreciseAsFileTime 或
// KeQuerySystemTimePrecise。
//
// 在少数无法使用 TSC（时间戳计数器）寄存器来实现 QPC 的平台上，例如由于硬件时钟信息
// （Hardware timer info）中解释的原因，获取高分辨率时间戳的代价可能显著高于获取低分
// 辨率时间戳。如果 10 到 16 毫秒的分辨率已经足够，你可以使用 GetTickCount64、
// QueryInterruptTime、QueryUnbiasedInterruptTime、KeQueryInterruptTime 或
// KeQueryUnbiasedInterruptTime 来获取不与外部时间参考同步的时间戳。对于需要与 UTC
// 同步的时间戳，可以使用 GetSystemTimeAsFileTime 或 KeQuerySystemTime。如果需要
// 更高分辨率，可以使用 QueryInterruptTimePrecise、
// QueryUnbiasedInterruptTimePrecise 或 KeQueryInterruptTimePrecise 来获取时间
// 戳。
//
// 一般来说，在多核和多处理器系统中，性能计数器的结果在所有处理器上是一致的，即使在不
// 同线程或进程中测量也是如此。但存在以下一些例外情况：
//
//      在某些处理器上运行 Windows Vista 之前的操作系统可能由于以下原因之一而违反这
//      种一致性：硬件处理器具有非不变的 TSC（时间戳计数器），并且 BIOS 没有正确指示
//      这种情况；使用的 TSC 同步算法不适合拥有大量处理器的系统。
//
//      当你在多线程环境中从不同线程获取性能计数器的时间戳时，可能会遇到一个问题：由
//      于硬件和调度的不确定性，两个时间戳之间的差异可能只有 ±1 个时钟周期。这种情况
//      下，时间戳的顺序可能是模糊的（ambiguous）。换句话说，你无法确定哪个时间戳真
//      正地早于或晚于另一个时间戳。例如如果 T2 - T1 = ±1 个时钟周期，那么你无法确
//      定 T1 是否早于 T2，或者它们是否几乎同时发生。
//
//      如果两个时间戳是从同一个线程获取的，那么这种 ±1 个时钟周期的不确定性不适用，
//      在同一线程中，时间戳的顺序是明确的，因为它们是在同一个上下文中生成的，不会受
//      到线程切换或硬件同步问题的影响。在此上下文中，术语 “时钟周期” 指的是等于 1 ÷
//      （通过 QueryPerformanceFrequency 获取的性能计数器频率）的时间间隔。
//
// 在具有多个时钟域且这些时钟域在硬件中未同步的大型服务器系统上使用性能计数器时，
// Windows 会确定 TSC 不能用于计时目的，并选择一个平台计数器作为 QPC 的基础。尽管在
// 这种情况下仍然可以提供可靠的时间戳，但访问延迟和可扩展性会受到不利影响。因此，如前
// 面的使用指导所述，只有在需要 1 微秒或更高分辨率时，才使用提供这种分辨率的 API。在
// 包含硬件同步（对所有处理器时钟域）的多时钟域系统上，TSC 被用作 QPC 的基础，因为这
// 实际上它们等效于作为一个单一时钟域系统来运行。
//
// 性能计数器预计可以在正确实现的虚拟化管理程序上运行的所有客户虚拟机中可靠工作。然而，
// 符合虚拟化管理程序版本 1.0 接口并提供参考时间增强功能的虚拟化管理程序可以显著降低
// 开销。有关虚拟化管理程序接口和增强功能的更多信息，请参阅 虚拟化管理程序规范。
//
// 我们强烈不推荐使用 RDTSC 或 RDTSCP 处理器指令直接查询时间戳计数器（TSC），因为在
// 某些版本的 Windows 上、虚拟机的实时迁移过程中，以及在没有不变或紧密同步的 TSC 的
// 硬件系统上，你无法获得可靠的结果。相反，我们建议你使用 QPC，以利用其提供的抽象性、
// 一致性和可移植性。
//
// https://learn.microsoft.com/en-us/windows/win32/sysinfo/acquiring-high-resolution-time-stamps#hardware-timer-info
//
// Hardware timer info
//
// TSC 寄存器（x86 和 x64）
//
// 所有现代的 Intel 和 AMD 处理器都包含一个 TSC（时间戳计数器）寄存器，这是一个 64
// 位的寄存器，以很高的速率递增，通常等于处理器的时钟频率。通过 RDTSC 或 RDTSCP 指
// 令可以读取该计数器的值，访问时间非常短，计算成本也很低，通常在几十到几百个机器周
// 期内，具体取决于处理器。尽管 TSC 寄存器看起来像是一个理想的时间戳机制，但在以下情
// 况下，它无法可靠地用于计时目的：
//
// 可移植性问题：并非所有处理器都有可用的 TSC 寄存器，因此直接在软件中使用 TSC 寄存
// 器会带来可移植性问题。Windows 会为 QPC 选择替代的时间源，从而避免了可移植性问题。
// 非不变 TSC：某些处理器可以改变 TSC 时钟的频率，或者停止 TSC 寄存器的递增，这使得
// 这些处理器上的 TSC 不适合用于计时。这些处理器被认为具有非不变 TSC 寄存器。Windows
// 会自动检测这种情况，并为 QPC 选择替代的时间源。
// 虚拟机实时迁移问题：即使虚拟化主机有一个可用的 TSC，当运行中的虚拟机进行实时迁移，
// 而目标虚拟化主机没有或不使用硬件辅助的 TSC 缩放时，可能会导致虚拟机看到 TSC 频率
// 的变化。如果这种类型的实时迁移对虚拟机是可能的，那么虚拟化管理程序应该清除 CPUID
// 中的不变 TSC 特性位。
// 多处理器或多核系统中的时钟同步问题：某些处理器和系统无法将每个核心上的时钟同步到相
// 同的值。Windows 会自动检测这种情况，并为 QPC 选择替代的时间源。
// 大型多处理器系统中的时钟同步问题：即使处理器具有不变 TSC，也可能无法将处理器时钟同
// 步到相同的值。Windows 会自动检测这种情况，并为 QPC 选择替代的时间源。
// 指令乱序执行问题：某些处理器会乱序执行指令。这可能导致在使用 RDTSC 对指令序列进行
// 计时时出现错误的周期计数，因为 RDTSC 指令可能与你在程序中指定的不同时间执行。为了
// 解决这个问题，某些处理器引入了 RDTSCP 指令。
//
// 与其他计时器一样，TSC 基于一个晶体振荡器，其确切频率事先并不知道，并且存在频率偏移
// 误差。因此，在使用之前，必须使用另一个时间参考对其进行校准。在系统初始化期间，
// Windows 会检查 TSC 是否适合用于计时目的，并执行必要的频率校准和核心同步。
//
// PM 时钟（x86 和 x64）
//
// ACPI 定时器（也称为 PM 时钟）被添加到系统架构中，以提供与处理器速度无关的可靠时间
// 戳。由于这是该定时器的唯一目标，它可以在一个时钟周期内提供时间戳，但它不提供任何其
// 他功能。
//
// HPET 定时器（x86 和 x64）
//
// 高精度事件定时器（HPET）是由 Intel 和 Microsoft 联合开发的，以满足多媒体和其他对
// 时间敏感的应用程序的计时需求。与 TSC（每个处理器都有一个）不同，HPET 是一个共享
// 的、平台范围内的资源，尽管一个系统可以有多个 HPET。自 Windows Vista 以来，
// Windows 一直支持 HPET，Windows 7 和 Windows 8 硬件徽标认证要求硬件平台支持
// HPET。
//
// 通用定时器系统计数器（Arm）
//
// 基于 Arm 的平台没有 Intel 或 AMD 平台上那样的 TSC、HPET 或 PM 时钟。相反，Arm 处
// 理器提供了通用定时器（有时也称为通用间隔定时器，或 GIT），其中包含一个系统计数器寄
// 存器（例如，CNTVCT_EL0）。通用定时器系统计数器是一个固定频率的平台范围内的时钟源。
// 它在启动时从零开始，并以很高的速率递增。在 Armv8.6 或更高版本中，这被定义为正好 1
// GHz，但应通过读取由早期引导固件设置的时钟频率寄存器来确定。有关更多详细信息，请参
// 阅《Arm 架构参考手册（A-profile 架构）》（DDI 0487）中的 “AArch64 状态中的通用
// 定时器” 一章。
//
// 循环计数器（Arm）
//
// 基于 Arm 的平台提供了一个性能监控循环计数器（Performance Monitors Cycle
// Counter）寄存器（例如，PMCCNTR_EL0）。这个计数器计算处理器时钟周期。它是非不变
// 的，其单位可能与实际时间无关。不建议使用该寄存器来获取时间戳。
//
// https://learn.microsoft.com/en-us/windows/win32/sysinfo/acquiring-high-resolution-time-stamps#general-faq-about-qpc-and-tsc
//
// General FAQ about QPC and TSC
//
// 以下是关于 QPC 和时间戳计数器 TSC 的常见问题解答：
//
// 问：QueryPerformanceCounter 是否与 Win32 的 GetTickCount 或 GetTickCount64 函
// 数相同？
// 答：不是。GetTickCount 和 GetTickCount64 与 QPC 没有关系。GetTickCount 和
// GetTickCount64 返回自系统启动以来的毫秒数。
//
// 问：我应该使用 QPC，还是直接调用 RDTSC/RDTSCP 指令？
// 答：为了避免错误和可移植性问题，我们强烈建议你使用 QPC，而不是直接使用 TSC 寄存器
// 或 RDTSC 或 RDTSCP 处理器指令。
//
// 问：QPC 与外部时间纪元（epoch）有何关系？它可以与外部纪元（如 UTC）同步吗？
// 答：QPC 基于一个硬件计数器，该计数器无法与外部时间参考（如 UTC）同步。如果需要可以
// 与外部 UTC 参考同步的精确时间戳，请使用 GetSystemTimePreciseAsFileTime。
//
// 问：QPC 是否受夏令时、闰秒、时区或管理员更改系统时间的影响？
// 答：不会。QPC 完全独立于系统时间和 UTC。
//
// 问：QPC 的准确性是否受电源管理或 Turbo Boost 技术导致的处理器频率变化的影响？
// 答：不会。如果处理器具有不变 TSC，则 QPC 不受这些变化的影响。如果处理器没有不变
// TSC，则 QPC 将改用不受处理器频率变化或 Turbo Boost 技术影响的平台硬件计时器。
//
// 问：QPC 是否能在多处理器系统、多核系统以及具有超线程技术的系统上可靠工作？
// 答：是的。
//
// 问：我如何确定并验证 QPC 在我的机器上是否工作正常？
// 答：你无需进行此类检查。
//
// 问：哪些处理器具有非不变 TSC？我如何检查我的系统是否具有非不变 TSC？
// 答：你无需自行进行此检查。Windows 操作系统在系统初始化时会进行多项检查，以确定
// TSC 是否适合作为 QPC 的基础。不过，出于参考目的，你可以通过以下方式之一确定你的
// 处理器是否具有不变 TSC：
// - 使用 Windows Sysinternals 的 Coreinfo.exe 工具
// - 检查与 TSC 特性相关的 CPUID 指令返回的值
// - 查阅处理器制造商的文档
//
// 以下是 Windows Sysinternals Coreinfo.exe 工具（www.sysinternals.com）提供的
// TSC-INVARIANT 信息示例（带星号表示“真”）：
//
// > Coreinfo.exe
// RDTSCP          * Supports RDTSCP instruction
// TSC             * Supports RDTSC instruction
// TSC-DEADLINE    - Local APIC supports one-shot deadline timer
// TSC-INVARIANT   * TSC runs at constant rate
//
// 问：QPC 是否能在 Windows RT 硬件平台上可靠工作？
// 答：是的。
//
// 问：QPC 的回绕频率是多少？
// 答：从最近一次系统启动起，至少 100 年内不会回绕，具体取决于所用的基础硬件计时器。
// 对于大多数应用程序来说，回绕并不是一个需要担心的问题。
//
// 问：调用 QPC 的计算成本是多少？
// 答：调用 QPC 的计算成本主要取决于基础硬件平台。如果以 TSC 寄存器作为 QPC 的基础，
// 则计算成本主要取决于处理器处理 RDTSC 指令所需的时间。根据所用的处理器，这个时间范
// 围从几十个 CPU 周期到几百个 CPU 周期不等。如果无法使用 TSC，则系统会选择其他硬件
// 时间基础。由于这些时间基础位于主板上（例如，在 PCI 南桥或 PCH 上），每次调用的计
// 算成本会高于 TSC，通常根据处理器速度和其他硬件因素，接近 0.8 - 1.0 微秒。这个成
// 本主要由访问主板上的硬件设备所需的时间决定。
//
// 问：调用 QPC 是否需要进行内核转换（系统调用）？
// 答：如果系统可以使用 TSC 寄存器作为 QPC 的基础，则不需要内核转换。如果系统必须使
// 用其他时间基础（如 HPET 或 PM 时钟），则需要系统调用。
//
// 问：性能计数器是否单调（非递减）？
// 答：是的。QPC 不会倒退。
//
// 问：性能计数器是否可用于对事件按时间排序？
// 答：可以。但是，当比较从不同线程获取的性能计数器结果时，相差 ±1 个时钟周期的值具有
// 模糊的顺序，就好像它们具有相同的时间戳一样。
//
// 问：性能计数器的准确性如何？
// 答：这取决于多种因素。更多信息，请参阅低级硬件时钟特性（Low-level hardware clock
// characteristics）。
//
// 问：我需要将 QPC 输出转换为毫秒。如何避免在转换为双精度或单精度浮点数时丢失精度？
// 答：在对整数性能计数器进行计算时，需要注意以下几点：
// - 整数除法会丢失余数。在某些情况下，这可能会导致精度丢失。
// - 在 64 位整数和浮点数（双精度）之间进行转换可能会导致精度丢失，因为浮点数的尾数部
//   分无法表示所有可能的整数值。
// - 64 位整数的乘法可能会导致整数溢出。
// - 一般来说，尽可能延迟这些计算和转换，以避免累积引入的误差。
//
// 问：我如何将 QPC 转换为 100 纳秒的时间间隔，以便将其添加到 FILETIME 中？
// 答：文件时间是一个 64 位值，表示自 1601 年 1 月 1 日 12:00 A.M.（UTC）以来经过
// 的 100 纳秒间隔数。文件时间用于返回时间戳的 Win32 API 调用，例如
// GetSystemTimeAsFileTime 和 GetSystemTimePreciseAsFileTime。相比之下，
// QueryPerformanceCounter 返回的值表示以 QueryPerformanceFrequency 获取的性能计
// 数器频率为单位的时间。在两者之间进行转换需要计算 QPC 时间间隔和 100 纳秒时间间隔
// 的比率。注意避免因值较小（例如 0.0000001 / 0.000000340）而丢失精度。
//
// 问：为什么 QPC 返回的时间戳是有符号整数？
// 答：涉及 QPC 时间戳的计算可能涉及减法。通过使用有符号值，可以处理可能得出负值的计
// 算。
//
// 问：我如何从托管代码中获取高分辨率时间戳？
// 答：调用 System.Diagnostics.Stopwatch 类中的 Stopwatch.GetTimeStamp 方法。有
// 关如何使用 Stopwatch.GetTimeStamp 的示例，请参阅从托管代码中获取高分辨率时间戳。
//
// 问：在什么情况下，QueryPerformanceFrequency 返回 FALSE，或者
// QueryPerformanceCounter 返回零？
// 答：在运行 Windows XP 或更高版本的任何系统上，这种情况都不会发生。
//
// 问：我是否需要将线程亲和性设置为单个核心才能使用 QPC？
// 答：不需要。这种场景既不必要也不理想。执行此操作可能会通过将处理限制在一个核心上，
// 或者在多个线程将亲和性设置为同一个核心时调用 QueryPerformanceCounter，从而在单个
// 核心上创建瓶颈，从而对应用程序的性能产生不利影响。This scenario is neither
// necessary nor desirable. Performing this scenario might adversely affect
// your application's performance by restricting processing to one core or
// by creating a bottleneck on a single core if multiple threads set their
// affinity to the same core when calling QueryPerformanceCounter.
//
// https://learn.microsoft.com/en-us/windows/win32/sysinfo/acquiring-high-resolution-time-stamps#low-level-hardware-clock-characteristics
//
// 底层硬件时钟特性（Low-level hardware clock characteristics）
//
// Absolute Clocks and Difference Clocks
//
// 绝对时钟提供准确的时间读数。它们通常基于协调世界时（UTC），因此其准确性部分取决于它
// 们与外部时间参考的同步程度。例如，通过网络时间协议（NTP）或全球定位系统（GPS）来同
// 步。差分时钟用于测量时间间隔，通常不基于外部时间纪元。QPC 是一个差分时钟，不与外部
// 时间纪元或参考同步。当你使用 QPC 进行时间间隔测量时，通常会比使用基于绝对时钟的时间
// 戳获得更高的精度。这是因为同步绝对时钟的时间可能会引入相位和频率变化，从而增加短期时
// 间间隔测量的不确定性。当绝对时钟与外部时间源同步时，可能会出现时间的跳跃（相位变
// 化）。例如，如果系统时钟与 NTP 服务器同步，可能会出现几毫秒甚至更长时间的调整。为了
// 使系统时钟与外部时间源保持同步，系统可能会调整时钟频率。这种频率调整会影响短期时间间
// 隔的测量精度。
//
// Resolution, Precision, Accuracy, and Stability
//
// QPC 以硬件计数器为基础。硬件计时器由三部分组成：一个时钟脉冲生成器、一个用于计数
// 时钟脉冲的计数器，以及一种取回计数器值的方法。这三部分的特性决定了 QPC 的分辨率、
// 精度、准确性和稳定性。
//
// 如果硬件生成器以恒定速率提供时钟脉冲，那么可以通过简单地计数这些时钟脉冲来测量时间
// 间隔。时钟脉冲生成的速率称为频率，以赫兹（Hz）表示。频率的倒数称为周期或时钟脉冲间
// 隔，以适当的国际单位制（SI）时间单位表示（例如，秒、毫秒、微秒或纳秒）。计时器的分
// 辨率等于周期。分辨率决定了区分任意两个时间戳的能力，并为可测量的最小时间间隔设定了
// 下限。这有时被称为时钟脉冲分辨率。
//
// 由于数字计数器以离散步骤前进，而时间是连续流逝的，因此数字时间测量引入了 ±1 个时钟
// 脉冲的测量不确定性。这种不确定性被称为量化误差。对于典型的时间间隔测量，这种效应通
// 常可以忽略不计，因为量化误差远小于正在测量的时间间隔。然而，如果被测量的周期很小，
// 并且接近计时器的分辨率，那么你需要考虑这种量化误差。引入的误差大小为一个时钟周期。
// 以下两个图表通过使用分辨率为 1 个时间单位的计时器，说明了 ±1 个时钟脉冲不确定性的
// 影响。
//          两个时间戳的读数都是0，因为分辨率的原因它们不可分辨
//          |      |
//          v      v
//          |-------|-------|-------|-------|
//          0       1       2       3       4
//
//          两个时间戳的间隔为1个时间单位，但实际的间隔比这个小很多
//                         | |
//                         v v
//          |-------|-------|-------|-------|
//          0       1       2       3       4
//
// QueryPerformanceFrequency 返回 QPC 的频率，周期和分辨率等于该值的倒数。
// QueryPerformanceFrequency 返回的性能计数器频率是在系统初始化期间确定的，并且在系
// 统运行期间不会改变。通常，QueryPerformanceFrequency 并不返回硬件时钟脉冲生成器的
// 实际频率。例如，在某些旧版本的 Windows 中，QueryPerformanceFrequency 返回 TSC
// 频率值除以 1024；而在运行支持虚拟化程序版本 1.0 接口（或在某些较新版本的 Windows
// 中始终如此）的虚拟化程序时，性能计数器频率被固定为 10 MHz（100nsec）。因此，不要
// 假设 QueryPerformanceFrequency 会返回基于硬件频率的值。QueryPerformanceCounter
// 读取性能计数器，并返回自 Windows 操作系统启动以来发生的总时钟脉冲数，包括机器处于
// 待机、休眠或连接待机等睡眠状态的时间。
//
// 从软件中访问（读取）时钟脉冲计数器需要时间，这种访问时间可能会降低时间测量的精度。
// 这是因为最小可测量时间间隔（能够测量的最小时间间隔）是分辨率和访问时间中较大的那个：
// 精度 = MAX [分辨率，访问时间]。例如，假设有一个假设性的硬件计时器，其分辨率为 100
// 纳秒，访问时间为 800 纳秒。如果使用平台计时器而不是 TSC 寄存器作为 QPC 的基础，就
// 可能出现这种情况。因此，精度将是 800 纳秒，而不是 100 纳秒。
//
// 如果访问时间大于分辨率，不要试图通过猜测来提高精度。换句话说，假设时间戳正好在函数
// 调用的中间、开始或结束时被获取，这是一种错误。相比之下，考虑以下示例，其中 QPC 的
// 访问时间仅为 20 纳秒，而硬件时钟的分辨率为 100 纳秒。如果使用 TSC 寄存器作为 QPC
// 的基础，就可能出现这种情况。在这里，精度由时钟分辨率限制。在实践中，你可以找到读取
// 计数器所需的时间大于或小于分辨率的时间源。在这两种情况下，精度将是两者中较大的那个。
// 下表提供了各种时钟的近似分辨率、访问时间和精度的信息。请注意，其中一些值会因不同的
// 处理器、硬件平台和处理器速度而有所不同。
//
//      时钟源              正常时钟频率    时钟分辨率  一般访问时间    精度
//      PC RTC                  64Hz        15.625ms    N/A         N/A
//      QPC TSC with 3GHz       3MHz        333ns       30ns        333ns
//      processor clock
//      RDTSC instruction       3GHz        333picosec  30ns        30ns
//      with 3GHz cycle time
//
// 因为 QPC 使用硬件计数器，所以当你了解一些硬件计数器的基本特性时，你就能了解 QPC 的
// 能力和限制。最常用的硬件时钟脉冲生成器是晶体振荡器。晶体是石英或其他陶瓷材料的小片，
// 它具有压电特性，能够提供一个廉价的频率参考，具有极好的稳定性和准确性。这个频率用于
// 生成时钟计数的时钟脉冲。时钟的准确性指的是与真实或标准值的一致程度。这主要取决于晶
// 体振荡器以指定频率提供时钟脉冲的能力。如果振荡频率过高，时钟会“走得快”，测量的时间
// 间隔会显得比实际长；如果频率过低，时钟会“走得慢”，测量的时间间隔会显得比实际短。对
// 于短时间间隔的典型时间间隔测量（例如，响应时间测量、网络延迟测量等），硬件振荡器的
// 准确性通常就足够了。然而，对于某些测量，振荡器频率的准确性变得很重要，特别是对于长
// 时间间隔或当你想比较在不同机器上进行的测量时。本节的其余部分探讨了振荡器准确性的影
// 响。
//
// 晶体的振荡频率是在制造过程中设定的，制造商以“百万分率”（ppm，parts per million）
// 表示最大频率偏移，称为最大频率偏移。一个标称频率为 1,000,000 Hz、最大频率偏移为
// ±10 ppm 的晶体，如果其实际频率在 999,990 Hz 到 1,000,010 Hz 之间，则符合规格。
// 将“百万分率”替换为“每秒微秒数”，我们可以将这种频率偏移误差应用于时间间隔测量。一个
// 偏移为 +10 ppm 的振荡器每秒会有 10 微秒的误差。例如测量 1 秒的时间间隔，可能将 1
// 秒的时间间隔测量为 0.999990 秒。一个方便的参考是，100 ppm 的频率误差会导致 24 小
// 时后产生 8.64 秒的误差。下表列出了由于累积误差导致的更长时间间隔的测量不确定性。
//
//      时间间隔        时钟频率偏移误差±10ppm产生的时间偏移
//      1usec           ±10picosec 每微妙10皮秒误差
//      1msec           ±10nsec 每毫秒10纳秒误差
//      1sec            ±10usec 每秒10微妙误差
//      1min            ±600usec
//      1hour           ±36msec
//      1day            ±0.86sec
//      1week           ±6.08sec
//
// 上表表明，对于短时间间隔，频率偏移误差（frequency offset error）通常可以忽略不计。
// 然而，对于长时间间隔，即使是小的频率偏移也可能导致相当大的测量不确定性。个人计算机
// 和服务器中使用的晶体振荡器通常制造时的频率公差为 ±30 到 50 ppm，很少情况下，晶体的
// 偏差可能高达 500 ppm。尽管可以提供频率偏移公差更小的晶体，但它们更昂贵，因此在大多
// 数计算机中没有使用。为了减少这种频率偏移误差的不利影响，最近版本的 Windows，特别是
// Windows 8，使用多个硬件计时器来检测频率偏移，并尽可能进行补偿。这个校准过程在启动
// Windows 时执行。如以下示例所示，硬件时钟的频率偏移误差影响了可实现的准确性，而时钟
// 的分辨率可能没那么重要。总之，当测量长时间间隔以及在不同系统之间比较测量结果时，频
// 率偏移误差变得越来越重要。时钟的稳定性描述了时钟频率是否会随时间变化，例如由于温度
// 变化的结果。用作计算机时钟脉冲生成器的石英晶体将表现出随温度变化的频率小幅度变化。
// 对于常见的温度范围，由热漂移引起的误差通常比频率偏移误差小得多。然而，为便携式设备
// 或受大温度波动影响的设备设计软件的人员可能需要考虑这种效应。
//
// 示例 1：假设你使用一个 1 MHz 的振荡器进行时间间隔测量，其分辨率为 1 微秒，最大频率
// 偏移误差为 ±50 ppm。现在，假设偏移量正好是 +50 ppm。这意味着实际频率将是
// 1,000,050 Hz。如果我们测量一个 24 小时的时间间隔，我们的测量值将比实际值短 4.3
// 秒（实际 24:00:00.000000，测量值为 23:59:55.700000）。
//      一天中的秒数 = 86,400
//      频率偏移误差 = 50ppm = 0.00005 每秒偏50微妙
//      86,400 秒 × 0.00005 = 4.3 秒
//
// 示例 2：假设处理器的 TSC 时钟由一个晶体振荡器控制，其标称频率为 3 GHz。这意味着分
// 辨率将是 1/3,000,000,000，约为 333 皮秒。假设用于控制处理器时钟的晶体的实际频率误
// 差为 ±50 ppm，并且实际偏移量为 +50 ppm。尽管分辨率令人印象深刻，但测量一个 24 小
// 时的时间间隔仍将比实际值短 4.3 秒（实际 24:00:00.0000000000，测量值为
// 23:59:55.7000000000）。
//      一天中的秒数 = 86,400
//      频率偏移误差 = 50 ppm = 0.00005
//      86,400 秒 × 0.00005 = 4.3 秒
// 这表明，高分辨率的 TSC 时钟不一定比低分辨率的时钟提供更准确的测量结果。
//
// 示例 3：考虑使用两台不同的计算机来测量同一个 24 小时的时间间隔。两台计算机的振荡器
// 的最大频率偏移均为 ±50 ppm。这两台系统对同一时间间隔的测量结果最多能相差多远？与前
// 面的示例一样，±50 ppm 在 24 小时内产生的最大误差为 ±4.3 秒。如果一个系统快了 4.3
// 秒，而另一个系统慢了 4.3 秒，那么 24 小时后的最大误差可能为 8.6 秒。
//      一天中的秒数 = 86,400
//      频率偏移误差 = ±50 ppm = ±0.00005
//      ±(86,400 秒 × 0.00005) = ±4.3 秒
//
// https://learn.microsoft.com/en-us/windows/win32/sysinfo/time-functions
// https://learn.microsoft.com/en-us/windows/win32/multimedia/multimedia-timers
//
// FILETIME structure minwinbase.h (include Windows.h) Windows 2000
// Contains a 64-bit value representing the number of 100-nanosecond intervals
// since January 1, 1601 (UTC).
//      typedef struct _FILETIME {
//          DWORD dwLowDateTime;
//          DWORD dwHighDateTime;
//      } FILETIME;
//
// void GetSystemTimeAsFileTime(FILETIME *out); Windows 2000
// sysinfoapi.h (include Windows.h) Kernel32.lib Kernel32.dll
//      Retrieves the current system date and time. The information is in
//      Coordinated Universal Time (UTC) format.
//
// void GetSystemTimePreciseAsFileTime(FILETIME *out); Windows 8 Windows Server 2012
// sysinfoapi.h (include Windows.h) Kernel32.lib Kernel32.dll
//      The GetSystemTimePreciseAsFileTime function retrieves the current
//      system date and time with the highest possible level of precision
//      (<1us). The retrieved information is in Coordinated Universal Time
//      (UTC) format.
//      Note  This function is best suited for high-resolution time-of-day
//      measurements, or time stamps that are synchronized to UTC. For
//      high-resolution interval measurements, use QueryPerformanceCounter
//      or KeQueryPerformanceCounter. For more info about acquiring
//      high-resolution time stamps, see Acquiring high-resolution timestamps.
//
// ULONGLONG GetTickCount64(); Windows Vista Windows Server 2008
// sysinfoapi.h (include Windows.h) Kernel32.lib Kernel32.dll
//      Retrieves the number of milliseconds that have elapsed since the system
//      was started.
//      The resolution of the GetTickCount64 function is limited to the
//      resolution of the system timer, which is typically in the range of
//      10 milliseconds to 16 milliseconds. The resolution of the
//      GetTickCount64 function is not affected by adjustments made by the
//      GetSystemTimeAdjustment function.
//      If you need a higher resolution timer, use a multimedia timer or a
//      high-resolution timer.
//      To compile an application that uses this function, define _WIN32_WINNT
//      as 0x0600 or later. For more information, see Using the Windows
//      Headers.
//
// LARGE_INTEGER union (winnt.h)
//      The LARGE_INTEGER structure is actually a union. If your compiler has
//      built-in support for 64-bit integers, use the QuadPart member to store
//      the 64-bit integer. Otherwise, use the LowPart and HighPart members to
//      store the 64-bit integer.
//      typedef union _LARGE_INTEGER {
//          struct {
//              DWORD LowPart;
//              LONG HighPart;
//          } DUMMYSTRUCTNAME;
//          struct {
//              DWORD LowPart;
//              LONG HighPart;
//          } u;
//          LONGLONG QuadPart; // a signed 64-bit integer
//      } LARGE_INTEGER;
//
// BOOL QueryPerformanceCounter(LARGE_INTEGER *count); Windows 2000
// profileapi.h (include Windows.h) Kernel32.lib Kernel32.dll
//      If the function fails, the return value is zero. To get extended error
//      information, call GetLastError. On systems that run Windows XP or
//      later, the function will always succeed and will thus never return
//      zero.
//      For more info about this function and its usage, see Acquiring
//      high-resolution time stamps.
//
// BOOL QueryPerformanceFrequency(LARGE_INTEGER *frequency); Windows 2000
// profileapi.h (include Windows.h) Kernel32.lib Kernel32.dll
//      Retrieves the frequency of the performance counter. The frequency of
//      the performance counter is fixed at system boot and is consistent
//      across all processors. Therefore, the frequency need only be queried
//      upon application initialization, and the result can be cached.
//      A pointer to a variable that receives the current performance-counter
//      frequency, in counts per second. If the installed hardware doesn't
//      support a high-resolution performance counter, this parameter can be
//      zero (this will not occur on systems that run Windows XP or later).
//      If the function fails, the return value is zero. To get extended error
//      information, call GetLastError. On systems that run Windows XP or
//      later, the function will always succeed and will thus never return
//      zero.
#define PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_SECS 0x00000002B6109100LL // 11644473600-sec
#define PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_MSEC 0x00000A9730B66800LL // 11644473600000-msec
#define PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_USEC 0x00295E9648864000LL // 11644473600000000-usec
#define PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_100N 0x019DB1DED53E8000LL // 116444736000000000-100nsec

void prh_impl_1970_utc_secs_to_filetime(prh_i64 secs, FILETIME *f) {
    // The time functions included in the C run-time use the time_t type to
    // represent the number of seconds elapsed since midnight, January 1, 1970.
    // The following example converts a time_t value to a FILETIME.
    //      void TimetToFileTime(time_t t, FILETIME *f) {
    //          ULARGE_INTEGER time_value;
    //          time_value.QuadPart = (t * 10000000LL) + 116444736000000000LL;
    //          f->dwLowDateTime = time_value.LowPart;
    //          f->dwHighDateTime = time_value.HighPart;
    //      }
    // FILETIME 单位为 100 纳秒，从 1601/1/1 为基准开始。
    secs = (secs + PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_SECS) * 10000000;
    f->dwLowDateTime = (DWORD)(secs & 0xFFFFFFFF);
    f->dwHighDateTime = (DWORD)(secs >> 32);
}

prh_i64 prh_impl_1970_utc_time_secs(const FILETIME *f) {
    prh_i64 secs = ((prh_i64)f->dwHighDateTime << 32) | f->dwLowDateTime;
    return secs / 10000000 - PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_SECS;
}

prh_i64 prh_impl_1970_utc_time_msec(const FILETIME *f) {
    prh_i64 msec = ((prh_i64)f->dwHighDateTime << 32) | f->dwLowDateTime;
    return msec / 10000 - PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_MSEC;
}

prh_i64 prh_impl_1970_utc_time_usec(const FILETIME *f) {
    prh_i64 usec = ((prh_i64)f->dwHighDateTime << 32) | f->dwLowDateTime;
    return usec / 10 - PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_USEC;
}

prh_i64 prh_impl_1970_utc_time_nsec(const FILETIME *f) {
    prh_i64 nsec = ((prh_i64)f->dwHighDateTime << 32) | f->dwLowDateTime;
    return (nsec - PRH_IMPL_FILETIME_DELTA_FROM_EPOCH_100N) * 100;
}

prh_i64 prh_impl_filetime_nsec(const FILETIME *f) {
    prh_i64 nsec = ((prh_i64)f->dwHighDateTime << 32) | f->dwLowDateTime;
    return nsec * 100;
}

prh_i64 prh_impl_system_time(void) {
    FILETIME f;
    GetSystemTimePreciseAsFileTime(&f);
    return ((prh_i64)f.dwHighDateTime << 32) | f.dwLowDateTime;
}

prh_i64 prh_system_secs(void) { // 可表示2.9千亿年
    FILETIME f;
    GetSystemTimePreciseAsFileTime(&f);
    return prh_impl_1970_utc_time_secs(&f);
}

prh_i64 prh_system_msec(void) { // 可表示2.9亿年
    FILETIME f;
    GetSystemTimePreciseAsFileTime(&f);
    return prh_impl_1970_utc_time_msec(&f);
}

void prh_impl_system_filetime(FILETIME *f) {
    GetSystemTimePreciseAsFileTime(f);
}

prh_i64 prh_system_usec(void) { // 可表示29万年
    FILETIME f;
    prh_impl_system_filetime(&f);
    return prh_impl_1970_utc_time_usec(&f);
}

void prh_impl_usec_to_timeusec(prh_timeusec *utc_time, prh_i64 usec) {
    utc_time->secs = usec / PRH_USEC_PER_SEC;
    utc_time->usec = usec % PRH_USEC_PER_SEC;
}

void prh_system_time(prh_timeusec *utc_time) {
    prh_impl_usec_to_timeusec(utc_time, prh_system_usec());
}

void prh_impl_date_time(prh_datetime *t, const SYSTEMTIME *s, prh_i32 usec) {
    // typedef struct _SYSTEMTIME {
    //      WORD wYear;         // the valid value is 1601 ~ 30827
    //      WORD wMonth;        // 1 ~ 12
    //      WORD wDayOfWeek;    // 0 ~ 6 (Sunday = 0)
    //      WORD wDay;          // 1 ~ 31
    //      WORD wHour;         // 0 ~ 23
    //      WORD wMinute;       // 0 ~ 59
    //      WORD wSecond;       // 0 ~ 59
    //      WORD wMilliseconds; // 0 ~ 999
    // } SYSTEMTIME;
    // Windows 2000 Professional Windows 2000 Server
    // minwinbase.h (include Windows.h)
    //      The system can periodically refresh the time by synchronizing with
    //      a time source. Because the system time can be adjusted either
    //      forward or backward, do not compare system time readings to
    //      determine elapsed time.
    //      The SYSTEMTIME does not check to see if the date represented is a
    //      real and valid date. When working with this API, you should ensure
    //      its validity, especially in leap year scenarios. See leap day
    //      readiness for more information.
    //      https://techcommunity.microsoft.com/blog/azuredevcommunityblog/it%e2%80%99s-2020-is-your-code-ready-for-leap-day/1157279
    t->year = s->wYear;
    t->month = (prh_byte)s->wMonth;
    t->mday = (prh_byte)s->wDay;
    t->wday = (prh_byte)s->wDayOfWeek;
    t->hour = (prh_byte)s->wHour;
    t->min = (prh_byte)s->wMinute;
    t->sec = (prh_byte)s->wSecond;
    t->usec = usec;
}

void prh_impl_system_date(SYSTEMTIME *s, const prh_datetime *t) {
    s->wYear = (WORD)t->year;
    s->wMonth = t->month;
    s->wDayOfWeek = t->wday;
    s->wDay = t->mday;
    s->wHour = t->hour;
    s->wMinute = t->min;
    s->wSecond = t->sec;
    s->wMilliseconds = 0;
}

void prh_system_time_from_date(prh_timeusec *utc_time, const prh_datetime *utc_date) {
    SYSTEMTIME s; FILETIME f;
    prh_impl_system_date(&s, utc_date);
    PRH_BOOLRET_OR_ABORT(SystemTimeToFileTime(&s, &f));
    prh_impl_usec_to_timeusec(utc_time, prh_impl_1970_utc_time_usec(&f) + utc_date->usec);
}

void prh_system_time_from_local_date(prh_timeusec *utc_time, const prh_datetime *local_date) {
    SYSTEMTIME local, s; FILETIME f;
    prh_impl_system_date(&local, local_date);
    PRH_BOOLRET_OR_ABORT(TzSpecificLocalTimeToSystemTime(prh_null, &local, &s));
    PRH_BOOLRET_OR_ABORT(SystemTimeToFileTime(&s, &f));
    prh_impl_usec_to_timeusec(utc_time, prh_impl_1970_utc_time_usec(&f) + local_date->usec);
}

void prh_system_date(prh_datetime *utc_date) {
    FILETIME f; SYSTEMTIME s;
    prh_impl_system_filetime(&f);
    prh_i64 filetime = ((prh_i64)f.dwHighDateTime << 32) | f.dwLowDateTime;
    prh_boolret(FileTimeToSystemTime(&f, &s));
    prh_impl_date_time(utc_date, &s, filetime / 10 % 1000000);
}

void prh_local_date(prh_datetime *local_date) {
    FILETIME f; SYSTEMTIME s, local;
    prh_impl_system_filetime(&f);
    prh_i64 filetime = ((prh_i64)f.dwHighDateTime << 32) | f.dwLowDateTime;
    prh_boolret(FileTimeToSystemTime(&f, &s));
    prh_boolret(SystemTimeToTzSpecificLocalTime(prh_null, &s, &local));
    prh_impl_date_time(local_date, &local, filetime / 10 % 1000000);
}

void prh_local_date_from(prh_datetime *local_date, const prh_timeusec *utc_time) {
    FILETIME f; SYSTEMTIME s, local;
    prh_impl_1970_utc_secs_to_filetime(utc_time->secs, &f);
    PRH_BOOLRET_OR_ABORT(FileTimeToSystemTime(&f, &s));
    PRH_BOOLRET_OR_ABORT(SystemTimeToTzSpecificLocalTime(prh_null, &s, &local));
    prh_impl_date_time(local_date, &local, utc_time->usec);
}

void prh_system_date_from(prh_datetime *utc_date, const prh_timeusec *utc_time) {
    // void GetSystemTime(SYSTEMTIME *SystemTime);
    // void GetLocalTime(SYSTEMTIME *SystemTime);
    // Windows 2000 Professional Windows 2000 Server
    // sysinfoapi.h (include Windows.h) Kernel32.lib Kernel32.dll
    //      GetSystemTime retrieves the current system date and time in
    //      Coordinated Universal Time (UTC) format.
    //      GetLocalTime retrieves the current local date and time.
    //
    // BOOL SystemTimeToTzSpecificLocalTime(
    //          const TIME_ZONE_INFORMATION *TimeZoneInformation, [optional]
    //          const SYSTEMTIME *UniversalTime,
    //          SYSTEMTIME *LocalTime);
    // Windows 2000 Professional Windows 2000 Server
    // timezoneapi.h (include Windows.h) Kernel32.lib Kernel32.dll
    //      Converts a time in Coordinated Universal Time (UTC) to a specified
    //      time zone's corresponding local time.
    //      TimeZoneInformation pointer to a TIME_ZONE_INFORMATION structure
    //      that specifies the time zone of interest. If TimeZoneInformation
    //      is NULL, the function uses the currently active time zone.
    //      The SystemTimeToTzSpecificLocalTime function takes into account
    //      whether daylight saving time (DST) is in effect for the local time
    //      to which the system time is to be converted.
    //      The SystemTimeToTzSpecificLocalTime function may calculate the
    //      local time incorrectly under the following conditions: The time
    //      zone uses a different UTC offset for the old and new years. The
    //      UTC time to be converted and the calculated local time are in
    //      different years.
    //      If the function fails, the return value is zero. To get extended
    //      error information, call GetLastError.
    //
    // BOOL TzSpecificLocalTimeToSystemTime(
    //          const TIME_ZONE_INFORMATION *TimeZoneInformation, [optional]
    //          const SYSTEMTIME *LocalTime,
    //          SYSTEMTIME *UniversalTime);
    // Windows XP Windows Server 2003
    // timezoneapi.h (include Windows.h) Kernel32.lib Kernel32.dll
    //      Converts a local time to a time in Coordinated Universal Time
    //      (UTC). TimeZoneInformation pointer to a TIME_ZONE_INFORMATION
    //      structure that specifies the time zone for the time specified
    //      in LocalTime. If TimeZoneInformation is NULL, the function uses
    //      the currently active time zone.
    //      If the function fails, the return value is zero. To get extended
    //      error information, call GetLastError.
    //      TzSpecificLocalTimeToSystemTime takes into account whether daylight
    //      saving time (DST) is in effect for the local time to be converted.
    //
    // BOOL FileTimeToSystemTime(const FILETIME *FileTime, SYSTEMTIME *out);
    // BOOL SystemTimeToFileTime(const SYSTEMTIME *SystemTime, FILETIME *out);
    // Windows XP Windows Server 2003
    // timezoneapi.h (include Windows.h) Kernel32.lib Kernel32.dll
    //      FileTimeToSystemTime converts a file time to system time format.
    //      System time is based on Coordinated Universal Time (UTC).
    //      FileTime must be less than 0x8000000000000000. Otherwise, the
    //      function fails.
    //      SystemTimeToFileTime converts a system time to file time format.
    //      System time is based on Coordinated Universal Time (UTC).
    //      The wDayOfWeek member of the SYSTEMTIME structure is ignored.
    //      A False return value can indicate that the passed SYSTEMTIME
    //      structure represents an invalid date. Certain situations, such as
    //      the additional day added in a leap year, can result in application
    //      logic unexpectedly creating an invalid date. For more information
    //      on avoiding these issues, see leap year readiness.
    //      If the function fails, the return value is zero. To get extended
    //      error information, call GetLastError.
    FILETIME f; SYSTEMTIME s;
    prh_impl_1970_utc_secs_to_filetime(utc_time->secs, &f);
    PRH_BOOLRET_OR_ABORT(FileTimeToSystemTime(&f, &s));
    prh_impl_date_time(utc_date, &s, utc_time->usec);
}

// Windows time is the number of milliseconds elapsed since the system was
// last started. You typically use the GetTickCount or GetTickCount64
// function to get the current Windows time. GetTickCount and
// GetTickCount64 are limited to the resolution of the system timer, which
// is approximately 10 milliseconds to 16 milliseconds. The elapsed time
// retrieved by GetTickCount or GetTickCount64 includes time the system
// spends in sleep or hibernation.（精度 10msec ~ 16msec）
//
// If you need a higher resolution timer, use the QueryUnbiasedInterruptTime
// function, a multimedia timer, or a high-resolution timer. The elapsed
// time retrieved by the QueryUnbiasedInterruptTime function includes only
// time that the system spends in the working state. The
// QueryUnbiasedInterruptTime function is available starting with Windows 7
// and Windows Server 2008 R2.（精度 0.5msec ~ 15.625msec）
//
// You can use the System Up Time performance counter to obtain the number
// of seconds elapsed since the computer was started. This performance
// counter can be retrieved from the performance data in the registry key
// HKEY_PERFORMANCE_DATA. The value returned is an 8-byte value. Windows
// Performance Counters provide a high-level abstraction layer that
// provides a consistent interface for collecting various kinds of system
// data such as CPU, memory, and disk usage. System administrators often
// use performance counters to monitor systems for performance or behavior
// problems. Software developers often use performance counters to examine
// the resource usage of their programs.
// https://learn.microsoft.com/en-us/windows/win32/perfctrs/performance-counters-portal
//
// https://learn.microsoft.com/en-us/windows/win32/sysinfo/interrupt-time
// Interrupt time is the amount of time since the system was last started,
// in 100-nanosecond intervals. The interrupt-time count begins at zero
// when the system starts and is incremented at each clock interrupt by
// the length of a clock tick. The exact length of a clock tick depends
// on underlying hardware and can vary between systems.
//
// Unlike system time, the interrupt-time count is not subject to
// adjustments by users or the Windows time service, making it a better
// choice for measuring short durations. Applications that require greater
// precision than the interrupt-time count (system timer tick) should use
// a high-resolution timer (QPC, cpu clock tick).
//
// The QueryInterruptTime[Precise], QueryUnbiasedInterruptTime[Precise]
// functions can be used to retrieve the interrupt-time count. Unbiased
// interrupt-time means that only time that the system is in the working
// state is counted — therefore, the interrupt-time count is not "biased"
// by time the system spends in sleep or hibernation. 无偏差中断时间，即不
// 会因为系统睡眠或休眠而产生偏差，其实就是对睡眠或休眠无感只统计实际工作状态的
// 时间。
//
// The timer resolution set by the timeBeginPeriod and timeEndPeriod
// functions affects the resolution of the QueryInterruptTime and
// QueryUnbiasedInterruptTime functions. However, increasing the timer
// resolution is not recommended because it can reduce overall system
// performance and increase power consumption by preventing the processor
// from entering power-saving states. Instead, applications should use a
// high-resolution timer.
//
// These functions produces different results on debug ("checked") builds
// of Windows, because the interrupt-time count and tick count are advanced
// by approximately 49 days. This helps to identify bugs that might not
// occur until the system has been running for a long time. 在调试模式下，
// 中断时间被设置大约最多可表示49天时间，以帮助方便鉴别程序问题。
//
// void QueryInterruptTime(ULONGLONG *InterruptTime); // 精度 0.5msec ~ 15.625msec
// void QueryInterruptTimePrecise(ULONGLONG *InterruptTime);
// Windows 7 Windows Server 2008 R2
// realtimeapiset.h (include Windows.h) Mincore.lib Kernel32.dll
//      Receive the interrupt-time count in system time units of 100
//      nanoseconds (same as FILETIME).
//      QueryInterruptTimePrecise is similar to the QueryInterruptTime
//      routine, but is more precise. The interrupt time reported by
//      QueryInterruptTime is based on the latest tick of the system clock
//      timer. The system clock timer is the hardware timer that
//      periodically generates interrupts for the system clock. The uniform
//      period between system clock timer interrupts is referred to as a
//      system clock tick, and is typically in the range of 0.5 milliseconds
//      to 15.625 milliseconds, depending on the hardware platform. The
//      interrupt time value retrieved by QueryInterruptTime is accurate
//      within a system clock tick.
//      To provide a system time value that is more precise than that of
//      QueryInterruptTime, QueryInterruptTimePrecise reads the timer
//      hardware directly, therefore a QueryInterruptTimePrecise call can
//      be slower than a QueryInterruptTime call.
//      Call the KeQueryTimeIncrement routine to determine the duration of
//      a system clock tick. At startup time, the operating system
//      determines the time increment to use for the system time. This time
//      increment remains constant until the computer restarts. During this
//      time, calls to KeQueryTimeIncrement always return the same time
//      increment value. The time increment does not change while the
//      computer is running, and it does not change as the result of a
//      suspend-resume cycle.
//      To compile an application that uses this function, define
//      _WIN32_WINNT as 0x0601 or later.

prh_i64 prh_steady_secs(void) {
    return (prh_i64)GetTickCount64() / PRH_MSEC_PER_SEC; // 包含睡眠时间
}

prh_i64 prh_steady_msec(void) { // GetTickCount64() 精度 10msec ~ 16msec，包含睡眠时间
    prh_i64 ticks = prh_clock_ticks();
    return prh_elapse_msec(ticks);
}

prh_i64 prh_steady_usec(void) {
    prh_i64 ticks = prh_clock_ticks();
    return prh_elapse_usec(ticks);
}

prh_i64 prh_steady_nsec(void) { // 保存纳秒只能表示292年
    prh_i64 ticks = prh_clock_ticks(); // 精度小于1微妙（<1us），包含待机休眠等睡眠时间
    return prh_elapse_nsec(ticks);
}

// BOOL GetThreadTimes(HANDLE hThread,
//          FILETIME *CreationTime, // the creation time of the thread
//          FILETIME *ExitTime,     // the exit time of the thread. If the thread has not exited, the content of this structure is undefined.
//          FILETIME *KernelTime,   // the amount of time that the thread has executed in kernel mode
//          FILETIME *UserTime);    // the amount of time that the thread has executed in user mode
// Windows XP Windows Server 2003
// processthreadsapi.h (include Windows.h) Kernel32.lib Kernel32.dll
//      Retrieves timing information for the specified thread.
//      If the function fails, the return value is zero. To get extended error
//      information, call GetLastError.
//      Thread creation and exit times are points in time expressed as the
//      amount of time that has elapsed since midnight on January 1, 1601 at
//      Greenwich, England.
//      Thread kernel mode and user mode times are amounts of time. For
//      example, if a thread has spent one second in kernel mode, this function
//      will fill the FILETIME structure specified by lpKernelTime with a
//      64-bit value of ten million. That is the number of 100-nanosecond units
//      in one second.
//      To retrieve the number of CPU clock cycles used by the threads, use
//      the QueryThreadCycleTime function.
//
// BOOL QueryThreadCycleTime(HANDLE handle, ULONG64 CycleTime);
// Windows Vista Windows Server 2008
// realtimeapiset.h (include Windows.h) Mincore.lib Kernel32.dll
//      Retrieves the cycle time for the specified thread. If the function
//      fails, the return value is zero. To get extended error information,
//      call GetLastError.
//      The number of CPU clock cycles used by the thread. This value includes
//      cycles spent in both user mode and kernel mode.
//      To enumerate the threads of the process, use the Thread32First and
//      Thread32Next functions. To get the thread handle for a thread
//      identifier, use the OpenThread function.
//      Do not attempt to convert the CPU clock cycles returned by
//      QueryThreadCycleTime to elapsed time. This function uses timer
//      services provided by the CPU, which can vary in implementation.
//      For example, some CPUs will vary the frequency of the timer when
//      changing the frequency at which the CPU runs and others will leave
//      it at a fixed rate. The behavior of each CPU is described in the
//      documentation provided by the CPU vendor.
//      To compile an application that uses this function, define _WIN32_WINNT
//      as 0x0600 or later.
//
// HANDLE GetCurrentThread();
// Windows XP Windows Server 2003
// processthreadsapi.h (include Windows.h) Kernel32.lib Kernel32.dll
//      Retrieves a pseudo handle for the calling thread.
//      The function cannot be used by one thread to create a handle that can
//      be used by other threads to refer to the first thread. The handle is
//      always interpreted as referring to the thread that is using it. A
//      thread can create a "real" handle to itself that can be used by other
//      threads, or inherited by other processes, by specifying the pseudo
//      handle as the source handle in a call to the DuplicateHandle function.
//      The pseudo handle need not be closed when it is no longer needed.
//      Calling the CloseHandle function with this handle has no effect. If
//      the pseudo handle is duplicated by DuplicateHandle, the duplicate
//      handle must be closed.
prh_i64 prh_thread_time(void) {
    HANDLE pseudo_handle = GetCurrentThread();
    FILETIME creation_time, exit_time, kernel_time, user_time;
    PRH_BOOLRET_OR_ABORT(GetThreadTimes(pseudo_handle, &creation_time, &exit_time, &kernel_time, &user_time));
    return prh_impl_filetime_nsec(&kernel_time) + prh_impl_filetime_nsec(&user_time);
}

prh_i64 prh_clock_ticks(void) {
    LARGE_INTEGER ticks;
    prh_boolret(QueryPerformanceCounter(&ticks));
    return ticks.QuadPart; // LONGLONG
}

void prh_impl_time_init(void) {
    LARGE_INTEGER freq;
    prh_boolret(QueryPerformanceFrequency(&freq));
    PRH_IMPL_TIMEINIT.ticks_per_sec = freq.QuadPart;
}

prh_i64 prh_elapse_secs(prh_i64 ticks) {
    return ticks / PRH_IMPL_TIMEINIT.ticks_per_sec;
}

prh_i64 prh_elapse_msec(prh_i64 ticks) {
    // To guard against loss-of-precision, we convert to microseconds
    // *before* dividing by ticks-per-second.
    return prh_impl_mul_div(ticks, PRH_MSEC_PER_SEC, PRH_IMPL_TIMEINIT.ticks_per_sec);
}

prh_i64 prh_elapse_usec(prh_i64 ticks) {
    // To guard against loss-of-precision, we convert to microseconds
    // *before* dividing by ticks-per-second.
    return prh_impl_mul_div(ticks, PRH_USEC_PER_SEC, PRH_IMPL_TIMEINIT.ticks_per_sec);
}

prh_i64 prh_elapse_nsec(prh_i64 ticks) {
    // To guard against loss-of-precision, we convert to nanoseconds
    // *before* dividing by ticks-per-second.
    return prh_impl_mul_div(ticks, PRH_NSEC_PER_SEC, PRH_IMPL_TIMEINIT.ticks_per_sec);
}

#ifdef PRH_TEST_IMPLEMENTATION
#include <time.h>
void prh_impl_time_test(void) {
    printf("\n\n[MSC][time]\n");
    printf("clock tick frequency %lli\n", (long long)PRH_IMPL_TIMEINIT.ticks_per_sec);
    printf("void * %zd-byte\n", sizeof(void *));
    printf("size_t %zd-byte\n", sizeof(size_t));
    printf("time_t %zi-byte\n", sizeof(time_t)); // seconds
    printf("clock_t %zi-byte\n", sizeof(clock_t));
    printf("CLOCKS_PER_SEC %li\n", CLOCKS_PER_SEC);
    int i, n = 30, count = 0; prh_i64 t1, t2;
    for (i = 0; i < n; i += 1) {
        printf("system time: %lli\n", (long long)prh_system_usec());
    }
    t1 = prh_steady_msec();
    for (i = 0; i < 10; i += 1, count = 0) {
        while ((t2 = prh_steady_msec()) == t1) {
            count += 1;
        }
        printf("steady msec: %lli count %d\n", (long long)t1, count);
        t1 = t2;
    }
    for (i = 0; i < n; i += 1) {
        printf("steady usec: %lli\n", (long long)prh_steady_usec());
    }
    for (i = 0; i < n; i += 1) {
        printf("steady nsec: %lli\n", (long long)prh_steady_nsec());
    }
    for (i = 0; i < n; i += 1) {
        printf("thread nsec: %lli\n", (long long)prh_thread_time());
    }
    for (i = 0; i < n; i += 1) {
        printf("clock ticks: %lli\n", (long long)prh_clock_ticks());
    }
    prh_real_assert(prh_impl_mul_div(1000000000001LL, 1000000000LL, 1000000LL) == 1000000000001000LL);
    long long long_long_number = 1000000000001LL;
    prh_real_assert((long_long_number * 1000000000LL / 1000000LL) != 1000000000001000LL);
}
#endif // PRH_TEST_IMPLEMENTATION
#else // POSIX BEGIN
// 无论地理位置如何，UNIX系统内部对时间的表示方式均是以自Epoch以来的秒数来度量的，
// Epoch亦即通用协调时间（UTC，以前也称为格林威治时间或GMT）的1970年1月1日早晨零点。
// 这也是UNIX系统问世的大致日期。日历时间存储于类型为time_t的变量中，此类型是由SUSv3
// 定义的整数类型。在32位Linux系统，time_t是一个有符号整数，可以表示的日期范围从1901
// 年12月13日20时45分52秒至2038年1月19日03时14分07秒，SUSv3未定义time_t值为负数时
// 的含义。因此当前许多32位UNIX系统都面临一个2038年的理论问题，如果执行的计算工作涉及
// 未来日期，纳秒在2038年之前就会与之遭遇。事实上到了2038年，可能所有的UNIX系统都早已
// 升级为64位或更多位数的系统，这一问题也许会随之而大为缓解。然而32位嵌入式系统，由于
// 其寿命较台式机硬件更长，故而仍然会少此问题的困扰。此外，对于依然以32位time_t格式
// 保存时间的历史数据和应用程序，这个问题将依然存在。
//
// #include <sys/time.h>
// int gettimeofday(struct timeval *tv, struct timezone *tz);
// struct timeval {
//     time_t tv_sec;       // seconds since 00:00:00 1 Jan 1970 UTC
//     suseconds_t tv_usec; // additional microseconds (long int)
// };
//      Return 0 for success. On error, -1 is returned and errno is set to
//      indicate the error.
//      参数tz是历史产物，早期的UNIX实现用其来获取系统的时区信息，目前已遭废弃，应
//      始终将其置为NULL。
// #include <time.h>
// time_t time(NULL);
//      返回相当于gettimeofday的tv_sec值，之所以存在两个本质上目的相同的系统调用，
//      自有历史原因。早期的UNIX实现提供了time()，而4.3BSD又补充了更为精确的
//      gettimeofday系统调用。
//
// SVr4, 4.3BSD. POSIX.1-2001 describes gettimeofday() but not settimeofday().
// POSIX.1-2008 marks gettimeofday() as obsolete, recommending the use of
// clock_gettime(2) instead.
// The time returned by gettimeofday() is affected by discontinuous jumps in
// the system time (e.g., if the system administrator manually changes the
// system time). If you need a monotonically increasing clock, see
// clock_gettime(2).
//
// 这里所描述的时间相关的各种系统调用的精度是受限于系统软件时钟（software clock）的
// 分辨率，它的度量单位被称为 jiffies。jiffies 的大小是定义在内核源代码的常量HZ。这
// 是内核按照round-robin的分时调度算法分配CPU进程的单位。
// 在2.4或以上版本的Linux/x86-32内核中，软件时钟速度是100赫兹，也就是说一个jiffy是
// 10毫秒。自Linux面世以来，由于CPU的速度已大大增加，Linux/x86-32 2.6.0内核的软件
// 时钟速度已经提高到1000赫兹。更高的软件时钟速率意味着定时器可以有更高的操作精度和
// 时间可以拥有更高的测量精度。然而这并非可以任意提高时钟频率，因为每个时钟中断会消
// 耗少量的CPU时间，这部分时间CPU无法执行任何操作。
// 经过内核开发人员之间的讨论，最终导致软件时钟频率成为一个可配置的内核选项。自2.6.13
// 内核，时钟可以设置到100、250（默认）或1000赫兹，对应的jiffy值分别为10、4、1毫秒。
// 自内核2.6.20，增加了一个频率300赫兹，它可以被两种常见的视频帧速率25帧每秒（PAL）
// 和30帧每秒（NTSC）整除。
#if defined(prh_plat_apple)
// https://developer.apple.com/forums/thread/735632 (Availability of Low-Level APIs)
// https://developer.apple.com/documentation/os/reading-unix-manual-pages
// https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/
// https://github.com/apple/darwin-xnu/blob/main/EXTERNAL_HEADERS/AvailabilityMacros.h
// https://developer.apple.com/documentation/kernel/mach
// https://github.com/phracker/MacOSX-SDKs/tree/master/MacOSX11.3.sdk
// https://www.manpagez.com/man/3/clock_gettime/
#include <mach/task.h>
#include <mach/mach.h>
#include <mach/mach_time.h>
#endif
#include <time.h> // clock_gettime time_t struct timespec
#include <sys/time.h> // gettimeofday time_t struct timeval

// The system clock represents the system-wide real time wall clock. It may
// not be monotonic: on most systems, the system time can be adjusted at any
// moment. System clock measures Unix Time (i.e., time since 00:00:00
// Coordinated Universal Time (UTC), Thursday, 1 January 1970, not counting
// leap seconds). The system clock's time value can be internally adjusted
// at any time by the operating system, for example due to NTP synchronization
// or the user changing the system's clock. Daylight Saving Time and time zone
// changes, however, do not affect it since it is based on the UTC time-zone.

prh_i64 prh_system_secs(void) {
#if defined(CLOCK_REALTIME)
    struct timespec ts;
    prh_zeroret(clock_gettime(CLOCK_REALTIME, &ts));
    return (prh_i64)ts.tv_sec;
#else
    struct timeval tv;
    prh_zeroret(gettimeofday(&tv, prh_null));
    return (prh_i64)tv.tv_sec;
#endif
}

prh_i64 prh_system_msec(void) {
#if defined(CLOCK_REALTIME)
    struct timespec ts;
    prh_zeroret(clock_gettime(CLOCK_REALTIME, &ts));
    return (prh_i64)ts.tv_sec * PRH_MSEC_PER_SEC + (ts.tv_nsec / 1000000);
#else
    struct timeval tv;
    prh_zeroret(gettimeofday(&tv, prh_null));
    return (prh_i64)tv.tv_sec * PRH_MSEC_PER_SEC + (tv.tv_usec / 1000);
#endif
}

prh_i64 prh_system_usec(void) {
#if defined(CLOCK_REALTIME)
    struct timespec ts;
    prh_zeroret(clock_gettime(CLOCK_REALTIME, &ts));
    return (prh_i64)ts.tv_sec * PRH_USEC_PER_SEC + (ts.tv_nsec / 1000);
#else
    struct timeval tv;
    prh_zeroret(gettimeofday(&tv, prh_null));
    return (prh_i64)tv.tv_sec * PRH_USEC_PER_SEC + tv.tv_usec;
#endif
}

void prh_system_time(prh_timeusec *t) {
#if defined(CLOCK_REALTIME)
    struct timespec ts;
    prh_zeroret(clock_gettime(CLOCK_REALTIME, &ts));
    t->secs = ts.tv_sec;
    t->usec = ts.tv_nsec / 1000;
#else
    struct timeval tv;
    prh_zeroret(gettimeofday(&tv, prh_null));
    t->secs = tv.tv_sec;
    t->usec = tv.tv_usec;
#endif
}

void prh_impl_date_time(prh_datetime *t, const struct tm *tm, prh_i32 usec) {
    // struct tm {
    //     int tm_sec;   // 0 ~ 60 since C99 allows for a positive leap second
    //     int tm_min;   // 0 ~ 59
    //     int tm_hour;  // 0 ~ 23
    //     int tm_mday;  // 1 ~ 31
    //     int tm_mon;   // 0 ~ 11
    //     int tm_year;  // year since 1900
    //     int tm_wday;  // 0 ~ 6 (sunday = 0)
    //     int tm_yday;  // 0 ~ 365
    //     int tm_isdst; // > 0 dst in effect, = 0 dst not effect, < 0 dst not available
    // };
    t->year = tm->tm_year + 1900; // 正负20亿年
    t->month = tm->tm_mon + 1; // 1 ~ 12
    t->mday = tm->tm_mday; // 1 ~ 31
    t->wday = tm->tm_wday; // 0 ~ 6 (sunday = 0)
    t->hour = tm->tm_hour; // 0 ~ 23
    t->min = tm->tm_min; // 0 ~ 59
    t->sec = tm->tm_sec; // 0 ~ 60 since C99
    t->usec = usec; // 0 ~ 999999
}

void prh_impl_system_date(struct tm *tm, const prh_datetime *t) {
    memset(tm, 0, sizeof(struct tm));
    tm->tm_year = t->year - 1900;
    tm->tm_mon = t->month - 1;
    tm->tm_mday = t->mday;
    tm->tm_hour = t->hour;
    tm->tm_min = t->min;
    tm->tm_sec = t->sec;
    tm->tm_wday = t->wday;
    tm->tm_isdst = -1; // not available
}

void prh_system_time_from_date(prh_timeusec *utc_time, const prh_datetime *utc_date) {
    // #include <time.h>
    // [[deprecated]] time_t timelocal(struct tm *tm);
    // time_t timegm(struct tm *tm);
    // The functions timelocal() and timegm() are the inverses of
    // localtime(3) and gmtime(3).
    struct tm utc;
    prh_impl_system_date(&utc, utc_date);
    time_t utc_secs = timegm(&utc); // timegm 是 gmtime_r 的反操作，忽略 tm_wday 和 tm_yady
    if (utc_secs == (time_t)-1) prh_abort_error(errno);
    utc_time->secs = utc_secs;
    utc_time->usec = utc_date->usec;
}

void prh_system_time_from_local_date(prh_timeusec *utc_time, const prh_datetime *local_date) {
    struct tm local;
    prh_impl_system_date(&local, local_date);
    time_t utc_secs = mktime(&local); // mktime 是 localtime_r 的反操作，忽略 tm_wday 和 tm_yady
    if (utc_secs == (time_t)-1) prh_abort_error(errno);
    utc_time->secs = utc_secs;
    utc_time->usec = local_date->usec;
}

void prh_system_date(prh_datetime *utc_date) {
    prh_timeusec utc_time;
    prh_system_time(&utc_time);
    time_t time = (time_t)utc_time.secs;
    struct tm tm;
    prh_boolret(gmtime_r(&time, &tm));
    prh_impl_date_time(utc_date, &tm, utc_time.usec);
}

void prh_local_date(prh_datetime *local_date) {
    prh_timeusec utc_time;
    prh_system_time(&utc_time);
    time_t time = (time_t)utc_time.secs;
    struct tm tm;
    prh_boolret(localtime_r(&time, &tm));
    prh_impl_date_time(local_date, &tm, utc_time.usec);
}

void prh_local_date_from(prh_datetime *local_date, const prh_timeusec *utc_time) {
    time_t time = (time_t)utc_time->secs;
    struct tm tm;
    prh_boolret(localtime_r(&time, &tm));
    prh_impl_date_time(local_date, &tm, utc_time->usec);
}

void prh_system_date_from(prh_datetime *utc_date, const prh_timeusec *utc_time) {
    // 夏令时（Daylight Saving Time，DST）是一种为了节约能源而人为调整时钟的做法。
    // 具体来说，它通过在夏季将时钟拨快一定时间（通常是1小时）。夏令时的主要目的是减
    // 少照明需求。通过将时钟拨快1小时，人们在夏季的傍晚可以更晚地开灯，从而节省电力。
    // 在一些国家和地区，夏令时被认为可以提高工作效率，因为人们可以在自然光照下工作
    // 更长时间。
    // #include <time.h>
    // struct tm *gmtime(const time_t *timer);
    // struct tm *gmtime_r(const time_t *timer, struct tm *result);
    //      If an error is detected, gmtime shall return a null pointer
    //      and set errno to indicate the error.
    //      The gmtime() function need not be thread-safe. The gmtime()
    //      function shall convert the time in seconds since the Epoch
    //      pointed to by timer into a broken-down time, expressed as
    //      Coordinated Universal Time (UTC).
    // struct tm *localtime(const time_t *timer);
    // struct tm *localtime_r(const time_t *timer, struct tm *result);
    //      If an error is detected, localtime shall return a null pointer
    //      and set errno to indicate the error.
    //      The localtime() function need not be thread-safe. The localtime()
    //      function shall convert the time in seconds since the Epoch pointed
    //      to by timer into a broken-down time, expressed as a local time.
    //      The function corrects for the timezone and any seasonal time
    //      adjustments. Local timezone information is used as though
    //      localtime() calls tzset().
    // time_t mktime(struct tm *timeptr);
    //      The mktime() function shall return the specified time since the
    //      Epoch encoded as a value of type time_t. If the time since the
    //      Epoch cannot be represented, the function shall return the value
    //       (time_t)-1 and set errno to indicate the error.
    //      The mktime() function shall convert the broken-down time,
    //      expressed as **local time**, in the structure pointed to by
    //      timeptr, into a time since the Epoch value with the same encoding
    //      as that of the values returned by time(). The original values of
    //      the tm_wday and tm_yday components of the structure shall be
    //      ignored.
    //      A positive or 0 value for tm_isdst shall cause mktime() to presume
    //      initially that Daylight Savings Time, respectively, is or is not
    //      in effect for the specified time. A negative value for tm_isdst
    //      shall cause mktime() to attempt to determine whether Daylight
    //      Savings Time is in effect for the specified time.
    //      Upon successful completion, the values of the tm_wday and tm_yday
    //      components of the structure shall be set appropriately, and the
    //      other components shall be set to represent the specified time
    //      since the Epoch, but with their values forced to the ranges
    //      indicated in the <time.h> entry; the final value of tm_mday shall
    //      not be set until tm_mon and tm_year are determined.
    time_t time = (time_t)utc_time->secs;
    struct tm tm;
    prh_boolret(gmtime_r(&time, &tm));
    prh_impl_date_time(utc_date, &tm, utc_time->usec);
}

// #include <time.h>
// int clock_gettime(clockid_t clockid, struct timespec *ts);
// int clock_getres(clockid_t clockid, struct timespec *res);
// struct timespec {
//     time_t     tv_sec;   /* Seconds */
//     /* ... */  tv_nsec;  /* Nanoseconds [0, 999'999'999] */
// };
//
// _POSIX_C_SOURCE >= 199309L POSIX.1-2001, SUSv2. Linux 2.6.
//
// On POSIX systems on which these functions are available, the symbol
// _POSIX_TIMERS is defined in <unistd.h> to a value greater than 0.
// POSIX.1-2008 makes these functions mandatory. The symbols _POSIX_MONOTONIC_CLOCK,
// _POSIX_CPUTIME, _POSIX_THREAD_CPUTIME indicate that CLOCK_MONOTONIC,
// CLOCK_PROCESS_CPUTIME_ID, CLOCK_THREAD_CPUTIME_ID are available. See also
// sysconf(3).
//
// Return 0 for success. On error, -1 is returned and errno is set to
// indicate the error. EOVERFLOW - The timestamp would not fit in time_t
// range. This can happen if an executable with 32-bit time_t is run on
// a 64-bit kernel when the time is 2038-01-19 03:14:08 UTC or later.
// However, when the system time is out of time_t range in other
// situations, the behavior is undefined.
//
// According to POSIX.1-2001, a process with "appropriate privileges"
// may set the CLOCK_PROCESS_CPUTIME_ID and CLOCK_THREAD_CPUTIME_ID
// clocks using clock_settime(). On Linux, these clocks are not settable
// (i.e., no process has "appropriate privileges"). C library/kernel
// differences: On some architectures, an implementation of clock_gettime()
// is provided in the vdso(7).
//
// The steady clock represents a monotonic clock. The time points of this
// clock cannot decrease as physical time moves forward and the time between
// ticks of this clock is constant. This clock is not related to wall clock
// time (for example, it can be time since last reboot), and is most suitable
// for measuring intervals.
//
// https://www.man7.org/linux/man-pages/man3/clock_gettime.3.html
//
// CLOCK_REALTIME
//      A settable system-wide clock that measures real (i.e., wall-clock)
//      time. Setting this clock requires appropriate privileges. This clock
//      is affected by discontinuous jumps in the system time (e.g., if the
//      system administrator manually changes the clock), and by frequency
//      adjustments performed by NTP and similar applications via adjtime(3),
//      adjtimex(2), clock_adjtime(2), and ntp_adjtime(3). This clock normally
//      counts the number of seconds since 1970-01-01 00:00:00 Coordinated
//      Universal Time (UTC) except that it ignores leap seconds; near a leap
//      second it is typically adjusted by NTP to stay roughly in sync with
//      UTC. 不包含闰秒的 UTC 时间。
// CLOCK_REALTIME_ALARM (since Linux 3.0; Linux-specific)
//      Like CLOCK_REALTIME, but not settable. See timer_create(2) for further
//      details. 不可设置。
// CLOCK_REALTIME_COARSE (since Linux 2.6.32; Linux-specific)
//      A faster but less precise version of CLOCK_REALTIME. This clock is not
//      settable. Use when you need very fast, but not fine-grained timestamps.
//      Requires per-architecture support, and probably also architecture
//      support for this flag in the vdso(7).
//      不可设置，比 CLOCK_REALTIME 速度快，但损失精度。
// CLOCK_TAI (since Linux 3.10; Linux-specific)
//      A nonsettable system-wide clock derived from wall-clock time but
//      counting leap seconds. This clock does not experience discontinuities
//      or frequency adjustments caused by inserting leap seconds as
//      CLOCK_REALTIME does. The acronym TAI refers to International Atomic
//      Time. 不可设置，但是包含闰秒。
//
// CLOCK_MONOTONIC
//      A nonsettable system-wide clock that represents monotonic time
//      since — as described by POSIX — "some unspecified point in the past".
//      On Linux, that point corresponds to the number of seconds that the
//      system has been running since it was booted.
//      The CLOCK_MONOTONIC clock is not affected by discontinuous
//      jumps in the system time (e.g., if the system administrator
//      manually changes the clock), but is affected by frequency
//      adjustments（会被频率调整影响）. This clock does not count time
//      that the system is suspended. All CLOCK_MONOTONIC variants
//      guarantee that the time returned by consecutive calls will
//      not go backwards, but successive calls may — depending on the
//      architecture — return identical (not-increased) time values.
//      不包含系统挂起的时间。由于精度原因，后续调用可能返回相同的未增加的时间值。
// CLOCK_MONOTONIC_RAW (since Linux 2.6.28; Linux-specific)
//      Similar to CLOCK_MONOTONIC, but provides access to a raw
//      hardware-based time that is not subject to frequency
//      adjustments. This clock does not count time that the system is
//      suspended. 不受频率调整影响，不包含系统挂起时间。
// CLOCK_MONOTONIC_COARSE (since Linux 2.6.32; Linux-specific)
//      A faster but less precise version of CLOCK_MONOTONIC. Use when you
//      need very fast, but not fine-grained timestamps. Requires
//      per-architecture support, and probably also architecture support
//      for this flag in the vdso(7). 比 CLOCK_MONOTONIC 更快，但是损失精度。
//
// CLOCK_BOOTTIME (since Linux 2.6.39; Linux-specific)
//      A nonsettable system-wide clock that is identical to CLOCK_MONOTONIC,
//      except that it also includes any time that the system is suspended.
//      This allows applications to get a suspend-aware monotonic clock
//      without having to deal with the complications of CLOCK_REALTIME,
//      which may have discontinuities if the time is changed using
//      settimeofday(2) or similar. 与 CLOCK_MONOTONIC 类似，但包含系统挂起时间。
// CLOCK_BOOTTIME_ALARM (since Linux 3.0; Linux-specific)
//      Like CLOCK_BOOTTIME. See timer_create(2) for further
//      details.
//
// CLOCK_PROCESS_CPUTIME_ID (since Linux 2.6.12)
//      This is a clock that measures CPU time consumed by this process
//      (i.e., CPU time consumed by all threads in the process). On Linux,
//      this clock is not settable.
// CLOCK_THREAD_CPUTIME_ID (since Linux 2.6.12)
//      This is a clock that measures CPU time consumed by this thread.
//      On Linux, this clock is not settable.
//
// https://man.freebsd.org
// FreeBSD 15.0
//      CLOCK_MONOTONIC
//      CLOCK_MONOTONIC_PRECISE
//      CLOCK_MONOTONIC_FAST
//      CLOCK_MONOTONIC_COARSE
//      CLOCK_BOOTTIME
//          包含系统挂起时间，CLOCK_BOOTTIME 是 CLOCK_MONOTONIC 的别名。
//      CLOCK_UPTIME
//      CLOCK_UPTIME_PRECISE
//      CLOCK_UPTIME_FAST
//          不包含系统挂起时间。
// FreeBSD 14.0
//      CLOCK_MONOTONIC
//      CLOCK_MONOTONIC_PRECISE
//      CLOCK_MONOTONIC_FAST
//      CLOCK_MONOTONIC_COARSE
//          包含系统挂起时间。
//      CLOCK_UPTIME
//      CLOCK_UPTIME_PRECISE
//      CLOCK_UPTIME_FAST
//      CLOCK_BOOTTIME
//          不包含系统挂起时间，CLOCK_BOOTTIME 是 CLOCK_UPTIME 的别名。
//
// #if defined(__APPLE__)
// https://www.manpagez.com/man/3/clock_gettime/
// https://github.com/phracker/MacOSX-SDKs/blob/master/MacOSX11.3.sdk/usr/include/time.h
//
// #include <time.h>
// int clock_gettime(clockid_t clock_id, struct timespec *tp);
// int clock_settime(clockid_t clock_id, const struct timespec *tp);
// int clock_getres(clockid_t clock_id, struct timespec *tp);
// uint64_t clock_gettime_nsec_np(clockid_t clock_id);
//
// These functions first appeared in Mac OSX 10.12. The clock_gettime(),
// clock_settime(), and clock_getres() system calls conform to IEEE Std
// 1003.1b-1993 (POSIX.1). cleck_gettime_nsec_np() is a non-portable
// Darwin extension. The clock IDs CLOCK_MONOTONIC_RAW and CLOCK_UPTIME_RAW
// are extensions to the POSIX interface.
//
// #if !defined(_POSIX_C_SOURCE) || defined(_DARWIN_C_SOURCE)
//      #define CLOCK_MONOTONIC_RAW         _CLOCK_MONOTONIC_RAW
//      #define CLOCK_MONOTONIC_RAW_APPROX  _CLOCK_MONOTONIC_RAW_APPROX
//      #define CLOCK_UPTIME_RAW            _CLOCK_UPTIME_RAW
//      #define CLOCK_UPTIME_RAW_APPROX     _CLOCK_UPTIME_RAW_APPROX
// #endif
//
// For clock_gettime_nsec_np() a return value of non-0 indicates success.
// A 0 return value indicates an error occurred and an error code is stored
// in errno.
//
// CLOCK_REALTIME
//      the system's real time (i.e. wall time) clock, expressed as the
//      amount of time since the Epoch. This is the same as the value
//      returned by gettimeofday(2).
//
// CLOCK_MONOTONIC
//      clock that increments monotonically, tracking the time since an
//      arbitrary point, and will continue to increment while the system
//      is asleep. 包含睡眠时间。
// CLOCK_MONOTONIC_RAW
//      clock that increments monotonically, tracking the time since an
//      arbitrary point like CLOCK_MONOTONIC. However, this clock is
//      unaffected by frequency or time adjustments. It should not be
//      compared to other system time sources. 不受频率调整、时间调整的影响。
// CLOCK_MONOTONIC_RAW_APPROX
//      like CLOCK_MONOTONIC_RAW, but reads a value cached by the system
//      at context switch. This can be read faster, but at a loss of
//      accuracy as it may return values that are milliseconds old.
//      比 CLOCK_MONOTONIC_RAW 更快，但是损失精度，可能返回几毫秒前的时间。
//
// CLOCK_UPTIME_RAW
//      clock that increments monotonically, in the same manner as
//      CLOCK_MONOTONIC_RAW, but that does not increment while the system
//      is asleep. The returned value is identical to the result of
//      **mach_absolute_time()** after the appropriate mach_timebase
//      conversion is applied. 与 CLOCK_MONOTONIC_RAW 类似，但不包含睡眠时间。
// CLOCK_UPTIME_RAW_APPROX
//      like CLOCK_UPTIME_RAW, but reads a value cached by the system at
//      context switch. This can be read faster, but at a loss of accuracy
//      as it may return values that are milliseconds old.
//      比 CLOCK_UPTIME_RAW 更快，但是损失精度，可能返回几毫秒前的时间。
//
// CLOCK_PROCESS_CPUTIME_ID
//      clock that tracks the amount of CPU (in user- or kernel-mode) used
//      by the calling process.
// CLOCK_THREAD_CPUTIME_ID
//      clock that tracks the amount of CPU (in user- or kernel-mode) used
//      by the calling thread.
//
// clock_getres()
//      The resolution of a clock is returned by the clock_getres() call.
//      This value is placed in a (non-null) *tp. This value may be smaller
//      than the actual precision of the underlying clock, but represents
//      a lower bound on the resolution.
// clock_gettime_nsec_np()
//      As a non-portable extension, the clock_gettime_nsec_np() function
//      will return the clock value in 64-bit nanoseconds.
//
// https://developer.apple.com/documentation/driverkit/3433733-mach_timebase_info/
// https://developer.apple.com/documentation/kernel/1462446-mach_absolute_time
// https://developer.apple.com/documentation/kernel/1646199-mach_continuous_time
//
// typedef struct mach_timebase_info *mach_timebase_info_t;
// typedef struct mach_timebase_info {
//      uint32_t denom;
//      uint32_t numer;
// } mach_timebase_info_data_t; // macOS 10.0+
//      Raw Mach Time API In general prefer to use the <time.h> API
//      clock_gettime_nsec_np(3), which deals in the same clocks
//      (and more) in ns units. Conversion of ns to (resp. from) tick
//      units as returned by the mach time APIs is performed by division
//      (resp. multiplication) with the fraction returned by
//      mach_timebase_info(). 纳秒数除以这个分数可以得到时钟 tick 数。
//
// kern_return_t mach_timebase_info(mach_timebase_info_t info); // DriverKit 24.4+
//      Returns fraction to multiply a value in mach tick units with to
//      convert it to nanoseconds. Return KERN_SUCCESS if info was filled
//      in. 返回一个分数 numer / denom，这个分数乘以 tick 数可以转换成纳秒。
//
// uint64_t mach_absolute_time(void); // macOS 10.0+
//      Return current value of a clock that increments monotonically
//      in tick units (starting at an arbitrary point), this clock does
//      not increment while the system is asleep. 不包含系统睡眠时间。
//      等价于 clock_gettime_nsec_np(CLOCK_UPTIME_RAW) 返回的纳秒数。
//
// uint64_t mach_continuous_time(void); // macOS 10.12+
//      Returns current value of a clock that increments monotonically
//      in tick units (starting at an arbitrary point), including while
//      the system is asleep. 包含系统睡眠时间。
//      等价于 clock_gettime_nsec_np(CLOCK_MONOTONIC_RAW) 返回的纳秒数。
// #endif

prh_i64 prh_clock_ticks(void) {
#if defined(prh_plat_apple)
    #if defined(AVAILABLE_MAC_OS_X_VERSION_10_12_AND_LATER) // macOS 10.12+
    return (prh_i64)clock_gettime_nsec_np(CLOCK_MONOTONIC_RAW); // 包含睡眠时间，不受频率或时间调整的影响，等价于 mach_continuous_time
    #else // macOS 10.0+
    return (prh_i64)mach_absolute_time(); // 不包含睡眠时间，不受频率或时间调整的影响
    #endif
#elif defined(prh_plat_linux)
    #if defined(CLOCK_BOOTTIME)
    clockid_t clock_id = CLOCK_BOOTTIME; // Linux 2.6.39，包含睡眠时间
    #elif defined(CLOCK_MONOTONIC_RAW)
    clockid_t clock_id = CLOCK_MONOTONIC_RAW; // Linux 2.6.28，不包含睡眠时间，不受频率或时间调整的影响
    #else
    clockid_t clock_id = CLOCK_MONOTONIC; // 不包含睡眠时间，受频率或时间调整的影响
    #endif
    struct timespec ts;
    prh_zeroret(clock_gettime(clock_id, &ts));
    return (prh_i64)ts.tv_sec * PRH_NSEC_PER_SEC + ts.tv_nsec;
#elif defined(CLOCK_MONOTONIC)
    struct timespec ts; // FreeBSD-like system, CLOCK_MONOTONIC 包含系统睡眠时间
    prh_zeroret(clock_gettime(CLOCK_MONOTONIC, &ts));
    return (prh_i64)ts.tv_sec * PRH_NSEC_PER_SEC + ts.tv_nsec;
#else
    struct timeval tv;
    prh_zeroret(gettimeofday(&tv, prh_null));
    return (prh_i64)tv.tv_sec * 1000000000 + tv.tv_usec * 1000;
#endif
}

#if defined(prh_plat_apple) && !defined(AVAILABLE_MAC_OS_X_VERSION_10_12_AND_LATER)
#define PRH_IMPL_NSEC_PRECISE 0
void prh_impl_time_init(void) {
    mach_timebase_info_data_t info; // ticks * n / d = nsecs => nsecs / (n / d) = ticks => nsecs * d / n = ticks
    mach_timebase_info(&info); // 1-sec = 1000000000-nsec = 1000000000 * d / n ticks
    PRH_IMPL_TIMEINIT.ticks_per_sec = prh_impl_mul_div(PRH_NSEC_PER_SEC, info.denom, info.numer);
}
#else
#define PRH_IMPL_NSEC_PRECISE 1
void prh_impl_time_init(void) {
    PRH_IMPL_TIMEINIT.ticks_per_sec = PRH_NSEC_PER_SEC;
}
#endif

prh_i64 prh_elapse_secs(prh_i64 ticks) {
#if PRH_IMPL_NSEC_PRECISE
    return ticks / PRH_NSEC_PER_SEC;
#else
    return ticks / PRH_IMPL_TIMEINIT.ticks_per_sec;
#endif
}

prh_i64 prh_elapse_msec(prh_i64 ticks) {
#if PRH_IMPL_NSEC_PRECISE
    return ticks / 1000000;
#else
    // To guard against loss-of-precision, we convert to microseconds
    // *before* dividing by ticks-per-second.
    return prh_impl_mul_div(ticks, PRH_MSEC_PER_SEC, PRH_IMPL_TIMEINIT.ticks_per_sec);
#endif
}

prh_i64 prh_elapse_usec(prh_i64 ticks) {
#if PRH_IMPL_NSEC_PRECISE
    return ticks / 1000;
#else
    // To guard against loss-of-precision, we convert to microseconds
    // *before* dividing by ticks-per-second.
    return prh_impl_mul_div(ticks, PRH_USEC_PER_SEC, PRH_IMPL_TIMEINIT.ticks_per_sec);
#endif
}

prh_i64 prh_elapse_nsec(prh_i64 ticks) {
#if PRH_IMPL_NSEC_PRECISE
    return ticks;
#else
    // To guard against loss-of-precision, we convert to nanoseconds
    // *before* dividing by ticks-per-second.
    return prh_impl_mul_div(ticks, PRH_NSEC_PER_SEC, PRH_IMPL_TIMEINIT.ticks_per_sec);
#endif
}

prh_i64 prh_steady_secs(void) {
    return prh_elapse_secs(prh_clock_ticks());
}

prh_i64 prh_steady_msec(void) {
    return prh_elapse_msec(prh_clock_ticks());
}

prh_i64 prh_steady_usec(void) { // 保存微妙可以表示29.2万年
    return prh_elapse_usec(prh_clock_ticks());
}

prh_i64 prh_steady_nsec(void) { // 保存纳秒只能表示292年
    return prh_elapse_nsec(prh_clock_ticks());
}

prh_i64 prh_thread_time(void) {
    // https://www.man7.org/linux/man-pages/man7/posixoptions.7.html
    // defined(_POSIX_THREAD_CPUTIME) && (_POSIX_THREAD_CPUTIME > 0)
#if defined(CLOCK_THREAD_CPUTIME_ID)
    struct timespec ts;
    prh_zeroret(clock_gettime(CLOCK_THREAD_CPUTIME_ID, &ts));
    return (prh_i64)ts.tv_sec * PRH_NSEC_PER_SEC + ts.tv_nsec;
#else
    return prh_steady_nsec();
#endif
}

#ifdef PRH_TEST_IMPLEMENTATION
void prh_impl_time_test(void) {
    printf("\n\n[GNU][time]\n");
    printf("clock tick frequency %lli\n", (long long)PRH_IMPL_TIMEINIT.ticks_per_sec);
    printf("time_t %zi-byte\n", sizeof(time_t)); // seconds, it is signed integer
    printf("clock_t %zi-byte\n", sizeof(clock_t));
    printf("CLOCKS_PER_SEC %li\n", CLOCKS_PER_SEC);
    int i, n = 30, count = 0; prh_i64 t1, t2;
    for (i = 0; i < n; i += 1) {
        printf("system time: %lli\n", (long long)prh_system_usec());
    }
    t1 = prh_steady_msec();
    for (i = 0; i < 10; i += 1, count = 0) {
        while ((t2 = prh_steady_msec()) == t1) {
            count += 1;
        }
        printf("steady msec: %lli count %d\n", (long long)t1, count);
        t1 = t2;
    }
    for (i = 0; i < n; i += 1) {
        printf("steady usec: %lli\n", (long long)prh_steady_usec());
    }
    for (i = 0; i < n; i += 1) {
        printf("steady nsec: %lli\n", (long long)prh_steady_nsec());
    }
    for (i = 0; i < n; i += 1) {
        printf("thread nsec: %lli\n", (long long)prh_thread_time());
    }
    for (i = 0; i < n; i += 1) {
        printf("clock ticks: %lli\n", (long long)prh_clock_ticks());
    }
    prh_real_assert(prh_impl_mul_div(1000000000001LL, 1000000000LL, 1000000LL) == 1000000000001000LL);
}
#endif // PRH_TEST_IMPLEMENTATION
#endif // POSIX END
#endif // PRH_TIME_IMPLEMENTATION
#endif // PRH_TIME_INCLUDE

#ifdef PRH_THRD_INCLUDE
// impl_hdl_ => x64 pthread_t size 8-byte HANDLE size 8-byte
#define prh_thrd_struct(...) {              \
    prh_ptr impl_hdl_;                      \
    prh_ptr extra_ptr;                      \
    prh_u32 thrd_id: 31, created: 1;        \
    __VA_ARGS__                             \
}

typedef struct prh_thrd_struct(void *userdata;) prh_user_thrd;
typedef struct prh_thrd_struct() prh_thrd;
typedef struct {
    prh_i32 thrd_cnt;
    prh_u32 thrd_max: 31, thrd_end: 1;
    prh_thrd *main;
    // [prh_thrd *] thrd_max 个非主线程个数
    // [prh_thrd *]
} prh_thrds;

typedef struct {
    prh_i32 thrd_cnt;
    prh_u32 thrd_max: 31, thrd_end: 1;
    prh_int thrd_size;
} prh_simple_thrds;

#define PRH_SIMPLE_THRD_ALIGNOF PRH_CACHE_LINE_SIZE
prh_static_assert(sizeof(prh_simple_thrds) <= PRH_SIMPLE_THRD_ALIGNOF);
prh_static_assert(sizeof(prh_simple_thrds) == 8 + sizeof(prh_int));

typedef int (*prh_thrdproc_t)(prh_thrd *thrd);
typedef void (*prh_thrdfree_t)(prh_thrd *thrd, int thrd_index); // thrd_index 0 for main thrd
extern prh_thread_local prh_thrd *PRH_IMPL_THRD;

#define prh_thrd_for_begin(THRD_TYPE, begin, end) {                             \
        prh_thrd **prh_impl_p = (begin);                                        \
        prh_thrd **prh_impl_e = (end);                                          \
        while (prh_impl_p < prh_impl_e) {                                       \
            THRD_TYPE *it = (THRD_TYPE *)*prh_impl_p++;                         \
            if (it == prh_null) continue;
#define prh_thrd_for_end()                                                      \
        }                                                                       \
    }

#define PRH_THRD_INDEX_MASK 0xffff
#define prh_thrd_id(thrd) ((int)((thrd)->thrd_id))
#define prh_thrd_index(thrd) (prh_thrd_id(thrd) & PRH_THRD_INDEX_MASK)
prh_inline prh_thrd *prh_thrd_self(void) { return PRH_IMPL_THRD; }
prh_inline void *prh_thrd_self_data(void) { return ((prh_user_thrd *)prh_thrd_self())->userdata; }
prh_inline int prh_thrd_self_id(void) { return prh_thrd_id(prh_thrd_self()); }
prh_inline int prh_thrd_self_index(void) { return prh_thrd_index(prh_thrd_self()); }

prh_inline prh_thrd **prh_thrd_begin(prh_thrds *s) { return &s->main; }
prh_inline prh_thrd **prh_thrd_end(prh_thrds *s) { return &s->main + (int)s->thrd_max + 1; }
prh_inline prh_thrd *prh_thrd_get(prh_thrds *s, int thrd_index) { assert(thrd_index >= 0 && thrd_index <= (int)s->thrd_max); return prh_thrd_begin(s)[thrd_index]; /* 0 for main thrd */ }
prh_inline prh_thrd *prh_thrd_get_with_end(prh_thrds *s, int thrd_index) { assert(thrd_index >= 0 && thrd_index <= (int)s->thrd_max + 1); return prh_thrd_begin(s)[thrd_index]; /* 0 for main thrd */ }
prh_inline prh_thrd *prh_thrd_main(prh_thrds *s) { return s->main; }
prh_inline void *prh_thrd_main_data(prh_thrds *s) { return ((prh_user_thrd *)prh_thrd_main(s))->userdata; }
prh_inline int prh_thrd_main_id(prh_thrds *s) { return prh_thrd_id(prh_thrd_main(s)); }

prh_thrds *prh_thrd_init(int thrd_group, int thrd_num, void *main_userdata); // 使用 prh_thrd_main_data() 获取主线程的 userdata
prh_thrds *prh_thrd_init_with_size(int thrd_group, int thrd_num, prh_int main_thrd_size);
void *prh_thrd_create(prh_thrds *s, prh_int thrd_size); // 仅创建线程，创建之后可以自由初始化，然后使用 prh_thrd_sched() 启动线程
int prh_thrd_sched(prh_thrds *s, void *created_thrd, prh_thrdproc_t proc, prh_int stack_size); // 返回 thrd_index
int prh_thrd_start(prh_thrds *s, prh_thrdproc_t proc, prh_int stack_size, void *userdata); // 线程需要初始化的仅有 userdata ，返回 thrd_index，使用 prh_thrd_self_data() 获取 userdata
void prh_thrd_join(prh_thrds *s, int thrd_index, prh_thrdfree_t thrd_free); // 记得调用 prh_thrd_free() 释放主线程
void prh_thrd_join_except_main(prh_thrds *s, prh_thrdfree_t thrd_free); // 释放所有 joined 线程，排除主线程，之后记得调用 prh_thrd_free() 释放主线程
void prh_thrd_jall(prh_thrds **s, prh_thrdfree_t thrd_free); // 释放所有 joined 线程，包括主线程
void prh_thrd_free(prh_thrds **s, prh_thrdfree_t thrd_free); // 释放主线程
void prh_thrd_exit(int exit_code);

#define prh_simp_thrd_for_begin(THRD_TYPE, s, begin, end) {                     \
        THRD_TYPE *it = (THRD_TYPE *)(begin);                                   \
        prh_thrd *prh_impl_e = (end);                                           \
        for (; (prh_thrd *)it < prh_impl_e; it = (THRD_TYPE *)prh_simp_thrd_next((s), (prh_thrd *)it)) {
#define prh_simp_thrd_for_end()                                                 \
        }                                                                       \
    }

prh_inline prh_thrd *prh_simp_thrd_begin(prh_simple_thrds *s) { return (prh_thrd *)((prh_byte *)s + PRH_SIMPLE_THRD_ALIGNOF); }
prh_inline prh_thrd *prh_simp_thrd_next(prh_simple_thrds *s, prh_thrd *curr_thrd) { return (prh_thrd *)((prh_byte *)curr_thrd + s->thrd_size); }
prh_inline prh_thrd *prh_simp_thrd_end(prh_simple_thrds *s) { return (prh_thrd *)((prh_byte *)prh_simp_thrd_begin(s) + (s->thrd_max + 1) * s->thrd_size); }
prh_inline prh_thrd *prh_simp_thrd_get(prh_simple_thrds *s, int thrd_index) { assert(thrd_index >= 0 && thrd_index <= (int)s->thrd_max); return (prh_thrd *)((prh_byte *)prh_simp_thrd_begin(s) + thrd_index * s->thrd_size); /* 0 for main thrd */ }
prh_inline prh_thrd *prh_simp_thrd_get_with_end(prh_simple_thrds *s, int thrd_index) { assert(thrd_index >= 0 && thrd_index <= (int)s->thrd_max + 1); return (prh_thrd *)((prh_byte *)prh_simp_thrd_begin(s) + thrd_index * s->thrd_size); /* 0 for main thrd */ }
prh_inline prh_thrd *prh_simp_thrd_main(prh_simple_thrds *s) { return prh_simp_thrd_begin(s); }
prh_inline int prh_simp_thrd_main_id(prh_simple_thrds *s) { return prh_thrd_id(prh_simp_thrd_main(s)); }
#define prh_simp_thrd_index(simple_thrds, thrd) (prh_thrd_id(thrd) - prh_simp_thrd_main_id(simple_thrds))

prh_simple_thrds *prh_simp_thrd_init(int thrd_group, int thrd_num, prh_int thrd_size);
void *prh_simp_thrd_create(prh_simple_thrds *s); // 仅创建线程，创建之后可以自由初始化，然后使用 prh_thrd_sched() 启动线程
int prh_simp_thrd_sched(prh_simple_thrds *s, void *created_thrd, prh_thrdproc_t proc, prh_int stack_size); // 返回 thrd_index
void prh_simp_thrd_join(prh_simple_thrds *s, int thrd_index, prh_thrdfree_t thrd_free); // 记得调用 prh_thrd_free() 释放主线程
void prh_simp_thrd_join_except_main(prh_simple_thrds *s, prh_thrdfree_t thrd_free); // 释放所有 joined 线程，排除主线程，之后记得调用 prh_thrd_free() 释放主线程
void prh_simp_thrd_jall(prh_simple_thrds **s, prh_thrdfree_t thrd_free); // 释放所有 joined 线程，包括主线程
void prh_simp_thrd_free(prh_simple_thrds **s, prh_thrdfree_t thrd_free); // 释放主线程

prh_thrd *prh_impl_thrd_create(int thrd_id, prh_int thrd_size);
void prh_impl_thrd_sched(prh_thrd *thrd, prh_thrdproc_t proc, prh_int stack_size);
void prh_impl_thrd_join(prh_thrd *thrd, prh_thrdfree_t thrd_free);

typedef struct prh_mutex prh_mutex;
int prh_mutex_size(void);
void prh_mutex_init(prh_mutex *p);
void prh_recursive_mutex_init(prh_mutex *p);
void prh_mutex_free(prh_mutex *p);
void prh_mutex_enter(prh_mutex *p);
bool prh_mutex_try_enter(prh_mutex *p);
void prh_mutex_exit(prh_mutex *p);

typedef struct prh_rwlock prh_rwlock;
int prh_rwlock_size(void);
void prh_rwlock_init(prh_rwlock *p);
void prh_rwlock_free(prh_rwlock *p);
void prh_rwlock_read_enter(prh_rwlock *p);
bool prh_rwlock_try_read(prh_rwlock *p);
void prh_rwlock_read_exit(prh_rwlock *p);
void prh_rwlock_write_enter(prh_rwlock *p);
bool prh_rwlock_try_write(prh_rwlock *p);
void prh_rwlock_write_exit(prh_rwlock *p);

typedef struct prh_cond prh_cond;
int prh_cond_size(void);
void prh_cond_init(prh_cond *p);
void prh_cond_free(prh_cond *p);
void prh_cond_wait_with_mutex_exit_reenter(prh_cond *p, prh_mutex *mutex);
void prh_cond_wait_with_read_exit_reenter(prh_cond *p, prh_rwlock *lock);
void prh_cond_wait_with_write_exit_reenter(prh_cond *p, prh_rwlock *lock);
void prh_cond_timed_wait_with_mutex_exit_reenter(prh_cond *p, prh_mutex *mutex, prh_u32 msec);
void prh_cond_timed_wait_with_read_exit_reenter(prh_cond *p, prh_rwlock *lock, prh_u32 msec);
void prh_cond_timed_wait_with_write_exit_reenter(prh_cond *p, prh_rwlock *lock, prh_u32 msec);
void prh_cond_signal(prh_cond *p);
void prh_cond_broadcast(prh_cond *p);

typedef struct prh_once prh_once;
typedef prh_u32 (*prh_once_init_routine)(prh_once *p, void *param, void **value);
int prh_once_size(void);
void prh_once_init(prh_once *p);
bool prh_once_execute(prh_once *p, prh_once_init_routine init, void *param, void **value);

typedef struct prh_thrd_cond prh_thrd_cond;
int prh_impl_thrd_cond_size(void);
void prh_impl_thrd_cond_init(prh_thrd_cond *p);
void prh_impl_thrd_cond_free(prh_thrd_cond *p);

prh_thrd_cond *prh_thrd_cond_init(void);
void prh_thrd_cond_free(prh_thrd_cond *p);
void prh_thrd_cond_lock(prh_thrd_cond *p);
void prh_thrd_cond_unlock(prh_thrd_cond *p);
void prh_thrd_cond_signal(prh_thrd_cond *p);
void prh_thrd_cond_broadcast(prh_thrd_cond *p);

typedef struct prh_thrd_sem prh_thrd_sem;
int prh_impl_thrd_sem_size(void);
void prh_impl_thrd_sem_init(prh_thrd_sem *p);
void prh_impl_thrd_sem_free(prh_thrd_sem *p);

prh_thrd_sem *prh_thrd_sem_init(void);
void prh_thrd_sem_free(prh_thrd_sem *s);
void prh_thrd_sem_wait(prh_thrd_sem *s);
void prh_thrd_sem_post(prh_thrd_sem *s, int n);

typedef struct prh_cond_sleep prh_cond_sleep;
int prh_impl_thrd_sleep_size(void);
void prh_impl_init_cond_sleep(prh_cond_sleep *p);
void prh_impl_free_cond_sleep(prh_cond_sleep *p);

prh_cond_sleep *prh_init_cond_sleep(void);
void prh_free_cond_sleep(prh_cond_sleep *p);
void prh_thrd_cond_sleep(prh_cond_sleep *p);
bool prh_thrd_try_sleep(prh_cond_sleep *p);
void prh_thrd_wakeup(prh_cond_sleep *p);

// 线程等待条件变量时会进入睡眠状态，有三种情况会导致线程被唤醒：
// 1. 意外唤醒，线程被系统意外唤醒，此时条件并没有真正成立
// 2. 真实唤醒，线程成功等到被系统唤醒，但条件可能被其他线程抢夺，当线程重新获取锁之后，条件可能不再成立
// 3. 等待超时，线程在设定的超时时间内，没有等到条件变量被触发
//
// 对于 prh_thrd_cond_timedwait(), 由于意外唤醒和被其他线程抢夺的存在，该函数不能真
// 正做到在条件未成立的情况下等满 msec 时间，参数 msec 仅表示一个最长等待时间。

#define prh_thrd_cond_wait(p, cond) {                                           \
    prh_thrd_cond_lock(p);                                                      \
    /* calling thread locked by the cond mutex */                               \
    while (!(cond)) {                                                           \
        prh_impl_plat_cond_wait(p);                                             \
    }                                                                           \
    /* calling thread locked and wakeup and cond meet */                        \
    prh_thrd_cond_unlock(p);                                                    \
}

#define prh_thrd_cond_timedwait(p, msec, cond_expr, cond_meet) {                \
    prh_thrd_cond_lock(p);                                                      \
    /* calling thread locked by the cond mutex */                               \
    prh_i64 prh_impl_ts[2];                                                     \
    bool prh_impl_timedwait = false;                                            \
label_cond_check:                                                               \
    if (cond_expr) {                                                            \
        prh_impl_timedwait = false;                                             \
    } else if (!prh_impl_timedwait) {                                           \
        prh_impl_timedwait = true;                                              \
        prh_impl_plat_cond_timedwait((p), prh_impl_plat_cond_time(prh_impl_ts, (msec))); \
        goto label_cond_check;                                                  \
    }                                                                           \
    (cond_meet) = !prh_impl_timedwait;                                          \
    /* calling thread locked and wakeup and cond may meet */                    \
    prh_thrd_cond_unlock(p);                                                    \
}

typedef struct {
    int page_size; // 虚拟内存页面大小
    int vmem_unit; // 虚拟内存分配颗粒度
    int cache_line_size; // 处理器缓存行大小
    int processor_count; // 逻辑处理器个数
} prh_sys_info;

void prh_system_info(prh_sys_info *info);
void prh_thrd_sleep_secs(int secs); // 32位有符号整数保存秒可以表示68年
void prh_thrd_sleep_msec(int msec); // 32位有符号整数保存毫秒可以表示24天
void prh_thrd_sleep(int secs, int nsec);

void prh_impl_plat_cond_wait(prh_thrd_cond *p);
bool prh_impl_plat_cond_timedwait(prh_thrd_cond *p, prh_ptr time);
prh_ptr prh_impl_plat_cond_time(prh_i64 *ptr, prh_u32 msec);

#ifdef PRH_THRD_IMPLEMENTATION
void prh_impl_plat_set_fault_handler(void);
void prh_impl_plat_print_thrd_info(prh_thrd *thrd);
void prh_impl_plat_thrd_start(prh_thrd *thrd, prh_thrdproc_t proc, prh_int reserved_stack_size);
void prh_impl_plat_thrd_join(prh_thrd *thrd);
prh_ptr prh_impl_plat_thrd_self(void);

#ifndef PRH_THRD_DEBUG
#define PRH_THRD_DEBUG PRH_DEBUG
#endif

prh_thread_local prh_thrd *PRH_IMPL_THRD = prh_null;

int prh_impl_thrd_start_proc(prh_thrd *thrd) {
    prh_thrdproc_t proc = (prh_thrdproc_t)thrd->extra_ptr;
    PRH_IMPL_THRD = thrd;
#if PRH_THRD_DEBUG
    prh_impl_plat_print_thrd_info(thrd);
#endif
    thrd->extra_ptr = 0; // 可以在用户线程函数中重用 extra_ptr
    return proc(thrd);
}

prh_int prh_impl_thrd_size(prh_int thrd_size) {
    assert(thrd_size >= sizeof(prh_thrd));
    return (prh_int)prh_round_cache_line_size(thrd_size);
}

prh_unt prh_impl_thrds_size(int thrd_num) {
    assert(thrd_num >= 0 && thrd_num < PRH_THRD_INDEX_MASK - 1);
    return (prh_unt)(sizeof(prh_thrds) + sizeof(void *) * thrd_num);
}

prh_unt prh_impl_simp_thrds_size(int thrd_num, prh_int thrd_size) {
    assert(thrd_num >= 0 && thrd_num < PRH_THRD_INDEX_MASK - 1);
    return PRH_SIMPLE_THRD_ALIGNOF + (thrd_num + 1) * thrd_size;
}

prh_thrd *prh_impl_thrd_create(int thrd_id, prh_int thrd_size) {
    thrd_size = prh_impl_thrd_size(thrd_size);
    prh_thrd *thrd = prh_cache_line_aligned_malloc(thrd_size);
    assert(thrd != prh_null);
    memset(thrd, 0, thrd_size);
    thrd->thrd_id = thrd_id;
    return thrd;
}

void prh_impl_launch_main_thrd(prh_thrd *main) {
    main->impl_hdl_ = prh_impl_plat_thrd_self();
    PRH_IMPL_THRD = main;
#if PRH_THRD_DEBUG
    prh_impl_plat_print_thrd_info(main);
#endif
}

prh_thrds *prh_thrd_init_with_size(int thrd_group, int thrd_num, prh_int main_thrd_size) {
    prh_thrds *s = prh_calloc(prh_impl_thrds_size(thrd_num));
    assert(thrd_group >= 0 && thrd_group < 0x3fff);
    prh_thrd *main = prh_impl_thrd_create(thrd_group << 16, main_thrd_size ? main_thrd_size : sizeof(prh_thrd));
    s->thrd_max = thrd_num;
    s->main = main;
    prh_impl_launch_main_thrd(main);
    return s;
}

prh_thrds *prh_thrd_init(int thrd_group, int thrd_num, void *main_userdata) {
    prh_thrds *s = prh_thrd_init_with_size(thrd_group, thrd_num, sizeof(prh_user_thrd));
    prh_user_thrd *main = (prh_user_thrd *)prh_thrd_main(s);
    main->userdata = main_userdata;
    return s;
}

prh_simple_thrds *prh_simp_thrd_init(int thrd_group, int thrd_num, prh_int each_thrd_size) {
    prh_int thrd_size = prh_impl_thrd_size(each_thrd_size);
    prh_unt simp_thrds_size = prh_impl_simp_thrds_size(thrd_num, thrd_size);
    prh_simple_thrds *s = prh_cache_line_aligned_malloc(simp_thrds_size);
    assert(s != prh_null);
    assert(thrd_group >= 0 && thrd_group < 0x3fff);
    memset(s, 0, simp_thrds_size);
    prh_thrd *main = prh_simp_thrd_main(s);
    main->thrd_id = thrd_group << 16;
    main->created = 1;
    s->thrd_max = thrd_num;
    s->thrd_size = thrd_size;
    prh_impl_launch_main_thrd(main);
    return s;
}

prh_thrd *prh_impl_create_and_set(prh_thrds *s, prh_int thrd_size) {
    int thrd_index = 1; // 从非主线程开始查找空线程
    prh_thrd *created_thrd;
    prh_thrd **thrd_pptr;
    if (s->thrd_end) {
        thrd_pptr = prh_thrd_begin(s);
        for (; thrd_index <= (int)s->thrd_max; thrd_index += 1) {
            if (*(thrd_pptr + thrd_index) == prh_null) {
                s->thrd_cnt += 1;
                goto label_find_empty_thrd;
            }
        }
    } else {
        assert(s->thrd_cnt >= 0 && s->thrd_cnt < (int)s->thrd_max);
        thrd_index = ++s->thrd_cnt;
        if (thrd_index >= (int)s->thrd_max) {
            s->thrd_end = 1;
        }
        goto label_find_empty_thrd;
    }
    prh_abort_error(__LINE__);
label_find_empty_thrd:
    created_thrd = prh_impl_thrd_create(prh_thrd_main_id(s) + thrd_index, thrd_size);
    prh_thrd_begin(s)[thrd_index] = created_thrd;
    return created_thrd;
}

int prh_thrd_start(prh_thrds *s, prh_thrdproc_t proc, prh_int stack_size, void *userdata) {
    prh_user_thrd *thrd = (prh_user_thrd *)prh_impl_create_and_set(s, sizeof(prh_user_thrd));
    thrd->userdata = userdata;
    prh_impl_plat_thrd_start((prh_thrd *)thrd, proc, stack_size);
    return prh_thrd_index((prh_thrd *)thrd);
}

void *prh_thrd_create(prh_thrds *s, prh_int thrd_size) {
    prh_thrd *thrd = prh_impl_create_and_set(s, thrd_size);
    return thrd;
}

void prh_impl_thrd_sched(prh_thrd *thrd, prh_thrdproc_t proc, prh_int stack_size) {
    prh_impl_plat_thrd_start(thrd, proc, stack_size);
}

int prh_thrd_sched(prh_thrds *s, void *created_thrd, prh_thrdproc_t proc, prh_int stack_size) {
    prh_impl_plat_thrd_start(created_thrd, proc, stack_size);
    return prh_thrd_index((prh_thrd *)created_thrd);
}

void *prh_simp_thrd_create(prh_simple_thrds *s) {
    prh_thrd *thrd = prh_null;
    int thrd_index = 1;
    if (s->thrd_end) {
        thrd = prh_simp_thrd_get_with_end(s, thrd_index);
        for (; thrd_index <= (int)s->thrd_max; thrd_index += 1, thrd = prh_simp_thrd_next(s, thrd)) {
            if (thrd->created == 0) {
                s->thrd_cnt += 1;
                goto label_find_empty_thrd;
            }
        }
    } else {
        assert(s->thrd_cnt >= 0 && s->thrd_cnt < (int)s->thrd_max);
        thrd_index = ++s->thrd_cnt;
        if (thrd_index >= (int)s->thrd_max) {
            s->thrd_end = 1;
        }
        thrd = prh_simp_thrd_get(s, thrd_index);
        goto label_find_empty_thrd;
    }
    prh_abort_error(__LINE__);
label_find_empty_thrd:
    thrd->created = 1;
    thrd->thrd_id = prh_simp_thrd_main_id(s) + thrd_index;
    return thrd;
}

int prh_simp_thrd_sched(prh_simple_thrds *s, void *created_thrd, prh_thrdproc_t proc, prh_int stack_size) {
    prh_impl_plat_thrd_start(created_thrd, proc, stack_size);
    return prh_simp_thrd_index(s, (prh_thrd *)created_thrd);
}

void prh_impl_thrd_join(prh_thrd *thrd, prh_thrdfree_t thrd_free) {
    prh_impl_plat_thrd_join(thrd);
    if (thrd_free) {
        thrd_free(thrd, thrd->thrd_id);
    }
    prh_aligned_free(thrd);
}

void prh_impl_thrd_single_join(prh_thrd **thrd_list, int thrd_index, prh_thrdfree_t thrd_free) {
    prh_thrd *thrd = thrd_list[thrd_index];
    if (thrd == prh_null) return;
    prh_impl_plat_thrd_join(thrd);
    if (thrd_free) {
        thrd_free(thrd, thrd_index);
    }
    prh_aligned_free(thrd);
    thrd_list[thrd_index] = prh_null;
}

void prh_thrd_join(prh_thrds *s, int thrd_index, prh_thrdfree_t thrd_free) {
    assert(thrd_index > 0 && thrd_index <= (int)s->thrd_max);
    prh_impl_thrd_single_join(prh_thrd_begin(s), thrd_index, thrd_free);
    s->thrd_cnt -= 1;
    s->thrd_end = 1;
}

void prh_thrd_join_except_main(prh_thrds *s, prh_thrdfree_t thrd_free) {
    prh_thrd **thrd_list = prh_thrd_begin(s);
    for (int i = 1; i <= (int)s->thrd_max; i += 1) {
        prh_impl_thrd_single_join(thrd_list, i, thrd_free);
    }
    s->thrd_cnt = 0;
    s->thrd_end = 0;
}

void prh_thrd_jall(prh_thrds **main, prh_thrdfree_t thrd_free) {
    prh_thrds *s = *main;
    if (s == prh_null) return;
    prh_thrd_join_except_main(s, thrd_free);
    prh_thrd_free(main, thrd_free);
}

void prh_thrd_free(prh_thrds **main, prh_thrdfree_t thrd_free) {
    prh_thrds *s = *main;
    if (s == prh_null) return;
    prh_thrd *main_thrd = prh_thrd_main(s);
    if (main_thrd) {
        if (thrd_free) {
            thrd_free(main_thrd, 0);
        }
        prh_aligned_free(main_thrd);
        s->main = prh_null;
    }
    prh_free(s);
    *main = prh_null;
}

void prh_impl_simp_thrd_join(prh_thrd *thrd, int thrd_index, prh_thrdfree_t thrd_free) {
    if (thrd->created == 0) return;
    prh_impl_plat_thrd_join(thrd);
    if (thrd_free) {
        thrd_free(thrd, thrd_index);
    }
    thrd->created = 0;
}

void prh_simp_thrd_join(prh_simple_thrds *s, int thrd_index, prh_thrdfree_t thrd_free) {
    prh_impl_simp_thrd_join(prh_simp_thrd_get(s, thrd_index), thrd_index, thrd_free);
    s->thrd_cnt -= 1;
    s->thrd_end = 1;
}

void prh_simp_thrd_join_except_main(prh_simple_thrds *s, prh_thrdfree_t thrd_free) {
    int thrd_index = 1;
    prh_simp_thrd_for_begin(prh_thrd, s, prh_simp_thrd_get_with_end(s, thrd_index), prh_simp_thrd_end(s))
        prh_impl_simp_thrd_join(it, thrd_index++, thrd_free);
    prh_simp_thrd_for_end()
    s->thrd_cnt = 0;
    s->thrd_end = 0;
}

void prh_simp_thrd_jall(prh_simple_thrds **main, prh_thrdfree_t thrd_free) {
    prh_simple_thrds *s = *main;
    if (s == prh_null) return;
    prh_simp_thrd_join_except_main(s, thrd_free);
    prh_simp_thrd_free(main, thrd_free);
}

void prh_simp_thrd_free(prh_simple_thrds **main, prh_thrdfree_t thrd_free) {
    prh_simple_thrds *s = *main;
    if (s == prh_null) return;
    prh_thrd *main_thrd = prh_simp_thrd_main(s);
    if (main_thrd->created) {
        if (thrd_free) {
            thrd_free(main_thrd, 0);
        }
        main_thrd->created = 0;
    }
    prh_aligned_free(s);
    *main = prh_null;
}

#if defined(prh_plat_windows)
// DWORD WINAPI ThreadProc(_In_ LPVOID lpParameter)
// HANDLE CreateThread(
//      [in, optional]  LPSECURITY_ATTRIBUTES   lpThreadAttributes,
//      [in]            SIZE_T                  dwStackSize,
//      [in]            LPTHREAD_START_ROUTINE  lpStartAddress,
//      [in, optional]  __drv_aliasesMem LPVOID lpParameter,
//      [in]            DWORD                   dwCreationFlags,
//      [out, optional] LPDWORD                 lpThreadId)
// 参数 lpThreadAttributes 指向 SECURITY_ATTRIBUTES 结构的指针，用于指定新线程的安
// 全描述符，并决定返回的句柄是否可被子进程继承。若为 NULL，则线程获得默认安全描述符，
// 且句柄无法被继承。默认安全描述符中的访问控制列表（ACL）来自创建者进程的主令牌。
// 参数 dwStackSize 新线程的初始栈大小，以字节为单位。系统会将该值向上取整到最近的页
// 面大小。若为 0，则新线程使用可执行文件的默认栈大小。若设置了
// STACK_SIZE_PARAM_IS_A_RESERVATION（0x00010000），则 dwStackSize 表示栈的保留大
// 小；否则表示提交大小。
// 参数 dwCreationFlags 控制线程创建的标志。CREATE_SUSPENDED (0x00000004) 线程以挂
// 起状态创建，需调用 ResumeThread 恢复执行。STACK_SIZE_PARAM_IS_A_RESERVATION
// (0x00010000) dwStackSize 表示栈的保留大小；否则表示提交大小
// 参数 lpThreadId 指向接收线程标识符的变量。若为 NULL，则不返回线程 ID。
// 若函数成功，返回值为新线程的句柄（具有 THREAD_ALL_ACCESS 访问权限）。若函数失败，
// 返回值为 NULL。要获取扩展错误信息，请调用 GetLastError。注意：CreateThread 即使
// lpStartAddress 指向无效地址也可能成功；若启动地址无效，线程运行时将发生异常并终止，
// 进程视为异常退出。
// 进程可创建的线程数受可用虚拟内存限制。默认情况下，每个线程拥有 1 MB 的栈空间。因此，
// 在 32 位系统上若未启用 /3GB 启动选项，就无法创建 2,048 个或更多线程。如果减小默认
// 栈大小，就可以创建更多线程；但更好的做法是每个处理器只创建一个线程，并用应用自己维护
// 的队列来保存请求上下文——线程先处理完一个队列里的所有请求，再处理下一个队列，这样性能
// 更优。
// 新线程句柄被创建时即带有 THREAD_ALL_ACCESS 访问权限。若创建线程时没有提供安全描述
// 符，系统会用创建者进程的主令牌构造一个默认安全描述符。随后其他线程调用 OpenThread
// 时，其有效令牌将与该安全描述符比对，以决定是否授予访问权。新线程在调用 GetCurrentThread
// 时，对自身拥有完全访问权限。
// Windows Server 2003 特殊行为：若线程是在远程进程中创建的，系统会用远程进程的主令牌
// 来计算线程对自身的访问权限；结果可能导致新线程调用 GetCurrentThread 时权限被削减
// （例如缺少 THREAD_SET_THREAD_TOKEN 或 THREAD_GET_CONTEXT），从而引发意外失败。
// 因此，不建议在模拟（impersonating）其他用户时创建线程。
// 如果线程以可运行状态创建（即未使用 CREATE_SUSPENDED 标志），它可能在 CreateThread
// 返回之前就开始执行，甚至早于调用者收到线程句柄和标识符。线程从 lpStartAddress 指定
// 的函数开始执行；该函数返回时，其 DWORD 返回值被用作 ExitThread 的退出码。可用 GetExitCodeThread
// 获取该返回值。
// 线程被创建时的优先级为 THREAD_PRIORITY_NORMAL；可用 GetThreadPriority
// SetThreadPriority 调整。线程终止后，其对象变为 signaled 状态，唤醒所有等待该对象
// 的线程；线程对象直到线程终止且所有句柄都被 CloseHandle 关闭后才从系统中删除。
// CreateThread、ExitThread、ExitProcess、CreateRemoteThread 以及由 CreateProcess
// 启动的新进程，在同一地址空间内串行化：任一时刻只能有一个事件发生。因此：
// - 在进程启动和 DLL 初始化期间，可创建新线程，但它们直到进程 DLL 初始化完成才开始执行；
// - 同一时刻仅一个线程可处于 DLL 初始化或分离例程中；
// - ExitProcess 会等待所有 DLL 初始化/分离例程结束才返回。
// 若可执行文件使用 C 运行时库（CRT），应使用 _beginthreadex/_endthreadex 管理线程，
// 而非 CreateThread/ExitThread；否则低内存时 CRT 可能终止进程。
//
// 每一个新线程或纤程都会获得自己的栈空间，该空间由“保留”和“初始已提交”两部分内存组成。
// 保留内存的大小代表栈在虚拟内存中的总分配量，因此，保留大小受限于虚拟地址范围。初始已
// 提交的页面在被访问之前不会占用物理内存；然而它们会从系统总提交限额（the system
// total commit limit），页文件（page file）大小 + 物理内存大小，中扣除相应页数。系
// 统会根据需要继续从保留的栈内存中提交额外页面，直到：栈达到 “保留大小减 1 页”（最后
// 一页用作保护页，防止栈溢出），或系统内存过低，操作失败。
// 最佳做法是尽可能选择小的栈尺寸，只提交线程或纤程可靠运行所需的部分。为栈保留的每一页
// 都不能再用于其他任何用途。栈随其线程退出而被释放；若线程被其他线程终止，则栈不会释放。
// 保留与初始提交栈内存的默认值在可执行文件头中指定。如果内存不足以保留或提交所请求的字
// 节数，线程或纤程创建将失败。链接器使用的默认栈保留大小为 1 MB。要为所有线程或纤程指
// 定不同的默认栈保留大小，可在模块定义文件（.def）中使用 STACKSIZE 语句。操作系统会把
// 指定大小向上取整到系统分配粒度的最近倍数（通常为 64 KB）。可用 GetSystemInfo 函数
// 获取当前系统的分配粒度。
// 若要改变初始提交的栈空间，可使用 CreateThread、CreateRemoteThread 或 CreateFiber
// 的 dwStackSize 参数。该值会被向上取整到最近的页边界。通常，保留大小就是可执行头中指
// 定的默认保留大小。然而，若 dwStackSize 指定的初始提交大小 ≥ 默认保留大小，则保留大
// 小将变为“新提交大小向上取整到 1 MB 的最近倍数”。若要改变保留栈大小，可把 CreateThread
// 或 CreateRemoteThread 的 dwCreationFlags 设为 STACK_SIZE_PARAM_IS_A_RESERVATION，
// 并通过 dwStackSize 参数指定保留大小；此时初始提交大小仍使用可执行头中的默认值。对于
// 纤程，可使用 CreateFiberEx 的 dwStackReserveSize 参数。提交大小则在 dwStackCommitSize
// 参数中指定。
// SetThreadStackGuarantee 函数可在栈溢出时，为线程或纤程设置保证可用的最小栈大小。
//
// uintptr_t _beginthreadex(
//      void *security,
//      unsigned stack_size,
//      unsigned (__stdcall *start_address)(void *),
//      void *arglist,
//      unsigned initflag,
//      unsigned *thrdaddr)
// 参数 ecurity 指向 SECURITY_ATTRIBUTES 结构的指针，用于决定返回的句柄是否可以被子
// 进程继承。如果 security 为 NULL，则句柄不能被继承。
// 参数 initflag 控制新线程的初始状态。设置为 0 表示线程立即运行；设置为 CREATE_SUSPENDED
// 表示线程以挂起状态创建，需使用 ResumeThread 来恢复执行；设置为 STACK_SIZE_PARAM_IS_A_RESERVATION
// 标志，表示将 stack_size 作为栈的初始保留大小（以字节为单位）；如果未指定此标志，则
// stack_size 表示栈的提交大小（commit size）。
// 参数 thrdaddr 指向一个 32 位变量，用于接收线程标识符（thread id）。如果为 NULL，
// 则不使用。
// 返回值，如果成功，这些函数将返回指向新创建线程的句柄；然而，如果新创建的线程退出过
// 快，_beginthread 可能不会返回有效句柄（详见下文）。出错时：_beginthread 返回 -1L，
// 并设置 errno 为：EAGAIN 线程过多，EINVAL 参数无效或栈大小错误，EACCES 资源不足
// （如内存）。_beginthreadex 返回 0，并设置 errno 和 _doserrno。如果 start_address
// 为 NULL，将触发无效参数处理程序；若继续执行，这些函数将设置 errno 为 EINVAL 并返回
// -1。有关返回码的更多信息，请参考 errno、_doserrno、_sys_errlist 和 _sys_nerr。
// _beginthread 函数创建一个线程，该线程从 start_address 指定的例程开始执行。
// 该例程必须使用 __cdecl（原生代码）或 __clrcall（托管代码）调用约定，并且 不应有返
// 回值。当线程从该例程返回时，它会自动终止。有关更多信息，请参见 Multithreading
// support for older code (Visual C++)。
// _beginthreadex 比 _beginthread 更接近 Win32 CreateThread API。_beginthreadex
// 与 _beginthread 的区别如下：
//  * _beginthreadex 有三个额外参数：initflag、Security 和 thrdaddr。新线程可以以
//    挂起状态创建，可指定安全属性，并可通过 thrdaddr（线程 ID）访问。
//  * 传递给 _beginthreadex 的例程必须使用 __stdcall（原生代码）或 __clrcall（托管
//    代码）调用约定，并且必须返回一个线程退出码。
//  * _beginthreadex 失败时返回 0，而不是 -1L。
//  * 使用 _beginthreadex 创建的线程通过调用 _endthreadex 终止。
// _beginthreadex 比 _beginthread 提供了更多控制线程创建方式的能力，_endthreadex
// 也更灵活。例如，使用 _beginthreadex，你可以使用安全信息、设置线程初始状态（运行或
// 挂起），并获取新线程的线程标识符。你还可以将 _beginthreadex 返回的线程句柄用于同步
// API，而 _beginthread 不行。
// _beginthreadex 比 _beginthread 更安全。如果由 _beginthread 生成的线程退出过快，
// 返回给调用者的句柄可能无效或指向另一个线程。然而，由 _beginthreadex 返回的句柄必
// 须由调用者关闭，因此只要 _beginthreadex 没有返回错误，它就保证是有效句柄。
// 你可以显式调用 _endthread 或 _endthreadex 来终止线程；然而，当线程从传递给
// _beginthread 或 _beginthreadex 的例程返回时，_endthread 或 _endthreadex 会被自
// 动调用。通过调用 _endthread 或 _endthreadex 终止线程，有助于确保为线程分配的资源
// 正确回收。
// 注意，对于链接到 Libcmt.lib 的可执行文件，不要调用 ExitThread，否则会阻止运行时系
// 统回收资源。_endthread 和 _endthreadex 会回收线程资源，然后调用 ExitThread。
// _endthread 会自动关闭线程句柄，而 _endthreadex 不会。因此，当你使用 _beginthread
// 和 _endthread 时，不要显式调用 CloseHandle；而使用 _beginthreadex 和 _endthreadex
// 时，必须调用 CloseHandle。_endthread 和 _endthreadex 会导致线程中待处理的 C++ 析
// 构函数不被调用。
// 当调用 _beginthread 或 _beginthreadex 时，操作系统负责分配线程栈；你无需将线程栈
// 地址传递给这些函数。此外，stack_size 参数可以为 0，此时操作系统将使用与主线程相同的
// 栈大小。
// 如果任何线程调用了 abort、exit、_exit 或 ExitProcess，所有线程都将终止。新线程的
// 区域设置（locale）使用每进程全局当前区域设置初始化。如果通过 _configthreadlocale
// 启用了每线程区域设置，线程可以通过 setlocale 或 _wsetlocale 独立更改其区域设置。
// 未设置每线程区域设置标志的线程会影响所有其他未设置该标志的线程的区域设置，以及所有新
// 创建的线程。更多信息，请参见 Locale。
// 这些函数，仅适用于多线程版本的 C 运行时库。要使用 _beginthread 或 _beginthreadex，
// 应用程序必须链接到多线程 C 运行时库（例如 libcmt.lib）。
#include <process.h>

void prh_impl_thrd_self_get_stack(prh_ptr *low, prh_ptr *high) {
    // VOID GetCurrentThreadStackLimits([out] PULONG_PTR LowLimit, [out] PULONG_PTR HighLimit)
    //      processthreadsapi.h
    //      Kernel32.lib Kernel32.dll
    //      Windows 8 Windows Server 2012
    // 获取系统为当前线程所分配栈的边界地址。用户模式代码有可能在线程创建时系统分配的
    // 区域之外的栈内存中执行。调用者可使用 GetCurrentThreadStackLimits 函数来验证
    // 当前栈指针是否位于返回的限制范围内。要编译使用此函数的应用程序，请将
    // _WIN32_WINNT 设置为 ≥ 0x0602（即 Windows 8）。
    GetCurrentThreadStackLimits((PULONG_PTR)low, (PULONG_PTR)high);
}

#if PRH_THRD_DEBUG
void prh_impl_plat_print_thrd_info(prh_thrd *thrd) {
    prh_ptr stack_low_limit = 0;
    prh_ptr stack_high_limit = 0;
    prh_impl_thrd_self_get_stack(&stack_low_limit, &stack_high_limit);
    prh_int stack_size = stack_high_limit - stack_low_limit;
    SYSTEM_INFO info;
    GetSystemInfo(&info);
    printf("[thrd %02d] %p %p stack %d-byte (%dKB) guard %d-byte\n",
        prh_thrd_id(thrd), (void *)stack_low_limit, (void *)stack_high_limit,
        (int)stack_size, (int)(stack_size/1024), (int)info.dwPageSize);
}
#endif

static unsigned __stdcall prh_impl_plat_thrd_procedure(void *param) {
    int n = prh_impl_thrd_start_proc((prh_thrd *)param);
    assert(n != STILL_ACTIVE); // STILL_ACTIVE (259)
    return (unsigned)n;
}

// Module-Definition (.Def) Files
// 模块定义（.def）文件向链接器提供有关导出、属性以及要链接的程序的其他信息。.def 文件
// 在构建 DLL 时最有用。由于 MSVC 提供了链接器选项（如 /EXPORT、/DEF）可替代模块定义
// 语句，因此通常不需要 .def 文件。你也可以使用 __declspec(dllexport) 来指定要导出的
// 函数。可通过 /DEF（指定模块定义文件） 链接器选项，在链接阶段调用 .def 文件。如果你
// 构建的是.exe 文件，它没有导出的名称，这时使用 .def 文件反而会使输出文件更大且加载更
// 慢。如果你没有使用 __declspec(dllexport) 关键字来导出 DLL 的函数，那么该 DLL 必须
// 提供一个 .def 文件。

void prh_impl_plat_thrd_start(prh_thrd *thrd, prh_thrdproc_t proc, prh_int reserved_stack_size) {
    // 1. stack_size 总是向上取整到 page size 的整数倍，并且调整为分配颗粒度的整数倍（通常为 64KB，可调用 GetSystemInfo 获取），如果为0则使用可执行文件设置的默认栈大小
    // 2. 预留栈大小（reserved pages）和初始提交大小（commited pages）的默认值在可执行文件头部中指定，可用使用编译选项控制 /STACK:reserve[,commit]
    // 3. reserve 和 commit 的单位为字节，默认预留大小为 1MB，默认初始提交大小是一个页面为 4KB，/STACK 编译选项在构建 .dll 文件时会被忽略
    // 4. 另一种设置栈大小的方法是：在模块定义（.def）文件中使用 STACKSIZE 语句，若同时指定了 STACKSIZE 和链接器选项 /STACK，则 STACKSIZE 会覆盖 /STACK 的设置
    // 5. STACKSIZE reserve[,commit]，该选项对 .dll 文件无用；也可以在 .exe 文件生成后，使用 EDITBIN 工具修改栈大小，editbin STACK:reserve[,commit] <exe-file>
    // 6. 注意，stack_size 默认指的是初始提交大小，但是一般我们要控制的是栈的总大小（预留大小），因此指定 STACK_SIZE_PARAM_IS_A_RESERVATION 标志来表示预留大小
    // 7. 系统会根据需要继续从预留的栈内存中提交额外页面，直到可用线程栈大小上限，其值为 “预留的栈大小 - 1个内存页面大小”，最后一页为保护页用于检测栈溢出
    // 8. 为栈预留的每一页都不能再用于其他任何用途，栈随其线程退出而被释放，若线程被其他线程终止，则栈不会释放
    // 9. SetThreadStackGuarantee 函数可在栈溢出时，为线程或纤程设置保证可用的最小栈大小
    assert(reserved_stack_size >= 0 && proc != prh_null);
    thrd->extra_ptr = (prh_ptr)proc; // 如果指定的栈大小 < 64KB，将使用默认的栈大小 1MB
    HANDLE thrd_hdl = (HANDLE)_beginthreadex(prh_null, (unsigned int)reserved_stack_size, prh_impl_plat_thrd_procedure, thrd, STACK_SIZE_PARAM_IS_A_RESERVATION, prh_null);
    if (thrd_hdl > 0) {
        thrd->impl_hdl_ = (prh_ptr)thrd_hdl;
    } else {
        prh_abort_error(errno);
    }
}

void prh_thrd_exit(int exit_code) {
    // ExitThread 是在 C 代码中退出线程的首选方法。然而，在 C++ 代码中，调用 ExitThread
    // 会导致线程在调用任何析构函数或执行其他自动清理操作之前就终止。因此，在 C++ 代码
    // 中，应该从线程函数中返回。
    // 当调用此函数（无论是显式调用还是从线程过程返回）时，当前线程栈将被释放，所有由该
    // 线程发起的、未与完成端口关联的挂起 I/O 将被取消，并且线程将终止。所有已附加的动
    // 态链接库（DLL）的入口点函数将被调用，并传入一个值，指示该线程正在从 DLL 中分离。
    // 如果当此函数被调用时，该线程是进程中的最后一个线程，则该线程的进程也将终止。
    // 线程对象的状态（thread object state）变为已触发（signaled），释放任何一直等待
    // 该线程终止的其他线程。线程的终止状态（termination status）从 STILL_ACTIVE 变
    // 更为 dwExitCode 参数的值。终止线程并不一定会从操作系统中删除线程对象，当线程的
    // 最后一个句柄被关闭时，线程对象才会被删除。
    // ExitProcess、ExitThread、CreateThread、CreateRemoteThread 函数以及正在启动
    // 的进程（作为 CreateProcess 调用的结果）在进程内部彼此串行化。在同一时刻，这些
    // 事件中只有一个可以在一个地址空间中发生。这意味着：
    // - 在进程启动和 DLL 初始化例程期间，可以创建新线程，但它们直到进程的 DLL 初始化
    //   完成后才开始执行。
    // - 在进程中，一次只能有一个线程处于 DLL 初始化或分离例程中。
    // - ExitProcess 不会返回，直到没有线程处于它们的 DLL 初始化或分离例程中。
    // 链接到静态 C 运行时库（CRT）的可执行文件中的线程应使用 _beginthread 和 _endthread
    // 进行线程管理，而不是 CreateThread 和 ExitThread。如果不这样做，则当线程调用
    // ExitThread 时会导致小的内存泄漏。另一种解决方法是将可执行文件链接到 DLL 中的
    // CRT，而不是静态 CRT。请注意，只有当 DLL 链接到静态 CRT 并且线程调用 DisableThreadLibraryCalls
    // 函数时，才会从 DLL 发生此内存泄漏。从链接到静态 CRT 的 DLL 中的线程调用
    // CreateThread 和 ExitThread 是安全的。
    //
    // void _endthreadex(unsigned retval)
    // 你可以显式调用 _endthread 或 _endthreadex 来终止线程；然而，当线程从作为参数
    // 传递给 _beginthread 或 _beginthreadex 的例程返回时，_endthread 或 _endthreadex
    // 会被自动调用。通过调用 _endthread 或 _endthreadex 来终止线程，有助于确保为线程
    // 分配的资源的正确回收。
    // 注意，对于与 Libcmt.lib 链接的可执行文件，不要调用 Win32 ExitThread API；这会
    // 阻止运行时系统回收已分配的资源。_endthread 和 _endthreadex 会回收为线程分配的
    // 资源，然后调用 ExitThread。_endthread 会自动关闭线程句柄，此行为与 ExitThread
    // 不同。因此，当你使用 _beginthread 和 _endthread 时，不要通过调用 CloseHandle
    // 显式关闭线程句柄。与 ExitThread API 类似，_endthreadex 不会关闭线程句柄。因
    // 此，当你使用 _beginthreadex 和 _endthreadex 时，必须通过调用 CloseHandle 关
    // 闭线程句柄。
    // 注意，_endthread 和 _endthreadex 会导致线程中待处理的 C++ 析构函数不被调用。
    //
    // GetExitCodeThread 函数仅在线程终止后返回由应用程序定义的有效错误代码。 因此，
    // 应用程序不应使用 STILL_ACTIVE (259) 作为错误代码。如果线程返回 STILL_ACTIVE
    // (259) 作为错误代码，则测试此值的应用程序可能会将其解释为表示线程仍在运行，并在
    // 线程终止后继续测试线程完成情况，这可能会使应用程序进入无限循环。为避免此问题，
    // 调用方应仅在确认线程退出后调用 GetExitCodeThread 函数。使用等待持续时间为零的
    // WaitForSingleObject 函数来确定线程是否已退出。
    assert(exit_code != STILL_ACTIVE); // The return value should never be set to STILL_ACTIVE (259).
#if 1
    _endthreadex((unsigned)exit_code);
#else
    ExitThread((DWORD)exit_code);
#endif
}

void prh_impl_close_handle(HANDLE handle) {
    // 如果函数失败，返回值为零。要获取扩展错误信息，请调用 GetLastError。如果应用程
    // 序在调试器下运行，当函数接收到无效句柄值或伪句柄值时，将引发异常。这种情况可能发
    // 生在：你关闭了一个句柄两次，或你对 FindFirstFile 返回的句柄调用了 CloseHandle，
    // 而不是调用 FindClose 函数。
    PRH_BOOLRET_OR_ERROR(CloseHandle(handle));
}

bool prh_impl_wait_single_object(HANDLE handle, DWORD msec) {
    DWORD n = WaitForSingleObject(handle, msec);
    if (n == WAIT_OBJECT_0) return true;
    if (n == WAIT_FAILED) prh_prerr(GetLastError());
    else if (n != WAIT_TIMEOUT) prh_prerr(n);
    return false;
}

void prh_impl_plat_thrd_join(prh_thrd *thrd) {
    HANDLE thrd_impl_hdl = (HANDLE)thrd->impl_hdl_;
    int exit_code = 0;
    if (prh_impl_wait_single_object(thrd_impl_hdl, INFINITE)) {
        DWORD ExitCode;
        if (GetExitCodeThread(thrd_impl_hdl, &ExitCode)) {
            exit_code = (int)ExitCode;
        } else {
            prh_prerr(GetLastError());
        }
    }
    // 终止线程并不一定会从操作系统中删除线程对象，当线程的最后一个句柄被关闭时，线程对象才会被删除。
    prh_impl_close_handle(thrd_impl_hdl);
#if PRH_THRD_DEBUG
    printf("[thrd %02d] joined %d\n", prh_thrd_id(thrd), exit_code);
#else
    if (exit_code != 0) {
        prh_print_exit_code(prh_thrd_id(thrd), exit_code);
    }
#endif
}

prh_ptr prh_impl_plat_thrd_self(void) {
    // HANDLE GetCurrentThread()
    //      processthreadsapi.h (include Windows.h)
    //      Kernel32.lib Kernel32.dll
    //      Windows XP Windows Server 2003
    // 返回当前调用线程的伪句柄。伪句柄（pseudo handle）是一种特殊常量，仅用作当前线
    // 程的句柄。调用线程可在需要线程句柄的任何场合使用它来指代自身。伪句柄不会被子进
    // 程继承。该句柄对线程对象拥有 THREAD_ALL_ACCESS 访问权限。更多信息请参阅《线程
    // 安全与访问权限》。Windows Server 2003 与 Windows XP：此句柄拥有线程安全描述
    // 符所允许的最大访问权限，作用于进程主令牌（the primary token of the process）。
    // 本函数不能被线程 A 用来创建一个可供线程 B 引用的句柄；该句柄始终被解释为正在使
    // 用它的线程本身。线程可以通过在 DuplicateHandle 调用中将伪句柄作为源句柄，来创
    // 建一个 “真实”句柄，该句柄可被其他线程使用，或被其他进程继承。伪句柄不再需要时无
    // 需关闭。对此句柄调用CloseHandle函数不会产生任何效果。如果通过 DuplicateHandle
    // 复制了伪句柄，则必须关闭所得到的重复句柄。
    // 不要在模拟（impersonating）安全上下文时创建线程。调用会成功，但新建线程在随后
    // 调用 GetCurrentThread 时，对自身将拥有降低的访问权限；这些权限来源于被模拟用户
    // 对进程的访问权限。某些访问权限（包括 THREAD_SET_THREAD_TOKEN 和
    // THREAD_GET_CONTEXT）可能不存在，导致意外失败。
    return (prh_ptr)GetCurrentThread();
}

// 调用 DWORD SuspendThread(HANDLE handle) 可以将对应线程挂起，它返回线程的原本的挂
// 起次数，如果失败返回 0xFFFFFFFF。一个线程可以被多次挂起（MAXIMUM_SUSPEND_COUNT），
// WinNT.h 中定义为 127 次。假如线程挂起了三次，在有资格让系统为它分配 CPU 之前，必须
// 恢复三次。显然，线程可以将自己挂起，但是它无法自己恢复。请注意，就内核模式下执行情况
// 而言，SuspendThread 是异步的，但在线程恢复之前，它是无法在用户模式下执行的。
//
// 实际开发中，应用程序在调用 SuspendThread 时必须小心，因为试图挂起一个线程时，我们不
// 知道线程在做什么。例如，如果线程正在分配堆中的内存，线程将锁定堆。当其他线程要访问堆
// 的时候，它们的执行将被中止，直到第一个线程恢复。只有在确切知道目标线程时哪个，或者它
// 在做什么，而且采取完备措施避免出现因挂起线程而引起问题或者死锁的时候，手动挂起才是安
// 全的。
//
// 怎样挂起一个进程中的所有线程。在一个特殊情况下，即调试器处理 WaitForDebugEvent 返回
// 的调试事件时，Windows 将冻结被调试进程中的所有线程，直至调试器调用 ContinueDebugEvent。
// Windows 没有提供其他方式挂起进程中的所有线程，因为存在竞态条件问题。虽然没有十全十美
// SuspendProcess 函数，但是可以使用 CreateToolHelp32Snapshot() 创建一个适用于大多数
// 情况的版本。这里我们借助 ToolHelp 函数来枚举系统中的线程列表，一旦找到属于某个进程的
// 线程，便调用 OpenThread 和 SuspendThread。我们不难理解 SuspendProcess 不能随便使
// 用，因为在枚举线程集合的时候，可能会有新的线程创建，也可能有线程被销毁。更糟糕的是，
// 在枚举线程 ID 时，可能会销毁一个已有线程，创建一个新的线程，而这两个线程恰好 ID 相同。
// 这样可能挂起任意一个线程，可能这个线程属于目标进程之外的进程。
//
// 函数 BOOL SwitchToThread() 可以切换到另一个可调度线程。调用该函数时，系统查看是否
// 存在急需 CPU 时间的饥饿线程，如果没有 SwithToThread() 会立即返回。如果存在，将调度
// 该线程，其优先级可能比 SwitchToThread 的主调线程低。饥饿线程可以运行一个时间量，然
// 后系统调度程序恢复正常运行。通过这个函数，需要莫格资源的线程可以强制一个可能拥有该资
// 源的低优先级线程放弃资源。如果在调用 SwitchToThread 时没有其他线程可以运行，则函数
// 返回 FALSE，否则函数将返回一个非零值。调用 SwitchToThread 与调用 Sleep(0) 类似。
// 区别在于，SwitchToThread 允许执行低优先级线程，Sleep 会立即重新调度主调线程，即使
// 低优先级线程还处于饥饿状态。
//
// 在超线程 CPU 上切换到另一个线程。超线程（hyper-threading）是 Xeon，Pentium 4 和
// 更新的 CPU 支持的一种技术。超线程处理器芯片有多个逻辑 CPU，每个都可以运行一个线程。
// 每个线程都有自己的体系结构状态（一组寄存器），但是所有线程共享主要的执行执行资源，比
// 如 CPU 高速缓存。当一个线程中止时，CPU 自动执行另一个线程，无需操作系统干预，只有在
// 缓存未命中，分支预测错误和需要等待前一个指令的结果等情况下，CPU 才会暂停。
//
// 在超线程 CPU 上执行旋转循环（spin loop）时，需要我们强制当前线程暂停，使另一个线程
// 可以访问芯片的资源。x86 体系结构支持一个名为 PAUSE 的汇编语言指令，PAUSE 指令可以确
// 保避免内存顺序违规，从而改进性能。此外，该指令还可以通过在非常耗电、密集的循环中添加
// 间歇（hiccup）性的空操作，以减少能源消耗。在 x86 上，PAUSE 指令等价于 REP NOP 指令，
// 这样就能够兼容更早的不支持超线程的 IA-32 CPU。PAUSE 会导致一定的延时（有些 CPU 上
// 为 0）。在 Win32 API 中，x86 PAUSE 指令使通过调用 WinNT.h 中定义的 YieldProcessor
// 宏实现的。有了这个宏，我们就可以编写与 CPU 体系结构无关的代码了。
//
// GetThreadTimes GetProcessTimes QueryThreadCycleTime QueryProcessCycleTime
// GetProcessTimes() 会返回进程中所有线程花费的时间，即使线程已经终止。
//
// 一般而言，有较高优先级的线程大多数时候都应是不可调度的，当这种线程要执行什么任务时，
// 很快就能得到 CPU 时间。这时，线程应该尽可能少地执行 CPU 指令，并重新进入睡眠，等待
// 再次被调度。相反，优先级低的可以保持为可调度状态，执行大量 CPU 指令以完成其任务。如
// 果遵循这些规则，整个操作系统就能够很好地响应用户。
//
// 系统通过线程的相对优先级，加上线程所属进程的优先级来确定线程的优先级值。有时候，这也
// 被称为线程的基本优先级（base priority level）。偶尔，系统也会提升一个线程的优先级，
// 通常是为了响应某种 I/O 事件比如窗口消息或者磁盘读取。系统只提升优先级值在 1~15 的线
// 程。事实上，正因为如此，这个范围被称为动态优先级范围。而且，系统不会把线程的优先级提
// 升到实时范围（高于 15）。因为实时范围内的线程执行了大多数操作系统功能，对提升设置上
// 限，可以防止应用程序影响操作系统。
//
// 另一种情况也会导致系统动态提升线程的优先级，例如有一个优先级为 4 的线程，它已经准备
// 好运行了，但是由于有一个优先级为 8 的线程一直处于可调度状态，因此它无法运行。这种情
// 况下，优先级为 4 的线程处于 CPU 时间饥饿状态，当系统检测到有线程已经处于饥饿状态 3
// 到 4 秒时，它会动态将饥饿线程的优先级提升至 15，并允许该线程运行两个时间片。当两个
// 时间片结束时，线程的优先级立即恢复到基本优先级。
//
// 设置线程优先级将影响系统如何给线程分配 CPU 资源。但是，线程还要执行 I/O 请求，以及
// 对磁盘文件读写数据。如果一个低优先级线程获得 CPU 时间，它可能很轻易地在很短时间内将
// 成百上千个 I/O 请求入列。因为 I/O 请求一般都需要时间进行处理，导致低优先级线程会挂
// 起高优先级线程，使它们无法完成任务，从而显著影响系统的响应性。因此，我们可以看到，在
// 执行一些运行时间较长的低优先级服务比如磁盘碎片整理程序、病毒扫描程序、内容索引程序的
// 时候，机器的响应性会变得很差。
//
// 从 Windows Vista 开始，线程可以在进行 I/O 请求时设置优先级了。我们可以通过调用
// SetThreadPriority 并传入 THREAD_MODE_BACKGROUND_BEGIN 来告诉 Windows，线程应该
// 发送低优先级的 I/O 请求。注意，这也将降低线程的 CPU 调度优先级。并可以传入 THREAD_MODE_BACKGROUND_END
// 让线程进行 normal 优先级 I/O 以及 normal CPU 调度优先级。系统不允许线程改变另一个
// 线程的 I/O 优先级。如果想让进程中的所有线程都进行低优先级的 I/O 请求和低 CPU 调度，
// 那么我们可以调用 SetPriorityClass，并传入 PROCESS_MODE_BACKGROUND_BEGIN 和
// PROCESS_MODE_BACKGROUND_END 标志实现。系统不允许线程改变另一个进程中线程的 I/O
// 优先级。在更细的粒度上，normal 优先级线程还可以执行对某个文件执行后台优先级 I/O，
// SetFileInformationByHandle(file, FileIoPriorityHintInfo, &phi, sizeof(PriorityHint))。
//
// 在默认情况下，如果其他因素都一样，系统将使线程在上一次运行的处理器上运行。让线程始终
// 在同一个处理器上运行有助于重用仍在处理器高速缓存中的数据。有一种称为 NUMA（Non-Uniform
// Memory Access）非统一内存访问的计算机体系结构，结构的计算机中由多个系统板（board）
// 组成，每个系统板都有自己的 CPU 和内存板块。NUMA 系统在 CPU 只访问自己所在系统板上的
// 内存时，可达到最佳性能。如果 CPU 需要访问其他系统板上的内存，性能下降得很厉害。
//
// Windows 允许我们设置进程和线程的关联性（affinity），也就是说，我们可以控制 CPU 让
// 哪些 CPU 运行特定的线程，这称为硬关联（hard affinity）。默认情况下，系统可以将任何
// CPU 调度给任何线程使用。如果要限制某些线程只在可用 CPU 的一个子集上运行，可以调用函
// 数 SetProcessAffinityMask。请注意，子进程将继承进程关联性。此外，我们还可以使用作
// 业内核对象，来限制一组进程只在一组 CPU 上运行。另外，Windows 任务管理器运行我们更改
// 进程的 CPU 关联性。
//
// 有时候，我们还需要限制进程中的一个线程只在一组 CPU 上运行，例如需要让一个有 4 个线程
// 的进程运行在一台有 4 个 CPU 的机器上。如果有些线程中有一个线程总在执行重要任务，需要
// 尽量使它总是获得 CPU，就需要限制其他三个线程不能在 CPU 0 上运行，只能在 CPU 1 2 3
// 上运行，可以调用 SetThreadAffinityMask 实现，其中 dwThreadAffinityMask 必须是进
// 程关联性掩码的真子集。为了更高效地使用 CPU 时间，调度程序可能会在多个 CPU 之间迁移
// 线程。在大多数环境里，改变线程的关联性，将妨碍调度程序的这种能力。例如：
//      线程            优先级              关联性
//      A                4                  CPU 0
//      B                8                  CPU 0 CPU 1
//      C                6                  CPU 1
// 当线程 A 被唤醒时，调度程序看到该线程可以在 CPU 0 上运行，就将其分配给 A。然后线程
// B 唤醒，调度程序将 CPU1 分配给 B。现在还一切正常，然后线程 C 唤醒，调度程序看到它只
// 能在 CPU1 上运行，但 CPU1 已经被优先级为 8 的线程 B 使用了。因为线程 C 的优先级为
// 6，所以它无法抢占线程 B，它本来可以抢占优先级为 4 的线程 A，但是因为线程 C 不能在
// CPU 0 上运行，所以调度程序也不能抢占线程 A。这说明设置线程的硬关联性，将影响调度程序
// 的调度方案。
//
// 有时候强制一个线程只使用特定的某个 CPU 并不是什么好主意。例如，可能有三个线程都只能
// 使用 CPU 0，而 CPU 1 2 3 却无所事事。如果能够告诉系统，我们想让一个线程运行在一个
// CPU 上，但系统运行将它移到另一个空闲的 CPU，那就更好了。要给线程设置一个理想的 CPU，
// 可以调用 DWORD SetThreadIdealProcessor(HANDLE thread, DWORD dwIdealProcessor)。
// 其中 dwIdealProcessor 不是位掩码，他是一个 0 到 31/63 之间的整数，表示线程希望设置
// 的 CPU。可以传入一个 MAXIMUM_PROCESSORS 值（WinNT.h 中定义，在 32 位操作系统中定
// 义为 32，64 位操作系统中定义为 64），表示线程没有理想 CPU。

#if prh_arch_32
#define PRH_MUTEX_SIZE_PTRS 6
#else prh_arch_64
#define PRH_MUTEX_SIZE_PTRS 5
#endif

#define PRH_RWLOCK_SIZE_PTRS 1
#define PRH_COND_SIZE_PTRS 1
#define PRH_ONCE_SIZE_PTRS 1

struct prh_mutex {
    CRITICAL_SECTION mutex;
};

struct prh_rwlock {
    SRWLOCK rwlock;
};

struct prh_cond {
    CONDITION_VARIABLE cond;
};

struct prh_once {
    INIT_ONCE once;
};

prh_static_assert(sizeof(struct prh_mutex) <= PRH_MUTEX_SIZE_PTRS * sizeof(void *));
prh_static_assert(sizeof(struct prh_rwlock) <= PRH_RWLOCK_SIZE_PTRS * sizeof(void *));
prh_static_assert(sizeof(struct prh_cond) <= PRH_COND_SIZE_PTRS * sizeof(void *));

struct prh_thrd_cond {
    CRITICAL_SECTION mutex; // 1st field
    CONDITION_VARIABLE cond;
};

struct prh_thrd_sem {
    CRITICAL_SECTION mutex; // 1st field
    CONDITION_VARIABLE cond; // 2nd field
    prh_int wakeup_semaphore;
};

struct prh_cond_sleep {
    CRITICAL_SECTION mutex; // 1st field
    CONDITION_VARIABLE cond; // 2nd field
    prh_atom_bool wakeup_semaphore;
};

int prh_mutex_size(void) {
    return (int)sizeof(prh_mutex);
}

int prh_rwlock_size(void) {
    return (int)sizeof(prh_rwlock);
}

int prh_cond_size(void) {
    return (int)sizeof(prh_cond);
}

int prh_once_size(void) {
    return (int)sizeof(prh_once);
}

int prh_impl_thrd_cond_size(void) {
    return (int)sizeof(prh_thrd_cond);
}

int prh_impl_thrd_sem_size(void) {
    return (int)sizeof(prh_thrd_sem);
}

int prh_impl_thrd_sleep_size(void) {
    return (int)sizeof(prh_cond_sleep);
}

void prh_mutex_init(prh_mutex *p) {
    prh_impl_critical_section_init(&p->mutex);
}

void prh_recursive_mutex_init(prh_mutex *p) {
    prh_mutex_init(p);
}

void prh_mutex_free(prh_mutex *p) {
    DeleteCriticalSection(&p->mutex);
}

void prh_mutex_enter(prh_mutex *p) {
    // 被 EnterCriticalSection 阻塞的线程，如果长时间获取不到锁，会在一定时间后超时。
    // 超时时间设置在注册表中 HKEY_LOCAL_MACHINE/System/CurrentControlSet/Control/
    // Session Manager/CriticalSectionTimeout。这个值以秒为单位，它的默认值大约是30
    // 天，259_2000 秒。同一个线程在 leave 之前可以多次 enter 同一个关键段。
    // 在使用关键段时还可能产生另一个问题，如果有两个或两个以上线程在同一时刻争夺同一个
    // 关键段，那么关键段会在内部使用一个事件内核对象，由于争夺现象很少发生，因此只有当
    // 第一次要用到事件内核对象的时候，系统才会真正创建它。Windows XP 之前，当内存不足
    // 以分配事件内核对象时，EnterCriticalSection 会抛出 EXCEPTION_INVALID_HANDLE
    // 异常。自 Windows XP 开始，引入了新的有键事件（keyed event）类型的内核对象，用
    // 来帮助解决资源不足的情况下创建事件的问题。当操作系统创建进程的时候，总是会创建一
    // 个有键事件，我们可以使用 Sysinternals 的 Process Explorer 工具找到这个名叫
    // \KernelObjects\CritSecOutOfMemoryEvent 的实例。这个未公开的内核对象的行为与
    // 事件内核对象相同，唯一的不同之处在于它的一个实例能够同步不同的线程组，每组由一个
    // 指针大小的键值来标识和阻挡。在关键段的情况中，当内存不足以创建一个事件内核对象的
    // 时候，可以将关键段的地址当作键值来使用。通过将关键段的地址当作键值，系统可以对试
    // 图进入这个关键段的线程进行同步，并在必要的情况下将它们阻挡在外。
    EnterCriticalSection(&p->mutex);
}

bool prh_mutex_try_enter(prh_mutex *p) {
    // 如果返回 true 表示已经成功锁定了关键段，之后必须有一个对应的 leave 调用。
    return (TRUE == TryEnterCriticalSection(&p->mutex));
}

void prh_mutex_exit(prh_mutex *p) {
    LeaveCriticalSection(&p->mutex);
}

void prh_rwlock_init(prh_rwlock *p) {
    InitializeSRWLock(&p->rwlock);
}

void prh_rwlock_free(prh_rwlock *p) {
    // SRWLOCK no need to free
}

void prh_rwlock_read_enter(prh_rwlock *p) { // Windows Vista Server 2008
    AcquireSRWLockShared(&p->rwlock);
}

bool prh_rwlock_try_read(prh_rwlock *p) { // Windows 7 Server 2008 R2
    return TryAcquireSRWLockShared(&p->rwlock) != 0;
}

void prh_rwlock_read_exit(prh_rwlock *p) { // Windows Vista Server 2008
    ReleaseSRWLockShared(&p->rwlock);
}

void prh_rwlock_write_enter(prh_rwlock *p) { // Windows Vista Server 2008
    AcquireSRWLockExclusive(&p->rwlock);
}

bool prh_rwlock_try_write(prh_rwlock *p) { // Windows 7 Server 2008 R2
    return TryAcquireSRWLockExclusive(&p->rwlock) != 0;
}

void prh_rwlock_write_exit(prh_rwlock *p) { // Windows Vista Server 2008
    ReleaseSRWLockExclusive(&p->rwlock);
}

void prh_cond_init(prh_cond *p) {
    InitializeConditionVariable(&p->cond);
}

void prh_cond_free(prh_cond *p) {
    // CONDITION_VARIABLE no need to free
}

void prh_cond_wait_with_mutex_exit_reenter(prh_cond *p, prh_mutex *mutex) {
    prh_boolret(SleepConditionVariableCS(&p->cond, &mutex->mutex, INFINITE)); // 临界区必须在此函数调用之前精确地进入一次
}

void prh_cond_wait_with_read_exit_reenter(prh_cond *p, prh_rwlock *lock) {
    prh_boolret(SleepConditionVariableSRW(&p->cond, &lock->rwlock, INFINITE, CONDITION_VARIABLE_LOCKMODE_SHARED));
}

void prh_cond_wait_with_write_exit_reenter(prh_cond *p, prh_rwlock *lock) {
    prh_boolret(SleepConditionVariableSRW(&p->cond, &lock->rwlock, INFINITE, 0));
}

void prh_cond_timed_wait_with_mutex_exit_reenter(prh_cond *p, prh_mutex *mutex, prh_u32 msec) {
    BOOL b = SleepConditionVariableCS(&p->cond, &mutex->mutex, msec); // 临界区必须在此函数调用之前精确地进入一次
    if (b == FALSE && GetLastError() != ERROR_TIMEOUT) prh_prerr(GetLastError());
}

void prh_cond_timed_wait_with_read_exit_reenter(prh_cond *p, prh_rwlock *lock, prh_u32 msec) {
    BOOL b = SleepConditionVariableSRW(&p->cond, &lock->rwlock, msec, CONDITION_VARIABLE_LOCKMODE_SHARED);
    if (b == FALSE && GetLastError() != ERROR_TIMEOUT) prh_prerr(GetLastError());
}

void prh_cond_timed_wait_with_write_exit_reenter(prh_cond *p, prh_rwlock *lock, prh_u32 msec) {
    BOOL b = SleepConditionVariableSRW(&p->cond, &lock->rwlock, msec, 0);
    if (b == FALSE && GetLastError() != ERROR_TIMEOUT) prh_prerr(GetLastError());
}

void prh_cond_signal(prh_cond *p) {
    WakeConditionVariable(&p->cond);
}

void prh_cond_broadcast(prh_cond *p) {
    WakeAllConditionVariable(&p->cond);
}

// VOID InitOnceInitialize(PINIT_ONCE InitOnce); // Windows Vista Server 2008
//
// InitOnceInitialize 函数用于动态初始化一次性初始化结构。若要静态初始化该结构，请将常
// 量 INIT_ONCE_STATIC_INIT 赋值给结构体。若要编译使用此函数，请将 _WIN32_WINNT 定义
// 为 0x0600 或更高版本。一次性初始化对象不能被移动或复制。进程必须不得修改初始化对象，
// 而应将其视为逻辑上不透明。只能使用一次性初始化函数来管理一次性初始化对象。

void prh_once_init(prh_once *p) {
    InitOnceInitialize(&p->once);
}

// BOOL InitOnceExecuteOnce(
//  [in, out]           PINIT_ONCE    InitOnce,
//  [in]                PINIT_ONCE_FN InitFn,
//  [in, optional]      PVOID         Parameter,
//  [in, out, optional] LPVOID        *Context
// );
// PINIT_ONCE_FN PinitOnceFn;
// BOOL PinitOnceFn(
//   [in, out]           PINIT_ONCE InitOnce,
//   [in, out, optional] PVOID Parameter,
//   [out, optional]     PVOID *Context
// );
//
// 当多个线程调用 InitOnceExecuteOnce 并传递相同的初始化块时，只有一个线程会执行 InitFn
// 指定的回调函数。其余线程将阻塞，直到回调函数完成。如果回调函数返回 TRUE 表示成功，
// InitOnceExecuteOnce 将一次性返回 TRUE 给所有调用者。然而，如果回调返回 FALSE 表示
// 失败，InitOnceExecuteOnce 仅返回 FALSE 给执行回调函数的单个线程。此时，其中一个剩余
// 的阻塞线程将解除阻塞并再次执行 InitFn。因此，在 InitFn 可能间歇性失败且需要重试的情
// 况下，所有线程应继续调用 InitOnceExecuteOnce，直到返回 TRUE。
//
// 参数 InitOnce 指向一次性初始化结构的指针。InitFn 指向应用程序定义回调函数。Parameter
// 要传递给回调函数的参数。
//
// 参数 Context 成功时接收与一次性初始化结构关联的数据。数据的低阶 INIT_ONCE_CTX_RESERVED_BITS
// 位始终为零。如果 Context 指向一个数据结构，则该结构必须 DWORD 对齐。在 Arm32 上，
// Context 不能是代码指针，因为 Arm32 代码指针的最低有效位始终为 1。
//
// 如果函数成功，返回值是非零值。如果失败返回零，调用 GetLastError 获取扩展错误信息。
//
// 此函数用于同步的一次性初始化。对于异步的一次性初始化，需要使用带有 INIT_ONCE_ASYNC
// 标志的 InitOnceBeginInitialize 函数。任何时刻只有一个线程可以执行 InitFn 指定的回
// 调函数。指定相同一次性初始化结构的其他线程将阻塞，直到回调完成。
//
// 要获得初始化的值，需要调用 InitOnceExecuteOnce，它将在内部使用双重检查锁定，并且在
// 需要时调用 InitFn 进行初始化，最后在 Context 参数中返回这个值。

bool prh_once_execute(prh_once *p, prh_once_init_routine init, void *param, void **value) {
    assert(((prh_ptr)value & 0x03) == 0); // 地址必须 DWORD 四字节对齐，INIT_ONCE_CTX_RESERVED_BITS 的值为 2
    return InitOnceExecuteOnce(&p->once, init, param, value) != 0;
}

// https://learn.microsoft.com/en-us/windows/win32/sync/using-one-time-initialization
//
// BOOL InitOnceBeginInitialize(
//  [in, out]       LPINIT_ONCE lpInitOnce,
//  [in]            DWORD       dwFlags,
//  [out]           PBOOL       fPending,
//  [out, optional] LPVOID      *lpContext
// );
//
// 开始一次性初始化。如果未指定 INIT_ONCE_CHECK_ONLY 且函数成功，则返回值为 TRUE。如
// 果指定了 INIT_ONCE_CHECK_ONLY 且初始化已经完成，则返回值为 TRUE。否则返回 FALSE，
// 要获取扩展错误信息，请调用 GetLastError。
//
// 参数 lpInitOnce 指向一次性初始化结构的指针。参数 dwFlags 可以是 0，或者以下一个或多
// 个标志的组合。
//  INIT_ONCE_ASYNC         0x00000002UL
//      启用并行执行的多个初始化尝试。如果使用此标志，后续对该函数的调用也要指定此标志，
//      否则调用将失败。
//  INIT_ONCE_CHECK_ONLY    0x00000001UL
//      此函数调用不开始初始化。返回值指示是否已经完成初始化。如果函数返回 TRUE，则
//      lpContext 参数接收数据。
//
// 参数 fPending 如果函数成功，此参数指示当前初始化状态。
//  1.  如果此参数为 TRUE 且 dwFlags 包含 INIT_ONCE_CHECK_ONLY，则初始化正在等待，且
//      上下文数据无效。
//  2.  如果此参数为 TRUE 且 dwFlags 不包含 INIT_ONCE_CHECK_ONLY，则初始化已经开始，
//      调用方可以执行初始化任务。
//  3.  如果此参数为 FALSE，则初始化已经完成，调用方可以从 lpContext 参数中检索上下文
//      数据。
//
// 参数 lpContext 成功时接收与一次性初始化结构关联的数据。数据的低阶 INIT_ONCE_CTX_RESERVED_BITS
// 位始终为零。
//
// 此函数可用于同步或异步的一次性初始化。对于异步一次性初始化，请使用 INIT_ONCE_ASYNC
// 标志。若要在同步一次性初始化期间指定要执行的回调函数，见 InitOnceExecuteOnce 函数。
// 如果函数成功，线程可以创建一个同步对象，并传递给 InitOnceComplete 函数的 lpContext
// 参数。
//
// 一次性初始化对象不能被移动或复制。进程必须不得修改初始化对象，而应将其视为逻辑上不透
// 明的。只能使用一次性初始化函数来管理一次性初始化对象。
//
// BOOL InitOnceComplete(
//  [in, out]      LPINIT_ONCE lpInitOnce,
//  [in]           DWORD       dwFlags,
//  [in, optional] LPVOID      lpContext
// );
//
// 完成由 InitOnceBeginInitialize 函数开始的一次性初始化。如果函数成功，返回值是非零
// 值。如果失败返回零，调用 GetLastError 获取扩展错误信息。
//
// 参数 lpInitOnce 指向一次性初始化结构的指针。参数 dwFlags 可以是以下标志之一。
//  INIT_ONCE_ASYNC         0x00000002UL
//      以异步模式操作。这允许多个并行执行的完成尝试。此标志必须与调用 InitOnceBeginInitialize
//      函数时传递的相应标志匹配。此标志不能与 INIT_ONCE_INIT_FAILED 结合使用。
//  INIT_ONCE_INIT_FAILED   0x00000004UL
//      初始化尝试失败。此标志不能与 INIT_ONCE_ASYNC 结合使用。若要使异步初始化失败，
//      只需放弃它，即不调用 InitOnceComplete 函数。
//
// 参数 lpContext，此数据将在后续调用 InitOnceBeginInitialize 函数时通过 lpContext
// 参数返回。如果 lpContext 指向一个值，则该值的低阶 INIT_ONCE_CTX_RESERVED_BITS 位
// 必须为零。如果 lpContext 指向一个数据结构，则该数据结构必须 DWORD 对齐。
//
// 如果使用 InitOnceBeginInitialize 和 InitOnceComplete 异步初始化模型，多个初始化
// 可以同时执行，但只有一个获胜，并且将它的值公布到 INIT_ONCE 数据结构。不同于同步模型，
// 其他线程调用该函数不会被第一个正在进行初始化的线程阻塞。如果一个线程要负责初始化这个
// 值，那么它将在这个 InitOnceBeginInitialize 返回后继续执行，在执行完初始化后，调用
// InitOnceComplete 并在 lpContext 参数中指定初始化的值。如果初始化失败，那么使用标志
// INIT_ONCE_INIT_FAILED 调用 InitOnceComplete。如果 InitOnceComplete 返回 FALSE，
// 那么它意味着另一个线程与调用线程（带有同步的初始化）发生竞争并且获取，而这个调用者必
// 须通过带有 INIT_ONCE_CHECK_ONLY 标志的 InitOnceBeginInitialize 函数来获取最终的
// 初始化值。

void prh_impl_thrd_cond_init(prh_thrd_cond *p) {
    prh_mutex_init((prh_mutex *)p);
    InitializeConditionVariable(&p->cond);
}

void prh_impl_thrd_cond_free(prh_thrd_cond *p) {
    prh_mutex_free((prh_mutex *)p);
    // A condition variable cannot be moved or copied while in use. The process
    // must not modify the object, and must instead treat it as logically
    // opaque. Only use the condition variable functions to manage condition
    // variables.
    // A condition variable with no waiting threads is in its initial state and
    // can be copied, moved, and forgotten without being explicitly destroyed.
}

prh_thrd_cond *prh_thrd_cond_init(void) {
    prh_thrd_cond *p = prh_malloc(sizeof(prh_thrd_cond));
    prh_impl_thrd_cond_init(p);
    return p;
}

void prh_thrd_cond_free(prh_thrd_cond *p) {
    // 仅当没有任何线程等待条件变量，将其销毁才是安全的。
    prh_impl_thrd_cond_free(p);
    prh_free(p);
}

void prh_thrd_cond_lock(prh_thrd_cond *p) {
    prh_mutex_enter((prh_mutex *)p);
}

void prh_impl_plat_cond_wait(prh_thrd_cond *p) {
    // the critical section must be entered exactly once by the caller at the
    // time SleepConditionVariableCS is called.
    prh_boolret(SleepConditionVariableCS(&p->cond, &p->mutex, INFINITE));
}

bool prh_impl_plat_cond_timedwait(prh_thrd_cond *p, prh_ptr time) {
    DWORD msec = (DWORD)time, error;
    if (SleepConditionVariableCS(&p->cond, &p->mutex, msec)) return true; // 线程被成功唤醒或被虚假唤醒
    if ((error = GetLastError()) != ERROR_TIMEOUT) prh_prerr(error); // 线程要么被唤醒，要么等待超时，其他情况不应该发生
    return false; // 线程等待超时
}

prh_ptr prh_impl_plat_cond_time(prh_i64 *ptr, prh_u32 msec) {
    return (prh_ptr)msec;
}

void prh_thrd_cond_unlock(prh_thrd_cond *p) {
    prh_mutex_exit((prh_mutex *)p);
}

void prh_thrd_cond_signal(prh_thrd_cond *p) {
    WakeConditionVariable(&p->cond);
}

void prh_thrd_cond_broadcast(prh_thrd_cond *p) {
    WakeAllConditionVariable(&p->cond);
}

void prh_impl_thrd_sem_init(prh_thrd_sem *p) {
    prh_impl_thrd_cond_init((prh_thrd_cond *)p);
    p->wakeup_semaphore = 0;
}

void prh_impl_thrd_sem_free(prh_thrd_sem *p) {
    prh_impl_thrd_cond_free((prh_thrd_cond *)p);
}

prh_thrd_sem *prh_thrd_sem_init(void) {
    prh_thrd_sem *p = prh_malloc(sizeof(prh_thrd_sem));
    prh_impl_thrd_sem_init(p);
    return p;
}

void prh_thrd_sem_free(prh_thrd_sem *p) {
    prh_impl_thrd_sem_free(p);
    prh_free(p);
}

void prh_thrd_sem_wait(prh_thrd_sem *p) {
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    while (p->wakeup_semaphore == 0) {
        prh_impl_plat_cond_wait((prh_thrd_cond *)p);
    }
    p->wakeup_semaphore -= 1;
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
}

void prh_thrd_sem_post(prh_thrd_sem *p, int new_semaphores) {
    assert(new_semaphores > 0);
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    p->wakeup_semaphore += new_semaphores;
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
    if (new_semaphores == 1) { // one semaphore available, can wakeup one thread to handle
        prh_thrd_cond_signal((prh_thrd_cond *)p);
    } else { // multi semaphore available, all thread can racing to handle them
        prh_thrd_cond_broadcast((prh_thrd_cond *)p);
    }
}

// TODO: 使用 WaitOnAddress() 重新实现 thrd cond sleep
// https://learn.microsoft.com/en-us/windows/win32/api/synchapi/nf-synchapi-waitonaddress

void prh_impl_init_cond_sleep(prh_cond_sleep *p) {
    prh_impl_thrd_cond_init((prh_thrd_cond *)p);
    prh_atom_bool_init(&p->wakeup_semaphore, false);
}

void prh_impl_free_cond_sleep(prh_cond_sleep *p) {
    prh_impl_thrd_cond_free((prh_thrd_cond *)p);
}

prh_cond_sleep *prh_init_cond_sleep(void) {
    prh_cond_sleep *p = prh_malloc(sizeof(prh_cond_sleep));
    prh_impl_init_cond_sleep(p);
    return p;
}

void prh_free_cond_sleep(prh_cond_sleep *p) {
    prh_impl_free_cond_sleep(p);
    prh_free(p);
}

bool prh_thrd_try_sleep(prh_cond_sleep *p) {
    if (prh_atom_bool_strong_clear(&p->wakeup_semaphore)) {
        return false;
    } else {
        return true;
    }
}

void prh_thrd_cond_sleep(prh_cond_sleep *p) {
    if (prh_atom_bool_strong_clear(&p->wakeup_semaphore)) return; // 已经有唤醒存在，不需要睡眠
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    while (!prh_atom_bool_read(&p->wakeup_semaphore)) {
        prh_impl_plat_cond_wait((prh_thrd_cond *)p);
    }
    prh_atom_bool_write(&p->wakeup_semaphore, false);
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
}

void prh_thrd_wakeup(prh_cond_sleep *p) {
    if (prh_atom_bool_read(&p->wakeup_semaphore)) return; // 已经有唤醒存在，无需重新唤醒
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    prh_atom_bool_write(&p->wakeup_semaphore, true);
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
    prh_thrd_cond_signal((prh_thrd_cond *)p);
}

// 以上一些线程同步机制，可以在进行线程同步的同时让线程保持在用户模式下。在用户模式下进
// 行线程同步的最大好处就是速度非常快。如果关心应用程序的性能，那么应该先看用户模式下的
// 同步机制能否适用。虽然用户模式下的线程同步机制提供了非常好的性能，但它们也的确存在一
// 些局限性。例如，对 Interlocked 系列函数只能对一个值进行操作，它们从来不会把线程切换
// 到等待状态。我们可以用关键段来把线程切换到等待状态，但是它们只能用来对同一个进程中的
// 线程进行同步。此外，在适用关键段的时候，我们无法为进入关键段指定一个最长等待时间。
//
// 与用户模式下的同步机制相比，内核对象的用途要广泛得多。实际上，内核对象唯一的缺点就是
// 它们的性能。当我们进行系统调用时，调用线程必须从用户模式切换到内核模式，完成后再切换
// 回来。这种切换非常耗时，在 x86 平台上，一个空的系统调用切换到内核模式大概会占用 200
// 个 CPU 周期，当然这还不包括执行被调函数在内核模式下的实现代码。但是，造成内核对象比
// 用户模式下的同步机制慢几个数量级的原因，是伴随调度新线程而来的刷新高速缓存以及错过高
// 速缓存（即未命中），这里我们谈论的是成百上千个 CPU 周期。
//
// 我们已经讨论了好几种内核对象，包括进程、线程、以及作业（Job）。几乎所有这些内核对象
// 都可以用来进行同步。对线程同步来说，这些内核对象中的每一种要么处于触发（signaled）
// 状态，要么处于未触发（nonsignaled）状态。Miscrosoft 未每种对象创建了一些规则，规定
// 如何在这两种状态之间进行转换。例如，进程内核对象在创建的时候总是处于未触发状态。当进
// 程终止时，操作系统会自动使进程内核对象变成触发状态。当进程内核对象被触发后，它将永远
// 保持在这种状态，再也不会变回到未触发状态。
//
// 下面的内核对象既可以处于触发状态，也可以处于未触发状态：进程、线程、作业、文件以及
// 控制台的标准流、事件、可等待计时器、信号量、互斥量。线程可以自己切换到等待状态，直到
// 另一个对象被触发为止。注意，用来决定每个对象处于触发状态还是未触发状态的规则与对象的
// 类型有关。等待函数使一个线程自愿进入等待状态，直到指定的内核对象被触发为止。注意，如
// 果线程在调用一个等待函数的时候，相应的内核对象已经处于触发状态，那么线程不会进入等待
// 状态。WaitForMultipleObjects() 可以用来同时等待多个内核对象的触发，其中 dwCount
// 参数传递等待的内核对象的数量，这个值必须在 1 ~ MAXIMUM_WAIT_OBJECTS（在 WinNT.h
// 头文件中被定义为 64）之间。
//
// 对一些内核对象来说，成功的调用 WaitForSingleObject 或 WaitForMultipleObjects 会
// 改变对象的状态。如果对象的状态发生了变化，称之为等待成功所引起的副作用。例如，等待
// 一个自动重置事件对象（auto reset event object），当事件对象被触发的时候，等待函数
// 检测到这一情况，会返回 WAIT_OBJECT_0 给调用线程。但是，就在函数返回之前，它会使事件
// 变为非触发状态。SignalObjectAndWait() 可以通过一个原子操作来触发一个内核对象并等待
// 另一个内核对象。出于两个原因，这个函数非常受欢迎。首先，因为我们经常需要触发一个对象
// 并等待另一个对象，让一个函数完成两个操作可以节省处理时间。每当我们调用的函数使线程从
// 用户模式切换到内核模式的时候，大概需要花费 200 个 CPU 周期（在 x86 平台上），而且
// 对线程进行重新调度甚至需要更多的时间。其次，如果没有 SignalObjectAndWait()，那么一
// 个线程就无法知道另一个线程何时出于等待状态。

// VOID Sleep(DWORD dwMilliseconds);
//
// 挂起当前线程的执行，直到指定的时间间隔超时。若要进入 “可提醒” 的等待状态，需要使用
// SleepEx 函数。参数 dwMilliseconds 线程将被挂起的时间间隔，以毫秒为单位。值为 0
// 时，线程会放弃剩余时间片，让给任何已就绪的线程；如果没有其他就绪线程，函数立即返回，
// 当前线程继续执行。Windows XP：值为 0 时，仅让给同等优先级的就绪线程；若无同等优先
// 级就绪线程，函数立即返回，当前线程继续执行。此行为从 Windows Server 2003 起改变。
// 值为 INFINITE 表示挂起永不超时（实际极少使用）。
//
// 本函数使线程放弃剩余时间片，并在 dwMilliseconds 指定的时间段内变为不可运行状态。
// 系统时钟以固定频率（ticks）“滴答” 。若 dwMilliseconds 小于系统时钟分辨率，线程
// 实际休眠时间可能短于指定值。若请求时间介于 1 与 2 个滴答之间，实际等待将在 1–2 滴
// 答范围内，以此类推。
//
// 为提高休眠间隔精度，先调用 timeGetDevCaps 获取系统支持的最小计时器分辨率，再调用
// timeBeginPeriod 将分辨率设为最小值。调用 timeBeginPeriod 需谨慎，频繁调用会显著
// 影响系统时钟、电源和调度器。若调用 timeBeginPeriod，应在应用早期调用一次，并务必
// 在应用结束时调用 timeEndPeriod 恢复。
//
// 休眠间隔过后，线程变为“就绪”状态。若指定 0 毫秒，线程将放弃剩余时间片但仍保持就绪。
// 注意，就绪线程不保证立即运行。因此，线程将在休眠时间间隔过去后的某个任意时间才会运
// 行，具体取决于系统“滴答”频率和其他进程的负载。详见 “调度优先级” 文档。在以下场景中
// 使用 Sleep 时需格外小心：
//
//  1.  直接或间接创建窗口的代码（例如 DDE、COM CoInitialize）。若线程创建任何窗口，
//      则必须处理消息。系统会向所有窗口广播消息。若线程使用 Sleep(INFINITE) 或
//      SleepEx(INFINITE) 无限等待，系统将死锁。
//  2.  受并发控制的线程（例如 I/O 完成端口、线程池）。例如，I/O 完成端口或线程池限制
//      可运行的关联线程数量。若已达最大并发线程数，则必须等某一线程执行结束，额外的新
//      关联线程才能运行。如果一个线程使用 Sleep(0) 或 SleepEx(0) 等待额外的关联线程
//      完成工作，进程可能死锁。因为当前执行线程调用 Sleep(0) 后执行并没有结束，额外
//      的线程可能没有机会得到执行，因此当前执行线程可能永远也等不到这个额外线程完成工
//      作。
//
// 对于这些场景，请使用 MsgWaitForMultipleObjects 或 MsgWaitForMultipleObjectsEx，
// 而非 Sleep 或 SleepEx。
//
// DWORD SleepEx(DWORD dwMilliseconds, BOOL bAlertable);
//
// 挂起当前线程，直到满足指定条件。执行将在以下任一情况发生时恢复：
//
//  * 一个 I/O 完成回调函数（I/O completion callback function）被调用。
//  * 一个异步过程调用（Asynchronous Procedure Call, APC）被排队到该线程。
//  * 超时时间间隔已过去。
//
// 参数 bAlertable，如果该参数为 FALSE，函数直到超时时间过去才会返回。如果发生 I/O
// 完成端口回调，函数不会立即返回，且 I/O 完成函数不会被执行。如果有 APC 被排队到线
// 程，函数不会立即返回，且 APC 函数不会被执行。
//
// 如果该参数为 TRUE，并且调用此函数的线程与调用 I/O 扩展函数（ReadFileEx 或
// WriteFileEx）的线程相同，则函数将在超时时间过去或发生 I/O 完成端口回调时返回。如
// 果发生 I/O 完成回调，则调用 I/O 完成函数。如果有 APC 被排队到线程（QueueUserAPC），
// 则函数将在超时时间过去或 APC 函数被调用时返回。
//
// 如果指定的超时时间间隔已过去，则返回值为零。如果函数因一个或多个 I/O 完成回调函数而
// 返回，则返回值为 WAIT_IO_COMPLETION。这种情况仅在 bAlertable 为 TRUE，并且调用
// SleepEx 函数的线程与调用 I/O 扩展函数的线程相同时才会发生。
//
// 本函数可与 ReadFileEx 或 WriteFileEx 函数配合使用，以挂起线程直到 I/O 操作完成。
// 这些函数指定一个完成例程，当 I/O 操作完成时将被执行。为了让完成例程被执行，当发生
// 完成端口回调时，调用 I/O 函数的线程必须处于“可提醒等待”状态。线程通过调用 SleepEx、
// MsgWaitForMultipleObjectsEx、WaitForSingleObjectEx 或 WaitForMultipleObjectsEx，
// 并将 bAlertable 参数设为 TRUE，即可进入可提醒等待状态。
//
// MMRESULT timeGetDevCaps(LPTIMECAPS ptc, UINT cbtc);
// typedef struct timecaps_tag {
//      UINT wPeriodMin; // 计时器支持的最小精度值，单位毫秒（milliseconds）
//      UINT wPeriodMax; // 计时器支持的最大精度值
// } TIMECAPS, *PTIMECAPS, *NPTIMECAPS, *LPTIMECAPS;
//
// timeapi.h (include windows.h)
// Windows 2000 Professional Windows 2000 Server
// Winmm.lib Winmm.dll
//
// 参数 cbtc，结构体 TIMECAPS 的字节大小。返回值 MMSYSERR_NOERROR 表示成功，一般错误
// MMSYSERR_ERROR，非法参数或其他错误 TIMERR_NOCANDO。
//
// MMRESULT timeBeginPeriod(UINT uPeriodMsec); // 设置周期性计时器的最小精度值
// MMRESULT timeEndPeriod(UINT uPeriodMsec); // 清除最小精度值的设置
//
// 请在即将使用计时器服务之前调用此函数 timeBeginPeriod，并在使用完毕之后立即调用
// timeEndPeriod 函数。每一次对 timeBeginPeriod 的调用都必须与一次对 timeEndPeriod
// 的调用相匹配，且两次调用中指定的最小分辨率必须相同。应用程序可以多次调用
// timeBeginPeriod，只要每一次调用都有对应的 timeEndPeriod 调用即可。
//
// 在 Windows 10 版本 2004 之前，此函数会影响全局 Windows 设置。对于所有进程，
// Windows 会使用 “任何进程所请求的最小值”（即最高分辨率）。从 Windows 10 版本 2004
// 开始，此函数不再影响全局计时器分辨率。对于调用了此函数的进程，Windows 会使用
// “该进程所请求的最小值”（即最高分辨率）。对于未调用此函数的进程，Windows 不保证提供
// 高于默认系统分辨率的精度。
//
// 从 Windows 11 开始，如果一个拥有窗口的进程被完全遮挡、最小化，或以其他方式对用户不
// 可见或不可听，Windows 不保证提供高于默认系统分辨率的精度。有关此行为的更多信息，请
// 参阅 SetProcessInformation。
//
// 设置更高的分辨率可以提高等待函数中超时间隔的准确性，但同时也会降低整体系统性能，因
// 为线程调度器会更频繁地切换任务。高分辨率还可能阻止 CPU 电源管理系统进入省电模式。设
// 置更高的分辨率并不会提高高分辨率性能计数器的准确性。
#include <timeapi.h>

prh_static_assert(MMSYSERR_NOERROR == 0);

void prh_impl_timer_resolution(prh_u32 *min_msec, prh_u32 *max_msec) {
    TIMECAPS TimeCaps;
    prh_zeroret(timeGetDevCaps(&TimeCaps, (UINT)sizeof(TIMECAPS)));
    *min_msec = (prh_u32)TimeCaps.wPeriodMin;
    *max_msec = (prh_u32)TimeCaps.wPeriodMax;
}

void prh_thrd_sleep_secs(int secs) { // 32位有符号整数保存秒可以表示68年
    // 1. Sleep(0) 线程仍然处于就绪状态，如果没有其他就绪线程，当前线程会继续执行
    // 2. 如果有其他就绪线程，当前线程会放弃当前时间片，将在下次调度机会继续执行
    Sleep(secs * 1000);
}

// Win32 的 Sleep(ms) 实际精度由系统时钟中断周期决定，默认粒度约为 15 ms（典型值
// 15.625 ms）。调用 timeBeginPeriod(1) 可把全局时钟分辨率降到 1 ms，实测 1 ~ 3
// 毫秒左右。但 timeBeginPeriod(1) 会影响系统全局，或影响进程全局（Windows 10 2004
// 开始）计时器分辨率。
//
// 除了 Sleep，还可以使用内核可等待计时器 CreateWaitableTimerEx。可等待计时器是一个
// 内核对象，可在多个线程间共享，如果设置了名称可以在多进程间共享，多个线程可以同时等待
// 该计时器，如果计时器是手动重置的，那么多个等待线程可以变为可调度状态。
//
// 手动重置和自动重置可等待计时器的区别，手动重置像电灯开关：你不去关它就常亮；自动重置
// 像点动按钮：按下去亮一下，松手就灭，且只能“服务”一个人。
// 手动重置 CREATE_WAITABLE_TIMER_MANUAL_RESET 0x00000001
//      到期时设为触发状态并持续保持，直到再次调用 SetWaitableTimer 或 CancelWaitableTimer 手动把它关掉
//      所有阻塞在 WaitForSingleObject/WaitForMultipleObjects 的线程同时被唤醒
//      需要再次调用 SetWaitableTimer，否则对象一直“亮着”，后续等待会立即返回
//      典型用法: 想一次性通知多个线程，或自己要多次“消费”这个触发信号
// 自动重置 0x00000000
//      到期时设为触发状态（signaling），但只唤醒一个正在等待的线程，随后内核立即把它自动清零（非触发状态）
//      仅一个线程被唤醒；其余线程继续等待下一次到期
//      不需要再次调用 SetWaitableTimer，周期字段 lPeriod 仍有效，下次到期内核会再次置信号
//      典型用法: 只想每次把一个工作线程放进线程池取任务
//
// SetWaitableTimerEx 与 SetWaitableTimer 的主要区别是，新 API “操作系统可以将到期
// 时刻往后挪”，也就是 Windows 的“定时器汇聚（Timer Coalescing）”机制。它新增了参数
// TolerableDelay（毫秒）告诉 OS “只要误差不超过这个值，就可以把我的定时器跟别人的凑
// 一起唤醒”，当 TolerableDelay > 0 时，OS 可把多个应用定时器合并到一次时钟中断里，
// 减少 CPU 唤醒次数。另外还新增 WakeContext（REASON_CONTEXT）用于系统遥测/诊断日志，
// 方便在 powercfg /sleepstudy 里看到是谁唤醒了机器。总之，旧 API 到期就必须准点唤醒，
// 新 API 允许你“宽限几毫秒”，OS 借此把多个定时器合并到一次唤醒，笔记本省电、服务器降
// CPU 占用。如果应用对 ±1 ms 抖动并不敏感，优先用 SetWaitableTimerEx 并给 TolerableDelay
// 填 5~50 ms，即可免费拿到功耗收益。
//
// HANDLE CreateWaitableTimerExW(
//   [in, optional] LPSECURITY_ATTRIBUTES lpTimerAttributes,
//   [in, optional] LPCWSTR               lpTimerName,
//   [in]           DWORD                 dwFlags,
//   [in]           DWORD                 dwDesiredAccess
// );
// synchapi.h (include Windows.h)
// Kernel32.lib Kernel32.dll
// Windows Vista Windows Server 2008
//
// 创建或打开一个可等待的计时器对象，并返回指向该对象的句柄。如果函数成功，返回值是计时
// 器对象的句柄。如果命名的计时器对象在函数调用之前已存在，函数将返回现有对象的句柄，并
// 且 GetLastError 返回 ERROR_ALREADY_EXISTS。如果函数失败，返回值为 NULL。要获取扩
// 展错误信息，请调用 GetLastError。
//
// 参数 lpTimerAttributes 指向一个 SECURITY_ATTRIBUTES 结构的指针。如果此参数为
// NULL，计时器句柄不能被子进程继承。如果 lpTimerAttributes 为 NULL，计时器对象将
// 获得默认安全描述符，且句柄不能被继承。计时器的默认安全描述符中的访问控制列表（ACL）
// 来自创建者的主令牌或模拟令牌（primary or impersonation token）。
//
// 参数 lpTimerName 计时器对象的名称。名称限制为 MAX_PATH 个字符。名称区分大小写。如
// 果 lpTimerName 为 NULL，计时器对象创建后将没有名称。如果 lpTimerName 与现有事件、
// 信号量、互斥体、作业或文件映射对象的名称匹配，函数将失败，并且 GetLastError 返回
// ERROR_INVALID_HANDLE。这是因为这些对象共享相同的命名空间。名称可以带有 “Global”
// 或 “Local” 前缀，以显式地在全局或会话命名空间中创建对象。名称的其余部分可以包含任
// 何字符，但不能包含反斜杠字符（\）。有关详细信息，请参阅 Kernel Object Namespaces。
// 快速用户切换是通过终端服务会话实现的。内核对象名称必须遵循终端服务的指南，以便应用
// 程序能够支持多个用户。对象可以在私有命名空间中创建。有关详细信息，请参阅 Object
// Namespaces。
//
// 参数 dwFlags 可以为 0 或以下值：
//      CREATE_WAITABLE_TIMER_MANUAL_RESET 0x00000001 计时器必须手动重置。否则，
//      系统会在释放单个等待线程后自动重置计时器。
//      CREATE_WAITABLE_TIMER_HIGH_RESOLUTION 0x00000002 创建一个高分辨率计时器。
//      在时间敏感的情况下，当几毫秒的到期延迟不可接受时，使用此值。此值在 Windows 10
//      版本 1803 及更高版本中受支持。
//
// 参数 dwDesiredAccess 计时器对象的访问掩码。有关访问权限的列表，请参阅
// Synchronization Object Security and Access Rights。
//
// 调用进程的任何线程可以在任意等待函数中，指定计时器对象句柄来进行等待。多个进程可以
// 拥有指向同一个计时器对象的句柄，从而可以使用该对象进行进程间同步。
//
//  * 如果 CreateWaitableTimerEx 的 lpTimerAttributes 参数启用了继承，则由
//    CreateProcess 函数创建的进程可以继承计时器对象的句柄。
//  * 进程可以在调用 DuplicateHandle 函数时指定计时器对象句柄。结果句柄可以被另一个
//    进程使用。
//  * 进程可以在调用 OpenWaitableTimer 或 CreateWaitableTimerEx 函数时指定计时器
//    对象的名称。
//
// 使用 CloseHandle 函数关闭句柄。系统会在进程终止时自动关闭句柄。当最后一个句柄被关
// 闭时，计时器对象被销毁。要将计时器与窗口关联，请使用 SetTimer 函数。
//
// BOOL SetWaitableTimer(
//   [in]           HANDLE              hTimer,
//   [in]           const LARGE_INTEGER *lpDueTime,
//   [in]           LONG                lPeriod,
//   [in, optional] PTIMERAPCROUTINE    pfnCompletionRoutine,
//   [in, optional] LPVOID              lpArgToCompletionRoutine,
//   [in]           BOOL                fResume
// );
// BOOL CancelWaitableTimer(
//   [in] HANDLE hTimer
// );
// synchapi.h (include Windows.h)
// Kernel32.lib Kernel32.dll
// Windows XP Windows Server 2003
//
// 激活指定的可等待计时器。当到期时间到达时，计时器被触发，并且设置计时器的线程调用可选
// 的完成例程。如果函数成功，返回值是非零值。如果函数失败，返回值为零。要获取扩展错误信
// 息，请调用 GetLastError。
//
// 参数 hTimer 指向计时器对象的句柄。该句柄由 CreateWaitableTimer 或 OpenWaitableTimer
// 函数返回。该句柄必须具有 TIMER_MODIFY_STATE 访问权限。有关详细信息，请参阅 Synchronization
// Object Security and Access Rights。
//
// 参数 lpDueTime 计时器状态被设置为触发的时间，以 100 纳秒间隔表示。使用 FILETIME
// 结构描述的格式。正值表示绝对时间。请确保使用基于 UTC 的绝对时间，因为系统内部使用
// 基于 UTC 的时间。负值表示相对时间。实际的计时器精度取决于硬件的能力。有关基于 UTC
// 的时间的详细信息，请参阅 System Time。Windows XP、Windows Server 2003、Windows
// Vista、Windows 7、Windows Server 2008 和 Windows Server 2008 R2：如果指定相对
// 时间，计时器包括在低功耗状态下的时间。例如，计时器在计算机处于睡眠状态时继续倒计时。
// Windows 8 及更高版本、Windows Server 2012 及更高版本：如果指定相对时间，计时器不
// 包括在低功耗状态下的时间。例如，计时器在计算机处于睡眠状态时不会继续倒计时。
//
// 因为相对时间在新版本操作系统中，不包含低功耗状态下的时间，也因此不可能具有在低功耗
// 状态被唤醒的功能（fResume）。计时器到期时，如果系统处于低功耗状态，如果需要将系统
// 即时唤醒处理计时器事件，请使用绝对时间。
//
// 参数 lPeriod 计时器的周期，以毫秒为单位。如果 lPeriod 为零，计时器触发一次。如果
// lPeriod 大于零，计时器是周期性的。周期性计时器在每个周期结束时自动重新激活，直到使
// 用 CancelWaitableTimer 函数取消计时器或使用 SetWaitableTimer 函数重置计时器。如
// 果 lPeriod 小于零，函数失败。
//
// 参数 pfnCompletionRoutine 可选完成例程的指针。完成例程是应用程序定义的函数，类型
// 为 PTIMERAPCROUTINE，在计时器触发时执行。有关计时器回调函数的详细信息，请参阅
// TimerAPCProc。有关 APC 和线程池线程的详细信息，请参阅备注。
//
// 参数 lpArgToCompletionRoutine 传递给完成例程的参数。参数 fResume 如果为 TRUE，
// 当计时器触发时，将对处于挂起功耗模式的系统进行恢复。否则，系统不会恢复。如果系统不
// 支持恢复，函数调用成功，但 GetLastError 返回 ERROR_NOT_SUPPORTED。
//
// 计时器最初是不活动的。要激活计时器，请调用 SetWaitableTimer。如果在调用 SetWaitableTimer
// 时计时器已经处于活动状态，计时器将停止，然后重新激活。以这种方式停止计时器不会将计时
// 器状态设置为触发，因此在计时器上阻塞的线程仍然保持阻塞。但是，它会取消任何待处理的完
// 成例程（completion routines）。
//
// 当指定的到期时间到达时，计时器变为不活动状态，并且如果没有任何待处理的 APC 已经排队
// （no outstanding APC already queued），则将可选的 APC（即可选参数 pfnCompletionRoutine
// 指定的过程）排队到设置计时器的线程。计时器的状态被设置为触发，使用指定的周期重新激活
// 计时器，并且设置计时器的已进入可警报等待状态的线程将调用完成例程。有关详细信息，请参
// 阅 QueueUserAPC。
//
// 请注意，APC 对于线程池线程不如其他触发机制（signaling mechanisms）有效，因为系统控
// 制线程池线程的生命周期，因此在通知传递之前，线程可能会被终止。与其使用 pfnCompletionRoutine
// 参数或其他基于 APC 的触发机制，不如使用可等待对象，例如 CreateThreadpoolTimer 创建
// 的计时器。对于 I/O，使用 CreateThreadpoolIo 创建的 I/O 完成对象或基于 hEvent 的
// OVERLAPPED 结构，其中事件可以传递给 SetThreadpoolWait 函数。
//
// 如果设置计时器的线程终止并且存在关联的完成例程，计时器将被取消。但是，计时器的状态保
// 持不变。如果没有完成例程，则终止线程对计时器没有影响。当手动重置的计时器被设置为触发
// 状态时，它保持在此状态，直到调用 SetWaitableTimer 重置计时器。因此，周期性手动重置
// 的计时器在初始到期时间到达时被设置为触发状态，并保持触发状态，直到被重置。当同步计时
// 器（默认的非手动计时器）被设置为触发状态时，它保持在此状态，直到线程完成对计时器对象
// 的等待操作。
//
// 如果系统时间被调整，任何待处理的绝对计时器的到期时间将被调整。要编译使用此函数的应用
// 程序，请定义 _WIN32_WINNT 为 0x0400 或更高版本。有关详细信息，请参阅 Using the
// Windows Headers。要使用计时器为窗口调度事件（to schedule an event for a window），
// 请使用 SetTimer 函数。
//
// 处理计时器的 API 使用各种不同的硬件时钟。这些时钟的分辨率可能与您预期的有很大不同：
// 有些以毫秒为单位（对于那些使用基于 RTC 的计时器芯片），有些以纳秒为单位（对于那些使
// 用 ACPI 或 TSC 计数器）。您可以使用 timeBeginPeriod 和 timeEndPeriod 函数调用更
// 改 API 的分辨率。您可以更改的分辨率的精确度取决于特定 API 使用的硬件时钟。有关详细
// 信息，请查阅您的硬件文档。Real Time Clock（RTC），Advanced Configuration and
// Power Interface（ACPI），Time Stamp Counter（TSC）。
//
// CancelWaitableTimer 函数不会改变计时器的触发状态。它会在计时器被设置为触发状态之前
// 停止计时器，并取消待处理的 APC。因此，对计时器执行等待操作的线程会继续等待，直到它们
// 等待函数超时，或者计时器被重新激活并且其状态被设置为触发。如果计时器已经处于触发状态，
// 它将保持在该状态。要重新激活计时器，请调用 SetWaitableTimer 函数。
//
// BOOL SetWaitableTimerEx(
//   [in] HANDLE              hTimer,
//   [in] const LARGE_INTEGER *lpDueTime,
//   [in] LONG                lPeriod,
//   [in] PTIMERAPCROUTINE    pfnCompletionRoutine,
//   [in] LPVOID              lpArgToCompletionRoutine,
//   [in] PREASON_CONTEXT     WakeContext, ***
//   [in] ULONG               TolerableDelay ***
// );
// typedef struct _REASON_CONTEXT {
//   ULONG Version;
//   DWORD Flags;
//   union {
//     struct {
//       HMODULE LocalizedReasonModule;
//       ULONG   LocalizedReasonId;
//       ULONG   ReasonStringCount;
//       LPWSTR  *ReasonStrings;
//     } Detailed;
//     LPWSTR SimpleReasonString;
//   } Reason;
// } REASON_CONTEXT, *PREASON_CONTEXT;
// synchapi.h (include Windows.h) minwinbase.h (include Windows.h)
// Kernel32.lib Kernel32.dll
// Windows 7 Windows Server 2008
//
// 激活指定的可等待计时器，并为计时器提供上下文信息。当到期时间到达时，计时器被触发，设
// 置计时器的线程将调用可选的完成例程。SetWaitableTimerEx 函数与 SetWaitableTimer
// 函数类似，但 SetWaitableTimerEx 可以用于指定计时器到期的上下文字符串和可容忍延迟。
//
// 参数 WakeContext 指向一个 REASON_CONTEXT 结构的指针，该结构包含计时器的上下文信息。
// 参数 TolerableDelay 到期时间的可容忍延迟，以毫秒为单位。
//
// 要编译使用此函数的应用程序，请定义 _WIN32_WINNT 为 0x0601 或更高版本。如果设置计时
// 器的线程终止并且存在关联的完成例程，计时器将被取消。但是，计时器的状态保持不变。如果
// 没有完成例程，则终止线程对计时器没有影响。如果调用 SetWaitableTimerEx 的线程退出，
// 计时器将被取消。这会在计时器被设置为触发状态之前停止计时器，并取消待处理的 APC；它不
// 会改变计时器的触发状态。
//
// REASON_CONTEXT 结构包含有关电源请求的信息。此结构由 PowerCreateRequest 和 SetWaitableTimerEx
// 函数使用。
//
// * 版本 Version 结构的版本号。此参数必须设置为 POWER_REQUEST_CONTEXT_VERSION。
// * 标志 Flags，电源请求原因的格式。此参数可以是以下值之一：
//      POWER_REQUEST_CONTEXT_DETAILED_STRING 0x00000002，Detailed 结构体标识一个
//      可本地化的字符串资源，用于描述电源请求的原因。
//      POWER_REQUEST_CONTEXT_SIMPLE_STRING	0x00000001，SimpleReasonString 参数
//      包含一个简单的、不可本地化的字符串，用于描述电源请求的原因。
// * 原因 Reason，一个联合体，包含 Detailed 结构或字符串。
// * Reason.Detailed，一个结构体，标识一个可本地化的字符串资源，用于描述电源请求原因。
// * Reason.Detailed.LocalizedReasonModule 包含字符串资源的模块。
// * Reason.Detailed.LocalizedReasonId 字符串资源的 ID。
// * Reason.Detailed.ReasonStringCount，ReasonStrings 参数中的字符串数量。
// * Reason.Detailed.ReasonStrings，字符串数组，用于在运行时替换字符串资源中的占位符。
// * Reason.SimpleReasonString，一个不可本地化的字符串，用于描述电源请求的原因。
//
// 将只读字符串作为 SimpleReasonString 或 ReasonStrings 传递是安全的，因为 PowerCreateRequest
// 和 SetWaitableTimerEx 函数会从字符串中读取内容，而不会写入它们。
//
// 是否唤醒休眠的系统，SetWaitableTimer 传入 fResume = TRUE，SetWaitableTimerEx 传
// 入非空的 WakeContext，即表示到期唤醒系统。当系统正处于睡眠（S3）/休眠（S4）状态时，
// 是否允许此定时器到期事件把机器唤醒，使其恢复到工作状态。
//  fResume = TRUE
//      如果定时器到期时整机处于睡眠/休眠，Windows 会主动唤醒系统，并像正常开机那样继
//      续执行后续流程（APC、线程等待等）。这是实现 “定时开机” “半夜自动下载” 等功能的
//      关键开关。
//  fResume = FALSE
//      定时器仍然会在内部到期，但不会唤醒系统；只有等到用户手动开机后，内核才会把已经
//      “过期” 的信号补发给等待线程。适用于纯软件定时任务，对“是否及时唤醒机器”无要求。
// 使用限制与注意。需要管理员权限；普通进程把 fResume 置 TRUE 会返回 ERROR_PRIVILEGE_NOT_HELD。
// 只对绝对时间（lpDueTime 为正）定时器有效；相对时间定时器即使置 TRUE 也会被内核忽
// 略。从 Windows 10 开始，若系统固件支持 “新式待机(S0 低功耗空闲)”，fResume 同样适
// 用于把机器从 S0 空闲 拉回活动状态。唤醒成功后，系统会给调用进程额外 2 min 的“宽限
// 期”，期间空闲计时器被自动延长，方便代码调用 SetThreadExecutionState 声明自己“正在
// 工作”，防止立刻再次睡眠。
//
// https://mirrors.arcadecontrols.com/www.sysinternals.com/Information/HighResolutionTimers.html
//
// 高分辨率计时器在各种不同的应用程序中都非常有用。例如，在 Windows 中，此类计时器最常
// 见的用途是多媒体应用程序生成声音或音频时需要精确控制。MIDI 是一个完美的例子，因为
// MIDI 序列器必须以 1 毫秒的精度保持 MIDI 事件的节奏。本文描述了 NT 中高分辨率计时器
// 的实现方式，并记录了 NtSetTimerResolution 和 NtQueryTimerResolution，这两个 NT
// 内核函数用于操作和返回有关系统时钟的信息。不幸的是，NtSetTimerResolution 和 NtQueryTimerResolution
// 并没有被 NT 内核导出，因此它们不可用于内核模式设备驱动程序。
//
// Windows NT 的所有计时器支持都基于一个系统时钟中断，默认运行在 10 毫秒的粒度上。因
// 此，标准 Windows 计时器的分辨率就是 10 毫秒。当多媒体应用程序使用 timeBeginPeriod
// 多媒体 API 时，该 API 由 Windows NT 动态链接库 WINMM.DLL 导出，调用会被重定向到
// Windows NT 内核模式函数 NtSetTimerResolution，该函数由本地 Windows NT 库 NTDLL.DLL
// 导出。
//
// NtSetTimerResolution 和 NtQueryTimerResolution 的定义如下。所有时间都以 100 纳
// 秒为单位指定。
//
// NTSTATUS NTAPI NtSetTimerResolution (
//     IN ULONG RequestedResolution,
//     IN BOOLEAN Set,
//     OUT PULONG ActualResolution
// );
//
// 参数 RequestedResolution 期望的计时器分辨率。必须在 NT 支持的系统计时器值的合法范
// 围内。在标准 x86 系统上，这个范围是 1-10 毫秒。在标准 x86 HAL 中，可接受范围内的值
// 会被四舍五入到下一个最高的毫秒边界。如果 Set 参数为 FALSE，则忽略此参数。
//
// 参数 Set，如果请求新的计时器分辨率，则为 TRUE；如果应用程序表示不再需要之前设置的分
// 辨率，则为 FALSE。参数 ActualResolution，调用返回后生效的计时器分辨率。
//
// 如果请求的分辨率在有效范围内的计时器值内，NtSetTimerResolution 返回 STATUS_SUCCESS。
// 如果 Set 为 FALSE，调用者必须之前调用过 NtSetTimerResolution，否则返回
// STATUS_TIMER_RESOLUTION_NOT_SET。
//
// NTSTATUS NTAPI NtQueryTimerResolution (
//     OUT PULONG MinimumResolution,
//     OUT PULONG MaximumResolution,
//     OUT PULONG ActualResolution
// );
//
// 参数 MinimumResolution 最小计时器分辨率。在标准 x86 系统上，大约是 1 毫秒。参数
// MaximumResolution 最大计时器分辨率。在标准 x86 系统上为 0x2625A，大约是 15 毫秒。
// 参数 ActualResolution 系统时钟的当前分辨率。
//
// 实现细节，NtSetTimerResolution 可以被多个应用程序调用来设置计时器分辨率。为了支持
// 后续进程设置计时器分辨率而不违反之前调用者的分辨率假设，NtSetTimerResolution 从不
// 降低计时器的分辨率，只提高它。例如，如果一个进程将分辨率设置为 5 毫秒，后续将分辨率
// 设置为 5 到 10 毫秒之间的调用将返回一个状态码表示成功，但计时器将保持在 5 毫秒。
// NtSetTimerResolution 还会在其进程控制块中跟踪进程是否设置了计时器分辨率，以便在调
// 用时 Set 等于 FALSE 时可以验证调用者之前是否请求过新的分辨率。每次设置新的分辨率时，
// 全局计数器会递增，每次重置时，计数器会递减。当计数器在重置调用时变为 0 时，计时器会
// 恢复到默认速率，否则不采取任何操作。同样，这通过保证分辨率至少与它们指定的一样好，来
// 保留所有请求高分辨率计时器的应用程序的计时器分辨率假设。
//
// 你可以使用 Sysinternals 的 ClockRes 小工具查看系统当前的时钟分辨率。

void prh_impl_thrd_sleep(prh_i64 due_time_100ns, bool resume) {
    if (due_time_100ns <= 0) {
        Sleep(0);
        return;
    }

    HANDLE timer;
#if defined(CREATE_WAITABLE_TIMER_HIGH_RESOLUTION)
    timer = CreateWaitableTimerExW(prh_null, prh_null, CREATE_WAITABLE_TIMER_HIGH_RESOLUTION, TIMER_ALL_ACCESS);
#else
    timer = CreateWaitableTimerExW(prh_null, prh_null, 0, TIMER_ALL_ACCESS);
#endif
    if (timer == prh_null) {
        prh_abort_error(GetLastError());
    }

    LARGE_INTEGER due_time;
    if (resume) {
        due_time.QuadPart = prh_impl_system_time() + due_time_100ns; // 100ns 为单位，绝对时间
    } else {
        due_time.QuadPart = -(due_time_100ns); // 100ns 为单位，相对时间
    }
#if !defined(CREATE_WAITABLE_TIMER_HIGH_RESOLUTION)
    prh_zeroret(timeBeginPeriod(1));
#endif
    if (SetWaitableTimer(timer, &due_time, 0, prh_null, prh_null, resume)) {
        prh_impl_wait_single_object(timer, INFINITE);
    } else {
        prh_prerr(GetLastError());
    }
#if !defined(CREATE_WAITABLE_TIMER_HIGH_RESOLUTION)
    prh_zeroret(timeEndPeriod(1));
#endif

    prh_impl_close_handle(timer);
}

void prh_thrd_sleep_msec(int msec) { // 32位有符号整数保存毫秒可以表示24天
    prh_impl_thrd_sleep(((prh_i64)msec) * 1000 * 10, false);
}

void prh_thrd_sleep(int secs, int nsec) { // 32位有符号整数保存秒可以表示68年
    prh_i64 due_time_100ns = (prh_i64)secs * 1000 * 1000 * 10 + nsec / 100;
    prh_impl_thrd_sleep(due_time_100ns, false);
}

void prh_thrd_sleep_and_trigger_system_wakeup(int secs, int nsec) {
    prh_i64 due_time_100ns = (prh_i64)secs * 1000 * 1000 * 10 + nsec / 100;
    prh_impl_thrd_sleep(due_time_100ns, true);
}

void prh_system_info(prh_sys_info *info) {
    // typedef struct _SYSTEM_INFO {
    // union {
    //     DWORD dwOemId; // 过时
    //     struct {
    //     WORD wProcessorArchitecture; // 处理器架构信息
    //     WORD wReserved;
    //     } DUMMYSTRUCTNAME;
    // } DUMMYUNIONNAME;
    // DWORD     dwPageSize; // 虚拟内存页面大小
    // LPVOID    lpMinimumApplicationAddress; // 应用程序或DLL可访问的地址范围
    // LPVOID    lpMaximumApplicationAddress; // 应用程序或DLL可访问的地址范围
    // DWORD_PTR dwActiveProcessorMask; // 处理器掩码值
    // DWORD     dwNumberOfProcessors; // 当前处理器组（current processor group）的的逻辑处理器个数
    // DWORD     dwProcessorType; // 过时
    // DWORD     dwAllocationGranularity; // 虚拟内存分配颗粒度
    // WORD      wProcessorLevel;
    // WORD      wProcessorRevision;
    // } SYSTEM_INFO, *LPSYSTEM_INFO;
    SYSTEM_INFO system_info;
    GetSystemInfo(&system_info);
    info->page_size = (int)system_info.dwPageSize;
    info->vmem_unit = (int)system_info.dwAllocationGranularity;

    // https://devblogs.microsoft.com/oldnewthing/20200824-00/?p=104116
    // 客户发现，他们原来用 GetSystemInfo 读取 dwNumberOfProcessors 来获取处理器数
    // 量。但文档指出，这只能给出当前处理器组里的处理器数，可能小于系统总数量。例如，在
    // 一台拥有 80 颗处理器的机器上（令人羡慕），dwNumberOfProcessors 只返回了 40 颗。
    // 如何跨所有处理器组获取总处理器数？简单方法：调用 GetActiveProcessorCount(ALL_PROCESSOR_GROUPS)，
    // 它会一次性统计所有组的处理器总数。麻烦方法：调用 GetLogicalProcessorInformationEx(RelationGroup)，
    // 然后遍历所有活跃组，把每组的 ActiveProcessorCount 累加。虽然代码量更大，但你也
    // 能看到处理器在各组中的分布情况，如果这正是你需要的额外信息。
    // DWORD GetActiveProcessorCount([in] WORD GroupNumber);
    //      参数处理器组的数值，或 ALL_PROCESSOR_GROUPS。如果失败返回零。
    //      winbase.h (include Windows.h)
    //      Kernel32.lib Kernel32.dll
    //      Windows 7 Windows Server 2008 R2 _WIN32_WINNT >= 0x0601
    DWORD processor_count = GetActiveProcessorCount(ALL_PROCESSOR_GROUPS);
    PRH_BOOLRET_OR_ERROR(processor_count);
    info->processor_count = (int)processor_count;

    // BOOL GetLogicalProcessorInformationEx(
    //      [in]            LOGICAL_PROCESSOR_RELATIONSHIP           RelationshipType,
    //      [out, optional] PSYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX Buffer,
    //      [in, out]       PDWORD                                   ReturnedLength)
    // typedef struct _SYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX {
    //  LOGICAL_PROCESSOR_RELATIONSHIP Relationship;
    //  DWORD                          Size; // 该结构体的大小
    //  union {
    //      PROCESSOR_RELATIONSHIP Processor;
    //      NUMA_NODE_RELATIONSHIP NumaNode;
    //      CACHE_RELATIONSHIP     Cache;
    //      GROUP_RELATIONSHIP     Group;
    //  } DUMMYUNIONNAME;
    // } SYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX, *PSYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX;
    // typedef enum _LOGICAL_PROCESSOR_RELATIONSHIP { // 同一类逻辑处理器之间的关系
    //  RelationProcessorCore,      // 共享单个处理器核心的所有逻辑处理器
    //  RelationNumaNode,           // 相同 NUMA 结点中的所有逻辑处理器
    //  RelationCache,              // 共享同一个缓存的逻辑处理器
    //  RelationProcessorPackage,   // 指定的逻辑处理器共享同一个物理封装（即主板上的一个插槽或焊接的封装，其内可能包含多个处理器核心或线程，每个核心或线程都被操作系统视为独立的处理器）。
    //  RelationGroup,              // 共享单个处理器组（a single processor group）的逻辑处理器
    //  RelationProcessorDie,       // 共享同一颗处理器芯片（die）
    //  RelationNumaNodeEx,         // 在 Windows Server 2022（21H2，构建 20348）中引入。用于请求返回完整的亲和性信息。与其他关系类型不同，RelationNumaNodeEx 不作为输入使用；它只是请求以完整组信息的形式返回 RelationNumaNode 的信息。
    //  RelationProcessorModule,
    //  RelationAll = 0xffff
    // } LOGICAL_PROCESSOR_RELATIONSHIP;
    // typedef struct _PROCESSOR_RELATIONSHIP {
    //   BYTE           Flags;
    //   BYTE           EfficiencyClass;
    //   BYTE           Reserved[20];
    //   WORD           GroupCount;
    //   GROUP_AFFINITY GroupMask[ANYSIZE_ARRAY];
    // } PROCESSOR_RELATIONSHIP, *PPROCESSOR_RELATIONSHIP;
    // typedef struct _NUMA_NODE_RELATIONSHIP {
    //   DWORD NodeNumber;
    //   BYTE  Reserved[18];
    //   WORD  GroupCount;
    //   union {
    //     GROUP_AFFINITY GroupMask;
    //     GROUP_AFFINITY GroupMasks[ANYSIZE_ARRAY];
    //   } DUMMYUNIONNAME;
    // } NUMA_NODE_RELATIONSHIP, *PNUMA_NODE_RELATIONSHIP;
    // typedef struct _CACHE_RELATIONSHIP {
    //   BYTE                 Level; // 1 L1 2 L2 3 L3
    //   BYTE                 Associativity;
    //   WORD                 LineSize;
    //   DWORD                CacheSize;
    //   PROCESSOR_CACHE_TYPE Type;
    //   BYTE                 Reserved[18];
    //   WORD                 GroupCount; // 保留
    //   union {
    //     GROUP_AFFINITY GroupMask; // 保留
    //     GROUP_AFFINITY GroupMasks[ANYSIZE_ARRAY]; // 保留
    //   } DUMMYUNIONNAME;
    // } CACHE_RELATIONSHIP, *PCACHE_RELATIONSHIP;
    // typedef enum _PROCESSOR_CACHE_TYPE {
    //   // Unified Cache（统一缓存）是一种同时存放指令和数据的缓存结构，与分离式（Harvard）缓存相对。通常
    //   // 位于更高层级（L2/L3），在多核 CPU 里常被所有核共享，例如 Intel 的共享 L3、ARM 的 big.LITTLE
    //   // 统一 L2。一套硬件同时缓存指令和数据，面积省、弹性高，但要承受结构冲突代价；常用于 L2/L3 共享层。
    //   CacheUnified,
    //   CacheInstruction,
    //   CacheData,
    //   CacheTrace,
    //   CacheUnknown
    // } PROCESSOR_CACHE_TYPE, *PPROCESSOR_CACHE_TYPE;
    SYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX *processor_info = prh_null;
    DWORD count = 0;
    BOOL status = GetLogicalProcessorInformationEx(RelationCache, processor_info, &count);
    if (status != FALSE || GetLastError() != ERROR_INSUFFICIENT_BUFFER) {
        prh_prerr(GetLastError());
        return;
    }
    processor_info = prh_malloc(count * sizeof(SYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX));
    if (!GetLogicalProcessorInformationEx(RelationCache, processor_info, &count)) {
        prh_prerr(GetLastError());
        prh_free(processor_info);
        return;
    }
    int cache_line_size = 0;
    for (int i = 0; i < (int)count; i += 1) {
        CACHE_RELATIONSHIP *cache = &processor_info[i].Cache;
        if (cache->Level == 1 && (cache->Type == CacheData || cache->Type == CacheUnified) && cache_line_size < cache->LineSize) {
            cache_line_size = cache->LineSize;
        }
    }
    info->cache_line_size = cache_line_size;
    prh_free(processor_info);
}

void prh_impl_plat_set_fault_handler(void) {

}

#ifdef PRH_TEST_IMPLEMENTATION
void prh_impl_thrd_test(void) {
    printf("BOOL %zd-byte\n", sizeof(BOOL));
    printf("TRUE %d FALSE %d\n", TRUE, FALSE);
    printf("UINT %zd-byte\n", sizeof(UINT));
    printf("CRITICAL_SECTION %zd-byte\n", sizeof(CRITICAL_SECTION));
    printf("CONDITION_VARIABLE %zd-byte\n", sizeof(CONDITION_VARIABLE));
    printf("void* %zd-byte\n", sizeof(void *));
    printf("HANDLE %zd-byte\n", sizeof(HANDLE));
    printf("MMSYSERR_NOERROR %d\n", MMSYSERR_NOERROR);
    printf("MAX_PATH %d\n", MAX_PATH);
    printf("MAXIMUM_SUSPEND_COUNT %d\n", MAXIMUM_SUSPEND_COUNT);
    printf("MAXIMUM_WAIT_OBJECTS %d\n", MAXIMUM_WAIT_OBJECTS);
    printf("MAXIMUM_PROCESSORS %d\n", MAXIMUM_PROCESSORS);
    printf("MEMORY_ALLOCATION_ALIGNMENT %d\n", MEMORY_ALLOCATION_ALIGNMENT);
    SYSTEM_INFO info;
    GetSystemInfo(&info);
    int arch = info.wProcessorArchitecture;
    if (arch == PROCESSOR_ARCHITECTURE_INTEL) {
        printf("PROCESSOR_ARCHITECTURE_INTEL X86\n");
    } else if (arch == PROCESSOR_ARCHITECTURE_AMD64) {
        printf("PROCESSOR_ARCHITECTURE_AMD64 X64\n");
    } else if (arch == PROCESSOR_ARCHITECTURE_ARM) {
        printf("PROCESSOR_ARCHITECTURE_ARM\n");
    } else if (arch == PROCESSOR_ARCHITECTURE_ARM64) {
        printf("PROCESSOR_ARCHITECTURE_ARM64\n");
    } else {
        printf("PROCESSOR_ARCHITECTURE_UNKNOWN\n");
    }
    printf("SYSTEM_INFO dwActiveProcessorMask %p\n", (void *)info.dwActiveProcessorMask);
    printf("SYSTEM_INFO dwNumberOfProcessors %d\n", (int)info.dwNumberOfProcessors);
    printf("SYSTEM_INFO lpMinimumApplicationAddress %p\n", (void *)info.lpMinimumApplicationAddress);
    printf("SYSTEM_INFO lpMaximumApplicationAddress %p\n", (void *)info.lpMaximumApplicationAddress);
    prh_u32 min_msec = 0, max_msec = 0;
    prh_impl_timer_resolution(&min_msec, &max_msec);
    printf("Timer Supported Resolution: %u ms %u ms\n", min_msec, max_msec);
    prh_sys_info sys_info;
    prh_system_info(&sys_info);
    printf("page size %d %dKB\n", sys_info.page_size, sys_info.page_size/1024);
    printf("vmem unit %d %dKB\n", sys_info.vmem_unit, sys_info.vmem_unit/1024);
    printf("cache line size %d\n", sys_info.cache_line_size);
    printf("active processor count %d\n", sys_info.processor_count);
#if defined(UNICODE)
    printf("UNICODE is defined\n");
#else
    printf("UNICODE is NOT defined\n");
#endif
#if defined(_UNICODE)
    printf("_UNICODE is defined\n");
#endif
#if defined(_CONSOLE)
    printf("_CONSOLE is defined\n");
#else
    printf("_CONSOLE is NOT defined\n");
#endif
#if defined(CREATE_WAITABLE_TIMER_HIGH_RESOLUTION)
    printf("CREATE_WAITABLE_TIMER_HIGH_RESOLUTION is defined\n");
#endif

    printf("prh_mutex %d-byte\n", (int)sizeof(prh_mutex));
    printf("prh_thrd_cond %d-byte\n", (int)sizeof(prh_thrd_cond));
    printf("prh_cond_sleep %d-byte\n", (int)sizeof(prh_cond_sleep));
}
#endif // PRH_TEST_IMPLEMENTATION
#else // PTHREAD BEGIN
// 线程间除全局内存还共享以下属性，它们对于进程而言是全局的，并非针对某个特定线程：
//
// 1. 进程ID和父进程ID，进程组ID与会话（session）ID，进程凭证（credential）
// 2. 控制终端，打开的文件描述符
// 3. 由 fcntl() 创建的记录锁（record lock）
// 4. 信号处置，间隔定时器和POSIX定时器
// 5. 文件系统的相关信息，例如文件权限掩码、当前工作目录和根目录
// 6. 系统 V（System V）信号量撤销（undo semadj）
// 7. 资源限制（resource limit），资源消耗（getrusage()）
// 8. CPU 时间消耗（times()），nice 值（setpriority() nice()）
//
// 各线程所独有的属性包括：
//
// 1. 线程ID，线程本地存储数据，errno 变量，浮点环境（fenv(3)）
// 2. 信号掩码，备选信号栈（sigaltstack()）
// 3. 实时调度策略和优先级
// 4. CPU 亲和力（affinity，Linux 所特有）
// 5. 能力（capability，Linux 所特有）
// 6. 线程栈，本地变量和函数的调用链接信息
//
// 所有的线程栈均驻留于同一虚拟地址空间，这意味着利用合适的指针，各线程可以在对方栈中
// 相互共享数据。这种方法偶尔也能派上用场，但由于局部变量的状态有效与否依赖于其所驻留
// 栈帧的生命周期，故而需要谨慎处理这一问题。当函数返回时，该函数栈帧所占用的内存区域
// 有可能为后续的函数调用所重用。如果线程终止，那么新线程有可能会对已终止线程的所占用
// 的内存空间重新加以利用。若无法正确处理这一依赖关系，由此产生的程序问题将难以捕获。
//
// 在多线程应用中处理信号，需要小心设计，作为通则一般建议在多线程程序中避免使用信号。
// UNIX 信号模型是基于 UNIX进程模型而设计的，问世比 pthreads 要早几十年。自然而然，
// 信号与线程模型之间存在一些明显的冲突。主要是因为，一方面针对单线程进程要保持传统的
// 信号语义（pthreads不应该改变传统进程的信号语义），与此同时又需要开发出适用于多线程
// 进程环境的新信号模型。信号与线程模型之间的差异意味着，将二者结合使用将会非常复杂，
// 应尽可能加以避免。尽管如此，有的时候还是必须在多线程中处理信号问题。
//
// 1995年POSIX.1c对POSIX线程API进行了标准化，该标准后来为SUSv3所接纳。Pthreads API
// 定义了一系列数据类型，如下所示。SUSv3 并未规定如何实现这些数据类型，可移植的程序应
// 该将其视为透明数据，程序应避免对此类数据类型变量的结构或内容产生任何依赖。 ::
//
//      pthread_t               线程ID
//      pthread_mutex_t         互斥对象
//      pthread_mutexattr_t     互斥属性
//      pthread_cond_t          条件变量
//      pthread_condattr_t      条件变量属性
//      pthread_key_t           线程特有数据的键
//      pthread_once_t          一次性初始化控制上下文
//      pthread_attr_t          线程属性
//
// 启动程序时产生的进程只有单条线程，称之为初始或主线程。调用 pthread_create() 负责
// 创建一个新的线程。新线程通过调用带有参数arg的函数start开始执行，并带有返回值类型
// 为 void*，当经强制转换的整数作为线程start函数的返回值时，必须避免与实现所定义的常
// 量 PTHREAD_CANCELED 值相同，否则线程退出后不能分辨是正常退出还是被取消而退出。参
// 数thread用户获取线程ID，SUSv3明确指出，在新线程开始执行之前，实现无需对thread参数
// 进行赋值，即新线程可能会在pthread_create返回给调用者之前已经开始运行。如新线程需
// 要获取自己的线程ID，则只能使用pthread_self()获取。调用pthread_create()之后，应用
// 程序无法确定接着会调度哪一个线程来使用CPU资源，程序不能隐含认为对特性调度顺序的依
// 赖。可以给线程设置线程属性，如果将attr设置为NULL，那么创建新线程时将使用各种默认属
// 性。
//
//      int pthread_create(
//          pthread_t *thread,
//          const pthread_attr_t *attr,
//          void *(*start)(void *),
//          void *arg);
//
// pthread_exit()函数用于终止调用线程，其返回值可由另一线程通过调用pthread_join()函
// 数来获取。调用pthread_exit相当于在线程start函数中执行return，不同之处在于，可在线
// 程start函数所调用的任意函数中调用pthread_exit()。参数retval执行了线程的返回值，
// retval所指向的内容不应该分配在线程栈中，因为线程终止后，将无法确定线程栈的内容是否
// 有效，例如系统可能会立刻将改进程虚拟内存的这片区域重新分配，供一个新的线程栈使用。
// 处于同样的理由，也不应该在线程栈中分配线程start函数的返回值。 ::
//
//      void pthread_exit(void *retval);
//
// 线程可以以以下方式终止运行：
//
// 1. 线程start函数执行return语句并返回指定值
// 2. 线程调用pthread_exit()
// 3. 调用pthread_cancel()取消线程
// 4. 任意线程调用了exit()，或者主线程执行了return语句，会导致进程中所有线程终止
// 5. 如果主线程调用了pthread_exit()，那么其他线程将继续运行
//
// 进程内部的每个线程都有一个唯一的标识（同一个进程中保证唯一，但不同进程中的线程ID可
// 能重名），称为线程ID。线程ID的用处：不同的pthreads函数利用线程ID来识别要操作的目标
// 线程，这些函数包括pthread_join() pthread_detach() pthread_cancel()
// pthread_kill()等；在一些应用中，以特定线程的线程ID作为动态数据结构的标签，以识别某
// 个数据结构的创建者和操作者。函数pthread_equal()可检查两个线程ID是否相同。因为必须
// 将pthread_t作为一种透明的数据类型对待，所以函数pthread_equal是必须的。Linux将
// pthread_t定义为无符号长整数，但在其他实现中则有可能是一个指针或结构体。SUSv3并未要
// 求将pthread_t实现为一个标量类型，该类型也可以是一个结构体。因此将线程ID强制类型转
// 换成整数值并不具有可移植性。在Linux的线程实现中，线程ID在所有进程中都是唯一的，不过
// 在其他实现中则未必如此，SUSv3特别之处，应用程序若使用线程ID来标识其他进程的线程，其
// 可移植性无法得到保证。此外，在对已终止线程施以pthread_join()，或者在已分离线程退出
// 后（detached thread），实现可以复用该线程的线程ID。 ::
//
//      pthread_t pthread_self(void);
//      int pthread_equal(pthread_t a, pthread_t b);
//
// POSIX线程ID与Linux专用的系统调用gettid()所返回的线程ID并不同。POSIX线程ID由线程
// 库实现和维护。gettid()返回的线程ID是一个内核分配的数字，类似于进程ID。虽然在Linux
// NPTL（Native POSIX Threads Library）实现中，每个POSIX线程都对应一个唯一的内核线
// 程ID，但应用程序一般无需了解内核线程ID，况且如果程序依赖于这一信息也将无法移植。
//
// 连接（joining）已终止的线程，函数pthread_join()等待对应的线程终止，如果线程已经
// 终止，pthread_join()会立即返回。retval可以获取线程return或通过pthread_exit()
// 终止时的返回值。如果前面一个终止的线程已经完成join，再次调用pthread_join将会导致
// 无法预知的行为。例如，相同的线程ID可能在join以后已经为另一个新建线程所重用，在度
// 调用pthread_join()可能等待的这个新线程。若线程并未分离（detached），则必须进行
// join。如果未能完成join，那么线程终止时将产生僵尸线程，与僵尸进程的概念相类似。除了
// 浪费系统资源以外，僵尸线程若积累过多，应用将再也无法创建新的线程。 ::
//
//      int pthread_join(pthread_t thread, void **retval);
//      int pthread_detach(pthread_t thread);
//      pthread_detach(pthread_self());
//
// pthread_join()执行的功能类似于针对进程的waitpid()，不过二者之间存在一些显著差别。
// 线程之间的关系时对等的（peers），进程中的任意线程均可以调用 pthread_join() 与该
// 进程的任何其他线程连接起来。例如如果线程A创建线程B，线程B再创建线程C，那么线程A可
// 以连接线程C，线程C也可以连接线程A。这与进程间的层次关系不同。父进程如果使用fork()
// 创建了子进程，那么它也是唯一能够对子进程调用wait()的进程。调用pthread_create()
// 创建的新线程与发起调用的线程之间，就没有这样的关系。无法“连接任何线程”，而对于进程
// 则可以通过调用waitpid(-1,&status,options)做得这一点，也不能以非阻塞方式进行连接，
// 类似于设置WHOHANG标志的waitpid()。限制pthread_join()只能连接特定线程ID，这样做
// 是“别有用心”的。其用意在于，程序应只能连接它所知道的线程。线程之间并无层次关系，如
// 果听任与任意线程连接的操作发生，那么所谓“任意”线程就可以包括由库函数私自创建的线
// 程，从而带来问题，而后面展示的使用条件变量技术也只运行线程连接它知道的其他线程。结
// 果是，函数库再获取线程返回状态时将不再能与该线程连接，只会一错再错，试图连接一个已
// 经过的线程ID。换言之，连接任意线程的操作与模块化的程序涉及理念背道而驰。
//
// 默认情况下，线程是可连接的（joinable），也就是说当线程退出时，其他线程可以通过调用
// pthread_join()获取其返回状态。有时程序员并不关心线程的返回状态，只是希望再线程终
// 止时能够自动清理并移除。在这种情况下，可以调用pthread_detach()将对应的线程标记为
// 分离（detached）状态。例如以下的代码，一个线程自己可以进行自我分离。一旦线程处于分
// 离状态，就不能再使用pthread_join()来获取其状态，也无法使其重返可连接状态。其他线程
// 调用了exit()或是主线程执行return语句时，即便遭到分离的线程也还是会受到影响。此时，
// 不管线程处于可连接状态还是已分离状态，进程的所有线程会立即终止。换言之，
// pthread_detach()只能控制线程终止之后所发生的事情，而非何时或如何终止线程。一个已经
// 处于分离状态的线程ID，不能再次使用它来调用pthread_join()或pthread_detach()。
//
// 可以使用 pthread_attr_t 设置线程的属性，包括初始的 detach 状态，栈大小和栈地址，
// 以及其他一些设定。其中新创建线程的 detach 状态默认是 PTHREAD_CREATE_JOINABLE。
// 创建线程时，每个线程都有一个属于自己的线程栈，且大小固定。在 Linux/x86-32架构上，
// 除主线程外的所有线程，其栈的缺省大小均为2MB，在一些64位架构下默认尺寸要大一些。为
// 了应对栈的增长，主线程的空间要大出许多。偶尔也需要改变线程栈的大小，再通过线程属性
// 对像创建线程时，调用函数pthread_attr_setstacksize()所设置的线程属性决定了线程栈
// 的大小。而使用与之相关的另一函数pthread_attr_setstack()可以同时控制线程栈的大小
// 和位置，不过设置栈的地址将降低程序的可移植性。更大的线程栈可以容纳大型的自动变量或
// 者深度的嵌套调用，这是改变每个线程栈大小的原因之一。而另一方面应用程序可能希望减少
// 每个线程栈，以便进程可以创建更多的线程。例如在x86-32系统中，用户模式可访问的虚拟地
// 址空间是3GB，而2MB的缺省栈大小则意味着最多只能创建1500各线程，更为准确的最大值还视
// 代码段、数据段、共享函数库等对虚拟内存的消耗量。特定架构的系统上，可采用的线程栈大
// 小最小值可以通过调用sysconf(_SC_THREAD_STACK_MIN)来确定，在Linux/x86-32上的
// NPTL实现中，该调用返回16384。在NPTL线程实现中，如果对线程栈尺寸资源限制
//（RLIMIT_STACK）的设置不同于unlimited，那么创建线程时会以其作为默认值。对该限制的
// 设置必须在运行程序之前，通过执行shell内建命令ulimit -s完成，在C shell下命令
// 为limit stacksize。在主程序中调用setrlimit()来设置限制的办法可能行不通，因为NPTL
// 在调用main()之前的运行时初始化期间就已经确定了默认栈的大小。
//
// pthread_attr_setstacksize() 函数将栈大小属性设置为 stacksize。栈大小属性决定了
// 线程分配的最小栈空间大小（以字节为单位）。pthread_attr_setstacksize() 可能会因以
// 下错误而失败：EINVAL 栈大小小于 PTHREAD_STACK_MIN（16384 字节）；在某些系统中，
// 如果 stacksize 不是系统页面大小的倍数，可能会返回 EINVAL 错误。线程的栈大小在创建
// 线程时就已固定，只有主线程的栈可以动态增长。缺陷说明：截至 glibc 2.8，如果指定的
// stacksize 不是 STACK_ALIGN（在大多数架构上为 16 字节）的倍数，它可能会向下取整，
// 这违反了 POSIX.1 标准。POSIX.1 规定分配的栈空间至少应为 stacksize 字节，而向下
// 取整会小于提供的 stacksize 参数值。
//
// pthread_attr_setstack() 函数将栈地址和栈大小属性设置为stackaddr和stacksize。这
// 些属性指定了线程应使用的栈的位置和大小。stackaddr 应指向调用者分配的大小为
// stacksize 字节的缓冲区的最低可寻址字节。已分配缓冲区的页面应同时具备可读和可写权
// 限。pthread_attr_setstack() 可能会因以下错误而失败：EINVAL：stacksize 小于
// PTHREAD_STACK_MIN（16384 字节）。在某些系统中，如果 stackaddr 或
// stackaddr + stacksize 未正确对齐，也可能会出现此错误。EACCES：POSIX.1 标准还提
// 到，如果 stackaddr 和 stacksize 所描述的栈区域对于调用者而言并非既可读又可写，则
// 会返回此错误。这些函数是为那些必须确保线程栈位于特定位置的应用程序提供的。对于大多
// 数应用程序来说，这并非必要，应避免使用这些函数。如果应用程序只是需要非默认的栈大小，
// 可使用 pthread_attr_setstacksize(3)。当应用程序使用 pthread_attr_setstack()
// 时，它就承担起了分配栈的责任。使用 pthread_attr_setguardsize(3) 设置的任何警戒区
// 大小值都将被忽略。如果认为有必要，应用程序有责任分配一个警戒区（一个或多个受保护的
// 页面，禁止读写）来处理栈溢出的可能性。stackaddr 中指定的地址应正确对齐：为了实现完
// 全的可移植性，应将其对齐到页面边界 sysconf(_SC_PAGESIZE)，使用 posix_memalign(3)
// 分配可能会很有用。可能地，stacksize 也应该是系统页面大小的倍数。如果使用 attr 创建
// 多个线程，那么调用者必须在每次调用 pthread_create(3) 之间更改栈地址属性；否则，这
// 些线程将尝试使用相同的内存区域作为它们的栈，从而导致混乱。
//
// pthread_attr_setguardsize() 函数将警戒区大小属性设置为 guardsize。如果大于 0，
// 那么系统会在线程栈的末尾额外分配至少 guardsize 字节的区域，作为栈的警戒区。如果
// guardsize 为 0，那么不会有警戒区。默认的警戒区大小与系统页面大小相同。如果已经设
// 置了栈地址属性（使用 pthread_attr_setstack() 或 pthread_attr_setstackaddr()），
// 这意味着调用者正在为线程分配栈，那么警戒区大小属性将被忽略（系统不会创建警戒区）：
// 应用程序有责任处理栈溢出问题。也许可以使用 mprotect() 手动在其分配的栈末尾定义一个
// 警戒区。警戒区由受保护的虚拟内存页面组成，以防止读写访问。如果一个线程的栈溢出到警
// 戒区，在大多数硬件架构上，它会收到一个 SIGSEGV 信号，从而得知发生了栈溢出。警戒区
// 从页面边界开始，并且在创建线程时，警戒区大小会在内部向上取整为系统页面大小。将警戒
// 区大小设置为 0 对于创建大量线程且确定不会发生栈溢出的应用程序来说，有助于节省内存。
// 如果线程在栈上分配大型数据结构，选择大于默认大小的警戒区可能对于检测栈溢出是必要的。
// 缺陷说明：截至 glibc 版本 2.8，NPTL 线程实现将警戒区包含在栈大小分配之内，而不是像
// POSIX.1 要求的那样在栈末尾分配额外的空间。这可能会导致 pthread_create(3) 返回
// EINVAL 错误，因为警戒区太大导致无足够多的实际栈空间。过时的 LinuxThreads 实现则做对了，
// 它在栈末尾分配额外的空间作为警戒区。 ::
//
//      int pthread_attr_init(pthread_attr_t *attr);
//      int pthread_attr_destroy(pthread_attr_t *attr);
//      int pthread_attr_setdetachstate(attr, int detachstate);
//      int pthread_attr_getdetachstate(attr, int *detachstate);
//      int pthread_attr_setstacksize(attr, size_t stacksize);
//      int pthread_attr_getstacksize(attr, size_t *stacksize);
//      int pthread_attr_setstack(attr, void *stackaddr, size_t stacksize);
//      int pthread_attr_getstack(attr, void **stackaddr, size_t *stacksize);
//      int pthread_attr_setguardsize(attr, size_t guardsize);
//      int pthread_attr_getguardsize(attr, size_t *guardsize);
//      int pthread_attr_setscope(attr, int scope);
//      int pthread_attr_getscope(attr, int *scope);
//      int pthread_attr_setinheritsched(attr, int inheritsched);
//      int pthread_attr_getinheritsched(attr, int *inheritsched);
//      int pthread_attr_setschedpolicy(attr, int policy);
//      int pthread_attr_getschedpolicy(attr, int *policy);
//      int pthread_attr_setschedparam(attr, const struct sched_param *param);
//      int pthread_attr_getschedparam(attr, struct sched_param *param);
//
//      detachstate: PTHREAD_CREATE_JOINABLE PTHREAD_CREATE_DETACHED
//      scope: PTHREAD_SCOPE_SYSTEM PTHREAD_SCOPE_PROCESS
//      inheritsched: PTHREAD_INHERIT_SCHED PTHREAD_EXPLICIT_SCHED
//      policy: SCHED_FIFO SCHED_RR SCHED_OTHER
//      struct sched_param { int sched_priority; } 0 ~ 99
//
// pthread_attr_setscope() 设置线程的竞争范围属性，竞争范围定义了一个线程为获取CPU
// 资源而与之竞争的线程集合。其中PTHREAD_SCOPE_SYSTEM表示所有进程中的线程都是对等的，
// 相当于它们基于调度策略和优先级对等的使用内核CPU。而PTHREAD_SCOPE_PROCESS线程只会
// 于进程内同样具有PTHREAD_SCOPE_PROCESS属性的线程竞争资源。POSIX.1要求实现至少支持
// 其中的一种竞争范围，Linux 支持 PTHREAD_SCOPE_SYSTEM，但不支持
// PTHREAD_SCOPE_PROCESS。在支持多种竞争范围的系统上，为了使
// pthread_attr_setscope()所做的参数设置在调用pthread_create()时生效，调用者必须使
// 用pthread_attr_setinheritsched()将属性对象的继承调度器属性设置为
// PTHREAD_EXPLICIT_SCHED。PTHREAD_SCOPE_SYSTEM 竞争范围通常表明一个用户空间线程直
// 接绑定到单个内核调度实体。在 Linux 系统中，过时的 LinuxThreads 实现和现代的 NPTL
// 实现都是如此，它们均为 1:1 线程实现（即一个用户空间线程对应一个内核线程）。POSIX.1
// 标准规定，默认的竞争范围由具体实现来定义。
//
// pthread_attr_setinheritsched() 函数将继承调度器属性设置为 inheritsched 指定的
// 值。继承调度器属性决定是从调用线程继承其调度属性，还是从 attr 中获取这些属性。以下
// 调度属性会受到该属性的影响：调度策略pthread_attr_setschedpolicy(3)、调度优先级
// pthread_attr_setschedparam(3) 和竞争范围 pthread_attr_setscope(3)。新初始化的
// 线程属性对象中，继承调度器属性的默认值是 PTHREAD_INHERIT_SCHED。
// pthread_attr_setinheritsched() 可能会因以下错误而失败：EINVAL：inheritsched 值
// 无效。ENOTSUP：POSIX.1 还记录了 pthread_attr_setinheritsched() 可能出现的一个
// 可选错误 ENOTSUP（“尝试将属性设置为不支持的值”）。缺陷说明：截至 glibc 2.8，如果
// 使用 pthread_attr_init(3) 初始化一个线程属性对象，那么该属性对象的调度策略会被设
// 置为 SCHED_OTHER，调度优先级会被设置为 0。然而，如果随后将继承调度器属性设置为
// PTHREAD_EXPLICIT_SCHED，那么使用该属性对象创建的线程会错误地从创建线程继承其调度
// 属性。如果在调用 pthread_create(3) 之前，在线程属性对象中显式设置了调度策略或调度
// 优先级属性，这个缺陷就不会出现。
//
// pthread_attr_setschedpolicy() 函数将调度策略属性设置为 policy。支持的值为
// SCHED_FIFO、SCHED_RR 和 SCHED_OTHER，其语义在 sched(7) 中有详细描述。
// 为了使 pthread_attr_setschedpolicy() 设置的策略在调用 pthread_create(3) 时生
// 效，调用者必须使用 pthread_attr_setinheritsched(3) 将继承调度器属性设置为
// PTHREAD_EXPLICIT_SCHED。pthread_attr_setschedpolicy() 可能会因以下错误而失败：
// EINVAL：policy 中的值无效。ENOTSUP：POSIX.1 还记录了
// pthread_attr_setschedpolicy() 可能出现的一个可选错误 ENOTSUP（“尝试将属性设置为
// 不支持的值”）。pthread_attr_setschedparam() 函数将调度参数属性设置为 param。
// 调度参数使用以下结构体：struct sched_param { int sched_priority; };关于每种调度
// 策略下允许的调度优先级范围的详细信息，请参阅 sched(7)。为了使
// pthread_attr_setschedparam() 设置的参数在调用 pthread_create(3) 时生效，调用者
// 必须使用 pthread_attr_setinheritsched(3) 将继承调度器属性设置为
// PTHREAD_EXPLICIT_SCHED。pthread_attr_setschedparam() 可能会因以下错误而失败：
// EINVAL：param 中指定的优先级对于当前的调度策略没有意义。ENOTSUP：POSIX.1 记录了
// pthread_attr_setschedparam() 可能出现的 ENOTSUP 错误。在 Linux 上，这个值永远
// 不会返回（但具有可移植性和前瞻性的应用程序仍然应该处理这个错误返回值）。
//
// 另外还有线程相关的CPU时间和调度函数： ::
//
// int pthread_getcpuclockid(pthread_t thread, clockid_t *clockid);
// int pthread_setschedprio(pthread_t thread, int prio);
// int pthread_setschedparam(pthread_t thread, int policy, const struct sched_param *param);
// int pthread_getschedparam(pthread_t thread, int *policy, struct sched_param *param);
// nice getcpu getpriority setpriority
// sched_getcpu sched_setscheduler sched_setparam sched_getparam
// sched_get_priority_max sched_get_priority_min sched_rr_get_interval
// sched_yield sched_setaffinity sched_getaffinity sched_setattr sched_getattr
//
// 调度策略。调度器是内核组件，它决定下一个由 CPU 执行的可运行线程。每个线程都有一个
// 关联的调度策略和一个静态调度优先级 sched_priority。调度器根据系统中所有线程的调度
// 策略和静态优先级来做出决策。对于采用普通调度策略（SCHED_OTHER、SCHED_IDLE、
// SCHED_BATCH）调度的线程，sched_priority不用于调度决策（必须指定为 0）。采用实时
// 策略（SCHED_FIFO、SCHED_RR）调度的线程程，其 sched_priority 值的范围是 1（低）到
// 99（高）。如数字所示，实时线程的优先级总是高于普通线程。请注意：POSIX.1 要求实现仅
// 为实时策略支持至少 32 个不同的优先级级别，有些系统仅提供这个最小值。可移植的程序应
// 该使用 sched_get_priority_min(2) 和 sched_get_priority_max(2) 来查找特定策略支
// 持的优先级范围。从概念上讲，调度器为每个可能的 sched_priority 值维护一个可运行线
// 程列表。为了确定下一个运行的线程，调度器会查找具有最高静态优先级的非空列表，并选择
// 该列表头部的线程。线程的调度策略决定了它将被插入到具有相同静态优先级的线程列表中的
// 位置，以及它将如何在该列表中移动。所有调度都是抢占式的：如果一个具有更高静态优先级
// 的线程准备好运行，当前正在运行的线程将被抢占，并返回到其静态优先级级别的等待列表中。
// 调度策略仅决定具有相同静态优先级的可运行线程列表内的顺序。
//
// SCHED_FIFO先进先出调度，只能用于静态优先级高于0的情况，这意味着当一个SCHED_FIFO
// 线程变为可运行状态时，它将始终立即抢占任何当前正在运行的SCHED_OTHER、SCHED_BATCH
// 或SCHED_IDLE线程。SCHED_FIFO是一种简单的无时间片划分的调度算法。对于采用
// SCHED_FIFO策略调度的线程，适用以下规则：一个正在运行的SCHED_FIFO线程如果被另一个
// 更高优先级的线程抢占，它将停留在其优先级列表的头部，并在所有更高优先级的线程再次阻
// 塞后立即恢复执行。当一个阻塞的SCHED_FIFO线程变为可运行状态时，它将被插入到其优先级
// 列表的末尾。如果调用 sched_setscheduler(2)、sched_setparam(2)、
// sched_setattr(2)、pthread_setschedparam(3) 或 pthread_setschedprio(3) 更改由
// pid 标识的正在运行或可运行的 SCHED_FIFO 线程的优先级，对该线程在列表中位置的影响
// 取决于线程优先级的变化方向：如果线程的优先级提高，它将被放置在其新优先级列表的尾部。
// 因此，它可能会抢占当前正在运行的具有相同优先级的线程。如果线程的优先级不变，它在运行
// 列表中的位置不变。如果线程的优先级降低，它将被放置在其新优先级列表的头部。根据
// POSIX.1 - 2008，使用除 pthread_setschedprio(3) 之外的任何机制更改线程的优先级
//（或策略），应导致该线程被放置在其优先级列表的末尾。调用 sched_yield(2) 的线程将被
// 放置在列表的末尾。没有其他事件会使采用 SCHED_FIFO 策略调度的线程在具有相同静态优先
// 级的可运行线程等待列表中移动。一个 SCHED_FIFO 线程会一直运行，直到它因 I/O 请求而
// 阻塞、被更高优先级的线程抢占，或者调用 sched_yield(2)。
//
// SCHED_RR 轮转调度是 SCHED_FIFO 的简单增强。上述关于SCHED_FIFO的所有描述也适用于
// SCHED_RR，不同之处在于每个线程只允许运行最长一个时间片。如果一个 SCHED_RR 线程已
// 经运行了等于或超过时间片的时间段，它将被放置在其优先级列表的末尾。一个被更高优先级
// 线程抢占并随后作为运行线程恢复执行的 SCHED_RR 线程将完成其轮转时间片的未使用部分。
// 可以使用 sched_rr_get_interval(2) 来获取时间片的长度。
//
// SCHED_OTHER 默认的 Linux 分时调度。SCHED_OTHER 只能用于静态优先级为 0 的情况
//（即采用实时策略的线程的优先级总是高于 SCHED_OTHER 线程）。SCHED_OTHER 是标准的
// Linux 分时调度器，用于所有不需要特殊实时机制的线程。要运行的线程是从静态优先级为
// 0 的列表中根据动态优先级选择的，该动态优先级仅在这个列表内确定。动态优先级基于
// nice 值，并且对于线程准备运行但被调度器拒绝运行的每个时间片，动态优先级都会增加。
// 这确保了所有 SCHED_OTHER 线程的公平进展。在 Linux 内核源代码中，SCHED_OTHER 策
// 略实际上被命名为 SCHED_NORMAL。
//
// SCHED_BATCH 批量调度（从 Linux 2.6.16 版本开始支持）仅能在静态优先级为 0 的情况
// 下使用。该策略与 SCHED_OTHER 类似，都是根据线程的动态优先级（基于 nice 值）来调
// 度线程。不同之处在于，此策略会让调度器始终假定该线程是 CPU 密集型的。因此，调度器
// 在唤醒行为方面会施加一个小的调度惩罚，使得该线程在调度决策中略微处于劣势。这个策略
// 适用于非交互式的工作负载，且这些工作负载不想降低其 nice 值；同时也适用于那些希望
// 采用确定性调度策略，避免交互性导致额外抢占（在工作负载的任务之间）的工作负载。
//
// SCHED_IDLE：极低优先级作业调度（从 Linux 2.6.23 版本开始支持）仅能在静态优先级为
// 0 的情况下使用；进程的 nice 值对此策略没有影响。此策略旨在以极低的优先级运行作业，
// 甚至比采用 SCHED_OTHER 或 SCHED_BATCH 策略且 nice 值为 +19 的优先级还要低。
//
// nice 值是一个属性，可用于影响 CPU 调度器在调度决策中对某个进程的偏好或不偏好。它
// 会影响 SCHED_OTHER 和 SCHED_BATCH 线程的调度。可以使用 nice(2)、setpriority(2)
// 或 sched_setattr(2) 来修改 nice 值。根据 POSIX.1，nice 值是每个进程的属性；也
// 就是说，一个进程中的线程应该共享一个 nice 值。然而，在 Linux 上，nice 值是每个线
// 程的属性：同一进程中的不同线程可能有不同的 nice 值。nice 值的范围在不同的 UNIX
// 系统中有所不同。在现代 Linux 上，范围是 -20（高优先级）到 +19（低优先级）。在其他
// 一些系统上，范围是 -20 到 20。非常早期的 Linux 内核（Linux 2.0 之前）的范围是负
// 无穷到 15。nice 值对 SCHED_OTHER 进程相对调度的影响程度在不同的 UNIX 系统和不同
// 的 Linux 内核版本中也有所不同。随着 Linux 2.6.23 中 CFS 调度器的出现，Linux 采
// 用了一种算法，使得 nice 值的相对差异产生更强的影响。在当前实现中，两个进程的 nice
// 值每相差一个单位，调度器对优先级较高的进程的偏好程度就会增加 1.25 倍。这使得非常
// 低的 nice 值（+19）在系统上有任何其他更高优先级负载时，确实为进程提供很少的 CPU
// 资源，而高 nice 值（-20）则为需要的应用程序（例如，一些音频应用程序）提供大部分
// CPU 资源。在 Linux 上，RLIMIT_NICE 资源限制可用于定义非特权进程的 nice 值可以提
// 高的上限。
//
// nice 值与组调度。当调度非实时进程（即采用 SCHED_OTHER、SCHED_BATCH 和
// SCHED_IDLE 策略调度的进程）时，如果内核配置了 CONFIG_FAIR_GROUP_SCHED 选项（通
// 常都是如此），CFS 调度器会采用一种称为 “组调度” 的技术。在组调度模式下，线程会以
// “任务组” 为单位进行调度。任务组之间存在层次关系，其根节点是系统中的初始任务组，也
// 就是 “根任务组”。任务组在以下情况下形成：一个 CPU 控制组（cgroup）中的所有线程会
// 组成一个任务组。该任务组的父任务组是对应父 cgroup 的任务组。如果启用了自动分组功
// 能，那么所有（隐式地）被划分到同一个自动组（即通过 setsid(2) 创建的同一个会话）中
// 的线程会组成一个任务组。因此，每个新的自动组都是一个独立的任务组。根任务组是所有这
// 些自动组的父任务组。如果启用了自动分组功能，根任务组则由根 CPU cgroup 中未被隐式
// 划分到新自动组的所有进程组成。如果禁用了自动分组功能，根任务组则由根 CPU cgroup 中
// 的所有进程组成。如果禁用了组调度（即内核配置时未开启 CONFIG_FAIR_GROUP_SCHED），
// 那么系统中的所有进程理论上会被划分到同一个任务组中。在组调度模式下，一个线程的nice
// 值仅在与同一任务组中的其他线程进行调度决策时才会产生影响。这与 UNIX 系统中 nice
// 值的传统语义相比，会产生一些令人意外的结果。特别是，如果启用了自动分组功能（这在各
// 种发行版中是默认设置），那么对某个进程使用 setpriority(2) 或 nice(1) 命令，其影
// 响仅体现在与同一会话（通常是同一个终端窗口）中执行的其他线程的调度关系上。相反，对
// 于分别处于不同会话（例如不同的终端窗口，每个窗口中的作业都与不同的自动组相关联）中
// 的两个 CPU 密集型进程，修改其中一个会话中进程的 nice 值，在调度器的决策中，对另一
// 个会话中的进程没有任何影响。这里有一个可能有用的解决方法，即使用如下命令修改终端会
// 话中所有进程的自动组 nice 值：echo 10 > /proc/self/autogroup。
//
// 线程取消机制。在通常情况下，程序中的多个线程会并发执行，每个线程各司其职直至其决意
// 退出，随即会调用函数pthread_exit()或者从线程启动函数中返回。有时候需要将一个线程
// 取消，即向线程发送一个请求要求其立即退出。比如一组线程正在执行一个运算一旦某个线程
// 检测到错误发生需要其他线程退出，取消线程的功能这时就派上用场。还有一种情况，一个由
// 图形界面驱动的应用程序可能会提供一个“取消”按钮，以便用户可以终止后台某个线程正在执
// 行的任务。这种情况下，主线程（控制图形界面）需要请求后台线程退出。 ::
//
//      int pthread_cancel(pthread_t thread);
//      int pthread_setcancelstate(int state, int *oldstate);
//      int pthread_setcanceltype(int type, int *oldtype);
//      void pthread_testcancel(void);
//      void pthread_cleanup_push(void *(routine)(void *), void *arg);
//      void pthread_cleanup_pop(int execute);
//
//      state:  PTHREAD_CANCEL_DISABLE PTHREAD_CANCEL_ENABLE
//      type:   PTHREAD_CANCEL_ASYNCHRONOUS PTHREAD_CANCEL_DEFERED
//
// 发出取消请求后，函数pthread_cancel()会立即返回，不会等待目标线程的退出。准确地说，
// 目标线程会发生什么，何时发生，这都取决于线程取消状态（state）和类型（type）。函数
// pthread_setcancelstate() 和 pthread_setcanceltype() 会设定标志，允许线程对取消
// 请求的响应过程加以控制。函数 pthread_setcancelstate() 会将调用线程的取消性状态置
// 为参数state所给定的值。其中 PTHREAD_CANCEL_DISABLE 设置线程不可取消，如果此类线
// 程收到取消请求则会挂起取消请求，直至将取消状态置为启用。PTHREAD_CANCEL_ENABLE
// 设置线程可以取消，这是新建线程取消性状态的默认值。而参数 oldstate 可以获取前一状态
// 的值，如果对前一状态没有兴趣，Linux 允许将oldstate置为NULL。不过SUSv3并没有规范
// 这一特性，所以要保证应用的可移植性，就不能依赖这一特性，应该总是为oldstate设置一个
// 非NULL的值。如果线程执行的代码片段需要不间断地一气呵成，那么临时屏蔽线程的取消行状
// 态就变得很有必要。
//
// 如果线程的取消行状态为启用状态，那么对取消请求的处理则取决于线程的取消性类型，该类
// 型可以通过调用函数 pthread_setcanceltype() 进行设定。其中
// PTHREAD_CANCEL_ASYNCHRONOUS 可能会在任何时点（也许是立即取消，但不一定）取消线程。
// 异步取消的应用场景很少，后面单独介绍。另一个值 PTHREAD_CANCEL_DEFERED 将取消请求
// 保持在挂起状态，直至到达取消点（cancellation point），这也是新建线程的缺省类型。
// 当某线程调用fork()时，子进程会继承调用线程的取消性类型及状态。而当某线程调用exec()
// 时，会将新程序主线程的取消性类型及状态分别重置为 PTHREAD_CANCEL_ENABLE 和
// PTHREAD_CANCEL_DEFERRED。
//
// 若将线程的取消性状态和类型分别置为启用和延迟，仅当线程抵达某个取消点时，取消请求才
// 会起作用。取消点即是对由实现定义的一组函数之一加以调用。SUSv3规定，实现若提供了下
// 表所列的函数，则这些函数必须是取消点。其中的大部分函数都有能力将线程无限期地阻塞起
// 来。 ::
//
//      accept aio_suspend clock_nanosleep close connect creat fcntl(F_SETLKW)
//      fsync fdatasync getmsg getpmsg lockf(F_LOCK) mq_receive mq_send
//      mq_timedreceive mq_timedsend msgrcv msgsnd msync nanosleep open
//      pause poll pread pselect pthread_cond_timedwait pthread_cond_wait
//      pthread_join pthread_testcancel putmsg putpmsg pwrite read readv
//      recv recvfrom recvmsg select sem_timedwait sem_wait send sendmsg
//      sendto sigpause sigsuspend sigtimedwait sigwait sigwaitinfo sleep
//      system tcdrain usleep wait waitid waitpid write writev
//
// 除这些函数外，SUSv3还指定了大量函数，系统实现可以将其定义为取消点。其中包括 stdio
// dlopen syslog ntfw popen semop unlink，以及从诸如 utmp 之类的系统文件中获取信
// 息的各种函数。可移植应用程序必须正确处理这一情况：线程在调用这些函数时有可能遭到取
// 消。SUSv3规定，处理上述两组必须或可能是取消点的函数之外，不得将标准中的任何其他函数
// 视为取消点，即调用这些函数不会招致线程取消，可移植程序加以处理。SUSv4在必须的可取消
// 函数列表中增加了openat，并移除了函数sigpause和usleep。系统实现可随意将标准并未规范
// 的其他函数标记为取消点。任何可能造成阻塞的函数，有可能是因为需要访问文件，都是取消
// 点的理想候选对象。处于这一理由，glibc将其中的许多非标准函数标记为取消点。
//
// 线程一旦收到取消请求，且启用了取消状态并将类型置为延迟，则会在下次抵达取消点时终止。
// 如果该线程尚未分离（detached），那么为防止其编程僵尸线程，必须由其他线程对其进行连
// 接（join）。连接之后，返回至函数 pthread_join() 中第二个参数的值将是一个特殊值，
// PTHREAD_CANCED。
//
// 如果一个需要取消的线程，其执行的代码并没有调用存在取消点的函数，例如计算密集型循环，
// 这时线程永远也不会响应取消请求。函数 pthread_testcancel() 的目的很简单，就是产生
// 一个取消点。线程如果已有处于挂起状态的取消请求，那么只要调用该函数，线程就会随之终
// 止。当线程执行的代码未包含取消点时，可以周期性地调用 pthread_testcancel()，以确保
// 对其他线程向其发送的取消请求做出及时响应。
//
// 一旦有取消请求处于挂起状态，线程在执行到取消点时如果只是草草收场，这会将共享变量以及
// pthreads对象，例如互斥量置于一种不一致状态，可能导致进程中其他线程产生错误结果、死
// 锁，甚至造成程序崩溃。为规避这一问题，线程可以设置一个或多个清理函数，当线程遭到取消
// 时会自动运行这些函数，在线程终止之前可执行诸如修改全局变量，解锁互斥量等动作。每个
// 线程都可以拥有一个清理函数栈，当线程遭取消时，会该栈自顶向下依次执行清理函数，首先
// 会执行最近设置的函数，接着时次新的函数，依次类推。当执行完所以清理函数后，线程终止。
// 函数 pthread_cleanup_push() 和 pthread_cleanup_pop() 分别负责向调用线程的清理
// 函数栈添加和移除清理函数。push 时还传入了一个 arg 参数，这个参数在清理函数调用时当
// 作参数传给清理函数。 **注意**，若线程因调用 pthread_exit() 而终止，则也会自动执行
// 尚未从清理函数栈中弹出的清理函数，线程正常返回（return）则不会执行清理函数。尽管这
// 里把 pthread_cleanup_push() 和 pthread_cleanup_pop() 描述为函数，SUSv3 却允许
// 将它们实现为宏，可展开为分别由 { 和 } 所包裹的语句序列。并非所有的 UNIX 都这样做，
// 不过包括 LINUX 在内的很多系统都是使用宏来实现的。由于这个限制必须在线程相同的作用
// 域中已匹配对的形式调用这两个函数，pthread_cleanup_push 的宏定义可以包含字符 {，
// 这种情况下，在 pthread_cleanup_pop 的定义中会包含对应的匹配字符 }。
//
// 如果设定线程为可异步取消时（PTHREAD_CANCEL_ASYNCHRONOUS），可以在任何时点将其取
// 消（即执行任何机器指令时），取消动作不会拖延到下一个取消点才执行。异步取消的问题在
// 于，尽管清理函数依然会得以执行，但处理函数却无从得知线程的具体状态。清理函数无法知
// 道将在哪里发生取消动作，或者准确的说，清理函数不清除需要执行哪些清理步骤。此外，由
// 于可以在任意点都可能被取消，线程很可能还处于某种未知状态，例如一个动态分配的函数本
// 来是需要在清理函数中清理的，但可能在执行malloc()期间就被取消了，这极有可能造成后续
// 的混乱。作为一般性原则，可异步取消的线程不应该分配任何资源，也不能获取互斥量或锁，
// 这导致大量库函数无法使用，其中就包括pthreads函数的大部分。SUSv3中有3各例外是
// pthread_cancel() pthread_setcancelstate() pthread_setcanceltype()，规范明确
// 要求将它们实现为异步取消安全。换言之，异步取消功能鲜有应用场景，其中之一是取消在执
// 行计算密集型循环的线程。
//
// 综上所述，函数 pthread_cancel() 允许某线程向另外一个线程发送取消请求，要求目的线
// 程终止。目标线程如何响应，取决于其取消性状态和类型。如果禁用线程的取消性状态，那么
// 会挂起（pending）取消请求，直至将线程的取消性状态置为启用。如果启用取消状态，那么
// 线程何时响应则依赖于取消性类型。若类型为延迟取消，则在线程下一次调用某个取消点函数
// 时进行取消。如果为异步取消类型，取消动作随时可能发送。线程可以设置一个清理函数栈，
// 其中的清理函数属于有开发人员定义的函数，当线程遭到取消时，会自动调用这些函数以执行
// 清理工作，例如恢复共享变量状态或解锁互斥量。
//
// 线程实现模型，实现线程API的三种不同模型，其实现差异主要集中在线程如何与内核调度实体
// （KSE, Kernel Scheduling Entity）相映射。KSE是内核分配CPU以及其他系统资源的单位，
// 在早于线程而出现的传统UNIX中，KSE等同于进程。
//
// 多对一（M:1）实现，用户级线程。在M:1线程实现中，关乎线程创建、调度以及同步的所有细
// 节全部由进程内用户空间的线程库来处理。对于进程中存在的多个线程，内核一无所知。M:1
// 实现的优势不多，其中最大的有点在于，许多线程操作速度都很快，因为无需切换到内核模式。
// 此外由于线程库无需内核支持，所以M:1实现在系统间的移植相对要容易一些。不过M:1实现也
// 存在一些严重缺陷：当一线程发起系统调用比如read()时，控制由用户空间的线程库转交给内
// 核，这就意味着如果read()调用遭到阻塞，那么所有的线程都会被阻塞。内核无法调度进程中
// 的这些线程，因为内核并不知道进程中存在这些线程，也就无法在多处理器平台上将各线程调
// 度给不同的处理器。另外，也不可能将一进程中某线程的优先级调整为高于其他进程的中的线
// 程，这是没有一样的，因为对线程的调度完全在进程中处理。
//
// 一对一（1:1）实现，内核级线程。在1:1线程实现中，每一线程映射为以恶单独的KSE。内核
// 分别对每个线程做调度处理。线程同步操作通过内核系统调用实现。1:1实现消除了M:1实现的
// 种种弊端。遭阻塞的系统调用不会导致进程的所有线程被阻塞，在多处理硬件平台上，内核还
// 可以将进程中的多个线程调度到不同的CPU上。不过，因为需要切换到内核模式，所以诸如线程
// 创建、上下文切换以及同步操作就需要慢一些。另外，为每个线程分别维护一个KSE也需要开
// 销，如果应用程序包含大量线程，则可能对内核调度造成严重的负担，降低系统的整体性能。
// 尽管有这些缺点，1:1实现通常更胜于M:1实现，LinuxThreads和NPTL都采用1:1模型。在NPTL
// 的开发期间，为了使得包含数千计数的进程得以高效运行，投入了巨大的努力。对内核调度进行
// 了重写并设计了新的线程实现。
//
// 多对多（M:N）实现，两级模型。M:N实现旨在结合1:1和M:1模型的优点，避免二者的缺点。在
// M:N模型中，每个进程都可拥有多个与之相关的KSE，并且也可以把多个线程映射到一个KSE。
// 这种设计运行内核将同一应用的线程调度到不同的CPU上运行，同时也解决了随线程数量大而放
// 大的性能问题。M:N模型的最大问题是过于复杂，线程调度任务由内核及用户空间的线程库共同
// 承担，二者之间势必要进行分工协作和信息交换。在M:N模型下，按照SUSv3标准要求来管理信
// 号也极为复杂。最初增考虑采用M:N模型来实现NPTL线程库，但若要保证Linux调度器即使在处
// 理大量KSE的情况下也能应对自如，则需要对内核所作的改动范围过大，可能也没有必要，故而
// 否决了这一方案。
//
// 针对pthreads API，Linux下由两种实现：LinuxThreads 这是最初的Linux线程实现，NPTL
// （Native POSIX Threads Library）这是Linux线程实现的现代版，以取代LinuxThreads。
// NPTL的性能优于LinuxThreads，也更符合SUSv3的pthreads标准。对NPTL的支持需要修改内
// 核，这始于Linux 2.6。值得强调的是，LinuxThreads实现已经过时，并且glibc从2.4版本
// 开始也已不再支持它，所有新的线程库开发都基于NPTL。
#if PRH_THRD_DEBUG
#if defined(prh_impl_pthread_getattr)
void prh_impl_plat_print_thrd_info(prh_thrd *thrd) {
    pthread_t tid = pthread_self();
    void *stackaddr = prh_null;
    size_t stacksize = 0, guard_size = 0;
    pthread_attr_t attr;
    // For pthread_attr_get_np() attr should be initialized prior to the call
    // by using pthread_attr_init(3). pthread_getattr_np() does this
    // automatically.
#if defined(prh_impl_pthread_attr_get_np)
    prh_zeroret(pthread_attr_init(&attr));
#endif
    prh_zeroret(prh_impl_pthread_getattr(tid, &attr));
    prh_zeroret(pthread_attr_getstack(&attr, &stackaddr, &stacksize));
    prh_zeroret(pthread_attr_getguardsize(&attr, &guard_size));
    prh_zeroret(pthread_attr_destroy(&attr));
    // stackaddr 是内存块的起始地址，一般对齐到内存页面大小边界，stacksize 是内存页面的整数倍
    printf("[thrd %02d] %p stack %d-byte (%dKB) guard %d-byte (%dKB)\n",
        prh_thrd_id(thrd), stackaddr, (int)stacksize, (int)(stacksize/1024),
        (int)guard_size, (int)(guard_size/1024));
}
#else
void prh_impl_plat_print_thrd_info(prh_thrd *thrd) {
    prh_unused(thrd);
}
#endif
#endif

static void *prh_impl_plat_thrd_procedure(void *param) {
    return (void *)(prh_int)prh_impl_thrd_start_proc((prh_thrd *)param);
}

prh_int prh_impl_thread_stack_size(prh_int stacksize) { // 改进：因为线程栈最小为16KB，当线程用来执行协程时，将主协程需要的除外可以直接拿来当子协程的栈用
    if (stacksize <= 0) return 0;
    // https://www.man7.org/linux/man-pages/man3/sysconf.3.html
    // https://www.man7.org/linux/man-pages/man3/sysconf.3p.html
    // 从sysconf获得的值是系统配置常量，在进程的生命周期内不会改变。
    // _SC_PAGESIZE: Size of a page in bytes. Must not be less than 1.
    // _SC_THREAD_STACK_MIN: minimal pthread stack size (16384B/16KB)
    long pagesize = sysconf(_SC_PAGESIZE);
    long minsize = sysconf(_SC_THREAD_STACK_MIN);
    prh_abort_errno_if(pagesize <= 0 || minsize <= 0);
    if (stacksize < minsize) stacksize = minsize;
    long times = (stacksize + pagesize - 1) / pagesize;
    return pagesize * times; // stacksize 是 pagesize 的整数倍
}

void prh_impl_plat_thrd_start(prh_thrd *thrd, prh_thrdproc_t proc, prh_int reserved_stack_size) {
    // 1. stacksize 最小 16KB，必须是页面大小的整数倍，默认值通常 2MB 到 8MB，线程的栈大小在创建线程时就已固定，只有主线程的栈可以动态增长
    // 2. stacksize 是线程栈的预留大小（reserved size），pthread 只能设置预留大小，物理页随用随配，没有对初始提交大小进行设置的接口。
    // 3. pthread_attr_setstack() 可以同时控制线程栈的大小和位置，不过设置栈的地址将降低程序的可移植性，指定的 stackaddr 是内存块的起始地址，必须对齐到页面大小的边界，分配的页面必须具有可读可写权限
    // 4. 当应用程序使用 pthread_attr_setstack() 时，它就承担起了分配栈的责任，使用 pthread_attr_setguardsize() 设置的任何警戒区大小值都将被忽略
    // 5. 如果认为有必要，应用程序有责任分配一个警戒区（一个或多个受保护的页面，禁止读写）来处理栈溢出的可能性，可以使用 mprotect() 手动在其分配的栈末尾定义一个警戒区
    // 6. 如果一个线程的栈溢出到警戒区，在大多数硬件架构上，它会收到一个 SIGSEGV 信号，从而得知发生了栈溢出
    // 7. 将警戒区大小设置为 0 对于创建大量线程且确定不会发生栈溢出的应用程序来说，有助于节省内存，默认的警戒区大小为 1 个页面大小
    // 8. 如果线程在栈上分配大型数据结构，为了能够检测到栈溢出，选择大于默认大小的警戒区可能对于检测栈溢出是必要的
    // 9. 截至 glibc 版本 2.8，NPTL 线程实现将警戒区包含在栈大小分配之内，而不是像POSIX.1 要求的那样在栈末尾分配额外的空间，这可能会导致 pthread_create(3) 返回 EINVAL 错误，因为无足够多的实际栈空间
    pthread_t *tid = (pthread_t *)&thrd->impl_hdl_;
    pthread_attr_t *attr_ptr = prh_null;
    pthread_attr_t attr;

    prh_int stacksize = prh_impl_thread_stack_size(reserved_stack_size);
    if (stacksize > 0) {
        attr_ptr = &attr;
        prh_zeroret(pthread_attr_init(attr_ptr));
        int n = pthread_attr_setstacksize(attr_ptr, stacksize);
        prh_abort_if_error(n);
    }

    assert(proc != prh_null);
    thrd->extra_ptr = (prh_ptr)proc;
    int n = pthread_create(tid, attr_ptr, prh_impl_plat_thrd_procedure, thrd);
    prh_abort_if_error(n);

    if (attr_ptr) {
        prh_zeroret(pthread_attr_destroy(attr_ptr));
    }
}

void prh_thrd_exit(int exit_code) {
    // pthread_exit() 函数用于终止当前线程，并通过参数 retval 返回一个退出码；如果该
    // 线程是可 join 的，则这个返回值可以被同一进程中另一个调用 pthread_join(3) 的线
    // 程获取。
    // 任何通过 pthread_cleanup_push(3) 注册的、尚未弹出的清理处理程序，将按照与压入
    // 顺序相反的顺序被弹出并执行。如果线程拥有线程局部数据（TLS），则在清理处理程序执
    // 行完毕后，相应的析构函数也会被调用（顺序未指定）。当线程终止时，进程共享资源（如
    // 互斥锁、条件变量、信号量、文件描述符）不会被释放，并且通过 atexit(3) 注册的函数
    // 不会被执行。当进程中最后一个线程终止时，进程将以退出状态 0 终止，等效于调用
    // exit(3)；此时，进程共享资源会被释放，并且通过 atexit(3) 注册的函数会被调用。
    // 从非主线程的起始函数返回将隐式调用 pthread_exit()，并以该函数的返回值作为线程
    // 的退出状态。为了允许其他线程继续运行，主线程应调用 pthread_exit() 而不是 exit(3)
    // 来终止自身。retval 所指向的值不应位于调用线程的栈上，因为线程终止后，该栈的内容
    // 是未定义的。
    // 已知缺陷（BUGS）。目前，内核在等待一个已停止的线程组时存在实现逻辑限制，特别是
    // 当线程组领头线程已调用 pthread_exit() 并死亡时。这可能导致某些问题，例如：
    // 向前台进程发送停止信号，但其线程组领头线程已经调用 pthread_exit()，可能导致终
    // 端被锁死等现象。
    pthread_exit((void *)(prh_int)exit_code);
}

void prh_impl_plat_thrd_join(prh_thrd *thrd) {
    void *retv = prh_null;
    pthread_t tid = *(pthread_t *)&thrd->impl_hdl_;
    int n = pthread_join(tid, &retv); // 返回0或错误码
    int thrd_id = prh_thrd_id(thrd);
    int exit_code = 0;
    if (n == 0) {
        exit_code = (int)(prh_int)retv;
    } else {
        prh_prerr(n);
    }
#if PRH_THRD_DEBUG
    if ((prh_unt)retv == (prh_unt)PTHREAD_CANCELED) { // -1 is PTHREAD_CANCELED
        printf("[thrd %02d] canceled join\n", thrd_id);
    } else {
        printf("[thrd %02d] joined %d\n", thrd_id, exit_code);
    }
#else
    if (exit_code != 0) {
        prh_print_exit_code(thrd_id, exit_code);
    }
#endif
}

prh_ptr prh_impl_plat_thrd_self(void) {
    return (prh_ptr)(prh_unt)pthread_self();
}

// 异步信号处理（信号相当于是阻塞所有线程的优先级最高的一路线程）
//
// 信号是事件发生时对进程的通知机制，有时也称为软件中断。信号与硬件中断的相似之处在于打
// 断程序执行的正常流程，大多数情况下，无法预测信号到达的精确时间。一个具有合适权限的进
// 程能够向另一个进程发送信号，信号的这一用法可作为一种同步技术，甚至是进程间通信（IPC）
// 的原始形式。进程也可以向自身发送信号。然后，发往进程的诸多信号，通常都源于内核，引发
// 内核为进程产生信息的各类事件包括：
//      1. 硬件发生异常，即硬件检测到一个错误条件并通知内核，随即再由内核发送相应信号
//      给相关进程。硬件异常的例子包括执行一条异常的机器指令，例如被0除，或者引用无法
//      访问的内存区域。
//      2. 用户键入能够产生信号的终端特殊字符，其中包括中断字符 SIGINT（通常是CTRL-C）、
//      暂停字符（通常是CTRL-Z）。
//      3. 发生了软件事件。 针对文件描述符的输出变为有效，调整了终端窗口大小，定时器到
//      期，进程执行的CPU时间超限，或者该进程的某个子进程退出。
//
// 针对每个信号，都定义了一个唯一的从1开始的整数，<signal.h> 以 SIGxxxx 的形式对这些
// 整数做了定义。由于每个信号的实际编号随系统不同而不同，所以在程序中应该总是使用这些符
// 号名。信号分为两大类，第一组用于内核向进程通知事件，构成所谓传统或标准信号。Linux 中
// 的标准信号编号范围为 1~31，然而 Linux 在 signal(7) 手册中列出的信号名称却超出了31
// 个，超出的原因有多种。有些名称只是其他名称的同义词，这是为了与其他 UNIX 实现保持源码
// 兼容性；其他名称名称虽有定义，但却并未使用。另一组信号由实时信息构成，其与标准信号的
// 差异将在后文介绍。不存在编号为 0 的信号，kill 函数对信号编号 0 有特殊的应用，POSIX
// 将此种信号编号值称为空信号。
//
//  信号                描述                                        默认行为
//  SIGHUP              终端断开或挂起                               term（终止进程）
//  SIGINT              终端中断                                    term（终止进程）
//  SIGQUIT             终端退出                                    core（产生核心转储文件，并终止进程）
//  SIGTSTP             终端停止                                    stop（停止进程）
//  SIGTTIN             终端被后台进程读取                           stop（停止进程）
//  SIGTTOU             终端被后台进程写入                           stop（停止进程）
//  SIGWINCH            终端窗口尺寸变化                             ignore（忽略该信号，内核将默默丢弃）
//  SIGTERM             终止进程                                    term（终止进程）
//  SIGKILL             确保杀死进程                                term（终止进程）
//  SIGSTOP             确保停止进程                                stop（停止进程）
//  SIGCONT             若停止则继续                                cont（恢复一个已停止的进程）
//  SIGABRT             中止进程，来源于abort(3)                     core（产生核心转储文件，并终止进程）
//  SIGIOT              同SIGABRT（Linux），硬件错误（某些UNIX）      core（产生核心转储文件，并终止进程）
//  SIGBUS              内存访问错误/总线错误                        term（可能产生核心转储文件）
//  SIGSEGV             页面非法访问                                core（产生核心转储文件，并终止进程）
//  SIGILL              非法指令                                    core（产生核心转储文件，并终止进程）
//  SIGFPE              算术异常                                    core（产生核心转储文件，并终止进程）
//  SIGEMT              硬件错误/仿真器陷阱                          term（可能产生核心转储文件）
//  SIGTRAP             跟踪或断点陷阱                              core（产生核心转储文件，并终止进程）
//  SIGUSR1 SIGUSR2     用户自定义信号                              term（终止进程）
//  SIGPIPE             管道断开，写入没有读取端的管道                term（终止进程）
//  SIGALRM             实时定时器到期                              term（终止进程）
//  SIGVTALRM           虚拟定时器到期                              term（终止进程）
//  SIGPROF             性能定时器到期                              term（终止进程）
//  SIGSTKFLT           协处理器错误                                term（终止进程）
//  SIGCHLD SIGCLD      子进程状态变化                              ignore（忽略该信号）
//  SIGURG              套接字上有紧急数据                          ignore（老版本可能终止进程）
//  SIGXCPU             超出CPU时间限制                             term（可能产生核心转储文件）
//  SIGXFSZ             超出文件大小限制                            term（可能产生核心转储文件）
//  SIGIO SIGPOLL       输入输出事件                                term（Linux），ignore（某些UNIX）
//  SIGPWR              电量即将耗尽                                term（Linux），ignore（某些UNIX）
//  SIGINFO             同SIGPWR（Linux），前台进程信息（某些UNIX）   term（终止进程）
//  SIGSYS              无效系统调用                                term（可能产生核心转储文件）
//  SIGUNUSED           未使用或与SIGSYS相同                        core（产生核心转储文件，并终止进程）
//  SIGLOST             未使用或NFS客户端文件锁丢失                  term（终止进程）
//
// 可中断和不可中断的进程睡眠状态。SIGKILL 和 SIGSTOP 信号对确保杀死和停止进程，对于
// 这一论断，此外要加入一条限制。内核经常需要令进程进入休眠，而休眠状态又分为两种：（一）
// 任务可中断（TASK_INTERRUPTIBLE），进程正在等待某一事件，例如正在等待终端输入，等待
// 数据写入当前的空管道，或者等待 System V 信号量值的增加。进程在该状态下所耗费的时间可
// 长可短。如果给这种状态下的进程发送一个信号，那么操作将中断，而传递来的信号将唤醒进程。
// ps(1) 命令在显式处于可中断状态的进程时，会将其进程状态（STAT）字段标记为字母 S。
// （二）任务不可中断（TASK_UNINTERRUPTIBLE），进程正在等待某些特定类型的事件，比如磁
// 盘 IO 的完成。如果给这种状态下的进程产生一个信号，那么在进程摆脱这种状态之前，系统将
// 不会把信号传递给进程。ps(1) 命令会将该状态的进程标记为字母 D。因为进程处于不可中断的
// 等待状态时的时间通常转瞬即逝，所以系统在进程脱离该状态时传递信号的现象也不易于被发现。
// 然而，在极少数情况下，进程可能因硬件故障、NFS 问题或者内核缺陷而在该状态下保持挂起，
// 这时 SIGKILL 将不会终止挂起的进程。如果问题诱因无法得到解决，那么就只能通过重启系统
// 来消灭该进程。
//
// 大多数 UNIX 系统实现都支持任务中断和不可中断两种状态。从内核 2.6.25 开始，Linux 加
// 入了第三种状态来解决上述进程挂起问题，任务可杀死（TASK_KILLABLE），该状态类似于不可
// 状态状态，但是会在进程收到一个致命信号（即一个杀死进程的信号）时将其唤醒。
//
// 有六种信号因硬件异常而触发：SIGBUS、SIGEMT、SIGFPE、SIGILL、SIGSEGV 和 SIGTRAP。
// 然而，对于任何特定的硬件异常，具体会触发哪种信号并没有明确的文档说明，且在某些情况下
// 显得并不合理。例如，某些 CPU 架构上非法的内存访问会触发 SIGSEGV，而在另一些架构上可
// 能触发 SIGBUS，反之亦然。再比如，在 x86 架构中，使用 int 指令时传递了非法参数（除了
// 3 或 128 之外的任何数字），会触发 SIGSEGV，尽管在这种情况下 SIGILL 似乎更合适，因为
// 这是 CPU 向内核报告非法操作指令的方式。
//
// SIGHUP - 终端断开或挂断
//      当终端断开时，将发送该信号给终端控制进程，后文将描述控制进程的概念以及产生
//      SIGHUP 信号的各种环境。SIGHUP 信号还可用于守护进程比如 init httpd inetd。
//      许多守护进程会在收到SIGHUP信号时重新进行初始化并重读配置文件。借助于显式执行
//      kill 命令或运行同等功能的程序或脚本，系统管理员可向守护进程手动发送 SIGHUP
//      信号来触发这些行为。
//      如果程序在执行时发现，已将对由终端产生信号的处置设为了忽略（SIG_IGN），那么不
//      应再去修改这些终端信号的行为。这并非系统的硬性规定，而是编写应用程序时所应遵循
//      的管理，终端信号包括 SIGHUP SIGINT SIGTSTP SIGQUIT SIGTTIN SIGTTOU。
// SIGINT - 终端中断
//      当用户键入终端中断字符（通常为CTRL-C）时，终端驱动程序将发送该信号给前台进程
//      组，该信号的默认行为是终止进程。
//      path/to/program & # 后台进程
//      终端 shell 自动将后台进程对 SIGINT 和 SIGQUIT 的处理方式设置为忽略，于是当
//      按下中断或退出字符时就不会影响到后台进程。
// SIGQUIT - 终端退出
//      在用户在键盘上键入退出字符（通常为CTRL-\），该信号将发送给前台进程组。默认情
//      况下，该信号终止进程，并生成可用于调试的核心转储文件。进程如果陷入无限循环，或
//      者不再响应时，使用SIGQUIT信号就很合适。键入CTRL-\，再调用gdb加载刚才生成的核
//      心转储文件，接着用backtrace命令来获取堆栈跟踪信息，就能发现正在执行的是程序的
//      那部分代码。
// SIGTSTP - 终端停止
//      作业控制的停止信号，当用户在键盘上输入挂起字符（通常是CTRL-Z）时，将发送该信号
//      给前台进程组，使其停止运行。后文描述了进程组（作业）和作业控制，以及程序应在何
//      时以及如何去处理该信号。该信号名源自终端停止（terminal stop）术语。
// SIGTTIN - 终端被后台进程读取
//      在作业控制 shell 下运行时，若后台进程组试图对终端进行 read() 时，终端驱动程序
//      则将向该进程组发送此信号。该信号默认将停止进程。
// SIGTTOU - 终端被后台进程写入
//      该信号的目的与 SIGTTIN 类似，但所针对的是后台作业的终端输出。在作业控制 shell
//      下运行时，如果对终端启用了终端输出停止（TOSTOP）选项，可能时通过 stty tostop
//      命令，而某一后台进程组试图会终端进行 write() 操作，那么终端驱动程序将向给进程
//      组发送 SIGTTOU 信号。该信号默认将停止进程。
// SIGWINCH - 终端窗口尺寸变化
//      在窗口环境中，当终端窗口尺寸发生变化时，要么是用户手动调整了大小，要么是因为程
//      序调用 ioctl() 对大小做了调整，会向前台进程组发送该信号。借助于为该信号安装的
//      处理程序，诸如 vi 和 less 之类的程序会在窗口尺寸调整后重新绘制输出。
// SIGTERM - 终止进程
//      用来终止进程的标准信号，也是 kill 和 killall 命令所发送的默认信号。用户有时会
//      使用 kill-KILL 或者 kill-9 显式向进程发送 SIGKILL 信号，然而这一做法通常是
//      错误的。精心设计的应用程序应当为 SIGTERM 信号设置处理程序，以便于其能够预先清
//      除临时文件和释放其他资源，从而全身而退。发送 SIGKILL 信号可以杀掉某个进程，从
//      而绕开了 SIGTERM 信号的处理程序。因此，总是应该首先尝试使用 SIGTERM信号来终止
//      进程，而把 SIGKILL 信号作为最后手段，去对付那些不响应 SIGTERM 信号的失控进程。
// SIGKILL - 确保杀死进程
//      此信号为必杀（sure kill）信号，处理程序无法将其阻塞、忽略、或捕获，故而一击必
//      杀，总能终止进程。SIGKILL 默认行为是终止进程，SIGSTOP 默认行为是停止进程，二
//      者的默认行为均无法改变。不能通过 signal() 和 sigaction() 对其行为进行修改，
//      也不允许阻塞这两个信号。不允许修改这些信号的默认行为，这也意味着总是可以利用这
//      些信号来杀死或停止一个进程。
// SIGSTOP - 确保停止进程
//      这是一个必停（sure stop）信号，处理器程序无法将其阻塞，忽略或者捕获，故而总是
//      能停止进程。
// SIGCONT - 进程继续
//      将该信号发送给已停止的进程，进程将会恢复运行（即在之后某个时间点重新获得调度）。
//      当接收信号的进程当前不处于停止状态，默认情况下会忽略该信号。进程可以捕获该信号，
//      以便在恢复运行时可以执行某些操作。
//      使用 SIGCONT 可以使某些处于停止状态的进行继续运行，包括因 SIGSTOP SIGTSTP
//      SIGTTIN SIGTTOU 信号而停止的进程。由于这些停止信号具有独特目的，所以再某些情
//      况下，内核对它们的处理方式将有别于其他信号。如果一个进程处于停止状态，那么一个
//      SIGCONT 信号的到来总是会促使其恢复运行，即使该进程阻塞或忽略了 SIGCONT 信号。
//      如果处于停止状态的进程正在阻塞 SIGCONT 信号，并且已经为 SIGCONT 信号建立了处
//      理函数，那么在进行恢复运行后，并且只有当取消对 SIGCONT 的阻塞时，进程才会去调
//      用相应的处理函数。如果有任一其他信号发送给一个已经停止的进程，那么在进程收到
//      SIGCONT 信号恢复运行之前，信号实际上并未传递。SIGKILL 信号则属于例外，因为该
//      信号总是会杀死进程，即使进程目前处于停止状态。
//      每当进程收到 SIGCONT 信号时，会将处于等待状态的停止信号丢弃，即进程根本不知道
//      这些信号。相反，如果任何停止信号传递给了进程，那么进程将自动丢弃任何处于等待状
//      态的 SIGCONT 信号。之所以采取这些措施，意在防止执行 SIGCONT 信号之后又被停止
//      信号撤销，反之亦然。
// SIGABRT - 中止进程
//      当进程调用 abort() 函数时，系统向进程发送该信号。默认行为：终止进程，并产生核
//      心转储文件。
// SIGIOT - 中止进程或硬件错误，Input Output Trap
//      在 Linux 中，该信号与 SIGABRT 相同。在其他一些 UNIX 实现中，该信号表示发生了
//      由实现定义的硬件错误。
// SIGBUS - 内存访问错误，内存地址可以访问但访问时发生错误
//      总线错误即表示发生了某种内存访问错误，例如地址未对齐、对应的物理地址不存在、硬
//      件内存校验错误等等。
//      BUS_ADRALN BUS_ADRERR BUS_OBJERR BUS_MCEERR_AR BUS_MCEERR_AO
//      硬件异常可以产生 SIGBUS SIGSEGV SIGILL SIGFPE 信号，调用 kill() 函数也可以
//      发送这类信号但较为少见。SUSv3 规定，在硬件异常的情况下，如果进程从此类信号处理
//      函数中返回，亦或进程忽略或阻塞了此类信号，那么进程的行为未定义。原因如下：
//      1.  从信号处理函数中返回：假设机器语言指令产生了上述信号，并因此而调用了信号处
//          理函数。当从处理函数正常返回后，程序会尝试从其中断处恢复执行。可当初引发信
//          号产生的恰恰正是这条指令，所以信号会再次触发，从而导致程序进入无限循环，重
//          复调用信号处理函数。
//      2.  忽略信号：忽略因硬件而产生的信号于情理不合，试想算术异常之后，程序应当如何
//          继续执行呢？无法明确，当由于硬件异常而产生上述信号时，Linux 会强制传递信
//          号，即使程序已经请求忽略此类信号。
//      3.  阻塞信号：与上一种情况一样，阻塞因硬件产生的信号也不合情理，不清楚程序随后
//          应当如何继续执行。在 Linux 2.4 以及更早的版本中，Linux 内核仅会将阻塞硬件
//          信号的企图忽略，信号无论如果都会传递给进程。而始于 Linux 2.6，如果硬件信号
//          遭到阻塞，那么该信号总会立即杀死进程，即使进程已经为此信号设置了处理函数。
//          Linux 2.6 之所以这样做，是由于 Linux 2.4 的行为中隐藏有缺陷，并可能在多
//          线程程序中引起死锁。
//      正确处理硬件产生的信号的方法有二：要么接受信号默认行为终止进程，那么为其编写不会
//      正常返回的处理函数。
// SIGSEGV - 页面非法访问，内存地址非法或不可访问
//      这一信号非常常见，当应用程序对内存的引用无效时，就会产生该信号。引起对内存无效
//      引用的原因很多，可能是因为要引用的页不存在，或者进程试图更新只读内存中某一位置
//      的内容，又或者进程企图在用户态去访问内核的部分内存。该信号的命名源于术语段违规。
//      SEGV_MAPERR SEGV_ACCERR SEGV_BNDERR SEGV_PKUERR
// SIGILL - 非法指令
//      如果进程试图执行非法或格式不正确的机器语言指令，系统将向进程发送该信号。
//      ILL_ILLOPC ILL_ILLOPN ILL_ILLADR ILL_ILLTRP ILL_PRVOPC ILL_PRVREG
//      ILL_COPROC ILL_BADSTK
// SIGFPE - 算术错误
//      该信号因特定类型的算术错误而产生，比如除以0，后缀 FPE 是浮点异常的缩写，不过整
//      型算术错误页能产生该信号。该信号何时产生取决于硬件架构和对CPU控制寄存器的设置。
//      例如在 x86-32 架构中，整数除以0总是产生 SIGFPE 信号，但是对浮点数除以0的处理
//      取决于是否启用了 FE_DIVBYZERO 异常。更多信息参考 fenv(3) 手册。
//      FPE_INTDIV FPE_INTOVF FPE_FLTDIV FPE_FLTOVF FPE_FLTUND FPE_FLTRES
//      FPE_FLTINV FPE_FLTSUB
// SIGEMT - 硬件错误
//      UNIX 系统通常用该信号来标识一个依赖于实现的硬件错误。Linux 系统仅在 Sun SPARC
//      实现中使用了该信号。后缀 EMT 源自仿真器陷阱（emulator trap），Digital PDP-11
//      的汇编程序助记符之一。
// SIGTRAP - 跟踪或断点陷阱
//      该信号用来实现断点调试功能以及 strace(1) 命令所执行的跟踪系统套用功能。更多信
//      息参见 ptrace(2) 手册。
//      TRAP_BRKPT TRAP_TRACE
// SIGUSR1 SIGUSR2 - 用户自定义信号
//      这两个信号供程序员自定义使用，内核绝不会为进程产生这些信号。进程可以使用这些信
//      号来相互通知事件的发生，或是彼此同步。在早期的 UNIX 实现中，这是可供应用随意使
//      用的仅有的两个信号。实际上，进程间可以发送任何信号，但如果内核也为进程产生相同
//      的信号，这两种情况就会发生混淆。现代UNIX实现则提供很多实时信号，也可用于程序员
//      自定义的目的。
// SIGPIPE - 管道断开
//      当某一进程试图向管道、FIFO、套接字写入信息时，如果这些设备并没有相应的读取进程，
//      那么系统将产生该信号。之所以如此，通常是因为读取进程已经关闭其作为 IPC 通道的文
//      件描述符。
// SIGALRM - 实时计时器到期
//      调用 alarm() 或 setitimer() 设置的实时定时器到期，内核将生成该信号。
// SIGVTALRM - 虚拟计时器到期
//      调用 setitimer() 设置的虚拟定时器刚一到期，内核就会产生该信号，虚拟定时器记录
//      的是进程在用户态所使用的CPU时间。
// SIGPROF - 性能计时器到期
//      由由 setitimer() 调用设置的性能分析定时器刚一过期，内核就将产生该信号。性能分
//      析定时器用于记录进程所使用的CPU时间。与虚拟定时器不同（SIGVTALRM），性能分析
//      定时器在对CPU时间计数时会将用户态与内核态都包含在内。
// SIGSTKFLT - 协处理器栈错误
//      singal(7) 手册将其记录为"协处理器栈错误"，Linux 对该信号作了定义，但并未加以
//      使用。
// SIGCHLD SIGCLD - 子进程状态变化
//      当父进程的某一子进程终止（调用了exit()或被信号杀死）时，内核将向父进程发送该
//      信号。当父进程的某一子进程因受到信号而停止或恢复时，也可能会向父进程发送该信号。
//      CLD_EXITED CLD_KILLED CLD_DUMPED CLD_TRAPPED CLD_STOPPED CLD_CONTINUED
// SIGURG - 紧急数据
//      系统发送该信号给一个进程，表示套接字上存在带外数据（也称作紧急数据）。
// SIGXCPU - 超出CPU时间限制
//      当进程的 CPU 时间超出对应的资源限制时，参见 RLIMIT_CPU，将发送该信号给进程。
//      RLIMIT_CPU 对进程可以消耗的 CPU 时间量的限制，以秒为单位。当进程达到软限制时，
//      它会收到 SIGXCPU 信号。此信号的默认行为是终止进程。然而，该信号可以被捕获，且
//      处理函数可以返回控制权给主程序。如果进程继续消耗 CPU 时间，它将每秒收到一次
//      SIGXCPU，直到达到硬限制，此时它将收到 SIGKILL。此描述为 Linux 的行为。不同实
//      现对达到软限制后继续消耗 CPU 时间的进程的处理方式有所不同。需要捕获此信号的可
//      移植应用程序应在首次收到 SIGXCPU 时执行有序的终止操作。
// SIGXFSZ - 超出文件大小限制
//      如果进程因试图增大文件，调用 write() 或 truncate() 而突破对进程文件大小的资
//      源限制时，参见 RLIMIT_FSIZE，将发送该信号给进程。
// SIGIO - 输入输出事件
//      利用 fcntl() 系统调用，可在特定类型（如终端、套接字）文件描述符上发送 IO 事件
//      时产生该信号。
//      POLL_IN POLL_OUT POLL_MSG POLL_ERR POLL_PRI POLL_HUP
// SIGPOLL - 输入输出事件
//      该信号从 System V 派生而来，与 Linux 中的 SIGIO 信号同义。
// SIGPWR - 电量即将耗尽
//      这是电源故障信号，当系统配备有不间断电源（UPS）时，可以设置守护进程来监控电源
//      发生故障时备用电池的剩余电流。如果电池电量将耗尽（如长时间停电之后），那么监控
//      进程会将该信号发往init进程，而后者则将其解读为快速、有序关闭系统的一个请求。
// SIGINFO - 电量即将耗尽或前台进程信息
//      在 Linux 中，该信号名与 SIGPWR 信号相同。在 BSD 系统中，键入 CTRL-T 可产生
//      SIGINFO 信号，用于获取前台进程组的状态信息。
// SIGSYS - 无效系统调用
//      如果进程发起的系统调用有误，那么将产生该信号，这意味着系统将进程执行的指令视为
//      一个系统调用陷阱（trap），但相关的系统调用编号却是无效的。
//      SYS_SECCOMP
// SIGUNUSED - 未使用或无效系统调用
//      顾名思义，该信号没有使用。在 Linux 2.4 及其后续版本中，该信号在很多架构中与
//      SIGSYS 信号同义。换言之，尽管信号还保持向后兼容，但信号编号在这些架构中不再处
//      于未使用状态。
// SIGLOST - 未使用或NFS客户端锁丢失
//      Linux 中存在该信号，但并未使用。在其他一些 UNIX 实现中，如果远端 NFS 服务器
//      在崩溃之后重新恢复，而 NFS 客户端却未能重新获得由本地进程所持有的锁，那么 NFS
//      客户端将向这些进程发送此信号，NFS 规范并未对该特性进行标准化。
//
// 信号因某些事件而产生，信号生成后，会于稍后被传递给某个进程，而进程也会采取某些措施来
// 响应信号。在产生和到达期间，信号处于等待（pending）状态。通常，一旦内核接下来要调度
// 进程运行，等待信号会马上送达，或者如果进程正在运行，则会立即传递信号，例如进程向自身
// 发送信号。然而，有时需要确保一段代码不被传递过来的信号打断，此时可以将信号添加到进程
// 的信号掩码中，这样会阻塞该组信号的到达。如果所产生的信号被掩码阻塞，那么信号将保持等
// 待状态，直至稍后将信号从掩码中移除解除阻塞。信号到达后，进程视具体信号执行如下默认操
// 作之一。（一）忽略信号：内核将信号丢弃，信号对进程不产生任何影响，进程不知道曾经出现
// 过该信号。（二）终止（杀死）进程：进程异常终止，而不是因调用 exit() 而发生的正常终
// 止。（三）产生核心转储文件，同时进程终止，核心转储文件包含对进程虚拟内存的镜像，可将
// 其加载到调试器中以检查进程终止时的状态。（四）停止进程，暂停进程的执行。（五）于之前
// 暂停后再度恢复进程的执行。
//
// 除了根据特定信号而采取的默认行为外，程序也能改变信号达到时的响应行为，这也被称为对信
// 号的处置（disposition）设置，程序可以对信号处置设置为：恢复采取默认行为；忽略信号，
// 这适用于默认行为将终止进程的信号；执行信号处理程序。注意，无法将信号处置设置为终止进
// 程或转储核心，除非这时信号的默认行为。效果最为近似的是为信号设置一个处理函数，并在其
// 中调用 exit() 或 abort()。abort() 函数为进程产生一个 SIGABRT 信号，该信号将引发
// 进行转储核心文件并终止。Linux 特有的 /proc/PID/status 文件包含有各种位掩码字段，
// 通过检查这些掩码可以确定进程对信号的处理。例如：cat /proc/521/status
//      Threads:        1
//      SigQ:   0/7579
//      SigPnd: 0000000000000000    线程等待的信号
//      ShdPnd: 0000000000000000    进程等待的信号
//      SigBlk: 0000000000010000    阻塞的信号
//      SigIgn: 0000000000380004    忽略的信号
//      SigCgt: 000000004b817efb    捕获的信号
//      CapInh: 0000000000000000
//      CapPrm: 0000000000000000
//      CapEff: 0000000000000000
//      CapBnd: 000001ffffffffff
//      CapAmb: 0000000000000000
//
// 信号在 UNIX 实现中出现很早，诞生之后又历经变革。在早期实现中，信号在特定场景下有可能
// 会丢失（即没有传递到目标进程）。此外，尽管系统提供了执行关键代码时阻塞信号传递的机制，
// 但阻塞有时不大可靠。BSD4.2 利用所谓可靠信号解决了这些问题，另外还增加了额外的信号来
// shell 的终端控制。System V 后来也为信号增加了可靠语义，但采用的模型与 BSD 无法兼容，
// 这一不兼容性直到 POSIX.1-1990 标准出台后才得以解决，该标准针对可靠信号所采取的规范
// 主要基于 BSD 模型。
//
// UNIX 系统提供了两种方法来改变信号处置：singal() 和 sigaction()。signal() 的行为
// 在不同 UNIX 实现间存在差异，这也意味着对可移植程序，应该使用 sigaction() 系统调用。
// 使用 signal() 无法在不改变信号处置的同时，还能获得当前的信号处理函数，要想做得这一
// 点必须使用 sigaction()。信号处理函数也称为信号捕捉器，是当指定信号传递给进程时将会
// 调用的函数。信号处理函数的调用，可能会随时打断主程序流程：内核代表进程来调用处理函数，
// 当处理函数返回时，主程序会在处理器打断的位置恢复执行。
//
// 虽然信号处理函数几乎可以为所欲为，但一般而言，设计应力求简单。现实的应用程序一般绝不
// 会在信号处理函数中调用 stdio 函数，例如 printf() 会访问全局的标准输出设备，信号的
// 异步中断可能导致输出混乱，甚至对于未安全实现的 printf() 还可能导致程序崩溃或者数据
// 破坏。简单的信号处理函数，将降低引发竞争条件的风险，下面是针对信号处理函数的两种常见
// 设计。（一）信号处理函数设置全局标志变量并退出，主程序对此标志进行周期性检查，一旦置
// 位随即采取相应动作。主程序若因监控一个或多个文件描述符的 IO 状态而无法进行这种周期性
// 检查时，则可令信号处理函数向一专用管道写入一个字节的数据，同时将该管道的读取断置于主
// 程序所监控的文件描述符范围之内。（二）信号处理函数执行某种类型的清理动作，接着终止进
// 程或者使用非本地跳转将栈解开并将控制返回到主程序中的预定位置。
//
// 在执行某信号的处理函数时会阻塞同类信号的传递（除非在调用sigaction时指定了SA_NODEFER  *** 进入信号处理函数之前，内核会自动屏蔽
// 标志。如果在执行处理函数时再次产生同类信号，那么会将该信号标记为零等待状态并在处理函       当前要处理的信号，除非设置了不延迟的
// 数返回之后再进行传递。另外，不会对信号进行排队处理，再执行处理函数期间，如果多次产生       标志（SA_NODEFER）。另外，如果同一个
// 同类信号，那么仍会将其标记为等待状态，但稍后只会传递一次。信号的这种“失踪”方式无疑将       信号处理函数处理多个不同的信号，这个
// 影响对信号处理函数的设计。首先，无法对信号的产生次数进行可靠的计数；其次，在为信号处       处理函数本身在执行时可能被另一个信号
// 理函数编码时可能需要考虑处理同类信号多次产生的情况，例如对 SIGCHLD 信号的处理。           中断。
//
// 参见 signal-safety(7) 获取可在信号处理函数内部安全调用的异步信号安全函数列表。
// https://www.man7.org/linux/man-pages/man7/signal-safety.7.html
//
// 在信号处理函数中，并不是所有系统调用以及库函数均可安全调用，这需要理解函数的两种概念：
// 可重入（reentrant）函数和异步信号安全（async-signal-safe）函数。可重入函数首先需要
// 区分单线程程序和多线程程序，因为多线程程序同一进程可存在多条独立并发的执行逻辑流。多
// 执行线程的概念与使用了信号处理函数的程序也有关联，因为信号处理函数可能会在任意时点异
// 步中断程序的执行，从而在同一个进程中实际形成了两条（即主程序和信号处理函数）独立的虽
// 然不是并发的执行线程。如果同一进程的多条线程可以同时安全地调用某一函数，那么该函数就
// 是可重入的。这里的安全意味着，无论其他线程调用该函数的执行状态如何，函数均可产生预期
// 结果。SUSv3 对可重入函数的定义是：函数由两条或多条线程调用时，即便时交叉执行，其效果
// 也与各线程以任意顺序一次调用时一致。更新全局变量或静态数据的函数可能是不可重入的，只
// 用到本地变量的函数可定是可重入的。如果对函数的两个调用同时试图更新同一个全局变量或数
// 据类型，那么二者很可能会相互干扰并产生不正确的结果。还有一些函数是不可重入的，是因为
// 它们使用了经静态分配的内存来返回信息。此类函数包括 crypt() getpwnam() gethostbyname()
// getservbyname() 等待，如果信号处理函数用到这类函数，那么将会覆盖主程序中上次调用同
// 一函数所返回的信息。将静态数据结构用于内部记账的函数也是不可重入的，最明显的例子是
// stdio 函数 printf() scanf() 等，它们会为缓冲区I/O更新内部数据结构。如果在信号处理
// 函数中调用了 printf()，而主程序又在调用 printf() 或其他 stdio 函数期间遭到信号处理
// 函数的中断，那么有时候就会看到奇怪的输出，甚至导致程序崩溃或者数据破坏。即使未使用不
// 可重入的库函数，可重入问题依然不可忽视，如果信号处理函数和主程序都要更新由程序员自定
// 义的全局性数据，那么对于主程序而言，这种信号处理函数就是不可重入的。
//
// 异步信号安全（async-signal-safe）函数，如果某一函数是可重入的，或者信号处理函数无法
// 将其中断，就称该函数时异步信号安全的。仅当信号处理函数中断了不安全函数的执行，且处理
// 函数本身也调用了这个不安全的函数时，该函数才是异步信号不安全的。换言之，编写信号处理
// 函数有如下两种选择：（一）确保信号处理函数本身是可重入的，并且只调用异步信号安全的函
// 数；（二）当主程序执行不安全函数或是去操作信号处理函数也可能更新的全局数据时，阻塞信
// 号的传递。第二种方法的问题是，在一个复杂程序中，要想确保主程序对不安全函数的调用不被
// 信号处理函数中断，这有些困难。出于这个原因，通常将上述规则简化为在信号处理函数中绝不
// 调用不安全的函数。如果使用同一个处理函数来处理多个不同信号，或者在调用 sigaction()
// 时设置了 SA_NODEFER 标志，那么处理函数就有可能自己中断自己。因此，处理函数如果更新
// 了全局或静态数据，即便主程序不使用这些变量，那么它们依然可能是不可重入的。
//
// 由于可能会更新 errno，线程安全的函数依然会导致信号处理函数不可重入，因为它们可能会
// 覆盖之前由主程序调用函数时所设置的errno值。有一种变通方法，即当信号处理函数使用了这
// 些更新 errno 的函数时，在其入口处保持 errno 值，并在其出口处恢复 errno 的旧值。尽
// 管存在可重入问题，有时仍需要在主程序和信号处理函数之间共享全局变量。信号处理函数可能
// 随时会修改全局变量，只要主程序能够正确处理这种可能性，共享全局变量就是安全的。一种常
// 见的设计是，信号处理函数只做一件事情，设置全局变量，主程序则周期性地检查这一标志，并
// 采取相应动作来响应信号传递同时清除标志。当信号处理函数以此方式来访问全局变量时，应该
// 总是在声明变量时使用 volatile 关键字，从而防止编译器将其优化到寄存器中。对全局变量
// 的读写可能不止一条机器指令，而信号处理函数可能会在这些指令序列之间将主程序中断，也将
// 此类变量访问称为非原子操作。C 语言标准以及 SUSv3 定义了一种整型数据类型 sig_atomic_t，
// 意在保证读写操作的原子性。因此，所有在主程序与信号处理器函数之间共享的全局变量都应
// 声明如下： volatile sig_atomic_t flag; 。注意 C 语言的自增和自减操作并不在 sig_atomic_t
// 的保护范围内。这些操作操作在某些硬件架构上可能不是原子操作，在使用 sig_atomic_t 变
// 量时唯一能做的就是在信号处理函数中进行设置，在主程序中进行检查，反之亦可。C99 和
// SUSv3 规定，实现应当定义两个常量 SIG_ATOMIC_MIN 和 SIG_ATOMIC_MAX （stdint.h），
// 用于规定可赋值给 sig_atomic_t 类型的值范围。标准要求，如果将 sig_atomic_t 表示为
// 有符号值，其范围至少应该在 -127 ~ 127 之间，如果作为无符号值则应该在 0 ~ 255 之间。
// 在 Linux 中，这两个常量分别等于有符号 32 为整数的正负极值。
//
// 目前为止看到的信号处理函数都是以返回主程序而终结，不过只是简单地从信号处理函数返回并   *** 硬件异常：SIGBUS SIGFPE SIGILL SIGSEGV
// 不能满足需要，有时候甚至没什么用处。硬件异常可以产生 SIGBUS、SIGFPE、SIGILL、
// SIGSEGV 信号，调用 kill() 函数来发送此类信号是另一种途径，但较为少见。SUSv3 规定，
// 在硬件异常的情况下，如果进程从此类信号处理函数中返回，亦或进程忽略或阻塞了此类信号，
// 那么进程的行为未定义，原因如下。从信号处理函数返回：假设机器语言指令产生了上述信号之
// 一，并因此而调用了信号处理函数。当从处理函数正常返回后，程序会尝试从其中断处恢复执行，
// 可当作引发信号产生的恰恰正是这条指令，所以信号会再次光临，程序将进入无限循环，重复调
// 用信号处理函数。忽略信号：忽略因硬件而产生的信号于清理不合，试想算术异常之后，程序应
// 当如何继续执行呢？无法明确。当由于硬件异常而产生上述信号之一时，Linux 会强制传递信
// 号，即使程序已经请求忽略此类信号。阻塞信号：与上一种情况一样，阻塞因硬件而产生的信号
// 也不和清理，不清楚程序随后应当如何继续处理。Linux 2.4 以及更早版本中，其内核会将阻
// 塞硬件产生信号的企图一一忽略，信号无论如何都会传递给进程，随后要么进程终止，要么信号
// 被信号函数处理。Linux 2.6 之后，如果信号预定阻塞，那么该信号总是会立刻杀死进程，即
// 使进行已经为此信号设置了处理函数。对于因硬件而产生的信号，Linux 2.6 之所以会改变对
// 其处于阻塞状态下的处理方式，是由于 Linux 2.4 的行为中隐藏有缺陷，并可能在多线程中
// 引起死锁。正确处理硬件产生的信号的方法有：要么接受信号的默认行为，即进程终止；要么为
// 其编写不会正常返回的处理函数。除了正常返回之外，终止处理函数执行的手动包括调用 _exit
// 以终止进程，或者调用 siglongjmp 确保将控制传递回主程序的某一位置（产生信号的指令位
// 置除外）。

// 以下是从信号处理函数中终止的其他方法：
//      1. 使用 _exit() 终止进程，处理函数事先可以做以下清理工作。注意不要使用 exit()
//          来终止信号处理函数，因为他不在安全函数之列。之所以不安全，是因为该函数会在
//          调用 _exit() 之前刷新 stdio 缓冲区。
//      2. 使用 kill() raise() 发送信号来杀掉进程，即信号的默认动作是终止进程。
//      3. 从信号处理函数中执行非本地跳转。
//      4. 使用 abort() 函数终止进程，并产生核心转储文件。函数 abort() 通过产生 SIGABRT
//          信号来终止调用进程。对 SIGABRT 的默认动作是产生核心转储文件并终止进程。调
//          试器可以利用核心转储文件来检测调用 abort() 时的程序状态。SUSv3 要求，无论
//          阻塞或者忽略 SIGABRT 信号，abort() 调用均不受影响。同时规定，除非进程捕获
//          SIGABRT 信息后未从信号处理函数返回，否则 abort() 必须终止进程。（一）abort()
//          函数永远不会返回。（二）abort() 函数首先会清除对 SIGABRT 的屏蔽，然后触发
//          SIGABRT 信号。（三）如果 SIGABRT 被应用程序设置成被忽略，或者被信号处理函
//          数捕获处理之后，abort() 函数将 SIGABRT 设置其默认处理函数，然后再次触发
//          SIGABRT 信号，触发执行默认处理函数终止进程。（四）如果第三步应用程序未更改
//          SIGABRT 信号的处理行为，就会直接调用默认的信号处理函数终止进程。（五）此类
//          进程终止属于异常终止，使用 atexit(3) on_exit(3) 注册的函数不会被执行。
//          （六）在 glibc 2.26 及之前的版本中，如果 abort() 导致进程终止，所有已打开
//          的流都会被关闭并刷新，相当于调用 fclose(3)。然而，这种做法在某些情况下会导
//          致死锁或数据损坏。因此，从 glibc 2.27 开始，abort() 终止进程时不再刷新流。
//          POSIX.1 标准允许这两种行为，指出 abort() “可以尝试对所有已打开的流执行
//          fclose()” —— 即是否刷新由实现决定。
//
// 在信号处理函数里执行非本地跳转。如果使用标准的 longjmp() 函数会存在一个问题，在进入
// 信号处理函数之前，内核会自动将引发调用的信号以及由 act.sa_mask 所指定的任意信号添加
// 到进程的信号掩码中，并在处理函数正常返回时再将它们从掩码中清除。如果使用 Longjmp()
// 退出信号处理函数，那么信号掩码会发生什么情况呢？这取决于特定 UNIX 实现，在 System
// V 一脉中，longjmp() 不会将信号掩码恢复，亦即在离开处理函数时不会对遭阻塞的信号解除
// 阻塞。Linux 遵循 System V 这一特性。这通常并非所希望的行为，因为引发对信号处理函数
// 调用的信号仍将保持阻塞。在源于 BSD 一脉的实现中，setjmp() 将信号掩码保持在 env 参
// 数种，而信号掩码的保存值由 longjmp() 恢复。鉴于两大 UNIX 流派之间的差异，POSIX.1-1990
// 选择不对 setjmp() 和 longjmp() 的信号掩码处理进行规范，而是定义了一对新函数
// sigsetjmp() 和 siglongjmp()，针对执行非本地跳转时的信号掩码进行显式控制。这两个函
// 数都不在异步信号安全函数的范围内，因为与在信号处理函数中调用这些函数一样，在执行非本
// 地跳转之后去调用任何非异步信号安全函数也需要冒同样的风险。此外，如果信号处理函数中断
// 了正在更新数据结构的主程序，那么执行非本地跳转退出处理函数后，这种不完整的更新动作很
// 可能会将数据结构体置于不一致状态。规避这一问题的一种技术是在程序对敏感数据进行更新
// 时，借助于 sigprocmask() 临时将信号阻塞起来。因此 longjmp(3p) 推荐应用程序不要在
// 信号处理函数中调用 longjmp() 和 siglongjmp()。
//
// #include <setjmp.h>
// int sigsetjmp(sigjmp_buf env, int savesigs); // 正常返回0，从longjmp返回val，如果val为0仍然需要返回1
// void siglongjmp(sigjmp_buf env, int val);
//
// typedef struct {
//     sigjmp_buf sigjmp;
//     volatile sig_atomic_t canjmp;
// } prh_sigjmp;
// int prh_sig_setjmp(prh_sigjmp *p) {
//     int longjmp_ret = 0; // SUSv3 不允许在赋值语句种调用 setjmp() 和 sigsetjmp()
//     if (sigsetjmp(p->sigjmp, 1) == 0) {
//         p->canjmp = 1; // 中断可能在设置canjmp或sigsetjmp调用之前发生
//     } else { // 或者在 canjmp=1 之后设置处理函数，保证信号触发时 jmpenv 已初始化
//         longjmp_ret = 1; // 从siglongjmp返回，每次触发信号之后都会重新回到这里，
//     } // 因此调用 prh_sig_setjmp() 之后主程序基本上不能再做任何有用的事情
//     return longjmp_ret;
// }
// prh_sigjmp jmpenv;
// int main(int argc, char **argv) {
//      struct sigaction sa;
//      sigemptyset(&sa.sa_mask);
//      sa.sa_flags = 0;
//      sa.sa_handler = sig_handler;
//      prh_zeroret(sigaction(SIGINT, &sa, prh_null));
//      prh_sig_setjmp(&jmpenv);
//      for (;;) pause(); // 等待信号直到被杀（killed）
// }
// void sig_handler(int sig) {
//      if (jmpenv.canjmp == 0) return;
//      siglongjmp(jmpenv, 1);
// }
//
// 在备选栈中处理信号 sigaltstack()。在调用信号处理函数时，内核通常会在进程栈中为其创
// 建函数帧。不过，如果进程对栈的扩展突破了对栈大小的限制时，这种做法就不大可行。例如，
// 栈的增长过大，以至于会触及到一片映射内存或向上增长的堆，又或者栈的大小以及逼近设置的
// RLIMIT_STACK 资源限制。当进程堆栈的扩展试图突破其上限时，内核将为该进程产生 SIGSEGV
// 信号。不过，因为栈空间已经耗尽，内核也就无法为进程安装的 SIGSEGV 处理函数创建栈帧。
// 结果是，处理函数得不到调用，而进程也就终止了。如果希望在这种情况下确保对 SIGSEGV 信
// 号处理函数的调用，就需要做如下工作。（一）分配一块被称为 “备选信号栈” 的内存区域，作
// 为信号处理器函数的栈帧。（二）调用 sigaltstack() 告之内核该备选信号栈的存在。（三）
// 在创建信号处理函数时指定 SA_ONSTACK 标志，亦即通知内核在备选栈上为处理函数创建栈帧。
// 利用系统调用 sigaltstack() 既可以创建一个备选信号栈，也可以将已创建的备选信号栈的
// 相关信息返回。
//
// #include <signal.h> 成功返回0，失败返回-1和errno，参数sigstack用于设置，old用于获取已设置的信号栈信息
// int sigaltstack(const stack_t *sigstack, stack_t *old_sigstack);
// typedef struct {
//      void *ss_sp; 栈起始地址，在实际使用信号栈时，内核会将 ss_sp 值自动对齐到与硬件架构相适应的地址边界
//      int ss_flags; 标志：SS_ONSTACK SS_DISABLE
//      size_t ss_size; 栈大小
// } stack_t;
//
// 可能的错误：EFAULT 参数 ss 或 old_ss 指向非法地址，EINVAL 参数 ss 不为空并且
// ss_flags 包含非法标志，ENOMEM 指定的 ss_size 小于 MINSIGSTKSZ，EPERM 尝试修改
// 正处于活动状态的备选信号栈，即线程正执行在当前的备选信号栈之上。
//
// 备选信号栈通常既可以静态分配，也可以在堆上动态分配。SUSv3 规定将常量 SIGSTKSZ 作为
// 划分备选栈大小的典型值，而将 MINSIGSTKSZ 作为调用信号处理器函数所需的最小值。在
// LINUX/x86-32 系统上，这两个值分别为 8192 和 2048。如果在获取已创建的备选信号栈的当
// 前信息时 SS_ONSTACK 置位，表明进程正在备选信号栈上执行，这时如果再试图创建一个新的
// 备选信号栈时会产生 EPERM 错误。在 sigstack 中指定，表示禁用当前已创建的备选信号栈，
// 在 old_sigstack 中返回表示不存在已创建的备选信号栈。
//
// 备选信号栈也是属于线程的属性，当信号设置的处置标记了 SA_ONSTACK，并且当前线程定义了
// 备选信号栈，那么会使用这个备选信号栈执行处理函数。
//
// void prh_impl_set_sigsegv_action(void (*sigsegv_handler)(int sig, siginfo_t *siginfo, void *ucontext)) {
//     // SIGSEGV 可能因为进程栈耗尽产生，此时该信号设置的处理函数将无法执行，因为已经没
//     // 有栈空间了，因此需要额外分配一个信号栈，让处理函数在这个新栈上执行。
//     stack_t altstk;
//     altstk.ss_sp = prh_malloc(SIGSTKSZ);
//     altstk.ss_size = SIGSTKSZ;
//     altstk.ss_flags = 0;
//     prh_abort_nz(sigaltstack(&altstk, prh_null)); // 不好的地方，需要为每个线程都创建一个 altstk
//     struct sigaction sa;
//     sigemptyset(&sa.sa_mask);
//     sa.sa_sigaction = sigsegv_handler;
//     sa.sa_flags = SA_ONSTACK | SA_SIGINFO;
//     prh_zeroret(sigaction(SIGSEGV, &sa, prh_null));
// }
//
// 系统调用的中断和重启。考虑如下常量：为某信号创建处理函数；发起一个阻塞式系统调用，例
// 如从终端设备调用 read() 会阻塞到有数据输入为止；当系统调用阻塞时，信号到来中断系统
// 调用，执行信号处理函数。那么信号处理函数返回后会发生什么呢？默认情况下，系统调用失败，
// 并返回 EINTR。不够更为常见的情况是希望遭到中断的系统调用得以继续运行。为此，可在系统
// 调用被中断后返回，利用如下代码来手动重启系统调用：
//      while ((n = read(fd, buf, BUF_SIZE)) == -1 && errno == EINTR)
//          continue;
//      #define NO_EINTR(expr) while ((expr) == -1 && errno == EINTR);
//
// 即使采用了类似 NO_ENTR() 这样的宏，让信号处理函数来中断系统调用还是颇为不便，因为只
// 要有意重启阻塞的调用，就需要为每个阻塞的系统调用添加代码。反之，可以调用指定了
// SA_RESTART 标志的 sigaction() 来创建信号处理函数，从而令内核代表进程自动重启系统
// 调用，还无需处理系统调用可能返回的 EINTR 错误。标志 SA_RESTART 是针对每个信号设置
// 的，换言之允许某些信号处理函数中断阻塞的系统调用，而其他系统调用则可以自动重启。
//
// SA_RESTART 标志对哪些系统调用和库函数有效呢？不幸的是，并非所有的系统调用都可以通过
// 指定 SA_RESTART 来达到重启的目的。究其原因，有部分历史因素。（一）BSD4.2 引入重启
// 系统调用的概念，包括中断对 wait() 和 waitpid() 的调用，以及如下 IO 系统调用 read()
// readv() write() 和阻塞的 ioctl() 操作。IO 系统调用都是可中断的，只有在操作慢速设备
// 时，才可以利用 SA_RESTART 来自动重启调用。慢速设备包括终端、管道、FIFO 以及套接字。
// 相比之下，磁盘文件并不在慢速设备之列，因为借助于缓冲区高速缓存，磁盘IO请求一般都可以
// 立即得到满足。当出现磁盘 IO 请求时，内核会令该进程休眠，直至完成 IO 动作为止。（二）
// 其他大量阻塞的系统调用则继承自 System V，在其初始设计中并未提供重启系统调用的功能。
//
// 在 Linux 中，如果采用 SA_RESTART 标志来创建信号处理函数，则如下阻塞的系统调用以及
// 建构于其上的库函数在遭到中断时是可以自动重启的：
//      1. 等待子进程的系统调用 wait() waitpid() wait3() wait4() waitid()。
//      2. 慢速设备IO系统调用 read() readv() write() writev() ioctl()，如果在收到
//          信号时以及传递了部分数据，那么还是会中断系统调用，但会返回成功，因为已经成
//          功传递了部分数据。
//      3. 系统调用 open()，在可能阻塞的情况下，例如在打开 FIFO 时。
//      4. 用于套接字的各种系统调用 accept() accept4() connect() send() sendmsg()
//          sendto() recv() recvfrom() recvmsg()。在 Linux 中，如果使用 setsockopt
//          来设置超时，这些系统调用不会自动重启，详情参考 signal(7) 手册。
//      5. 对 POSIX 消息队列继续 IO 操作的系统调用 mq_receive() mq_timedreceive()
//          mq_send() mq_timedsend()。
//      6. 用于设置文件锁的系统调用和库函数 flock() fcntl() lockf()。
//      7. Linux 特有系统调用 futex() 的 FUTEX_WAIT 操作。
//      8. 用于递减 POSIX 信号量的 sem_wait() sem_timedwait() 函数，但在内核 2.6.22
//          之前，不管是否设置了 SA_RESTART 标志，futex() sem_wait() sem_timedwait()
//          遭到中断时总是产生 EINTR 错误。
//      9. 用于同步 POSIX 线程的函数 pthread_mutex_lock() pthread_mutex_trylock()
//          pthread_mutex_timedlock() pthread_cond_wait() pthread_cond_timedwait()。
//
// 以下阻塞的系统调用以及构建于其上的库函数，即便指定了 SA_RESTART 也不会自动重启：
//      1. poll() ppoll() select() pselect() 等 IO 多路复用调用，SUSv3 明文规定，
//          无论设置 SA_RESTART 表示与否，都不对 select() pselect() 遭信号处理函数
//          中断时的行为进行定义。
//      2. Linux 特有的 epoll_wait() 和 epoll_pwait() 系统调用。
//      3. Linux 特有的 io_getevents() 系统调用。
//      4. 操作 System V 消息队列和信号量的阻塞系统调用 semop() semtimedop() msgrcv()
//          msgsnd()。虽然 System V 原本并未提供自动启动系统调用的功能，但在某些 UNIX
//          实现上，如果设置了 SA_RESTART 标志，这些系统调用还是会自动重启。
//      5. 对 inotify 文件描述符发起的 read() 调用。
//      6. 用于将进程挂起指定时间的系统调用和库函数 sleep() nanosleep() clock_nanosleep()。
//      7. 特意设计用来等待某一信号到达的系统调用 pause() sigsuspend() sittimedwait()
//          sigwaitinfo()。
//
// #include <signal.h>
// int siginterrupt(int sig, int flag); 成功返回0，错误返回-1和errno
//
// 函数 siginterrupt() 用于改变信号的 SA_RESTART 设置。若参数 flag 为真（1），则针
// 对信号 sig 的处理函数将会中断阻塞的系统调用的执行；如果为假，那么在执行 sig 信号处
// 理函数之后，会自动重启阻塞的系统调用。函数 siginterrupt() 的工作原理是，调用
// sigaction 获取信号当前的处理函数副本，调整 oldact 中的 SA_RESTART 标志，接着再次
// 调用 sigaction 来更新信号处理函数。SUSv4 标记 siginterrupt() 已废止，并推荐使用
// sigaction() 加以替代。
//
// 在 Linux 上，即使没有信号处理函数，某些阻塞的系统调用也会产生 EINTR 错误。如果系统
// 调用遭到阻塞，并且进程因信号 SIGSTOP SIGTSTP SIGTTIN SIGTTOU 而停止，之后又因收
// 到 SIGCONT 信号而恢复执行时，就会发生这种情况。以下系统调用和函数具有这一行为：
// epoll_pwait() epoll_wait()，对 Inotify 文件描述符执行的 read 调用，semop()
// semtimedop() sigtimedwait() sigwaitinfo()。内核 2.6.24 之前，poll() 也曾存在
// 这种行为，2.6.22 之前的 sem_wait() sem_timedwait() futex(FUTEX_WAIT)，2.6.9
// 之前的 msgrcv() msgsnd()，以及 2.4 之前的 nanosleep() 也同样如此。在 2.4 之前，
// 也可以以这种方式中断 sleep()，但是不会返回错误值，而是返回休眠所剩余的秒数。这种行
// 为的结果是，如果程序可能因信号而停止和重启，那么就需要添加代码来重启这些系统调用，即
// 便该程序没有为停止信号设置处理函数。
//
// #include <signal.h> 成功返回0，失败返回-1和errno
// int sigaction(int sig, const struct sigaction *act, struct sigaction *oldact);
// struct sigaction { 该结构可能比这里展示的复杂
//      void (*sa_handler)(int sig); 不要同时设置 sa_handler 和 sa_sigaction
//      void (*sa_sigaction)(int sig, siginfo_t *siginfo, void *ucontext);
//      sigset_t sa_mask; 信号处理函数执行期间需要阻塞的信号集合
//      int sa_flags; 用于控制处理函数调用的标志
//      void (*sa_restorer)(void); 内部实现，外部应用程序不应该使用
// };
//
// glibc 的 sigaction() 包装函数在试图更改 NPTL 线程库（Native POSIX Threads
// Library）内部使用的两个实时信号的处理方式时，会返回 EINVAL，参见 nptl(7) 。在支持
// 信号蹦床（signal trampoline）的架构上，glibc 的 sigaction() 包装函数会把蹦床代码
// （the trampoline code）的地址填入 act.sa_restorer 字段，并在act.sa_flags 中设置
// SA_RESTORER 标志，参见 sigreturn(2)。原始的 Linux 系统调用名为 sigaction()，但
// 随着 Linux 2.2 引入实时信号，旧的固定大小 32 位 sigset_t 已无法满足需求，于是新增
// 了系统调用 rt_sigaction() 来支持更大的 sigset_t。新系统调用增加第四个参数 size_t
// sigsetsize，用于指定 act.sa_mask 和 oldact.sa_mask 中信号集的字节数。当前该参数
// 必须等于 sizeof(sigset_t)，否则返回 EINVAL。glibc 的 sigaction() 包装函数隐藏了
// 这些细节，当内核提供 rt_sigaction() 时，它会透明地调用后者。可将 sigaction() 的第
// 二个参数设为 NULL 来查询当前信号处置；也可把第二和第三个参数都设为 NULL 来检查给定
// 信号在当前机器上是否有效。
//
// 可能错误：EFAULT - act 或者 oldact 执行非法内存，EINVAL - 指定了一个非法的信号，
// 当指定了 SIGKILL 或 SIGSTOP 也会产生这个错误。SIGKILL 和 SIGSTOP 信号不能阻塞、
// 忽略、或设置新的处理函数。无法阻塞 SIGKILL 或 SIGSTOP —— 在 sa_mask 中指定它们会
// 被静默忽略。
//
// sig 是要获取或改变的信号编号，该参数可以是除 SIGKILL 和 SIGSTOP 之外的任何信号。
// act 指向新处理函数的数据结果，如果仅对信号的现有处理函数感兴趣，那么可将该参数设为
// NULL。oldact 用来返回当前信号的处理函数，如果无意获取当前信息，可将该参数设为NULL。
// sa_restorer 字段仅供内部使用，用以确保当信号处理函数完成后，会调用专用的 sigreturn
// 系统调用，借此来恢复进程的指向上下文，以便于进程从信号处理函数中断的位置继续执行。
// POSIX 没有指定该字段，该字段更多信息参考 sigreturn(2)。
//
// sa_handler 指定信号处理函数的地址，亦或是常量 SIG_IGN 或 SIG_DFL，仅当 sa_handler
// 是地址（不是 SIG_IGN SIG_DFL）时，才会对 sa_mask 和 sa_flags 字段加以处理。sa_mask
// 定义了一组信号，在调用由 sa_handler 所定义的处理函数时将阻塞该组信号。这些信号会在
// 处理函数执行之前阻塞，直到信号处理函数返回，将自动清除阻塞。此外，当前引发处理函数调
// 用的信号或自动添加到信号掩码中（在没有设置 SA_NODEFER 的情况下），这意味着当正在执行
// 处理函数时，如果同一信号第二次到达，信号处理函数将不会递归中断自己。但由于不会对遭阻
// 塞的信号进行排队，如果在处理函数执行过程中重复产生这些信号中的任何信号，稍后对信号的
// 传递都是一次性的。
//
// POSIX.1-1990 禁止将 SIGCHLD 的动作设为 SIG_IGN；POSIX.1-2001 及以后则允许这样做，
// 以便通过忽略 SIGCHLD 防止僵尸进程产生，见 wait(2)。然而，历史 BSD 与 System V 对
// 忽略 SIGCHLD 的行为并不一致，因此唯一完全可移植的确保子进程不变成僵尸的方法是：捕获
// SIGCHLD 并在处理函数中调用 wait(2) 或类似函数。POSIX.1-1990 只规定了 SA_NOCLDSTOP，
// POSIX.1-2001 增加了 SA_NOCLDWAIT、SA_NODEFER、SA_ONSTACK、SA_RESETHAND、
// SA_RESTART 和 SA_SIGINFO 作为 XSI 扩展。POSIX.1-2008 把 SA_NODEFER、SA_RESETHAND、
// SA_RESTART 和 SA_SIGINFO 移入基础标准。在面向旧版 UNIX 的程序中使用这些标志可能降
// 低可移植性。SA_RESETHAND 与 SVr4 同名标志兼容。SA_NODEFER 与 SVr4 同名标志在 1.3.9
// 及之后的内核兼容，旧内核允许接收任何信号，而不仅仅是正在安装的信号（即会覆盖任何
// sa_mask 设置）。
//
// 由 fork(2) 创建的子进程会继承父进程信号处置的拷贝。在 execve(2) 执行期间，已处理的
// 信号处置会被重置为默认；被忽略信号的处置保持不变。根据 POSIX，如果进程忽略一个并非由
// kill(2) 或 raise(3) 产生的 SIGFPE、SIGILL 或 SIGSEGV，其行为未定义（即忽略一个硬
// 件信号的行为是未定义的）。整数除以 0 的结果未定义，某些架构会生成 SIGFPE（同样，最小
// 负整数除以 -1 也可能产生 SIGFPE），忽略该信号可能导致代码死循环。
//
// sa_flags 用于控制信号处理函数执行的各种选项：
//      SA_NOCLDSTOP - 仅当信号为 SIGCHLD 时有效。若设置此标志，当子进程暂停（收到
//          SIGSTOP、SIGTSTP、SIGTTIN 或 SIGTTOU）或继续执行（收到 SIGCONT）时，不
//          会产生 SIGCHLD 信号通知父进程，参见 wait(2)。
//      SA_NOCLDWAIT（Linux 2.6）- 仅当信号为 SIGCHLD 时有效。若设置此标志，子进程
//          终止时不会变成僵尸进程，参见 waitpid(2)。此标志适用于为 SIGCHLD 建立信号
//          处理函数，或将 SIGCHLD 的处理方式设为 SIG_DFL 的情况。POSIX.1 未明确规定：
//          若在为 SIGCHLD 设置处理函数时启用 SA_NOCLDWAIT，子进程终止时是否仍会产生
//          SIGCHLD 信号。在 Linux 上仍会生成该信号；而其他一些实现则不会。
//      SA_NODEFER - 在信号处理函数执行期间，不自动阻塞该信号，除非该信号已显式包含在
//          act.sa_mask 中。因此，同一信号可能在处理函数执行期间再次递达。此标志仅在为
//          信号建立处理函数时有效。SA_NOMASK 是此标志的过时、非标准别名。
//      SA_ONSTACK - 由 sigaltstack(2) 提供的替代信号栈上调用信号处理函数。若无替代
//          栈可用，则使用默认栈。此标志仅在为信号建立处理函数时有效。
//      SA_RESETHAND - 信号处理函数被调用前，自动将该信号的处理方式恢复为默认行为。此
//          标志仅在为信号建立处理函数时有效。SA_ONESHOT 是此标志的过时、非标准别名。
//      SA_RESTART - 使某些被信号中断的系统调用自动重启，以兼容 BSD 信号语义。此标志
//          仅在为信号建立处理函数时有效。详见 signal(7) 中关于系统调用重启的讨论。
//      SA_RESTORER - 不供应用程序使用。C 库利用此标志表明 sa_restorer 字段包含 “信
//          号蹦床”（signal trampoline）的地址。详见 sigreturn(2)。
//      SA_SIGINFO（Linux 2.2）- 指定信号处理函数接收三个参数（而非默认的一个参数）。
//          此时应使用 sa_sigaction 字段而非 sa_handler。此标志仅在为信号建立处理函
//          数时有效。
//      SA_UNSUPPORTED（Linux 5.11）- 用于动态探测标志位支持情况。若注册处理函数时设
//          置此标志，并同时包含其他可能不被内核支持的标志位，则可通过后续 sigaction()
//          调用的 oldact->sa_flags 判断哪些标志位实际支持。
//      SA_EXPOSE_TAGBITS（Linux 5.11）- 默认情况下，信号递交时，siginfo_t 的
//          si_addr 字段中的架构相关标签位（tag bits）会被清除。若设置此标志，则会保
//          留架构特定的部分标签位。若程序需兼容早于 5.11 的 Linux 版本，必须使用
//          SA_UNSUPPORTED 探测此标志的支持情况。
//      动态探测标志位支持：Linux 的 sigaction() 调用接受在 act->sa_flags 中设置未
//      知标志位而不报错。自 Linux 5.11 起，内核的行为是：第二次 sigaction() 调用会
//      把 oldact->sa_flags 中的未知位清零，即第二次调用 sigaction() 获取已经设置的
//      处理函数信息，返回的标志位会清除那些不支持的标记。然而，历史上第二次 sigaction()
//      调用通常会保留这些未知位。因此，不能仅通过检测 sa_flags 中是否存在某个标志位来
//      判断新标志是否受支持；程序必须先确认 SA_UNSUPPORTED 已被清零，然后才能依赖
//      sa_flags 的内容。由于除非检测通过，否则无法保证信号处理函数的行为正确，因此明智
//      的做法是：在注册处理函数并执行检测时阻塞受影响的信号；若无法阻塞（例如信号是同步
//      的），则在信号处理函数内部执行第二次 sigaction() 调用执行检查。
//      对于不支持某个特定标志的内核，即使 act->sa_flags 中设置了该标志，内核也会表现
//      得如同该标志未被设置一样。标志 SA_NOCLDSTOP、SA_NOCLDWAIT、SA_SIGINFO、
//      SA_ONSTACK、SA_RESTART、SA_NODEFER、SA_RESETHAND 以及 SA_RESTORER（若架构
//      有定义）可能无法可靠地用此机制探测，因为它们在 Linux 5.11 之前就已引入。但一般
//      来说，程序可以假定这些标志受支持，因为它们自 2003 年发布的 Linux 2.6 起就已被
//      实现。
//
// 当使用 sigaction() 建立信号处理函数并设置 SA_SIGINFO 标志时，处理函数有三个参数：
//      void handler(int sig, siginfo_t *info, void *ucontext);
// sig - 触发本次信号处理函数调用的信号编号。
// ucontext - 指向 ucontext_t 结构的指针（被强制转换为 void *）。该结构由内核保存在
//      用户态栈中，用于记录信号发生时的上下文信息；详情参见 sigreturn(2)。关于
//      ucontext_t 的进一步说明可参考 getcontext(3) 和 signal(7)。通常情况下，信号
//      处理函数并不会使用这个参数。
//      https://www.man7.org/linux/man-pages/man3/getcontext.3.html
//      https://www.man7.org/linux/man-pages/man3/makecontext.3.html
//      该结构提供了所谓的用户上下文信息，描述调用信号处理函数前的进程状态。使用该结构
//      的其他函数有 getcontext() setcontext() makecontext() swapcontext() 分别
//      允许进程去获取、改变、创建、交换执行上下文。可以使用这些函数来实现协程，令进程
//      的执行线程在两个或多个函数之间交替。SUSv3 规定了这些函数，但将他们标记为已废
//      止。SUSv4 则将其删去，并建议使用 POSIX 线程来重写旧有的应用程序。
// info - 指向 siginfo_t 结构的指针，该结构包含关于信号的更多详细信息：
//      siginfo_t { 所有信号都定义了前三个字段，其他字段可能是联合体字段，需在特定情况下使用
//      int      si_signo;     信号编码，所有信号都定义了前三个字段
//      int      si_errno;     若信号由某次失败的系统调用触发，则存放对应的 errno；否则为 0（Linux 下基本不用）
//      int      si_code;      产生信号的原因代码，告诉 SA_SIGINFO 信号处理函数“这条信号为什么产生”
//      int      si_trapno;    /* Trap number that caused hardware-generated signal (unused on most architectures) */ 部分架构上硬件异常对应的陷阱号，大多数平台忽略
//      pid_t    si_pid;       /* Sending process ID */
//      uid_t    si_uid;       /* Real user ID of sending process */
//      int      si_status;    /* Exit value or signal */
//      clock_t  si_utime;     /* User time consumed */
//      clock_t  si_stime;     /* System time consumed */
//      union sigval si_value; /* Signal value */
//      int      si_int;       /* POSIX.1b signal */
//      void    *si_ptr;       /* POSIX.1b signal */
//      int      si_overrun;   /* Timer overrun count; POSIX.1b timers */
//      int      si_timerid;   /* Timer ID; POSIX.1b timers */
//      void    *si_addr;      /* Memory location which caused fault */
//      long     si_band;      /* Band event (was int in glibc 2.3.2 and earlier) */
//      int      si_fd;        /* File descriptor */
//      short    si_addr_lsb;  /* Least significant bit of address (since Linux 2.6.32) */
//      void    *si_lower;     /* Lower bound when address violation occurred (since Linux 3.19) */
//      void    *si_upper;     /* Upper bound when address violation occurred (since Linux 3.19) */
//      int      si_pkey;      /* Protection key on PTE that caused fault (since Linux 4.6) */
//      void    *si_call_addr; /* Address of system call instruction (since Linux 3.5) */
//      int      si_syscall;   /* Number of attempted system call (since Linux 3.5) */
//      unsigned int si_arch;  /* Architecture of attempted system call (since Linux 3.5) */
//      }
//  使用 kill(2) 或 sigqueue(3) 发送的信号会填充 si_pid（发送进程的 PID）和 si_uid
// （发送进程的真实 UID）。此外，由 sigqueue(3) 发送的信号还会把发送方指定的整数值或指
// 针值分别写入 si_int 和 si_ptr；详见 sigqueue(3)。
//      信号来源                有效字段
//      kill(2)                 si_pid si_uid
//      sigqueue(3)             si_pid si_uid si_int/si_ptr
// 由 POSIX.1b 定时器（Linux 2.6 起）发出的信号会填充 si_overrun 和 si_timerid。
// si_timerid 是内核内部用来标识该定时器的 ID，它不等于 timer_create(2) 返回的定时
// 器 ID。si_overrun 给出定时器的 overrun 计数，与调用 timer_getoverrun(2) 得到的
// 信息相同。这两个字段是 Linux 特有的非标准扩展。
//      信号来源             有效字段（这两个字段 Linux 特有）
//      POSIX.1b定时器       si_overrun 定时器超期计数
//                          si_timerid 内核内部定时器
// 用于消息队列通知，参见 mq_notify(3) 中对 SIGEV_SIGNAL 的说明。
//      si_int/si_ptr       保存调用 mq_notify(3) 时给出的 sigev_value
//      si_pid              消息发送进程的进程ID
//      si_uid              消息发送者的真实用户ID
// SIGCHLD 会填充 si_pid、si_uid、si_status、si_utime 和 si_stime，提供关于子进程
// 的信息。字段 si_utime、si_stime 不包含用于等待子进程的时间，与 getrusage(2)、
// times(2) 不同。在 Linux 2.6 之前以及 Linux 2.6.27 之后，时间单位为
// sysconf(_SC_CLK_TCK)；在 Linux 2.6 至 2.6.27 之间因 bug 使用了可由用户配置的
// system jiffy，见 time(7)。
//      si_pid              子进程的 PID
//      si_uid              子进程的真实 UID
//      si_status           若 si_code 为 CLD_EXITED，则为子进程退出码；否则为导致状态改变的信号编号
//      si_utime si_stime   子进程消耗的用户态/内核态 CPU 时间
// SIGILL、SIGFPE、SIGSEGV、SIGBUS 和 SIGTRAP 会填充 si_addr，给出发生错误的地址。
// 在某些架构上，这些信号还会填充 si_trapno。对于 SIGBUS 的子错误 BUS_MCEERR_AO 和
// BUS_MCEERR_AR，还会填充 si_addr_lsb，表示出错地址的最低有效位，从而指示损坏范围；
// 例如整页损坏时，si_addr_lsb = log2(sysconf(_SC_PAGESIZE))。当 SIGTRAP 由 ptrace(2)
// 事件 (PTRACE_EVENT_foo) 触发时，si_addr 不会被填充，但 si_pid 和 si_uid 会给出
// 触发该事件的进程 PID 与 UID；若由 seccomp(2) 触发，则显示的是被跟踪进程（tracee）。
// BUS_MCEERR_* 和 si_addr_lsb 均为 Linux 特有扩展。
//      SIGILL              si_addr 非法指令地址
//      SIGFPE              si_addr 算术异常指令的地址
//      SIGSEGV             si_addr 页故障的地址, SEGV_BNDERR si_lower si_upper 给出越界地址，SEGV_PKUERR si_pkey 触发错误的内存保护键
//      SIGBUS              si_addr 产生内存访问错误的地址，BUS_MCEERR_AO BUS_MCEERR_AR si_addr_lsb 表示损坏粒度（位掩码）即出错地址的最低有效位
//      SIGTRAP             si_addr 断点/陷阱地址
//                          ptrace(2) si_pid si_uid 发送该事件的进程 PID 和 UID，不会指定 si_addr
//                          seccomp(2) si_pid si_uid 被跟踪进程的 PID 和 UID
// SIGIO/SIGPOLL（Linux 上两者等价）会填充 si_band 和 si_fd。
//      si_band             与 poll(2) 的 revents 字段相同的位掩码
//      si_fd               发生 I/O 事件的文件描述符，详见 fcntl(2) 中对 F_SETSIG 的说明
// SIGSYS（Linux 3.5 起） 无效系统调用，当 seccomp 过滤器返回 SECOMP_RET_TRAP 时产
// 生，会填充 si_call_addr、si_syscall、si_arch、si_errno 等字段，具体描述见
// seccomp(2)。
//      si_call_addr        触发 seccomp 违规的系统调用指令地址
//      si_syscall          尝试的系统调用编号
//      si_arch             系统调用架构编号
//      si_errno            seccomp 返回的 SECCOMP_RET_TRAP 错误码
//
// siginfo_t 中的 si_code 是一个数值（不是位掩码），用来告诉 SA_SIGINFO 信号处理函数
// “该信号为什么产生”。对于 ptrace(2) 产生的事件，此时 si_code 的值为
//      (SIGTRAP | PTRACE_EVENT_foo << 8)
// 即低字节是 SIGTRAP，高字节存放 ptrace 事件编号。对于非 ptrace(2) 事件下面按信号类
// 别列出 si_code 可能取到的宏值及其含义。自 glibc 2.20 起，只要在包含任何头文件之前
// 定义下列任一宏，即可从 <signal.h> 获得这些符号定义。但对于 TRAP_* 常量，仅前两条定
// 义方式可用，glibc 2.20 之前则无需任何特性测试宏即可使用。
//      _XOPEN_SOURCE >= 500
//      _XOPEN_SOURCE 与 _XOPEN_SOURCE_EXTENDED 同时定义
//      _POSIX_C_SOURCE >= 200809L
// 对于一般信号，si_code 可以是以下值，用来表明信号产生的来源：
//      SI_USER         用户空间触发的信号，由 kill(2) 或 raise(2) 调用进程发起，其他有效字段 si_pid si_uid
//      SI_KERNEL       由内核发起的信号
//      SI_QUEUE        sigqueue(3)，其他有效字段 si_pid si_uid si_int/si_ptr
//      SI_TIMER        POSIX 定时器、或 setitimer(2)/alarm(2) 超时
//                      POSIX 仅保证由 timer_create(2) 创建的信号会携带 SI_TIMER；实现可对其他类型的定时器也提供该值。Linux 的行为与 NetBSD 一致。
//      SI_MESGQ        POSIX 消息队列状态变化（Linux 2.6.6）
//      SI_ASYNCIO      异步 I/O （AIO）操作已经完成
//      SI_SIGIO        入队 SIGIO（仅 Linux 2.2 及以前；2.4 改用 SIGIO/SIGPOLL 专用代码）
//      SI_TKILL        tkill(2) 或 tgkill(2)（Linux 2.4.19）
// 非法指令（SIGILL）信号的 si_code 参数，另外 si_addr 字段指出非法指令的地址:
//      ILL_ILLOPC      非法操作码
//      ILL_ILLOPN      非法操作数
//      ILL_ILLADR      非法寻址方式
//      ILL_ILLTRP      非法陷阱
//      ILL_PRVOPC      特权操作码
//      ILL_PRVREG      特权寄存器
//      ILL_COPROC      协处理器错误
//      ILL_BADSTK      内部栈错误
// 算术异常（SIGFPE）信号的 si_code 参数，另外 si_addr 字段指出算术异常指令的地址：
//      FPE_INTDIV      整数除以 0
//      FPE_INTOVF      整数溢出
//      FPE_FLTDIV      浮点除以 0
//      FPE_FLTOVF      浮点溢出
//      FPE_FLTUND      浮点下溢
//      FPE_FLTRES      浮点结果不精确
//      FPE_FLTINV      浮点无效操作
//      FPE_FLTSUB      下标越界
// 段错误或页面非法访问（SIGSEGV）信号的 si_code 参数，另外 si_addr 字段指出对应的非法地址：
//      SEGV_MAPERR     地址未映射
//      SEGV_ACCERR     映射对象权限不符
//      SEGV_BNDERR     地址边界检查失败（Linux 3.19），越界地址范围 si_lower si_upper
//      SEGV_PKUERR     内存保护键拒绝访问，参见 pkeys(7)（Linux 4.6），应用在本次访问上的内存保护键通过 si_pkey 字段给出
// 总线或内存访问错误（SIGBUS）信号的 si_code 参数，另外 si_addr 字段指出当前导致内存访问错误的地址：
//      BUS_ADRALN      地址未对齐
//      BUS_ADRERR      物理地址不存在
//      BUS_OBJERR      对象特定的硬件错误
//      BUS_MCEERR_AR   硬件内存校验错误已消耗，需处理，内核已无法恢复数据完整性，程序捕获异常后只能退出进程（Linux 2.6.32）
//      BUS_MCEERR_AO   检测到进程中的硬件内存校验错误但未消耗，可选处理，内核不会立即杀死进程而是把错误标记到页表，允许程序选择是否继续运行（Linux 2.6.32）
// 跟踪或断点陷阱（SIGTRAP）信号的 si_code 参数，另外 si_addr 字段指出触发陷阱的指令地址：
//      TRAP_BRKPT       进程断点
//      TRAP_TRACE       进程跟踪陷阱
//      TRAP_BRANCH      进程分支陷阱（IA64 only，Linux 2.4）
//      TRAP_HWBKPT      硬件断点/观察点（IA64 only，Linux 2.4）
// 对于 ptrace(2) 事件产生的跟踪陷阱（SIGTRAP）信号，没有指定 si_addr 字段：
//      si_code         ((PTRACE_EVENT_foo << 8) | SIGTRAP)
//      si_pid          触发陷阱的进程ID
//      si_uid          触发陷阱的真实用户ID
// 子进程状态变化（SIGCHLD）信号的 si_code 参数，其他表示子进程信息的有效字段 si_pid si_uid si_utime si_stime：
//      CLD_EXITED       子进程正常退出，字段 si_status 表示退出状态，在其他原因中是导致子进程状态变化的信号编号
//      CLD_KILLED       子进程被信号杀死
//      CLD_DUMPED       子进程异常终止并产生核心转储文件
//      CLD_TRAPPED      被跟踪的子进程进入陷阱
//      CLD_STOPPED      子进程停止
//      CLD_CONTINUED    停止的子进程继续（Linux 2.6.9）
// 输入输出事件（SIGIO/SIGPOLL）信号的 si_code 参数，其他有效字段 si_band si_fd：
//      POLL_IN         数据可读
//      POLL_OUT        缓冲区可写
//      POLL_MSG        输入消息到达
//      POLL_ERR        I/O 错误
//      POLL_PRI        高优先级输入
//      POLL_HUP        设备挂断或断开
// 无效系统调用（SIGSYS）信号的 si_code 参数，其他有效字段 si_call_addr si_syscall si_arch si_errno：
//      SYS_SECCOMP     由 seccomp 过滤器规则触发（Linux 3.5）
//
// 未文档化特性：在引入 SA_SIGINFO 之前，可通过为 sa_handler 提供第二个参数 struct
// sigcontext 来获取信号附加信息；该结构与 ucontext->uc_mcontext 中的结构相同。详情
// 见相关 Linux 内核源码，此用法现已废弃。
//
// 当内核向 SA_SIGINFO 处理函数递交由硬件异常引起的信号时，并不总是为 siginfo_t 的所
// 有相关字段提供有意义的值。例如，在 x86 上用非法参数调用 int 指令（除 3 或 128 以外
// 的任何数）会触发 SIGSEGV，但传给信号处理函数的 siginfo_t 除 si_signo 和 si_code
// 外全为 0，尽管其他字段（例如 si_addr）本应被设置。在 Linux 2.6.13 及之前版本中，若
// 在 sa_flags 中指定 SA_NODEFER，不延迟传递信号即立即触发信号，不仅不会阻塞当前递送的
// 信号，也不会阻塞 sa_mask 中指定的信号。该缺陷在 Linux 2.6.14 修复。
//
// 实时信号。定义于 POSIX.1b 中的实时信号，意在弥补对标准信号的诸多限制。较之于标准信
// 号，实时信号的优势如下。（一）实时信号的信号范围有所扩大，可用于应用程序自定义目的，
// 而标准信号中可供应用程序随意使用的信号仅两个 SIGUSR1 和 SIGUSR2。（二）对实时信号
// 所采取的队列化管理，如果将某一实时信号的多个实例发送给一个进程，那么信号将会传递多
// 次。（三）当发送一个实时信号时，可为信号指定伴随数据，一个整型或指针值，供接收进程
// 的信号处理函数处理。（四）不同实时信号的传递顺序得到保障，如果有多个不同的实时信号
// 处于等待状态，那么将率先传递具有最小编号的信号，换言之信号的编号越小其优先级越高。
// 如果时同一类型的多个信号在排队，那么信号的传递顺序与信号触发的顺序保持一致。
//
// SUSv3 要求，实现所提供的各种实时信号不得少于 _POSIX_RTSIG_MAX 个，Linux 内核定义
// 了 32 个不同的实时信号，编号范围为 32~63。头文件 signal.h 定义的 RTSIG_MAX 表示
// 实时信号的可用数量，SIGRTMIN 和 SIGRTMAX 表示可用实时信号编号的最小值和最大值。
// 采用 LinuxThreads 线程实现的系统将 SIGRTMIN 定义为 35，这是因为 LinuxThreads 内
// 部使用了前三个实时信号，而采用 NPTL 线程实现的系统将 SIGRTMIN 定义为 34，因为 NPTL
// 内部使用了两个实时信号。
//
// 对实时信号的区分方式有别于标准信号，不再依赖所定义常量。然而，程序不应将实时信号编号
// 的整数值在应用程序代码中写死，因为实时信号的范围因 UNIX 实现的不同而各异。与之相反，
// 指代实时信号编号可以采用 SIGRTMIN+x 的形式。注意 SUSv3 并未要求 SIGRTMIN 和
// SIGRTMAX 定义为简单的整数值，可以将其定义为函数，就像 Linux 一样。
//
// 排队的实时信号需要内核维护相应的数据结构，由于这些数据结构会消耗内核内存，故而内核对
// 排队实时信号的数量设置了限制。SUSv3 允许实现为每个进程可排队的各类实时信号数量设置
// 上限，并要求其下限不得少于 _POSIX_SIGQUEUE_MAX，sysconf(_SC_SIGQUEUE_MAX) 也能
// 获得这一信息。从 Linux 2.6.8 开始，使用资源限制 RLIMIT_SIGPENDING 来限制，针对
// 某个特定实际用户 ID 下辖的所有进程可排队的实时信号总数。sysconf() 从 glibc2.10 开
// 始返回 RLIMIT_SIGPENDING 对应的限制值，至于正在等待某一进程的实时信号数量，可从
// Linux 专用文件 /proc/PID/status 中的 SigQ 字段获取。
//
// 为了能让一对进程收发实时信号，SUSv3 规定：（一）发送进程使用 sigqueue() 系统调用
// 来发送信号及其伴随数据。使用 kill() killpg() raise() 也能发送实时信号，然而至于
// 系统是否会对信号进行排队处理，SUSv3 中规定由具体实现决定。这些接口在 Linux 中会对
// 实时信号进行排队，但在其他许多 UNIX 实现中则不然。（二）要为该信号建立一个处理函数，
// 接收进程应以 SA_SIGINFO 标志发起 sigaction() 调用，从而能够获取伴随数据。在 Linux
// 中，即使接收进程在建立信号处理函数时并未指定 SA_SIGINFO，也能对实时信号进行排队，
// 但在这种情况下，将不可能获得信号的伴随数据。然而，SUSv3 也不要求实现确保这一行为，
// 所以依赖这一点将有损于应用的可移植性。
//
// #include <signal.h>
// int sigqueue(pid_t pid, int sig, const union sigval value);
// union sigval {
//      int sival_int;
//      void *sival_ptr;
// };
//
// 使用 sigqueue() 发送信号所需要的权限与 kill() 的要求一致，也可以发送空信号，信号
// 0，其语义与 kill() 中的含义相同。不同于 kill()，sigqueue() 不能通过将 pid 指定
// 为负值向整个进程组发送信号。一旦触及对排队信号的数量限制，sigqueue() 调用会失败，
// 并将 errno 置为 EAGAIN，以示需要再次发送信号，即在当前队列中某个信号传递之后的某一
// 时间点。
//
// https://www.man7.org/linux/man-pages/man2/kill.2.html
// https://www.man7.org/linux/man-pages/man3/kill.3p.html
// #include <signal.h>
// int kill(pid_t pid, int sig); 成功返回0，失败返回-1和errno，EINVAL 非法信号 EPERM 没有权限 ESRCH 进程或进程组不存在
// int killpg(pid_t pgrp, int sig); EINVAL 非法信号 EPERM 没有权限 ESRCH 进程组不存在或者pgrp为零但当前进程没有所属进程组
// int raise(int sig); 向进程自身发送信号，返回0成功，非零表示失败。
//
// 一个进程可以使用 kill() 系统调用向另一个进程发送信号，之所以称为 kill 是因为早期
// UNIX 实现中大多数信号默认行为是终止进程。pid 参数可以标识一个或多个目标进程。
//  1.  如果 pid 大于 0，那么将信号发送给 pid 指定的进程。POSIX.1 规定，若线程向自身
//      发送信号，且该线程未阻塞该信号，且没有其他线程解除阻塞或在 sigwait(3) 中等待，
//      其他线程不会抢掉该信号，则在 kill() 返回前，必须至少向该线程交付一个未阻塞的
//      该信号。
//  2.  如果 pid 等于 0，那么会将信号发送给与调用进程同组的每个进程，包括调用进程本身。
//  3.  如果 pid 等于 -1，那么调用进程会向拥有权限的任何进程发送该信号，除了init进程
//      （进程ID为1）和调用进程自身之外。SUSv3 并未要求将调用进程排除在信号接收范围之
//      外，Linux 此处所遵循的是 BSD 语义。POSIX.1 要求 kill(-1, sig) 向所有有权发
//      送信号的进程发送信号，但可排除某些实现定义的系统进程。Linux 允许向自身发信号，
//      但 kill(-1, sig) 不会向调用进程自身发送信号。显而易见，这种信号发送方式也称为
//      广播信号。
//  4.  如果 pid 小于 -1，那么会向组ID为(-pid)的所有进程发送该信号，向一个进程组的所
//      有进程发送信号在 shell 作业控制中有特殊用途。Linux 2.6 至 2.6.7 存在缺陷：当
//      向进程组发送信号时，若调用者对进程组中任一成员无权限，则 kill() 会错误地返回
//      EPERM，尽管信号仍被成功递送到有权限的进程。
//
// 进程要发送信号给另一进程，还需要适当的权限：
//  1.  特权级（在 Linux 上拥有 CAP_KILL 能力）进程可以向任何进程发送信号。
//  2.  以root用户和组运行的init进程，是一种特例，仅能接收已安装了处理函数的信号，这可
//      防止系统管理员意外杀死 init 进程。
//  3.  如果发送者的实际或有效用户ID与接收进程的实际用户ID或者保持设置用户（saved set-user-id）
//      匹配，那么非特权进程也可以向另一进程发送信号。利用这一规则，用户可以向由他们启
//      动的 set-user-id 程序发送信号，而无需考虑目标进程有效用户ID的当前设置。将目标
//      进程有效用户ID排除在检查范围之外，这一举措的辅助作用在于防止用户A向用户B的进程
//      发送信号，而该进程正在执行的 set-user-id 程序又属于用户A。SUSv3 要求强制执行
//      该规则，但 kill(2) 手册描述，Linux 内核在 2.0 版本之前所遵循的规则略有不同。
//  4.  SIGCONT 信号需要特殊处理，无论对用ID的检查结果如何，非特权进程可以向同一会话中的
//      任何其他进程发送这一信息。利用这一规则，运行作业控制的 shell 可以重启已停止的
//      作业（进程组），即使作业进程已经修改了它们的用户ID（例如使用系统调用改变其凭据
//      成为特权级进程）。
//  Linux 对非特权进程向另一进程发送信号所需的权限规则曾数次变化：
//      Linux 1.0 – 1.2.2：只要发送方的有效用户 ID 等于目标进程的有效用户 ID，或发送
//      方的真实用户 ID 等于目标进程的真实用户 ID，即可发送信号。
//      Linux 1.2.3 – 1.3.77：只要发送方的有效用户 ID 与目标进程的真实或有效用户 ID
//      之一匹配，即可发送信号。
//      Linux 1.3.78 起：采用与 POSIX.1 一致的规则。
//
// 如果并无进程与指定的 pid 相匹配，那么 kill() 调用失败，同时将 errno 设置为 ESRCH。
// 如果进程无权发送信号给所请求的 pid，那么调用会失败，errno 为 EPERM。若 pid 表示一系
// 列进程（即为负值时），只要可以向其中之一发送信号，kill() 就会返回成功。
//
// 如果将参数 sig 指定为 0，即空信号，则无信号发送。相反，kill() 仅会去执行错误检查，
// 查看是否可以向目标进程发送信号。从另一角度来看，这意味着，可以使用空信号来检测具有特
// 定 pid 的进程是否存在。若 ESRCH 则表明目标进程不存在，若 EPERM 则表示进程存在但无
// 权向该进程发送信号。特定进程ID存在并不能保证特定进程仍在运行。因为内核会随着进程的生
// 灭而循环使用进程ID，一段时间之后同一进程ID所指向的可能是另一新的进程。此外，特定进程
// ID 存在，但可能是一个僵尸进程，即进程已死但其父进程尚未执行wait()来获取其终止状态。
// 还可使用其他技术来检查某一特定进程是否正在运行：
//  1.  wait() 系统调用，仅用于监控调用者的子进程。
//  2.  信号量和独占文件锁，如果进程持续持有某一信号或文件锁，并且一直处于被监控状态，
//      那么如能获取到信号量或锁时，即表明该进程已经终止。
//  3.  诸如管道和 FIFO 之类的 IPC 通道，可对监控目标进程进行设置，令其在自身生命周期
//      内持有对通道进行写操作的打开文件描述符。同时，令监控进程持有针对通道进程读操作
//      的打开文件描述符，且当通道写入段关闭时即可获知目标进程已经关闭。
//  4.  例如进程ID为 12345 的进行存在，那么目录 /proc/12345 将存在，可以使用如 stat
//      之类的系统调用来进行检查。但这一技术，会受进程ID值的循环使用影响。
//
// raise() 向进程自身发送信号。单线程程序中相当于调用 kill(getpid(), sig)，多线程程
// 序中相当于 pthread_kill(pthread_self(), isg)，即将信号发送给当前进程中的当前线程。
// 相比之下，kill(getpid(), sig) 将发送一个信号给当前进程，并可将该信号传递给该进程的
// 任一线程。当进程使用 raise() 或者 kill() 向自身发送信号时，信号将立即传递，即信号处
// 理函数在 raise() 返回给调用者之前执行。Linux 上，glibc 在 2.3.3 版本之后，如果内
// 核提供 tgkill(2) 系统调用，给特定线程发送信号，那么 raise() 将使用 tgkill(2) 进行
// 实现；而旧版本将使用 kill(2) 实现。
//
// killpg() 可以向某一进程组的所有进程发送一个信号。killpg(pg, sig) 调用相当于
// kill(-pg, sig)。如果指定 pg 的值为0，那么会向调用所属进程组的所有进程发送此信号，
// SUSv3 对此未作规范，但大多数 UNIX实现对该情况的处理方式与 Linux 相同。POSIX 规定，
// 如果 pg 小于等于 1，那么 killpg() 的行为未定义。在 BSD 类型的系统与 System V 类型
// 的系统中，权限检查存在多种差异，详见 POSIX 对 kill(3p) 的说明。POSIX 未提及的一个
// 差异是：BSD 规定只要至少有一个目标进程权限检查失败，就不发送任何信号并返回 EPERM；
// 而 POSIX 只有所有目标进程权限检查都失败时才返回 EPERM。
//
// #include <signal.h>
// #include <string.h>
// char *strsignal(int sig);
// const char *sigdescr_np(int sig); 字符串信息不进行本地化
// void psignal(int sig, const char *s);
// void psiginfo(const siginfo_t *p, const char *s);
//
// strsignal() 返回对应信号的本地语言描述信息，根据当前 locale 中的 LC_MESSAGES 类别
// 进行本地化。返回的字符串仅在下次调用 strsignal() 之前有效，但该函数是线程安全的。
// strsignal() 返回与信号编号对应的描述字符串；若编号无效，则返回未知信号提示信息。在一
// 些系统（不包括 Linux）上，无效编号可能返回 NULL。sigdescr_np() 返回对应的描述字符
// 串，返回的字符串静态分配，在整个程序生命周期内有效，若信号编号无效，则返回 NULL。
//
// psignal() 把一条消息写到标准错误输出，格式为：“字符串s: 信号描述字符串\n”。若 s 为
// NULL 或空字符串，则省略冒号及空格。若 sig 无效，则提示未知信号。psiginfo() 与
// psignal() 类似，但针对 siginfo_t 结构 pinfo 提供的信息进行打印。除了输出信号描述
// 信息外，还额外打印信号来源及其它相关细节，例如：硬件异常时的出错地址，SIGCHLD 时的子
// 进程 PID，kill(2) / sigqueue(3) 信号发送者的 UID 与 PID。glibc 2.12 之前的
// psiginfo() 存在以下 bug：某些情况下缺少末尾换行，对实时信号不显示额外细节。
//
// #include <signal.h>
// int sigemptyset(sigset_t *set); 清空，成功返回0，失败返回-1和errno
// int sigfillset(sigset_t *set); 包含所有信号
// int sigaddset(sigset_t *set, int sig); 添加一个信号到信号集
// int sigdelset(sigset_t *set, int sig); 删除一个信号到信号集
// int sigismember(const sigset_t *set, int sig); 返回1表示信号集里包含信号sig，返回0表示不包含，返回-1和errno表示错误
//
// 多个信号可使用一个称之为信号集的数据结构来表示，即 sigset_t。像大多数 UNIX 实现一样，
// sigset_t 数据类型在 Linux 中是一个位掩码，然而 SUSv3 对此并无要求，但仅要求可对其
// 进行赋值即可，因此必须使用某些标量类型（比如一个整数）或者一个 C 语言结构体来实现该
// 类型。类型 sigset_t 必须在使用操作之前通过调用 sigfillset() 或 sigfillset() 进行
// 初始化，如果不这样做，结果是未定义的。glibc 中的 sigfillset() 在构造所有信号时，不
// 会把 NPTL线程库内部使用的两个实时信号包含进去，详见 nptl(7)。可能的错误：EINVAL 信
// 号非法。
//
// #include <signal.h> 成功返回0，失败返回-1和errno
// int sigprocmask(int how, const sigset_t *set, sigset_t *oldset); 暂时阻塞信号，当去掉掩码后会继续处理信号；EFULT - set 或 oldset 非法地址，EINVAL - 参数非法
// int sigpending(sigset_t *set); 获取当前进程中正在等待的信号集；EFULT - set 地址非法
//
// 内核会为每个进程维护一组信号掩码，并阻塞其中的信号针对该进程的传递。如果将遭阻塞的信
// 号发送给某进程，那么对该信号的传递将延后，直至从进程信号掩码中移除该信号，从而解除阻
// 塞。信号掩码其实是属于线程的属性，在多线程中，每个线程都可使用 pthread_sigmask()
// 函数来独立检查和修改线程的信号掩码。向信号掩码中添加一个信号，有如下几种方式：
//  1.  当信号处理函数被调用时，可能将当前信号自动添加到信号掩码中，这处决于 sigaction
//      函数设置信号处理函数时是否设置 SA_NODEFER 标志。
//  2.  使用 sigaction 函数设置信号处理函数时，可以指定一组额外信号，当调用处理函数时
//      会将其阻塞。
//  3.  使用 sigprocmask() 系统调用，随时可以显式的向信号掩码中添加和移除信号。
//
// 等待信号集只是一个掩码，仅表明一个信号是否已经触发，但并未表明其发生的次数。换言之，
// 如果同一信号在阻塞状态下产生多次，那么会将该信号记录在等待信号集中，并在稍后仅传递
// 一次。标准信号和实时信号之间的差别之一在于，内核对实时信号进行了排队处理。即使进程
// 没有阻塞信号，其所接收到的信号也比发送给它的要少得多，比如信号发送速度如此之快，以至
// 于在内核考虑将执行权调度给接收进程之前，新信号就已经到达，这时就会导致多次发送的信号
// 在进程等待信号集中只记录了一次。
//
// 信号因某些事件而产生，信号生成后，会于稍后被传递给某个进程，而进程也会采取某些措施来
// 响应信号。在产生和到达期间，信号处于等待（pending）状态。通常，一旦内核接下来要调度
// 进程运行，等待信号会马上送达，或者如果进程正在运行，则会立即传递信号，例如进程向自身
// 发送信号。然而，有时需要确保一段代码不被传递过来的信号打断，此时可以将信号添加到进程
// 的信号掩码中，这样会阻塞该组信号的到达。如果所产生的信号被掩码阻塞，那么信号将保持等
// 待状态，直至稍后将信号从掩码中移除解除阻塞。
//
// 如何传递一个处于等待状态的信号？同步产生的信号会立即传递，执行特定机器指令导致的硬件
// 异常信号，包括 SIGBUS SIGFPE SIGILL SIGSEGV SIGEMT，以及使用 kill() raise()
// killpg() 向进程自身发送的信号，这些信号的产生都是同步的。即这些信号在产生的地方就立
// 即中断主程序，直接触发信号处理函数的调用，比如 raise() 在返回之前就已经执行了信号的
// 处理函数。当异步产生一个信号时，即使并未将其阻塞，在信号产生和实际传递之间仍可能存在
// 一个瞬时延迟，在此期间，信号处于等待状态。这是因为内核将等待信号传递给进程的时机是，
// 该进程正在执行，且发生由内核态到用户态的下一次切换时。实际上，这意味着在以下时刻才会
// 传递信号：一个线程被调度到CPU上执行时，即在一个时间片的开始处；系统调用返回时，信号
// 的传递可能引起正在阻塞的系统调用过早完成。
//
// 解除对多个信号的阻塞时，信号的传递顺序。如果进程使用 sigprocmask() 解除了对多个等待
// 信号的阻塞，那么所有这些信号会立即传递给该进程。就目前的 Linux 实现而言，Linux 内核
// 按照信号编号的升序来传递序号。例如，如果对处于等待状态的信号 SIGINT（编号为2）和
// SIGQUIT（编号为3）同时解除阻塞，那么无论这两个信号的产生次序如何，SIGINT 都将先于
// SIGQUIT 而传递。然而，也不能对传递标准信号的特定顺序产生任何依赖，因为 SUSv3 规定
// 多个信号的传递顺序由系统实现决定。该条款仅适用于标准信号，因为实时信号的相关标准规
// 定，对于解除阻塞的实时信号而言，其传递顺序必须得到保障。当多个解除了阻塞的信号正在
// 等待传递时，如果在信号处理函数执行期间发生了内核态到用户态之间的切换，那么将中断此
// 处理函数的执行，转而去调用第二个信号的处理函数。例如：
//  1.  解除对处于等待状态的信号 SIGINT 和 SIGCOUNT 的阻塞
//  2.  内核调用 SIGINT 信号的处理函数
//  3.  SIGINT 处理函数发起了一个系统调用
//  4.  内核调用 SIGQUIT 信号的处理函数
//
// sigprocmask() 函数既可以修改进程的信号掩码，也可以获取当前的掩码值，或者两者同时操
// 作。how 参数指定了 sigprocmask() 函数如何设置信号掩码：
//      SIG_BLOCK - 将 set 中的信号添加到信号掩码中。
//      SIG_UNBLOCK - 将 set 中的信号从信号掩码中移除，即使要移除的信号并没有处在阻
//          塞状态，也不会返回错误。
//      SIG_SETMASK - 将 set 信号集赋值给信号掩码。
//
// 上述各种清空下，若 oldset 不为空，则返回设置之前的信号掩码。如果仅获取当前的信号掩
// 码而不对其进行修改，那么可以将 set 设为空，此时将忽略 how 参数。SUSv3 规定，如果在
// 解除阻塞时由任何对应的信号，那么在 sigprocmask() 调用返回前至少传递一个信号。换言
// 之，如果解除了对某个等待信号的阻塞，那么会立刻将该信号传递给进程执行调用。系统会忽略
// 对 SIGKILL 和 SIGSTOP 信号的阻塞，如果试图阻塞这些信号，sigprocmask() 既不会予以
// 关注，也不会产生错误。如果修改了正在等待的阻塞信号的处置函数，那么当后来解除信号的阻
// 塞时，将根据新的处置来处理信号。例如将信号处置设为忽略（SIG_IGN），或者设置为默认
// （SIG_DFL）而信号的默认行为是忽略信号，那么对应的正在等待的信号将从进行的等待集中移
// 除，因此不会传递该信号，相当于阻止了对正处于等待状态的信号的传递。
//
// 在多线程进程中使用 sigprocmask() 的行为是不明确（unspecified）的；应该改用
// pthread_sigmask(3)。内核与 C 库对 sigset_t 的定义大小不同。本手册页把内核使用的类
// 型称为 kernel_sigset_t（内核源码中仍叫 sigset_t）。glibc 包装函数调用 sigprocmask()
// 时，glibc 会静默忽略试图阻塞 NPTL 线程实现内部使用的两个实时信号，详见 nptl(7)。
// 原始系统调用名为 sigprocmask()，Linux 2.2 引入实时信号后，32 位固定大小的旧类型
// old_kernel_sigset_t 已不够用，于是新增 rt_sigprocmask()，支持更大的 kernel_sigset_t。
// 新系统调用新增第 4 个参数 size_t sigsetsize，指定 set 与 oldset 的字节数，必须为
// 架构相关的固定值 sizeof(kernel_sigset_t)。glibc 的 sigprocmask() 包装函数会透明
// 地在支持时调用 rt_sigprocmask()。每个线程拥有自己独立的信号掩码。fork(2) 的子进程
// 会继承父进程的信号掩码，信号掩码会跨越 execve(2) 的执行后仍保留。若 SIGBUS、SIGFPE、
// SIGILL 或 SIGSEGV 在阻塞期间由硬件异常产生，结果将未定义，除非这些信号来自 kill(2)、
// sigqueue(3) 或 raise(3)。允许（但无意义）同时把 set 和 oldset 设为 NULL。
//
// 如果某个信号既被阻塞又被设置为“忽略”，那么当它触发时不会被加入线程的待处理信号集中。
// 线程的待处理信号集，是该线程自己的待处理信号，与整个进程的待处理信号的合集，详见
// signal(7)。通过 fork(2) 创建的子进程，其初始待处理信号集为空；跨 execve(2) 执行会
// 保留现有的待处理信号集。在 glibc 2.2.1 及更早版本中，sigpending() 的包装函数存在一
// 个缺陷：无法正确返回有关挂起的实时信号（real-time signals）的信息。
//
// https://www.man7.org/linux/man-pages/man5/core.5.html
// https://www.man7.org/linux/man-pages/man1/coredumpctl.1.html
// https://www.man7.org/linux/man-pages/man8/systemd-coredump.8.html
//
// 核心转储文件（core）。特定信号会引发进程创建一个核心转储文件并终止运行。所谓核心转储
// 是内含进程终止时内存映像的一个文件，术语 core 源于一种老迈的内存技术。将该内存映像加
// 载到调试器，即可查明信号到达时程序代码和数据的状态。引发程序生成核心转储文件的方式之
// 一是键入退出字符（通常是CTRL-\），从而生成 SIGQUIT 信号。核心转储文件创建于进程的
// 工作目录中，名为 core。这是核心转储文件的默认位置和名称，这些默认值都可以进行配置。
// 借助于许多实现所提供的工具（例如 FreeBSD 中的 gcore），可获取某一正在运行进程的核心
// 转储文件。Linux 系统也有类似功能，使用 gdb 去连接（attach）一个正在运行的进程，然后
// 运行 gcore 命令。但要产生核心文件，需要满足一些条件：
//  1.  进程对核心文件有写权限，并且对应名称的文件在指定目录下能够创建成功
//  2.  进程的核心文件大小（RLIMIT_CORE）和可创建文件大小（RLIMIT_FSIZE）没有受到限制
//  3.  用户对正在执行的二进制可执行文件有读取权限
//  4.  当前目录所在文件系统不能是只读的，空间不能已满，i-node 资源没有耗尽，用户在该
//      文件系统上还没有达到其配额限制
//  5.  set-user-id 或 set-group-id 程序必须由文件属主或属组执行时，才会产生核心文
//      件，这可防止恶意用户将一个安全程序的内存转储出来，再针对诸如密码之类的敏感信息
//      进行刺探。借助于 Linux 专有的系统调用 prctl() 的 PR_SET_DUMPABLE 操作，可以
//      为进程设置 dumpable 标志。当非文件属主或属组运行 set-user-id 或 set-group-id
//      程序时，如果设置了 dumpable 标志则可以生成核心文件。另外，始于内核 2.6.13，针
//      对 set-user-id 和 set-group-id 进程是否产生核心文件，如下配置文件提供了系统
//      级控制：/proc/sys/fs/suid_dumpable，参见 proc(5) 手册。
//  6.  始于内核版本 2.6.23，利用 Linux 特有的 /proc/PID/coredump_filter，可以对写
//      入核心转储文件的内存映射类型施以进程级控制。该文件中的值是一个4位掩码，分别对应
//      4中类型的内存映射：私有匿名映射、私有文件映射、共享匿名映射、共享文件映射。文件
//      文件默认值提供了传统的 Linux 行为，即仅对私有匿名和共享匿名映射进行转储，参见
//      core(5) 手册。
//
// #include <signal.h> 等待信号的发生
// int sigsuspend(const sigset_t *mask);
// int sigwait(const sigset_t *set, int *sig);
// int sigwaitinfo(const sigset_t *set, siginfo_t *info); *** MacOS 不支持
// int sigtimedwait(const sigset_t *set, siginfo_t *info, const struct timespec *timeout); *** MacOS 不支持
// #include <unistd.h> 暂停进程等待被信号中断或进行终止
// int pause(void); 暂停进程的执行，等待信号的中断或者直至一个未处理信号终止进程为止；总是返回 -1 和 EINTR
//
// 在解释 sigsuspend() 之前，先介绍一下它的一种使用场景，在对信号编程时偶尔会遇到如下
// 情况：（1）临时阻塞一个信号，以防止其中断关键代码片段的执行；（2）解除对信号的阻塞，
// 然后暂停执行，直至有信号到达。在第2步中，如何检测到在解除阻塞到执行暂停期间的信号呢，
// 因为信号可能随时到达，如果使用以下代码就检测不到这种情况：
//      sigprocmask(SIG_SETMASK, &prev_mask, NULL);
//      pause();
//
// 要避免这个问题，需要将解除信号阻塞和挂起进程这两个动作封装成一个原子操作，这正是系统
// 调用 sigsuspend() 的目的。sigsuspend() 使用 mask 指向的信号集替换进行的信号掩码，
// 然后挂起进程的执行，直到其捕获到信号，并从信号处理函数返回。一旦处理函数返回，还会将
// 进程信号掩码恢复为调用前的值。调用 sigsuspend()，相当于以不可中断的方式执行以下操
// 作。虽然恢复旧的信号掩码咋看起来似乎麻烦，但为了需要反复等待信号的情况下避免竞争条件，
// 这一做法至关重要。在这种情况下，除非是在 sigsuspend() 调用期间，否则信号必须保持阻
// 塞状态。若 sigsuspend() 总是返回 -1 和 EINTR 或者 EFAULT 表示 mask 地址非法。
//      sigprocmask(SIG_SETMASK, &mask, &prev_mask);
//      pause();
//      sigprocmask(SIG_SETMASK, &prev_mask, NULL);
//
// 因为不能阻塞 SIGKILL 和 SIGSTOP，指定这些信号到 mask 中不会对线程的信号掩码产生效
// 果。如果信号终止了进程，sigsuspend() 将不会返回。如果等到了信号，那么信号的处理函数
// 将被调用，并且信号掩码会重置回调用前的值，之后 sigsuspend() 才会返回。
//
// 以上描述了使用 sigsuspend() 挂起进程来等待信号，然而这种方法需要编写信号处理函数，
// 以及需要应对信号异步传递所带来的复杂性。对于某些应用而言，这种方法过于繁杂。作为替代
// 方案，可以利用 sigwaitinfo() 和 sigtimedwait() 系统调用来同步接收信号。使用这些
// 同步等待的系统调用，需要首先对 set 中的信号集进行阻塞。如果没有这样做，而信号在首次
// 调用 sigwaitinfo() 之前，或者两次连续调用 sigwaitinfo() 之间到达，那么对信号的处
// 理只能依靠当前信号的处理函数。SUSv3 规定，调用 sigwaitinfo() 而不阻塞 set 中的信
// 号将导致不可预知的行为。sigwaitinfo() 将挂起进程的执行，直至 set 信号集中的某一信
// 号抵达。如果调用 sigwaitinfo() 时，set 中的某一信号已经处于等待状态，那么该调用将
// 立即返回。传递的信号就此从进程的等待信号队列中移除，并且将返回信号编号作为函数结果，
// info 参数如果不为空，则会返回信号的相关信息。sigwaitinfo() 所接收信号的传递顺序和
// 排队特性与信号的类型相关，也就是说不对标准信号进行排队处理而实行低编号优先的原则，而
// 对实时信号进行排队处理。除了卸去编写信号处理函数的负担之外，因为 sigwaitinfo() 返回
// 了对应信号的信息可直接在主程序中进行处理，使用 sigwaitinfo() 来等待信号也要比信号
// 处理函数外加 sigsuspend() 的组合要稍快一些。
//
// sigtimedwait() 系统调用是 sigwaitinfo() 调用的变体，唯一的区别是 sigtimedwait()
// 允许指定等待时限。如果将时限指定为 0，那么函数将立即超时。如果调用超时而又没有收到信
// 号，sigtimedwait() 将调用失败，返回 -1 和 EAGAIN。如果将 timeout 参数指定为 NULL，
// 那么 sigtimedwait() 将完全等同于 sigwaitinfo()。SUSv3 对于 timeout 的 NULL 值
// 语焉不详，而某些 UNIX 实现则将该值视为轮询请求并立即返回。
//
// #include <sys/signalfd.h>
// int signalfd(int fd, const sigset_t *mask, int flags); *** Linux 特有
//
// Linux 2.6.22 开始提供了非标准的 signalfd() 系统调用，利用该调用可以创建一个特殊的
// 文件描述符，发往调用者的信号都可从该描述符中读取。signalfd 机制为同步接收信号提供了
// sigwaitinfo() 之外的另一种选择。mask 是一个信号集，指定了有意通过 sigalfd 文件描
// 述符来读取的信号。如同 sigwaitinfo() 一样，通常也应该使用 sigprocmask() 阻塞 mask
// 中的所有信号，以确保有机会读取这些信号之前，不会按照设置的信号处理函数对它们进行处
// 理。如果指定 fd 为 -1，那么 signalfd() 会创建一个新的文件描述符，否则将修改与 fd
// 相关的 mask 值，且该 fd 必须是前面某一次 signalfd() 创建的描述符。早期实现将 flag
// 参数保留下来供将来使用，且必须将其指定为 0。然而，Linux 从版本 2.6.27 开始支持两个
// 标志 SFD_CLOEXEC SFD_NONBLOCK，参见文件描述符的 O_CLOEXEC 和 O_NONBLOCK。
//
// 创建文件描述符之后，可以使用 read() 调用从中读取信号，提供给 read() 的缓冲区必须足
// 够大，至少应该能够容纳一个 signalfd_siginfo 结构，该结构返回与传统 siginfo_t 结构
// 类似的字段信息。read() 每次调用都将返回与等待信号数目相等的 signalfd_siginfo 结构，
// 并填充到提供的缓冲区中。如果调用时并无信号正在等待，那么 read() 将阻塞，直到信号到
// 达。也可以使用 fcntl() 的 F_SETFL 将文件描述符设置为非阻塞 O_NONBLOCK，使得读操作
// 不在阻塞，且若无信号等待，则调用失败返回 EAGAIN。
//
// select() poll() epoll() 可以将 sigalfd 描述符和其他描述符混合起来进行监控。如果有
// 信号正在等待，那么这些技术将文件描述符指示为可读取。当不在需要 signalfd 文件描述符
// 时，应该关闭 signalfd 以释放相关的内核资源。
//
// 从某种角度，可将信号视为进程间通信（IPC）的方式之一。然而，信号作为一种 IPC 机制却
// 饱受限制。首先，与其他 IPC 方法相比，对信号编程集繁杂且困难，具体原因如下：
//  1.  信号的异步本质就意味着需要面对各种问题，包括可重入性需求、竟态条件以及在信号处
//      理函数中正确处理全局变量。如果使用 sigwaitinfo() 或者 signalfd() 来同步获取
//      信号，这些问题中的大部分都不会遇到。
//  2.  没有对标准信号进行排队处理，即使是对于实时信号，也存在对信号排队数量的限制。这
//      意味着，为了避免丢失信息，接收信号的进程必须相方设法通知发送者，自己为接收另一
//      个信号做好了准备。要做的这一点，最显而易见的方法是由接收者向发送者发送信号。
//
// 还有一个更深层次的问题，信号所携带的信息量有限：只有信号编号，以及实时信号情况下了一
// 个整数或指针附加数据。与诸如管道之类的其他 IPC 方法相比，过低的带宽使得信号传输极为
// 缓慢。由于上述种种限制，很少将信号用户进程间通信。
//
// https://www.man7.org/linux/man-pages/man7/signal.7.html
//
// 系统调用和库函数被信号处理函数中断。如果信号处理函数在某个系统调用或库函数调用被阻塞
// 时被触发，那么在处理函数执行完毕并且返回之后：主程序调用会自动重启；或者以 EINTR 错
// 误返回。具体发生哪种行为取决于接口以及信号处理函数是否使用了 SA_RESTART 标志，参见
// sigaction(2)。不同 UNIX 系统的细节有所不同，以下是 Linux 的细节行为。
//
// 如果对以下接口的阻塞调用被信号处理函数中断，那么如果使用了 SA_RESTART 标志，调用会
// 在信号处理函数返回后自动重启；否则调用会以 EINTR 错误失败：
//
//  1.  “慢速” 设备上的 I/O 调用：read(2)、readv(2)、write(2)、writev(2) 和
//      ioctl(2)。“慢速” 设备是指 I/O 调用可能无限期阻塞（期限不明确）的设备，例如
//      终端、管道或套接字。如果在被信号处理函数中断之前，I/O 调用已经传输了一些数据，
//      那么调用将返回成功状态（通常是传输的字节数）。注意，根据此定义，本地磁盘不是慢
//      速设备；磁盘设备上的 I/O 操作不会被信号中断。因为磁盘 I/O 操作总会比较快的返
//      回，并使调用者不再处在阻塞状态，不像真正的 “慢速” 设备，进程可能无限期阻塞，除
//      非系统停机，否则可能一直阻塞。
//  2.  可能阻塞的 open(2) 操作，例如打开 FIFO 时，参见 fifo(7)。
//  3.  进程等待：wait(2)、wait3(2)、wait4(2)、waitid(2) 和 waitpid(2)。
//  4.  套接字接口：accept(2)、connect(2)、recv(2)、recvfrom(2)、recvmmsg(2)、
//      recvmsg(2)、send(2)、sendto(2) 和 sendmsg(2)，除非套接字上设置了超时，见下
//      文。
//  5.  文件锁定接口：flock(2) 以及 fcntl(2) 的 F_SETLKW 和 F_OFD_SETLKW 操作。
//  6.  POSIX 消息队列接口：mq_receive(3)、mq_timedreceive(3)、mq_send(3) 和
//      mq_timedsend(3)。
//  7.  futex(2) 的 FUTEX_WAIT（Linux 2.6.22 起；在此之前，总是以 EINTR 失败）。
//  8.  getrandom(2)。
//  9.  futex(2) 的 FUTEX_WAIT_BITSET。
//  10. POSIX 信号量接口：sem_wait(3) 和 sem_timedwait(3)（Linux 2.6.22 起；在此
//      之前，总是以 EINTR 失败）。
//  11. 从 inotify(7) 文件描述符读取的 read(2)（Linux 3.8 起；在此之前，总是以
//      EINTR 失败）。
//
// 以下接口在被信号处理函数中断后永远不会重启，无论是否使用了 SA_RESTART；它们在被信号
// 处理函数中断时总是以 EINTR 错误失败：
//
//  1.  通过 setsockopt(2) 设置了超时（SO_RCVTIMEO）的 “输入” 套接字接口：
//      accept(2)、recv(2)、recvfrom(2)、recvmmsg(2)（带有非空超时参数时）和
//      recvmsg(2)。
//  2.  通过 setsockopt(2) 设置了超时（SO_SNDTIMEO）的 “输出” 套接字接口：
//      connect(2)、send(2)、sendto(2) 和 sendmsg(2)。
//  3.  用于等待信号的接口：pause(2)、sigsuspend(2)、sigtimedwait(2) 和
//      sigwaitinfo(2)。
//  4.  文件描述符多路复用接口：epoll_wait(2)、epoll_pwait(2)、poll(2)、ppoll(2)、
//      select(2) 和 pselect(2)。
//  5.  System V IPC 接口：msgrcv(2)、msgsnd(2)、semop(2) 和 semtimedop(2)。
//  6.  睡眠接口：clock_nanosleep(2)、nanosleep(2) 和 usleep(3)。
//  7.  io_getevents(2)。
//
// sleep(3) 函数在被信号处理函数中断时永远不会重启，但会返回成功：剩余的睡眠秒数。在某
// 些情况下，seccomp(2) 的用户空间通知功能可能会导致某些系统调用在本不会被 SA_RESTART
// 重启的情况下被重启；详情见 seccomp_unotify(2)。
//
// 系统调用和库函数被停止信号中断。在 Linux 上，即使没有信号处理函数，某些阻塞接口在进
// 程被停止信号停止后，通过 SIGCONT 恢复时，也可能以 EINTR 错误失败。这种行为未被
// POSIX.1 批准，可能在其他系统上不会发生。具有此行为的 Linux 接口包括：
//
//  1.  通过 setsockopt(2) 设置了超时（SO_RCVTIMEO）的 “输入” 套接字接口：
//      accept(2)、recv(2)、recvfrom(2)、recvmmsg(2)（带有非空超时参数时）和
//      recvmsg(2)。
//  2.  通过 setsockopt(2) 设置了超时（SO_SNDTIMEO）的 “输出” 套接字接口：
//      connect(2)、send(2)、sendto(2) 和 sendmsg(2)。
//  3.  epoll_wait(2)、epoll_pwait(2)。
//  4.  semop(2)、semtimedop(2)。
//  5.  sigtimedwait(2)、sigwaitinfo(2)。
//  6.  Linux 3.7 及更早版本：从 inotify(7) 文件描述符进行读取 read(2)。
//  7.  Linux 2.6.21 及更早版本：futex(2) 的 FUTEX_WAIT、sem_timedwait(3)、
//      sem_wait(3)。
//  8.  Linux 2.6.8 及更早版本：msgrcv(2)、msgsnd(2)。
//  9.  Linux 2.4 及更早版本：nanosleep(2)。
//
// 信号处理函数是进程的属性，在一个多线程程序中，一个特定信号的处理函数对于所有线程都是
// 相同的。由 fork(2) 创建的子进程会继承来自父进程的所有信号处置设置。在一个 execve(2)
// 执行期间，处理过的信号的处置会重置成默认行为，而忽略的信号处置方式保持不变。
//
// 每个线程拥有自己独立的信号掩码。由 fork(2) 创建的子进程会继承父进程的信号掩码，信号
// 掩码会跨越 execve(2) 保留。信号可以是进程定向的（process-directed）或线程定向的
// （thread-directed）。进程定向信号是针对整个进程的。若信号由内核非硬件异常原因产生，
// 或通过 kill(2) 或 sigqueue(3) 发送，则为进程定向。进程定向信号可被任何未阻塞该信号
// 的线程接收。若多个线程均未阻塞该信号，则内核会任意选择一个线程来投递信号。
//
// 线程定向信号是针对特定线程的。若信号因执行特定机器语言指令触发硬件异常（例如，非法内
// 存访问产生 SIGSEGV，数学错误产生 SIGFPE），或通过 tgkill(2) 或 pthread_kill(3)
// 等接口向特定线程发送，则为线程定向。线程可以通过 sigpending(2) 获取其当前挂起的信号
// 集。该集合是进程定向挂起信号集与调用线程自身挂起信号集的并集。通过 fork(2) 创建的子
// 进程，其初始挂起信号集为空；execve(2) 会保留现有的挂起信号集。
//
// 信号处理函数的执行。每当从内核态切换到用户态执行时（例如从系统调用返回，或线程被调度
// 到 CPU 上执行），内核会检查是否存在挂起（pending）且未被阻塞的信号，且该信号有对应
// 的信号处理函数。根据这个步骤，内核可以明确控制内核自己的代码不会被信号打断。如果存在
// 这样的信号，将执行以下步骤：
//  (1) 内核为信号处理函数的执行做必要的准备工作：
//      1.1 从挂起信号集中移除该信号。
//      1.2 如果信号处理函数是通过带有 SA_ONSTACK 标志的 sigaction(2) 安装的，并且
//          线程定义了替代信号栈（通过 sigaltstack(2)），则安装使用该替代栈。
//      1.3 将与信号相关的上下文信息保存到栈上的一个特殊帧中。保存的信息包括：
//           -  程序计数器寄存器（即信号处理函数返回时应执行的主程序中的下一条指令地址）；
//           -  架构特定的寄存器状态，用于恢复被中断的程序；
//           -  线程当前的信号掩码；
//           -  线程的替代信号栈设置；
//          如果信号处理函数是通过带有 SA_SIGINFO 标志的 sigaction(2) 安装的，则上
//          述信息可通过信号处理函数的第三个参数指向的 ucontext_t 对象访问。该对象反
//          映的是信号递送时的状态，而不是处理函数中的状态；例如，存储在该对象中的阻塞
//          信号掩码不会包含通过 sigaction(2) 新阻塞的信号。
//      1.4 将 act->sa_mask 中指定的信号添加到线程的信号掩码中。正在递送的信号也会被
//          添加到信号掩码中，除非在注册处理函数时指定了 SA_NODEFER。因此，这些信号在
//          处理函数执行期间被阻塞。
//  (2) 内核在栈上为信号处理函数构建一个栈帧。内核将线程的程序计数器设置为指向信号处理
//      函数的第一条指令，并将该函数的返回地址配置为指向用户空间代码中的信号蹦床（在
//      sigreturn(2) 中描述）。
//  (3) 内核将控制权交回用户空间，从信号处理函数的起始处开始执行。
//  (4) 当信号处理函数返回时，控制权传递给信号蹦床代码。
//  (5) 信号蹦床调用 sigreturn(2)，这是一个系统调用，它使用步骤 1 中创建的栈帧中的信
//      息，将线程恢复到调用信号处理函数之前的状态。线程的信号掩码和替代信号栈设置作为
//      此步骤流程的一部分被恢复。sigreturn(2) 调用完成后，内核将控制权交回用户空间，
//      线程从被信号处理函数中断的地方继续执行。
//
// 注意：如果信号处理函数不返回（例如使用 siglongjmp(3) 跳出处理函数，或通过 execve(2)
// 执行新程序），则不会执行最后一步。在这种情况下，程序员有责任使用 sigprocmask(2) 恢复
// 信号掩码的状态（如果希望解除信号处理函数入口处阻塞的信号）。需要注意的是，siglongjmp(3)
// 是否会恢复信号掩码取决于 sigsetjmp(3) 调用时指定的 savesigs 值。
//
// 从内核的角度来看，信号处理函数代码的执行与任何其他用户空间代码的执行完全相同。也就是
// 说，内核不会记录任何特殊状态信息，表明线程当前正在执行信号处理函数。所有必要的状态信
// 息都保存在用户空间寄存器和用户空间栈中。因此，嵌套信号处理函数的深度仅受用户空间栈
// （以及合理的软件设计）的限制。
//
// #include <signal.h>
// #include <pthread.h>
// int pthread_sigmask(int how, const sigset_t *set, sigset_t *oldset);
// int pthread_kill(pthread_t thread, int sig);
// int pthread_sigqueue(pthread_t thread, int sig, const union sigval value); *** Linux 特有函数
//
// 新创建的新线程会从其创建者处继承信号掩码的一份拷贝，可以使用 pthread_sigmask() 来
// 改变或获取当前的信号掩码。pthread_sigmask() 成功返回 0 错误返回正值的错误码。除了
// 所操作的是线程信号掩码之外，pthread_sigmask() 与 sigprocmask() 用法完全相同。
// SUSv3 特别指出，在多线程程序中使用函数 sigprocmask() 其结果是未定义的，也无法保证
// 程序的可移植性。事实上，函数 sigprocmask() 和 pthread_sigmask() 在包括 Linux 在
// 内的很多系统实现中都是相同的。
//
// 函数 pthread_kill() 向同一进程下的另一线程发送信号 sig，目标线程由 thread 指定。
// 因为仅在同一进程中可保证线程ID的唯一性，所以无法调用 pthread_kill() 向其他进程中的
// 线程发送信号。在实现函数 pthread_kill() 时，使用了 Linux 特有的 tgkill(tgid, tid, sig)
// 系统调用，将信号 sig 发送给 tid（由 gettid() 所返回的内核线程 ID）标识的线程，该
// 线程从属于由 tgid 标识的线程组中。如果 sig 为 0 则不会发送信号，但是会执行错误检查。
// pthread_kill() 成功返回 0，错误返回正整数值的错误码，EINVAL 参数非法，ESRCH 无效
// 线程。
//
// 在尝试发送 NPTL 线程实现内部使用的两个实时信号时，glibc 的 pthread_kill() 实现会
// 返回错误（EINVAL）。详情参见 nptl(7)。如果实现检测到线程 ID 在其生命周期结束后被使
// 用，pthread_kill() 应返回错误 ESRCH。glibc 实现会在可以检测到无效线程 ID 的情况下
// 返回此错误。POSIX 指出，使用生命周期已结束的线程 ID 会产生未定义行为，而在
// pthread_kill() 调用中使用无效线程 ID 可能会导致段错误。
//
// 信号处理方式是进程范围内的。如果信号 sig 安装了处理函数，该处理函数将在指定的线程
// thread 中执行。但如果信号的处理方式是默认的 “停止”、“继续” 或 “终止”，这些操作将
// 影响整个进程。
//
// Linux 特有的函数 pthread_sigqueue() 将 pthread_kill() 和 sigqueue() 的功能合二
// 为一，向同一进程中的另一个线程发送携带附属数据的信号。该函数从 glibc 2.11 开始加入库
// 中但需要内核的支持，始于 Linux 2.6.31 内核通过系统调用 rt_tgsigqueueinfo() 来提供
// 这一支持。
//
// 线程间除全局内存还共享以下属性，它们对于进程而言是全局的，并非针对某个特定线程：
//  1.  进程ID和父进程ID，进程组ID与会话（session）ID，进程凭证（credential）
//  2.  控制终端，打开的文件描述符
//  3.  由 fcntl() 创建的记录锁（record lock）
//  4.  信号处置，间隔定时器和POSIX定时器
//  5.  文件系统的相关信息，例如文件权限掩码、当前工作目录和根目录
//  6.  系统 V（System V）信号量撤销（undo semadj）
//  7.  资源限制（resource limit），资源消耗（getrusage()）
//  8.  CPU 时间消耗（times()），nice 值（setpriority() nice()）
//
// 各线程所独有的属性包括：
//  1.  线程ID，线程本地存储数据，errno 变量，浮点环境（fenv(3)）
//  2.  信号掩码，备选信号栈（sigaltstack()）
//  3.  实时调度策略和优先级
//  4.  CPU 亲和力（affinity，Linux 所特有）
//  5.  能力（capability，Linux 所特有）
//  6.  线程栈，本地变量和函数的调用链接信息
//
// 在多线程应用中处理信号，需要小心设计，作为通则一般建议在多线程程序中避免使用信号。
// UNIX 信号模型是基于 UNIX 进程模型而设计的，问世比 pthreads 要早几十年。自然而然，
// 信号与线程模型之间存在一些明显的冲突。主要是因为，一方面针对单线程进程要保持传统的
// 信号语义（pthreads不应该改变传统进程的信号语义），与此同时又需要开发出适用于多线程
// 进程环境的新信号模型。信号与线程模型之间的差异意味着，将二者结合使用将会非常复杂，
// 应尽可能加以避免。尽管如此，有的时候还是必须在多线程中处理信号问题。
//
// UNIX 信号模型如果映射到线程中。要了解 UNIX 信号如果映射到 pthreads 模型，需要知道
// 信号模型哪些方面属于进程（由进程中的所有线程共享），哪些方面属于进程中的单个线程。
//  1.  信号触发的进程停止或终止动作属于进程层面。如果进程中的任一线程收到默认处置的信
//      号，且其默认行为是停止或终止进程，那么将停止或终止进程中的所有线程。
//  2.  信号设置的处置属于进程层面，进程中的所有线程共享对每个信号的处置设置。如果某一
//      线程使用函数 sigaction() 为某一信号创建处理函数，那么当收到该信号使，任何线程
//      都可能去调用该处理函数。与之类似，如果将信号的处置设置为忽略，那么所有线程都会
//      忽略该信号。
//  3.  信号的发送即可针对整个进程，也可针对某个特定线程。满足如下三者之一的信号是面向
//      线程的：
//          (1) 信号的产生源来自线程自身上下文中对特定指令的执行导致的硬件异常，例如
//              SIGBUS SIGFPE SIGILL SIGSEGV SIGEMT SIGTRAP。
//          (2) 当线程试图对已断开的管道进行写操作时所产生的 SIGPIPE 信号。
//          (3) 由函数 pthread_kill() 或 pthread_sigqueue() 所发出的信号，这些函
//              数允许线程向同一进程下的其他线程发送信号。
//      由其他机制产生的所有信号都是面向进程的。例如其他进程通过调用 kill() 或者
//      sigqueue() 所发送的信号；用户键入特殊中断字符产生的信号 SIGINT SIGTSTP；还有
//      一些信号由软件事件产生，例如终端窗口大小的调整（SIGWINCH）或者定时器到期
//      （例如 SIGALRM）。
//  4.  当多线程程序收到一个信号，且该进程已然为此信号创建了处理函数时，内核会任选一个
//      线程来接收这一信号，并在该线程中调用信号处理函数。这种行为与信号的原始语义保持
//      一致。让进程针对单个信号重复处理多次时没有意义的。
//  5.  信号掩码是针对当个线程的。对于多线程程序来说，并不存在一个作用于整个进程范围的
//      信号掩码，可以管理所有线程。使用 pthread_sigmask() 各线程可独立阻止和放行各种
//      信号。通过操作每个线程的信号掩码，应用程序可以控制哪些线程可以处理进程收到的信
//      号。新创建的新线程会从其创建者处继承信号掩码的一份拷贝，可以使用 pthread_sigmask()
//      来改变或获取当前的信号掩码。
//  6.  针对整个进程所挂起（pending）的信号，以及为每个线程所挂起的信号，内核都分别维
//      护有记录。调用函数 sigpending() 会返回进程挂起以及当前线程挂起的信号集合。在
//      新创建的线程中，每个线程的挂起信号初始为空。可以将一个针对线程的信号仅向目标线
//      程投送，如果该信号遭线程阻塞，那么它会一致保持挂起，直至线程将其放行或者线程终
//      止。
//  7.  如果信号处理函数中断了对 pthread_mutex_lock() 的调用，那么该调用总会自动重新
//      启动。如果一个信号处理函数中断了对 pthread_cond_wait() 的调用，则该调用要么
//      自动重新启动（Linux 就是如此），那么返回0表示遭遇了假唤醒，此时设计良好的程序
//      会重新检查相应的判断条件并重新发起调用。SUSv3 对这两个函数的行为要求与此处的
//      描述一致。
//  8.  备选信号栈式每个线程特有的，新创建的线程并不从创建线程处继承备选信号栈。更确切
//      地说，SUSv3 规定每个内核调用实体（KSE）都有一个单独的备选信号栈。在按 1:1 实
//      现线程的系统中（例如Linux）每一个线程对应一个 KSE。
//
// 妥善处理异步信号，信号的各种因素，诸如可重入问题、系统调用中断的重启、以及避免竞争条
// 件，当使用信号处理函数对异步产生的信号加以处理时，这些都将导致情况变得复杂。另外，没
// 有任何 pthread 函数属于异步信号安全的，pthread 函数均无法在信号处理函数中安全调用。
// 因为这些原因，所以当多线程应用程序必须处理异步产生的信号时，通常不应该将信号处理函数
// 作为接收信号的通知机制，而推荐使用如下方法：
//  1.  所有线程都阻塞进程可能接收的所有异步信号，最简单的方法是在创建任何其他线程之前，
//      由主线程阻塞这些先后，后续创建的每个线程都会继承主线程信号掩码的一份拷贝。
//  2.  再创建一个专用线程，调用 sigwaitinfo() sigtimedwait() sigwait() 来接收收到
//      的信号。函数 sigwait() 会等待 set 所指向的信号集合中的任意一个信号的到达，接
//      收该信号，且在参数 sig 中将其返回。如有多个线程在调用 sigwait() 等待同一信号，
//     那么当信号到达时只有一个线程会实际接收到，也无法确定收到信号的会时哪个线程。
//
// 这一方法的优势在于，同步接收异步产生的信号。当接收到信号时，专有线程可以安全地在互斥
// 量的保护下修改共享变量，并可调用非异步信号安全的函数。也可以就条件变量发出信号，并采
// 用其他线程或进程的通讯及同步机制。可以构建一个简单的 sigwait_multiple() 例程来实现
// 多个线程等待同一个信号。可能的实现是让每个 sigwait_multiple() 调用者注册对一组信号
// 的兴趣。然后，调用者等待线程特定的条件变量。一个单独的服务线程对所有注册信号的并集调
// 用 sigwait() 函数。当 sigwait() 函数返回时，设置适当的状态并广播条件变量。新的
// sigwait_multiple() 调用者可能会导致挂起的 sigwait() 调用被取消并重新发出，以更新
// 正在等待的信号集。
//
// 不是同步的信号都是异步信号，同步信号是与当前正在执行的线程或进程相关的信号，例如当
// 前执行线程执行当前指令触发的硬件异常信号，就是同步信号，硬件异常信号可以由当前执行
// 线程直接调用进程注册的信号处理函数进行处理。另一种同步信号是当前执行线程调用函数
// kill() killpg() raise() 向进程自己发送的信号，或者调用 pthread_kill() 以及
// pthread_sigqueue() 向线程自己发送的信号，也是同步的，这些信号也会在产生的地方直接
// 进行传递，也即如果阻塞直接挂到当前线程中，如果未阻塞会直接调用处理函数。因为这些自
// 己发送的信号也可能异步产生，因此也可以通过上面推荐的方式进行处理。同步产生的信号会
// 立即传递，直接触发信号处理函数的调用，在调用返回前就已经执行了处理函数。
// 其他信号都是异步的，包括调用 kill() killpg() 向其他进程发送的信号，pthread_kill()
// pthread_sigqueue() 向当前进程其他线程发送的信号，这些信号只能等待对应线程的下一个
// CPU 时间片开始执行。即当异步产生一个信号时，即使并未将其阻塞，在信号产生和实际传递
// 之间仍可能存在一个瞬时延迟，在此期间，信号处于等待状态。这是因为内核将等待信号传递给
// 进程的时机是，该进程中的线程正在执行，且发生由内核态到用户态的下一次切换时。
//
// sigwaitinfo() 怎么处理进程中共享的挂起信号？如果进程中有挂起的信号，并且同时有多个
// 线程调用 sigwaitinfo() 在等待，每个挂起的信号都会选择其中一个线程来处理。另外每个
// 线程自己挂起的信号，只能通过自己调用 sigwaitinfo() 来处理。但是如果没有人调用
// pthread_kill() 或 pthread_sigqueue() 给线程发送信号，那么只需要在主线程执行
// sigwaitinfo() 也是可行的，因为所有信号都属于进程所有。
//
// 线程和进程控制。与信号机制类似，exec() fork() exit() 的问世均早于 pthreads，以下
// 是在多线程程序中使用此类系统调用需要注意的问题。线程和exec()，只要有任一线程调用了
// exec() 系列函数之一，调用程序将被完全替换，除了调用 exec() 的线程除外，其他所有线程
// 都将立即消失。没有任何线程会针对线程持有数据执行析构，也不会调用清理函数。该进程的所
// 有互斥量（为进程私有）和属于进程的条件变量都会消失。调用 exec() 之后，调用线程的线程
// ID 是不确定的。线程与exit()，如果任何线程调用了exit()，或者主线程执行了 return，那
// 么所有线程都将消失，也不会执行线程特有数据的析构以及清理函数。
//
// 线程和fork()，当多线程进程调用 fork() 时，仅会将发起调用的线程复制到子进程中，子进
// 程中该线程的线程ID与父进程中发起 fork() 调用的线程ID一致。其他线程均在子进程中消失，
// 也不会为这些线程调用清理函数以及针对线程特有数据的析构。这将导致以下一些问题：
//  1.  虽然将发起调用的线程复制到子进程中，但全局变量的状态以及所有的 pthreads 对象，
//      如互斥量、条件变量等，都会在子进程中得以保留。因为在父进程中为这些 pthreads 对
//      象分配了内存，而子进程则获得了该内存的一份拷贝。这回导致很棘手的问题。例如，假
//      设在调用 fork() 时，另一线程已经锁定了某一互斥量，且对某一全局数据结构的更新也
//      做了一半。此时子进程中的线程无法解锁这一互斥量，因为其并非该互斥量的属主，如果
//      试图获取这一互斥量，线程会遭阻塞。此外，子进程中的全局数据拷贝可能也处于不一致
//      状态，因为对其进行更新的线程在执行到一半时就消失了。
//  2.  因为并未执行清理函数和针对线程持有数据的析构，多线程程序的 fork() 调用会导致子
//      进程的内存泄露。另外，子进程中的线程很可能无法访问父进程中由其他线程所创建的线
//      程特有数据项，因为子进程没有相应的引用指针。
//
// 由于这些问题，推荐在多线程程序中调用 fork() 的唯一情况是：其后紧跟对 exec() 的调用，
// 因为新程序会覆盖原有内存，exec() 将导致子进程的所有 pthreads 对象消失。对于那些必须
// 执行 fork()，而其后又无 exec() 跟随的程序来说，pthreads 提供了一种机制：fork 处理
// 函数。可以利用 pthread_atfork() 来创建 fork 处理函数：
//      pthread_atfork(prepare_func, parent_func, child_func);
// 每一次 pthread_atfork() 调用都会将 prepare_func 添加到一个函数列表中，在调用 fork
// 创建新的子进程之前，会按注册次序相反的顺序自动执行该函数列表中的函数。与之类似，会将
// parent_func 和 child_func 添加到一函数列表中，在 fork() 返回前，将分别在父、子进
// 程中按注册顺序自动运行。在使用线程的库函数时，有时候 fork 处理函数很实用。如果没有这
// 一机制，对于那些随意调用了此函数库和fork()，又对函数库创建的其他线程一无所知的应用程
// 序，函数库真就是无计可施。
//
// 调用 fork() 所产生的子进程从调用 fork() 的线程处继承 fork 处理函数。执行 exec()
// 期间，fork 处理函数将不再保留，因为处理函数的代码会在执行 exec() 的过程中遭到覆盖。
// 在 Linux 上，如果使用 NPTL 线程库的程序执行了 vfork()，那么将不再调用 fork 处理
// 函数。不过，在使用 LinuxTHreads 程序的同一种情况下却有效。
#include <sys/types.h>
#include <pthread.h>
#include <signal.h>

void prh_impl_prerr_sigpipe_sigxfsz(int i, bool kernel) {
    const char *s = "SIGPIPE\0SIGXFSZ";
    fprintf(stderr, "%s from %s\n", s + i * 8, kernel ? "kernel" : "user");
}

void prh_impl_prerr_sigsys(void *calladdr, int err) {
    fprintf(stderr, "SIGSYS %p errno %d\n", calladdr, err);
}

void prh_impl_prerr_sigsegv(int i, void *calladdr) {
    const char *s = "SEGERR\0 MAPERR\0 ACCERR\0 BNDERR";
    fprintf(stderr, "SIGSEGV %p %s\n", calladdr, s + i * 8);
}

void prh_impl_prerr_sigbus(int i, void *calladdr) {
    const char *s = "BUSERR\0 ADRALN\0 ADRERR\0 OBJERR\0 MCEERR";
    fprintf(stderr, "SIGBUS %p %s\n", calladdr, s + i * 8);
}

void prh_impl_prerr_sigill(int i, void *calladdr) {
    const char *s = "ILLERR\0 ILLOPC\0 ILLOPN\0 ILLADR\0 ILLTRP\0 PRVOPC\0 OPVREG\0 COPROC\0 BADSTK";
    fprintf(stderr, "SIGILL %p %s\n", calladdr, s + i * 8);
}

void prh_impl_prerr_sigfpe(int i, void *calladdr) {
    const char *s = "FPEERR\0 INTDIV\0 INTOVF\0 FLTDIV\0 FLTOVF\0 FLTUND\0 FLTRES\0 FLTINV\0 FLTSUB";
    fprintf(stderr, "SIGFPE %p %s\n", calladdr, s + i * 8);
}

#if defined(SIGEMT)
void prh_impl_prerr_sigemt(int code, void *calladdr) {
    fprintf(stderr, "SIGEMT %p code %d\n", calladdr, code);
}
#endif

void prh_impl_sighw_action(int sig, siginfo_t *info, void *ucontext) {
    // SUSv3 规定，在硬件异常的情况下，如果进程从此类信号处理函数中返回，亦或进程忽略
    // 或阻塞了此类信号，那么进程的行为未定义。当由于硬件异常而产生上述信号之一时，Linux
    // 会强制传递信号，即使程序已经请求忽略此类信号。Linux 2.4 以及更早版本中，其内核
    // 会将阻塞硬件产生信号的企图忽略，信号无论如何都会传递给进程，随后要么进程终止，要
    // 么信号被信号函数处理。Linux 2.6 之后，如果信号预定阻塞，那么该信号总是会立刻杀
    // 死进程，即使进程已经为此信号设置了处理函数。对于因硬件而产生的信号，Linux 2.6
    // 之所以会改变对其处于阻塞状态下的处理方式，是由于 Linux 2.4 的行为中隐藏有缺陷，
    // 并可能在多线程中引起死锁。正确处理硬件产生的信号的方法有：要么接受信号的默认行
    // 为，即进程终止；要么为其编写不会正常返回的处理函数。
    //
    // 有六种信号因硬件异常而触发：SIGBUS、SIGEMT、SIGFPE、SIGILL、SIGSEGV 和
    // SIGTRAP。然而，对于任何特定的硬件异常，具体会触发哪种信号并没有明确的文档说明，
    // 且在某些情况下显得并不合理。例如，某些 CPU 架构上非法的内存访问会触发 SIGSEGV，
    // 而在另一些架构上可能触发 SIGBUS，反之亦然。再比如，在 x86 架构中，使用 int 指
    // 令时传递了非法参数（除了 3 或 128 之外的任何数字），会触发 SIGSEGV，尽管在这种
    // 情况下 SIGILL 似乎更合适，因为这是 CPU 向内核报告非法操作指令的方式。
    //
    // SIGSEGV 可能因线程栈耗尽触发，因此这种情况下的硬件异常不会有机会执行到这个处理
    // 函数中来打印该信号的详细信息。
    int si_code = info->si_code;
    int code = 0;
    // psiginfo(info, prh_null);
    if (sig == SIGSEGV) {
        switch (si_code) {
            case SEGV_MAPERR: code = 1; break; // 无效地址映射
            case SEGV_ACCERR: code = 2; break; // 非法访问权限
#if defined(SEGV_BNDERR)
            case SEGV_BNDERR: code = 3; break; // 地址边界检查失败
#endif
        }
        prh_impl_prerr_sigsegv(code, info->si_addr);
    } else if (sig == SIGBUS) {
        switch (si_code) {
            case BUS_ADRALN: code = 1; break; // 地址未对齐
            case BUS_ADRERR: code = 2; break; // 物理地址不存在
            case BUS_OBJERR: code = 3; break; // 对象特定的硬件错误
#if defined(BUS_MCEERR_AR) && defined(BUS_MCEERR_AO)
            case BUS_MCEERR_AR: case BUS_MCEERR_AO: code = 4; break; // 硬件内存校验错误
#elif defined(BUS_OOMERR)
            case BUS_OOMERR: code = 4; break; // 不能分配内存页映射
#endif
        }
        prh_impl_prerr_sigbus(code, info->si_addr);
    } else if (sig == SIGILL) {
        switch (si_code) {
            case ILL_ILLOPC: code = 1; break; // 非法操作码
            case ILL_ILLOPN: code = 2; break; // 非法操作数
            case ILL_ILLADR: code = 3; break; // 非法寻址方式
            case ILL_ILLTRP: code = 4; break; // 非法陷阱
            case ILL_PRVOPC: code = 5; break; // 非法特权操作码
            case ILL_PRVREG: code = 6; break; // 非法特权寄存器
            case ILL_COPROC: code = 7; break; // 协处理器错误
            case ILL_BADSTK: code = 8; break; // 内部栈错误
        }
        prh_impl_prerr_sigill(code, info->si_addr);
    } else if (sig == SIGFPE) {
        switch (si_code) {
            case FPE_INTDIV: code = 1; break; // 整数除零
            case FPE_INTOVF: code = 2; break; // 整数溢出
            case FPE_FLTDIV: code = 3; break; // 浮点除零
            case FPE_FLTOVF: code = 4; break; // 浮点溢出
            case FPE_FLTUND: code = 5; break; // 浮点下溢
            case FPE_FLTRES: code = 6; break; // 结果不精确
            case FPE_FLTINV: code = 7; break; // 无效操作
            case FPE_FLTSUB: code = 8; break; // 下标越界
        }
        prh_impl_prerr_sigfpe(code, info->si_addr);
    }
#if defined(SIGEMT)
    else
    {
        prh_impl_prerr_sigemt(si_code, info->si_addr);
    }
#endif
    abort(); // 硬件异常处理函数不能从处理函数中返回，产生核心文件并终止程序
}

void prh_impl_sigsys_action(int sig, siginfo_t *info, void *ucontext) {
    // si_call_addr si_syscall 字段在老版本或非 Linux 平台上可能不存在
    prh_impl_prerr_sigsys(info->si_addr, info->si_errno);
    // 当进程收到信号而终止时，将不会调用退出处理函数，此时最佳的应对方式是为可能发送
    // 给进程的信号建立信号处理函数，并于其中设置标志位，令主程序据此来调用 exit()，
    // 因为 exit() 不属于异步信号安全函数。即便如此，还是无法处理SIGKILL信号，因为无
    // 法改变SIGKILL的默认行为。这也是应该避免使用SIGKILL来终止进程的另一原因。建议
    // 使用SIGTERM，这也是kill命令默认发送的信号。
    prh_zeroret(raise(SIGTERM)); // 终止进程
}

void prh_impl_sigpipe_sigxfsz_action(int sig, siginfo_t *info, void *ucontext) {
    // 当线程试图对已断开的管道进行写操作时所产生的 SIGPIPE 信号，也是属于线程的同步
    // 信号。另外，当服务器进程终止时会关闭所有打开的文件描述符，这会导致向客户端发送
    // FIN，而客户端TCP响应ACK，这就是TCP连接终止工作的前半部分。如果此时客户不理会
    // 读取数据时返回的错误，反而写入更多的数据到服务器上会发生什么呢？这种情况是可能
    // 发生的，例如客户可能在读回任何数据之前执行两次针对服务器的写操作，而第一次写引
    // 发了RST。而当一个进程向某个已收到RST的套接字执行写操作时，内核会向该进程发送一
    // 个SIGPIPE信号。该信号的默认行为是终止进程，因此进程必须捕获以免不情愿的终止。
    // 不论该进程是捕获该信号并从其信号处理函数返回，还是简单地忽略该信号，写操作都将
    // 返回EPIPE错误。
    //
    // 一个在Usenet上常被问及的问题是如何在第一次写操作而不是在第二次写操作时捕获该信
    // 号。这是不可能的，第一次写操作引发 RST，第二次写引发 SIGPIPE 信号。因为写一个
    // 已接收了 FIN 的套接字不成问题，但写一个已接收了 RST 的套接字是一个错误。处理
    // SIGPIPE 的建议方法取决于它发生时应用进程想做什么。如果没有特殊的事情要做，那么
    // 将信号处理方法直接设置为 SIG_IGN，并假设后续的输出操作将检查 EPIPE 错误并终止。
    // 如果信号出现时需采取特殊措施（可能需要在日志文件中记录），那么就必须捕获该信号，
    // 以便在信号处理函数中执行所有期望的动作。但是必须意识到，如果使用了多个套接字，该
    // 信号的递交无法告诉我们是哪个套接字出错。如果我们确实需要知道是哪个写操作出错，那
    // 还是需要在信号处理函数返回后再处理 EPIPE 错误。
    if (sig == SIGPIPE) {
        prh_impl_prerr_sigpipe_sigxfsz(0, info->si_code == SI_KERNEL);
    } else {
        // 不终止进程让主程序检查 EFBIG 错误
        prh_impl_prerr_sigpipe_sigxfsz(1, info->si_code == SI_KERNEL);
    }
}

void prh_set_sigaction(int sig, void (*action)(int sig, siginfo_t *siginfo, void *ucontext)) {
    struct sigaction sa; // 信号处理函数是属于进程的属性
    prh_zeroret(sigfillset(&sa.sa_mask));
    sa.sa_flags = SA_SIGINFO;
    sa.sa_sigaction = action;
    prh_zeroret(sigaction(sig, &sa, prh_null));
}

void prh_ign_sigaction(int sig) {
    struct sigaction sa;
    prh_zeroret(sigemptyset(&sa.sa_mask));
    sa.sa_flags = 0;
    sa.sa_handler = SIG_IGN;
    prh_zeroret(sigaction(sig, &sa, prh_null));
}

void prh_main_sigaction(void) {
    // （1）终端信号，保持默认行为，关注时注册处理函数处理即可
    // SIGHUP              终端断开或挂起                               term（终止进程）
    // SIGINT              终端中断                                    term（终止进程）
    // SIGQUIT             终端退出                                    core（产生核心转储文件，并终止进程）
    // SIGTSTP             终端停止                                    stop（停止进程）
    // SIGTTIN             终端被后台进程读取                           stop（停止进程）
    // SIGTTOU             终端被后台进程写入                           stop（停止进程）
    // SIGWINCH            终端窗口尺寸变化                             ignore（忽略该信号，内核将默默丢弃）
    //
    // (2) 基本不能干预的信号，无需特别处理的信号，可在用到时再去关注的信号
    // SIGKILL SIGSTOP     不能干预的信号
    // SIGCONT             基本不能干预                                cont（恢复一个已停止的进程）
    // SIGTERM             终止进程                                    term（终止进程）
    // SIGCHLD SIGCLD      子进程状态变化                              ignore（忽略该信号）
    // SIGURG              套接字上有紧急数据                          ignore（老版本可能终止进程）
    // SIGIO SIGPOLL       输入输出事件                                term（Linux），ignore（某些UNIX）
    // SIGPWR              电量即将耗尽                                term（Linux），ignore（某些UNIX）
    // SIGINFO             同SIGPWR（Linux），前台进程信息（某些UNIX）   term（终止进程）
    // SIGUSR1 SIGUSR2     用户自定义信号                              term（终止进程）
    // SIGALRM             实时定时器到期                              term（终止进程）
    // SIGVTALRM           虚拟定时器到期                              term（终止进程）
    // SIGPROF             性能定时器到期                              term（终止进程）
    // SIGSTKFLT           协处理器错误                                term（终止进程）
    // SIGLOST             未使用或NFS客户端文件锁丢失                  term（终止进程）
    // SIGXCPU             超出CPU时间限制                             term（可能产生核心转储文件）
    // SIGABRT             中止进程，来源于abort(3)                     core（产生核心转储文件，并终止进程），即使设置了处理函数，当处理函数返回到 abort() 后，abort() 会触发执行默认行为终止进程
    // SIGIOT              同SIGABRT（Linux），硬件错误（某些UNIX）      core（产生核心转储文件，并终止进程）
    // SIGTRAP             跟踪或断点陷阱                              core（产生核心转储文件，并终止进程），陷阱一般用于跟踪和调整，
    //
    // (3) 比较重要的信息，注册处理函数打印信号信息，应该程序如需特别处理可注册新的处理函数
    // SIGBUS SIGSEGV SIGILL SIGFPE SIGEMT                            硬件异常信号，处理函数不能正常返回
    // SIGSYS              无效系统调用                                term（可能产生核心转储文件），在处理函数中退出程序
    // SIGUNUSED           未使用或与SIGSYS相同                        core（产生核心转储文件，并终止进程）
    // SIGPIPE             管道断开，写入没有读取端的管道                term（终止进程），不终止进程让主程序检查 EPIPE
    // SIGXFSZ             超出文件大小限制                            term（可能产生核心转储文件），不终止进程让主程序检查 EFBIG
    int sighw[] = {
        SIGBUS, SIGSEGV, SIGILL, SIGFPE,
#if defined(SIGEMT)
        SIGEMT
#endif
    };
    for (int i = 0; i < prh_array_size(sighw); i += 1) {
        prh_set_sigaction(sighw[i], prh_impl_sighw_action); // 处理函数不能正常返回
    }
    prh_set_sigaction(SIGSYS, prh_impl_sigsys_action); // 在处理函数中退出程序
    // 当线程试图对已断开的管道进行写操作时会产生属于线程的 SIGPIPE 信号，而 SIGPIPE
    // 默认行为是终止进程。合适的做法是执行自己的处理函数，而不走默认的终止进程的行为。
    // 让应用程序走检查 EPIPE 错误的流程。
    prh_set_sigaction(SIGPIPE, prh_impl_sigpipe_sigxfsz_action);
    // RLIMIT_FSIZE，这是进程可以创建的文件的最大字节大小。尝试将文件扩展到此限制之外
    // 会导致发送 SIGXFSZ 信号。默认情况下此信号会终止进程，但进程可以选择捕获此信号。
    // 在这种情况下，相关的系统调用（例如 write(2)、truncate(2)）将因 EFBIG 错误而
    // 失败。
    prh_set_sigaction(SIGXFSZ, prh_impl_sigpipe_sigxfsz_action);
    // 忽略紧急数据，避免应用程序使用TCP紧急机制可能是避免TCP“紧急数据”安全隐患的最佳方式
    prh_ign_sigaction(SIGURG);
}

#if defined(prh_plat_linux) || defined(prh_plat_freebsd) || defined(prh_plat_netbsd)
#define PRH_IMPL_SIGTIMEDWAIT_SUPPORT 1
#else
#define PRH_IMPL_SIGTIMEDWAIT_SUPPORT 0
#endif

#if PRH_IMPL_SIGTIMEDWAIT_SUPPORT
void prh_impl_sig_mask_set(sigset_t *sigset) {
    prh_zeroret(sigfillset(sigset));
    int signob[] = {SIGTSTP, SIGTTIN, SIGTTOU, SIGKILL, SIGSTOP, SIGCONT};
    for (int i = 0; i < prh_array_size(signob); i += 1) {
        prh_zeroret(sigdelset(sigset, signob[i]));
    }
    int sigsync[] = {
        SIGBUS, SIGSEGV, SIGILL, SIGFPE,
#if defined(SIGEMT)
        SIGEMT,
#endif
        SIGSYS, SIGPIPE, SIGXFSZ
    };
    for (int i = 0; i < prh_array_size(sigsync); i += 1) {
        prh_zeroret(sigdelset(sigset, sigsync[i]));
    }
}
#endif

void prh_main_set_sigmask(void) {
#if PRH_IMPL_SIGTIMEDWAIT_SUPPORT
    sigset_t sigset;
    prh_impl_sig_mask_set(&sigset);
    // 只需主线程在创建新线程之前设置信号掩码，之后新创建的线程都会自动继承这些信号掩码
    prh_zeroret(pthread_sigmask(SIG_SETMASK, &sigset, prh_null));
#endif
}

int prh_thrd_signal_poll(const sigset_t *set, siginfo_t* info) {
#if PRH_IMPL_SIGTIMEDWAIT_SUPPORT
    // https://www.man7.org/linux/man-pages/man2/sigwaitinfo.2.html
    // https://www.man7.org/linux/man-pages/man3/sigtimedwait.3p.html
    // int sigwaitinfo(const sigset_t *set, siginfo_t*info);
    // int sigtimedwait(const sigset_t *set, siginfo_t *info, const struct timespec *timeout);
    // 成功返回信号编号（正数），失败返回-1和errno，EAGAIN 没有信号在挂起状态，EINTR
    // 系统调用被信号处理函数中断（不是信号集 set 中的信号）或被进程停止后继续执行打断，
    // EINVAL 非法参数 timeout。
    struct timespec timeout = {0}; // 不等待只检查当前是否已经有挂起的信号需要处理
    sigset_t sigset;
    int sig;
    if (set == prh_null) {
        prh_impl_sig_mask_set(&sigset);
        set = &sigset;
    }
label_continue:
    if ((sig = sigtimedwait(set, info, &timeout)) > 0) {
        return sig;
    }
    if (sig == -1 && errno == EINTR) {
        goto label_continue;
    }
    return 0;
#else
    return 0;
#endif
}

// 互斥量类型，PTHREAD_MUTEX_NORMAL 不具死锁自检功能，线程加锁已经由自己锁定的互斥量
// 会发生死锁，线程解锁未锁定的或由其他线程锁定的互斥量会导致不确定的结果，但在Linux上
// 对这类互斥量的这两种操作都会成功。
//
// PTHREAD_MUTEX_ERRORCHECK 会对上述情况进行错误检查并返回相关错误，这类互斥量运行起
// 来比一般类型要慢，不过可将其作为调试工具，已发现程序在哪里违反了互斥量使用的基本原
// 则。
//
// PTHREAD_MUTEX_RECURSIVE 递归互斥量维护由一个锁计数器，同一线程重复锁定会增加锁计
// 数，当解锁时会递减计数只有当锁计数器值降至0时才会释放该互斥量，解锁时如果互斥量处于
// 未锁定状态或已由其他线程锁定，则操作会失败。
//
// 如果互斥量不设置pthread_mutexattr_setrobust(&attr, PTHREAD_MUTEX_ROBUST)，当线
// 程在解锁之前异常退出，互斥锁将保持锁定状态导致死锁。
//
// 条件变量总是结合互斥量使用，条件变量就共享变量的状态改变发出通知，而互斥量则提供该
// 共享变量访问的互斥。

struct prh_mutex {
    pthread_mutex_t mutex;
};

struct prh_thrd_cond {
    pthread_mutex_t mutex; // 1st field
    pthread_cond_t cond;
};

struct prh_thrd_sem {
    pthread_mutex_t mutex; // 1st field
    pthread_cond_t cond; // 2nd field
    prh_int wakeup_semaphore;
};

struct prh_cond_sleep {
    pthread_mutex_t mutex; // 1st field
    pthread_cond_t cond; // 2nd field
    prh_atom_bool wakeup_semaphore;
};

int prh_mutex_size(void) {
    return (int)sizeof(prh_mutex);
}

int prh_impl_thrd_cond_size(void) {
    return (int)sizeof(prh_thrd_cond);
}

int prh_impl_thrd_sem_size(void) {
    return (int)sizeof(prh_thrd_sem);
}

int prh_impl_thrd_sleep_size(void) {
    return (int)sizeof(prh_cond_sleep);
}

void prh_mutex_init(prh_mutex *p) {
    prh_zeroret(pthread_mutex_init(&p->mutex, prh_null));
}

void prh_recursive_mutex_init(prh_mutex *p) {
    pthread_mutexattr_t attr;
    prh_zeroret(pthread_mutexattr_init(&attr));
    prh_zeroret(pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE));
    prh_zeroret(pthread_mutex_init(&p->mutex, &attr));
    prh_zeroret(pthread_mutexattr_destroy(&attr));
}

void prh_mutex_free(prh_mutex *p) {
    prh_zeroret(pthread_mutex_destroy(&p->mutex));
}

prh_mutex *prh_mutex_init(void) {
    prh_mutex *p = prh_malloc(sizeof(prh_mutex));
    prh_mutex_init(p);
    return p;
}

prh_mutex *prh_recursive_mutex_init(void) {
    prh_mutex *p = prh_malloc(sizeof(prh_mutex));
    prh_recursive_mutex_init(p);
    return p;
}

void prh_mutex_free(prh_mutex *p) {
    prh_mutex_free(p);
    prh_free(p);
}

void prh_mutex_enter(prh_mutex *p) {
    prh_zeroret(pthread_mutex_lock(&p->mutex));
}

bool prh_mutex_try_enter(prh_mutex *p) {
    int n = pthread_mutex_trylock(&p->mutex);
    if (n == 0) return true;
    if (errno != EBUSY) prh_abort_error(errno);
    return false;
}

void prh_mutex_exit(prh_mutex *p) {
    prh_zeroret(pthread_mutex_unlock(&p->mutex));
}

// It is advised that an application should not use a PTHREAD_MUTEX_RECURSIVE
// mutex with condition variables because the implicit unlock performed for
// a pthread_cond_timedwait() or pthread_cond_wait() may not actually release
// the mutex (if it had been locked multiple times). If this happens, no other
// thread can satisfy the condition of the predicate.

void prh_impl_thrd_cond_init(prh_thrd_cond *p) {
    prh_mutex_init((prh_mutex *)p);
    prh_zeroret(pthread_cond_init(&p->cond, prh_null));
}

void prh_impl_thrd_cond_free(prh_thrd_cond *p) {
    // 仅当没有任何线程等待条件变量，将其销毁才是安全的，经销毁的条件变量之后可以调用
    // pthread_cond_init() 对其进行重新初始化。
    prh_mutex_free((prh_mutex *)p);
    prh_zeroret(pthread_cond_destroy(&p->cond));
}

prh_thrd_cond *prh_thrd_cond_init(void) {
    prh_thrd_cond *p = prh_malloc(sizeof(prh_thrd_cond));
    prh_impl_thrd_cond_init(p);
    return p;
}

void prh_thrd_cond_free(prh_thrd_cond *p) {
    // 仅当没有任何线程等待条件变量，将其销毁才是安全的，经销毁的条件变量之后可以调用
    // pthread_cond_init() 对其进行重新初始化。
    prh_impl_thrd_cond_free(p);
    prh_free(p);
}

// 互斥量必须在当前线程锁定的情况下调用该函数，该函数在进入休眠前会自动解锁互斥
// 量。当线程被唤醒该函数返回时，会自动用当前线程锁定互斥量。
// 条件变量的一个通用设计原则：必须由一个while循环而不是if来控制对pthread_cond_wait()
// 的调用，这是因为当代码从pthread_cond_wait()返回时并不能确定判断条件的状态，所
// 以应该立即重新检查判断条件，在条件不满足的情况下继续休眠等待。
// 从pthread_cond_wait()返回时，之所以不能对判断条件的状态做任何假设，是因为：
// 1. 其他线程可能会率先醒来，也许有多个线程在等待获取与条件变量相关的互斥量。即使
//    就互斥量发出通知的线程将判断条件置为预期状态，其他线程依然有可能率先获取互斥
//    量并改变相关共享变量的状态，进而改变判断条件的状态。
// 2. 设计时设置宽松的判断条件或许更为简单，有时用条件变量来表征可能性而非确定性在
//    设计应用程序时会更为简单。换言之就条件变量发送信号意味着可能有些事情需要接收
//    信号的信号去响应，而不是一定有一些事情要做。适用这种方法，可以基于判断条件的
//    近似情况来发送条件变量通知，接收信号的线程可以通过再次检查判断条件来确定是否
//    需要做些什么。
// 3. 可能会发生虚假唤醒的情况，在一些实现中即使没有任何其他线程真地就条件变量发出
//    信号，等待此条件变量的线程仍有可能醒来。在一些多处理器系统上，为确保高效实现
//    而采用的技术会导致此类不常见的虚假唤醒。
// 线程等待条件变量的步骤：
// 1. pthread_mutex_lock
// 2. ... operation before wait ...
// 3. while condition not meet
// 4.   pthread_mutex_unlock and enter sleep
// 5.   wakeup and pthread_mutex_lock (may block if other thread hold lock)
// 6. mutex locked and condition meet
// 7. ... operation after wait ...
// 8. pthread_mutex_unlock

void prh_thrd_cond_lock(prh_thrd_cond *p) {
    prh_mutex_enter((prh_mutex *)p);
}

// pthread_cond_wait() pthread_cond_timedwait()
//
// 如果一个信号被传递给正在等待条件变量的线程，那么当信号处理程序返回后，该线程将继续
// 等待该条件变量，就好像它从未被中断过一样；或者，由于虚假唤醒（spurious wakeup），
// 它可能返回零。如果一个信号处理函数中断了对 pthread_cond_wait() 的调用，则该调用要
// 么自动重新启动（Linux 就是如此），那么返回 0 表示遭遇了假唤醒，此时设计良好的程序
// 会重新检查相应的判断条件并重新发起调用。这些函数不应返回 EINTR 错误码。
//
// 如果在条件变量 cond 被触发（signal）或广播（broadcast）之前，abstime 指定的绝对
// 时间已经到达（即系统时间等于或超过 abstime），或在调用时 abstime 指定的绝对时间已
// 经过去，则函数将返回一个错误 ETIMEDOUT。

void prh_impl_plat_cond_wait(prh_thrd_cond *p) {
    // pthread_cond_wait() 和 pthread_cond_timedwait() 都不会因为 EINTR 而返回
    prh_zeroret(pthread_cond_wait(&p->cond, &p->mutex));
}

bool prh_impl_plat_cond_timedwait(prh_thrd_cond *p, prh_ptr time) {
    int n = pthread_cond_timedwait(&p->cond, &p->mutex, (struct timespec *)time);
    if (n == 0) return true; // 线程被成功唤醒或被虚假唤醒
    if (n != ETIMEDOUT) prh_abort_error(n); // 线程要么被唤醒，要么等待超时，其他情况不应该发生
    return false; // 线程等待超时
}

prh_ptr prh_impl_plat_cond_time(prh_i64 *ptr, prh_u32 msec) {
    prh_i64 system_abstime = prh_system_msec() + msec; // u32 msec 最大可表示48天
    struct timespec *ts = (struct timespec *)ptr;
    ts->tv_sec = (time_t)(system_abstime / 1000);
    ts->tv_nsec = (int)((system_abstime % 1000) * 1000000);
    return (prh_ptr)ts;
}

void prh_thrd_cond_unlock(prh_thrd_cond *p) {
    prh_mutex_exit((prh_mutex *)p);
}

// The pthread_cond_broadcast() function shall wakeup all threads currently
// blocked on the specified condition variable cond.
// The pthread_cond_signal() function shall wakeup at least one of the
// threads that are blocked on the specified condition variable cond (if
// any threads are blocked on cond).
// If more than one thread is blocked on a condition variable, the scheduling
// policy shall determine the order in which threads are unblocked.
// The pthread_cond_broadcast() and pthread_cond_signal() functions shall
// have no effect if there are no threads currently blocked on cond.

void prh_thrd_cond_signal(prh_thrd_cond *p) {
    // 唤醒至少一个等待的线程，比broadcast更高效。应用这种方式的典型情况是，所有等待
    // 的线程都在执行完全相同的任务。这种情况下，可以避免唤醒所有等待的线程，然后某一
    // 线程获得调度，此线程检查了共享变量的状态（在相关互斥量的保护下），发现有任务需
    // 要完成并执行所需工作并改变共享变量状态，最后释放对相关互斥量的锁定。如果唤醒了
    // 多余的线程，会额外轮流等待锁定互斥量然后检测共享变量的状态，不过由于第一个线程
    // 已经完成了工作这些多余的线程会发现无事可做，随即解锁互斥量继续休眠。
    prh_zeroret(pthread_cond_signal(&p->cond));
}

void prh_thrd_cond_broadcast(prh_thrd_cond *p) {
    // 唤醒所有等待的线程，通常适用的情况是处于等待状态的所有线程执行的任务不同，其各
    // 自关联于条件变量的判定条件不同。条件变量并不保存变量，只是传递应用程序状态信息
    // 的一种通讯机制。发送信号时若无任何线程在等待该条件变量，这个信号也就会不了了
    // 之，线程如果在此后等待该条件变量，只有当再次收到此条件变量的下一信号时才能解除
    // 阻塞状态。
    prh_zeroret(pthread_cond_broadcast(&p->cond));
}

void prh_impl_thrd_sem_init(prh_thrd_sem *p) {
    prh_impl_thrd_cond_init((prh_thrd_cond *)p);
    p->wakeup_semaphore = 0;
}

void prh_impl_thrd_sem_free(prh_thrd_sem *p) {
    prh_impl_thrd_cond_free((prh_thrd_cond *)p);
}

prh_thrd_sem *prh_thrd_sem_init(void) {
    prh_thrd_sem *p = prh_malloc(sizeof(prh_thrd_sem));
    prh_impl_thrd_sem_init(p);
    return p;
}

void prh_thrd_sem_free(prh_thrd_sem *p) {
    prh_impl_thrd_sem_free(p);
    prh_free(p);
}

void prh_thrd_sem_wait(prh_thrd_sem *p) {
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    while (p->wakeup_semaphore == 0) {
        prh_impl_plat_cond_wait((prh_thrd_cond *)p);
    }
    p->wakeup_semaphore -= 1;
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
}

void prh_thrd_sem_post(prh_thrd_sem *p, int new_semaphores) {
    assert(new_semaphores > 0);
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    p->wakeup_semaphore += new_semaphores;
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
    if (new_semaphores == 1) { // one semaphore available, can wakeup one thread to handle
        prh_thrd_cond_signal((prh_thrd_cond *)p);
    } else { // multi semaphore available, all thread can racing to handle them
        prh_thrd_cond_broadcast((prh_thrd_cond *)p);
    }
}

void prh_impl_init_cond_sleep(prh_cond_sleep *p) {
    prh_impl_thrd_cond_init((prh_thrd_cond *)p);
    prh_atom_bool_init(&p->wakeup_semaphore, false);
}

void prh_impl_free_cond_sleep(prh_cond_sleep *p) {
    prh_impl_thrd_cond_free((prh_thrd_cond *)p);
}

prh_cond_sleep *prh_init_cond_sleep(void) {
    prh_cond_sleep *p = prh_malloc(sizeof(prh_thrd_cond));
    prh_impl_init_cond_sleep(p);
    return p;
}

void prh_free_cond_sleep(prh_cond_sleep *p) {
    // 仅当没有任何线程等待条件变量，将其销毁才是安全的，经销毁的条件变量之后可以调用
    // pthread_cond_init() 对其进行重新初始化。
    prh_impl_free_cond_sleep(p);
    prh_free(p);
}

bool prh_thrd_try_sleep(prh_cond_sleep *p) {
    if (prh_atom_bool_strong_clear(&p->wakeup_semaphore)) {
        return false;
    } else {
        return true;
    }
}

void prh_thrd_cond_sleep(prh_cond_sleep *p) {
    if (prh_atom_bool_strong_clear(&p->wakeup_semaphore)) return; // 已经有唤醒存在，不需要睡眠
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    while (!prh_atom_bool_read(&p->wakeup_semaphore)) {
        prh_impl_plat_cond_wait((prh_thrd_cond *)p);
    }
    prh_atom_bool_write(&p->wakeup_semaphore, false);
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
}

void prh_thrd_wakeup(prh_cond_sleep *p) {
    if (prh_atom_bool_read(&p->wakeup_semaphore)) return; // 已经有唤醒存在，无需重新唤醒
    prh_thrd_cond_lock((prh_thrd_cond *)p);
    prh_atom_bool_write(&p->wakeup_semaphore, true);
    prh_thrd_cond_unlock((prh_thrd_cond *)p);
    prh_thrd_cond_signal((prh_thrd_cond *)p);
}

// #include <unistd.h>
// unsigned int sleep(unsigned int seconds);
// int usleep(useconds_t usec);
//
// sleep(3) 函数会使调用线程进入睡眠状态，直到以下两种情况之一发生：
//  1.  指定的实际秒数（real-time seconds）已经过去；
//  2.  收到一个未被忽略的信号。
//
// 返回值：如果请求的时间已过去，返回 0；如果被信号处理函数中断，则返回剩余的睡眠秒数。
// 在 Linux 上，sleep(3) 是通过 nanosleep(2) 实现的。关于所使用的时钟的讨论，可以参
// 考 nanosleep(2) 的手册页。在其他一些系统上，sleep(3) 可能是通过 alarm(2) 和
// SIGALRM 实现的（POSIX.1 允许这样做）。因此，将 alarm(2) 和 sleep(3) 的调用混用是
// 一个糟糕的主意。注意：从信号处理函数中使用 longjmp(3) 或在睡眠期间修改 SIGALRM 的
// 处理方式会导致未定义行为。
//
// usleep(3) 函数使调用线程暂停执行至少 usec 微秒。实际的暂停时间可能会因为系统活动、
// 处理调用的时间或系统时钟粒度而稍微延长。返回值：成功返回0，失败返回 -1 和 errno。
// EINTR - 被信号中断，参见 signal(7)。EINVAL - usec 大于或等于 1000000（1s，在某
// 些系统上，这被认为是错误）。
//
// 4.3BSD、POSIX.1-2001：POSIX.1-2001 声明该函数已废弃，建议使用 nanosleep(2) 替
// 代。在 POSIX.1-2008 中被移除。glibc 2.2.2 之前的实现：返回类型为 void。从 glibc
// 2.2.2 开始，返回类型为 int，与 POSIX 版本一致。只有 EINVAL 错误返回被 SUSv2 和
// POSIX.1-2001 文档化。
//
// 与信号和定时器的交互：usleep() 函数与 SIGALRM 信号以及其他定时器函数，如 alarm(2)、
// sleep(3)、nanosleep(2)、setitimer(2)、timer_create(2)、timer_delete(2)、
// timer_getoverrun(2)、timer_gettime(2)、timer_settime(2)、ualarm(3)）的交互是
// 未定义的。usleep() 是一个简单的微秒级睡眠函数，但由于其在现代标准中已被废弃，建议在
// 新代码中使用 nanosleep(2) 或其他更现代的定时器函数。
//
// #include <time.h>
// int nanosleep(const struct timespec *duration, struct timespec *rem);
// struct timespec {
//      time_t  tv_sec;   /* Seconds */
//      ...     tv_nsec;  /* Nanoseconds [0, 999'999'999] */
// };
//
// nanosleep(2) 函数使调用线程暂停执行，直到以下两种情况之一发生：
//  1.  指定的时间（duration）已经过去；
//  2.  收到一个信号，该信号触发了调用线程中的信号处理函数或终止了进程。
//
// 如果调用被信号处理函数中断，nanosleep() 会返回 -1，将 errno 设置为 EINTR，并将剩
// 余时间写入 rem 指向的结构中（除非 rem 是 NULL）。然后可以使用 *rem 的值再次调用
// nanosleep()，以完成指定的暂停。时间粒度：如果 duration 不是底层时钟粒度，参见
// time(7)，的精确倍数，则时间间隔将向上舍入到下一个倍数。此外，暂停完成后，线程可能仍
// 需等待一段时间才能再次获得 CPU 的执行权。时间漂移：由于 nanosleep() 睡眠一段相对时
// 间间隔，如果调用被信号反复中断，那么每次中断和重新启动之间的时间会导致最终完成暂停的
// 时间逐渐漂移。可以通过使用 clock_nanosleep(2) 并指定绝对时间值来避免此问题。
//
// 信号干扰：如果一个捕获信号并使用 nanosleep() 的程序，以极高的频率接收信号，那么内核
// 在计算睡眠间隔和返回的剩余时间时的调度延迟和舍入误差可能导致剩余时间在连续重启
// nanosleep() 调用时稳步增加。为了避免此类问题，建议使用带有 TIMER_ABSTIME 标志的
// clock_nanosleep(2)，以睡眠到绝对截止时间。
//
// timespec(3) 结构用于以纳秒精度指定时间间隔。tv_nsec 字段的值必须在 [0, 999999999]
// 范围内。与 sleep(3) 和 usleep(3) 相比，nanosleep() 具有以下优点：它提供了更高的时
// 间间隔指定精度；POSIX.1 明确规定它不与信号交互；它使恢复被信号处理函数中断的睡眠变得
// 更加容易。
//
// 如果成功地按照请求的时间持续睡眠，nanosleep() 返回 0。如果调用被信号处理函数中断或
// 遇到错误，nanosleep() 返回 -1，并设置 errno 以指示错误。EFAULT 从用户空间复制信息
// 时出错，这通常是因为 duration 或 rem 地址非法。EINTR 被发送到线程的信号中断。剩余
// 的睡眠时间已写入 *rem，以便线程可以轻松地再次调用 nanosleep()。EINVAL 表示tv_nsec
// 字段的值不在范围 [0, 999999999] 内，或者 tv_sec 为负数。
//
// POSIX.1 规定 nanosleep() 应该基于 CLOCK_REALTIME 时钟测量时间。然而，Linux 使用
// 的是 CLOCK_MONOTONIC 时钟。这通常不重要，因为 POSIX.1 对 clock_settime(2) 的规
// 定表明，对 CLOCK_REALTIME 的不连续更改不应影响 nanosleep()：通过 clock_settime(2)
// 设置 CLOCK_REALTIME 时钟的值，必须不影响等待基于此时钟的相对时间服务的线程，相对时间
// 服务包括 nanosleep() 函数。因此，这些时间服务将在请求的持续时间过去后到期，与时钟的
// 新旧值无关。
//
// 为了支持需要更精确暂停的应用程序（例如，控制某些时间敏感的硬件），Linux 2.5.39 之前
// 的版本中，nanosleep() 在使用实时策略（如 SCHED_FIFO 或 SCHED_RR）的线程中，会以微
// 秒精度忙等最多 2 毫秒。这一特殊扩展在 Linux 2.5.39 中被移除，因此在 Linux 2.6.0
// 及更高版本的内核中不可用。
//
// 在 Linux 2.4 中，如果 nanosleep() 被信号（例如 SIGTSTP）停止，则在被 SIGCONT 信
// 号恢复后，调用会以 EINTR 错误失败。如果随后重新启动系统调用，则线程在停止状态花费的
// 时间不会计入睡眠间隔。此问题已在 Linux 2.6.0 及更高版本的内核中修复。
//
// #include <time.h>
// int clock_nanosleep(clockid_t clockid, int flags, const struct timespec *t, struct timespec *remain);
//
// 和 nanosleep(2) 一样，clock_nanosleep(2) 允许调用线程以纳秒精度暂停指定的时间间
// 隔。它与 nanosleep(2) 的区别在于，它允许调用者选择用于测量睡眠间隔的时钟，并且允许
// 将睡眠间隔指定为绝对值或相对值。参数 clockid 指定用于测量睡眠间隔的时钟。该参数可以
// 取以下值之一：
//  1.  CLOCK_REALTIME 一个可设置的系统范围实时钟（real-time clock）
//  2.  CLOCK_TAI (since Linux 3.10) 一个基于墙钟时间但计算闰秒的系统范围时钟
//  3.  CLOCK_MONOTONIC 一个不可设置的、单调递增的时钟，测量自系统启动后某个未指定点
//      的时间。
//  4.  CLOCK_BOOTTIME (since Linux 2.6.39) 与 CLOCK_MONOTONIC 相同，但包括系统挂
//      起的时间。
//  5.  CLOCK_PROCESS_CPUTIME_ID 一个可设置的属于每个进程的时钟，测量进程中所有线程
//      消耗的 CPU 时间。
//
// 关于这些时钟的更多细节，可以参考 clock_getres(2)。此外，由 clock_getcpuclockid(3)
// 和 pthread_getcpuclockid(3) 返回的 CPU 时钟 ID 也可以传递给 clockid。如果 flags
// 为 0，则 t 中指定的值被解释为相对于 clockid 指定时钟当前值的相对时间间隔。如果flags
// 是 TIMER_ABSTIME，则 t 被解释为由 clockid 指定时钟测量的绝对时间，如果 t 小于或等
// 于当前时钟值，clock_nanosleep() 将立即返回，而不会暂停调用线程。
//
// clock_nanosleep() 使调用线程暂停执行，直到以下两种情况之一发生：
//  1.  指定的时间 t 已经过去；
//  2.  收到一个信号，该信号触发了调用线程中的信号处理函数或终止了进程。
//
// 如果调用被信号处理函数中断，clock_nanosleep() 会以 EINTR 错误失败。此外，如果
// remain 不为 NULL，且 flags 不是 TIMER_ABSTIME，它会将剩余未睡眠的时间返回到
// remain 中。然后可以使用这个值再次调用 clock_nanosleep()，以完成（相对）睡眠。
//
// 如果成功地按照请求的时间间隔睡眠，clock_nanosleep() 返回 0。如果调用被信号处理函数
// 中断或遇到错误，clock_nanosleep() 会返回一个正的错误码：
//      EFAULT - t 或 remain 地址非法。
//      EINTR - 睡眠被信号处理函数中断，参见 signal(7)。
//      EINVAL - tv_nsec 字段的值不在范围 [0, 999999999] 内，或者 tv_sec 为负数，
//          或者 clockid 无效（CLOCK_THREAD_CPUTIME_ID 不是允许的 clockid 值）。
//      ENOTSUP - 内核不支持使用此 clockid 进行睡眠。
//
// 如果 t 中指定的时间间隔不是底层时钟粒度（参见 time(7)）的精确倍数，则时间间隔将向上
// 舍入到下一个倍数。此外，暂停完成后，线程可能仍需等待一段时间才能再次获得 CPU 的执行
// 权。使用绝对定时器有助于避免 nanosleep(2) 中描述的定时器漂移问题。这类问题在尝试重
// 新启动被信号反复中断的相对睡眠的程序中更为严重。为了执行一个避免这些问题的相对睡眠，
// 可以调用 clock_gettime(2) 获取所需的时钟，将所需的时间间隔加到返回的时间值上，然后
// 使用 TIMER_ABSTIME 标志调用 clock_nanosleep()。
//
// 无论是否使用 sigaction(2) 的 SA_RESTART 标志，clock_nanosleep() 在被信号处理函
// 数中断后都不会重新启动。当 flags 是 TIMER_ABSTIME 时，remain 参数是未使用的，也是
// 不必要的。绝对睡眠可以通过相同的 t 参数重新启动。
//
// POSIX.1 规定，clock_nanosleep() 对信号的处理方式或信号掩码没有影响。POSIX.1 规定，
// 通过 clock_settime(2) 更改 CLOCK_REALTIME 时钟的值后，新的时钟值将用于确定绝对
// 时间 clock_nanosleep() 阻塞的线程何时唤醒；如果新的时钟值超过了睡眠间隔的结束时间，
// 则 clock_nanosleep() 调用将立即返回。POSIX.1 规定，通过 clock_settime(2) 更改
// CLOCK_REALTIME 时钟的值对相对时间 clock_nanosleep() 阻塞的线程没有影响。
//
// 时间睡眠函数 clock_nanosleep(2) nanosleep(2) usleep(3) sleep(3) 总是会被信号中
// 断，无论信号是否设置了 SA_RESTART 标志，都不会自动重新启动系统调用。另外，睡眠函数
// 不会被 SIGSTOP 等停止信号中断，如果一个进程停止后又被 SIGCONT 继续执行，睡眠函数也
// 会继续执行，进程停止的时间也会计入睡眠时间。
#include <time.h>

void prh_thrd_sleep_secs(int secs) { // 32位有符号整数保存秒可以表示68年
    prh_thrd_sleep(secs, 0);
}

void prh_thrd_sleep_msec(int msec) { // 32位有符号整数保存毫秒可以表示24天
    int nsec = (msec % 1000) * 1000000;
    prh_thrd_sleep(msec / 1000, nsec);
}

void prh_thrd_sleep(int secs, int nsec) { // 严格睡满一段时间
    assert(secs >= 0 && nsec >= 0 && nsec < PRH_NSEC_PER_SEC);
    struct timespec duration = {.tv_sec = secs, .tv_nsec = nsec};
    struct timespec remain;
#if defined(prh_plat_linux) || defined(CLOCK_MONOTONIC)
#if defined(prh_plat_linux)
    clockid_t clockid = CLOCK_BOOTTIME; // Linux CLOCK_BOOTTIME 包含系统睡眠时间
#else
    clockid_t clockid = CLOCK_MONOTONIC; // FreeBSD CLOCK_MONOTONIC 包含系统睡眠时间
#endif
    prh_zeroret(clock_gettime(clockid, &remain));
    duration.tv_sec += remain.tv_sec;
    duration.tv_nsec += remain.tv_nsec;
    if (duration.tv_nsec >= PRH_NSEC_PER_SEC) {
        duration.tv_sec += 1;
        duration.tv_nsec -= PRH_NSEC_PER_SEC;
    }
    int n;
label_continue: // 这里 duration 是绝对时间，被中断后不需要重新计算
    if ((n = clock_nanosleep(clockid, TIMER_ABSTIME, &duration, prh_null)) == 0) {
        return;
    }
    if (n == EINTR) {
        goto label_continue;
    }
    assert(n == EINTR);
#else
label_continue: // 这里 duration 是相对时间，每次中断后需要重新计算
    if (nanosleep(&duration, &remain) == 0) {
        return;
    }
    if (errno == EINTR) {
        duration = remain;
        goto label_continue;
    }
    assert(errno == EINTR);
#endif
}

void prh_thrd_sleep_and_trigger_system_wakeup(int secs, int nsec) {
}

#if !defined(_SC_NPROCESSORS_ONLN)
#include <sys/sysinfo.h> // get_nprocs
#endif

#if defined(prh_plat_apple)
#include <sys/sysctl.h> // sysctlbyname
#endif

void prh_system_info(prh_sys_info *info) {
    // https://www.man7.org/linux/man-pages/man3/sysconf.3p.html
    errno = 0;
    info->page_size = (int)sysconf(_SC_PAGESIZE);
    info->vmem_unit = (int)sysconf(_SC_THREAD_STACK_MIN);
#if defined(_SC_NPROCESSORS_ONLN)
    info->processor_count = (int)sysconf(_SC_NPROCESSORS_ONLN);
#else
    info->processor_count = get_nprocs();
#endif
#if !defined(prh_plat_apple)
#if defined(_SC_LEVEL1_DCACHE_LINESIZE)
    info->cache_line_size = (int)sysconf(_SC_LEVEL1_DCACHE_LINESIZE);
#elif defined(prh_plat_linux)
    FILE *file = fopen("/sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size", "rb");
    if (file != prh_null) {
        fscanf(file, "%d", &info->cache_line_size);
    } else {
        prh_prerr(__LINE__);
    }
#else
    info->cache_line_size = PRH_CACHE_LINE_SIZE; // 使用默认大小
#endif
#endif
    prh_preno_if(errno != 0);
#if defined(prh_plat_apple)
    // https://developer.apple.com/documentation/kernel/1387446-sysctlbyname
    // int sysctlbyname(const char *name, void *get, size_t *getlen, void *set, size_t setlen); macOS 10.0+
    prh_i64 cache_line_size = 0;
    size_t size = sizeof(cache_line_size);
    int n = sysctlbyname("hw.cachelinesize", &cache_line_size, &size, NULL, 0);
    prh_preno_if(n != 0);
    info->cache_line_size = (int)cache_line_size;
#endif
}

prh_sys_info *prh_get_sys_info(void) {
    static prh_sys_info si = {0};
    if (si.page_size == 0) {
        prh_system_info(&si);
    }
    return &si;
}

void prh_impl_plat_set_fault_handler(void) {
    prh_main_sigaction();
}

#ifdef PRH_TEST_IMPLEMENTATION
#include <sys/resource.h> // getrlimit POSIX.1-2008
// In SUSv2 the getpagesize() call was labeled LEGACY, and it was removed in
// POSIX.1-2001.
int getpagesize(void);
// sysconf/fpathconf/pathconf/confstr获取的值是系统配置常量，在一个进程的生命
// 期间都不会改变。
// https://www.man7.org/linux/man-pages/man2/getrlimit.2.html
// https://www.man7.org/linux/man-pages/man7/posixoptions.7.html
// https://www.man7.org/linux/man-pages/man3/confstr.3.html
// https://www.man7.org/linux/man-pages/man3/confstr.3p.html
// https://www.man7.org/linux/man-pages/man3/sysconf.3.html
// https://www.man7.org/linux/man-pages/man3/sysconf.3p.html
void prh_impl_thrd_test(void) {
    long n = 0;
    char buf[32];
    struct rlimit l = {0};

    printf("\n\n[GNU][posix]\n");
    printf("_SC_VERSION: %ldL\n", sysconf(_SC_VERSION));
    printf("Resource limit infinity: RLIM_INFINITY = %lld = unlimited\n", (long long)RLIM_INFINITY);
    n = getrlimit(RLIMIT_AS, &l); // address space
    printf("[%d] The max size of the process's virtual memory: %lldB max %lldB\n", (int)n, (long long)l.rlim_cur, (long long)l.rlim_max);
    n = getrlimit(RLIMIT_STACK, &l);
    printf("[%d] The max size of the process stack space: %lldB max %lldB\n", (int)n, (long long)l.rlim_cur, (long long)l.rlim_max);
    n = getrlimit(RLIMIT_NICE, &l);
    printf("[%d] The max nice value can be raised: %lldB max %lldB\n", (int)n, (long long)l.rlim_cur, (long long)l.rlim_max);
    n = sysconf(_SC_PAGESIZE);
    printf("_SC_PAGESIZE: %dKB\n", (int)(n/1024));
    printf("getpagesize() %dKB\n", (int)(getpagesize()/1024));
#if defined(_SC_LEVEL1_DCACHE_LINESIZE)
    n = sysconf(_SC_LEVEL1_DCACHE_LINESIZE);
    printf("_SC_LEVEL1_DCACHE_LINESIZE: %d\n", (int)n);
#endif
    n = sysconf(_SC_2_VERSION);
    printf("_SC_2_VERSION: %ldL\n", n);
    n = sysconf(_SC_THREADS);
    printf("_SC_THREADS support: %ldL\n", n);
    n = sysconf(_SC_RAW_SOCKETS);
    printf("_SC_RAW_SOCKETS support: %ldL\n", n);
    n = sysconf(_SC_THREAD_ATTR_STACKADDR);
    printf("_SC_THREAD_ATTR_STACKADDR support: %ldL\n", n);
    n = sysconf(_SC_THREAD_ATTR_STACKSIZE);
    printf("_SC_THREAD_ATTR_STACKSIZE support: %ldL\n", n);
    n = sysconf(_SC_THREAD_CPUTIME);
    printf("_SC_THREAD_CPUTIME support: %ldL\n", n);
    n = sysconf(_SC_THREAD_PRIORITY_SCHEDULING);
    printf("_SC_THREAD_PRIORITY_SCHEDULING support: %ldL\n", n);
    n = sysconf(_SC_ATEXIT_MAX);
    printf("_SC_ATEXIT_MAX: %ld\n", n);
    n = sysconf(_SC_HOST_NAME_MAX);
    printf("_SC_HOST_NAME_MAX: %ld\n", n);
    n = sysconf(_SC_LOGIN_NAME_MAX);
    printf("_SC_LOGIN_NAME_MAX: %ld\n", n);
    n = sysconf(_SC_OPEN_MAX);
    printf("_SC_OPEN_MAX: %ld\n", n);
    n = sysconf(_SC_THREAD_KEYS_MAX);
    printf("_SC_THREAD_KEYS_MAX: %ld\n", n);
    n = sysconf(_SC_THREAD_STACK_MIN);
    printf("_SC_THREAD_STACK_MIN: %dKB\n", (int)(n/1024));
    n = sysconf(_SC_THREAD_THREADS_MAX);
    printf("_SC_THREAD_THREADS_MAX: %ld\n", n);
    n = sysconf(_SC_MAPPED_FILES);
    printf("_SC_MAPPED_FILES: %ld\n", n);
    n = sysconf(_SC_LINE_MAX);
    printf("_SC_LINE_MAX: %ld\n", n);
    confstr(_CS_GNU_LIBC_VERSION, buf, sizeof(buf));
    printf("_CS_GNU_LIBC_VERSION: %s\n", buf);
    confstr(_CS_GNU_LIBPTHREAD_VERSION, buf, sizeof(buf));
    printf("_CS_GNU_LIBPTHREAD_VERSION: %s\n", buf);

    printf("\n\n[GNU][pthread]\n");
    printf("void* %d-byte\n", (int)sizeof(void *));
    printf("pthread_t %d-byte\n", (int)sizeof(pthread_t));
    printf("pthread_key_t %d-byte\n", (int)sizeof(pthread_key_t));
    printf("pthread_attr_t %d-byte\n", (int)sizeof(pthread_attr_t));
    printf("pthread_once_t %d-byte\n", (int)sizeof(pthread_once_t));
    printf("pthread_mutex_t %d-byte\n", (int)sizeof(pthread_mutex_t));
    printf("pthread_mutexattr_t %d-byte\n", (int)sizeof(pthread_mutexattr_t));
    printf("pthread_cond_t %d-byte\n", (int)sizeof(pthread_cond_t));
    printf("pthread_mutexattr_t %d-byte\n", (int)sizeof(pthread_mutexattr_t));
    printf("PTHREAD_CANCELED %d\n", (int)(prh_unt)PTHREAD_CANCELED);
    printf("ETIMEDOUT = %d\n", ETIMEDOUT);
    printf("EDEADLK = %d\n", EDEADLK);
    printf("EINVAL = %d\n", EINVAL);
    printf("ENOTSUP = %d\n", ENOTSUP);
    printf("ESRCH = %d\n", ESRCH);
    assert(sizeof(pthread_t) <= sizeof(void *));

#ifdef SIGSTKSZ
    printf("SIGSTKSZ %d\n", SIGSTKSZ);
#endif
#ifdef MINSIGSTKSZ
    printf("MINSIGSTKSZ %d\n", MINSIGSTKSZ);
#endif
#ifdef _POSIX_SIGQUEUE_MAX // 实时信号排队队列的长度不得小于该值
    printf("_POSIX_SIGQUEUE_MAX %d\n", _POSIX_SIGQUEUE_MAX);
#endif
#ifdef _SC_SIGQUEUE_MAX
    printf("sysconf(_SC_SIGQUEUE_MAX) %d\n", (int)sysconf(_SC_SIGQUEUE_MAX));
#endif
#ifdef RLIMIT_SIGPENDING
    prh_real_zeroret(getrlimit(RLIMIT_SIGPENDING, &l));
    printf("sysconf(RLIMIT_SIGPENDING) %d\n", (int)l.rlim_cur);
#endif
#ifdef _POSIX_RTSIG_MAX
    printf("_POSIX_RTSIG_MAX %d\n", _POSIX_RTSIG_MAX);
#endif
#ifdef RTSIG_MAX // 实时信号的可用数量
    printf("RTSIG_MAX %d\n", RTSIG_MAX);
#endif
#ifdef SIGRTMIN // 实时信号编号的最小值
    printf("SIGRTMIN %d\n", SIGRTMIN);
#endif
#ifdef SIGRTMAX // 实时信号编号的最大值
    printf("SIGRTMAX %d\n", SIGRTMAX);
#endif

    printf("prh_mutex %d-byte\n", (int)sizeof(prh_mutex));
    printf("prh_thrd_cond %d-byte\n", (int)sizeof(prh_thrd_cond));
    printf("prh_cond_sleep %d-byte\n", (int)sizeof(prh_cond_sleep));
}
#endif // PRH_TEST_IMPLEMENTATION
#endif // PTHREAD END
#endif // PRH_THRD_IMPLEMENTATION
#endif // PRH_THRD_INCLUDE

// Reactor Pattern 和 Proactor Pattern
//
// Reactor = 事件驱动 + 非阻塞 I/O，用户负责搬数据。
// Proactor = 真正的异步 I/O，内核负责搬数据，用户只处理“完成”回调。
//
// 把一次网络 I/O 简化成 “等待事件 → 把数据搬进/搬出用户缓冲区 → 通知用户代码” 三步，
// 就可以看清两种模式的本质区别：
//
// 1. Reactor（反应器）
//
//  谁来等：框架/库帮你等事件（select/epoll/IOCP 的“事件”端口）。
//  谁来搬数据：用户代码自己搬——事件到了，框架只告诉你“fd 可读了”或“fd 可写了”，然后你自己调用 read/write/recv/send。
//  回调里做什么：只做“非阻塞”的拷贝，如果一次没拷完，要保留状态，等下一次事件再继续。
//  典型实现：Java NIO、libevent、libuv（默认）、Redis、Nginx、Linux epoll。
//  一句话：“通知我什么时候能干，但活我自己干。”
//
// 2. Proactor（前摄器）
//
//  谁来等：操作系统/框架把数据搬到事先给定的缓冲区之后，才把“已完成”事件递给你。
//  谁来搬数据：内核或底层异步引擎（Windows IOCP、Linux io_uring 的 IOSQE_IO_LINK+readv、Boost.ASIO 的 “true async” 模式）。
//  回调里做什么：直接处理完整的数据，不用再管“半包”“粘包”重试；失败也只要看错误码。
//  典型实现：Windows IOCP + AcceptEx/ReadFileEx、Boost.ASIO（Proactor 模式）、io_uring 的异步接口、Windows RIO。
//  一句话：“通知我活已经干完了。”
//
// 以读操作为例：
//  步骤        Reactor                     Proactor
//  ① 注册      告诉框架“等可读事件”         告诉框架/内核“把数据读进这个缓冲区，完事叫我”
//  ② 等待      select/epoll_wait 阻塞      内核异步搬运数据
//  ③ 通知      “fd 可读了”                 “已经读好 n 字节，缓冲区里有数据”
//  ④ 处理      用户代码 read/recv          直接拿数据用
//
// 无论是 epoll_wait() 还是 GetQueuedCompletionStatusEx() 都可以尝试获取指定大小的
// 事件数组；这样的话就可以设计一个统一的优化策略：如果某次大小为 n 的数组用满了，下一
// 轮之前可以将数组大小翻倍（或者 1.5x 放大）。
//
// 虽然理论上异步 IO 的性能要高于非阻塞同步 IO，但是异步 IO 割裂了上下文，尤其是资源上    *** 虽然理论上异步 IO 性能高于非阻塞同步 IO，但异步 IO 割裂了上下文
// 下文，因此在资源管理上充满了艰险。首先为了让 os kernel 能够直接将网卡收到的数据写入
// 内存页，这部分内存必须事先提供；而操作系统避免内存页被内存管理 swap-out，必须将这块
// 内存页 pin 住。对于每个发出去的 read 异步请求，都伴随着一块被 PIN 住的 mem-page，
// 更揪心的是在请求 complete 之前，内存页始终被 pin 的死死的。如果有很多恶意连接，建立
// 了连接之后就什么都不做，那么按照每个内存页 4K 计算，用不了多少时间内存管理就撑不住了。
// 在 Windows 上这个时候异步的 IO 操作就会返回一个错误 WSAENOBUFS，表示 too many
// pinned memory pages。对于这个问题，我的想法是使用 read-probe-request，即对于新建
// 立的连接，先发一个大小为 0 的异步 read，如果之后这个请求完成了，那就说明 socket 存
// 在可读数据，后面就可以大胆读了。当然，不排除有恶意客户端针对性的搞破坏，那样就要做一
// 些资源使用的处理了。
//
// 对于 accept 调用来说，这个问题稍微没有那么严重，因为可以控制 concurrent outstanding
// accept requests 的数量在一个比较小的值，比如 10；甚至完全不考虑做优化，顺序依次的发
// 都行，毕竟这个优化对应到 epoll 也要求调用 accept() 直到出现 EAGAIN，并不是一个每个
// 人都会做的优化。
//
// 相比较下，同步 IO 一个明显的优势是可以利用 stack，内存资源的使用上更加紧凑。这个很
// 容易理解，因为 read() 操作的发起和结束是在一个函数调用上下文，完全可以在 read() 调
// 用时使用一部分 stack 空间，比如 64-KB，利用 readv() 读取一个 buffer vetor 即可。
// 等到这个栈帧结束，这部分资源完璧归赵。对于异步 IO 来说，因为 request 和 completion
// 是分开的上下文，栈内存就别想了，只能动一些其他的手段。
//
// 对于关闭逻辑，对于服务端程序来说，应该尽量避免主动 shutdown；主要是为了避免进入
// TIME-WAIT，毕竟这个时间段长达 2MSL（据说在 Linux 上固定是 60s)。那么正确的关闭逻辑
// 应该这样操作：
//
//      服务端通过 EPOLLRDHUP 或者 read() 知道对端关闭，然后进入被动关闭流程。如果服务
//      端自己要结束，则服务端通过 shutdown() 先关闭 socket 的写端，保留读端（因为可能   *** 服务器关闭写端实际就是主动关闭
//      有数据还在路上）；这样的客户端通过 EPOLLRDHUP 或者 read() 返回 0 就主动断开连
//      接，发出 FIN 包；然后服务端接着进入被动关闭流程。对于一些异常的 socket，服务端
//      别无法他，只能主动断开，一般来说这种关闭的连接数量较少。
//
// https://idea.popcount.org/2017-02-20-epoll-is-fundamentally-broken-12/

#ifdef PRH_IOCP_INCLUDE
#ifdef PRH_IOCP_IMPLEMENTATION
#if defined(prh_plat_windows)
// 当线程发出一个异步设备 I/O 请求的时候，它会被临时挂起，直到设备完成 I/O 请求为止。
// 此类挂起会损害性能，这是因为线程无法进行有用的工作，比如开始对另一个客户请求进行处
// 理。因此简而言之，我们希望线程不会被阻塞，这样它们就能始终进行有用的工作。Microsoft
// 开发出了一种非常好的机制称为 I/O 完成端口（I/O completion port），它可以帮助我们
// 创建高性能而且伸缩性好的应用程序。通过使用 I/O 完成端口，我们可以让线程在读取设备和
// 写入设备的时候不必等待设备的响应，从而显著地提高吞吐量。值得注意的是，I/O 完成端口也
// 可以和设备 I/O 完全无关，它是一种有无数种用途的绝佳的线程间通信机制。
//
// 存在两种类型的输入输出同步方式：同步 I/O 和异步 I/O。异步 I/O 也被称为重叠 I/O。同
// 步 I/O 中，线程启动 I/O 操作后会立即进入等待状态，直到 I/O 请求完成。执行异步 I/O
// 的线程通过调用适当的函数将 I/O 请求发送到内核。如果内核接受了该请求，调用线程将继续
// 处理其他任务，直到内核向线程发出信号，表明 I/O 操作已完成。然后，线程会中断当前任务，
// 并处理 I/O 操作后的数据。在某些情况下，I/O 请求预计会花费大量时间，例如刷新或备份大
// 型数据库，或者通过慢速通信链路进行传输，此时异步 I/O 通常是优化处理效率的好方法。然
// 而，对于相对快速的 I/O 操作，处理内核 I/O 请求和内核信号的开销可能会使异步 I/O 的优
// 势降低，特别是当需要执行许多快速 I/O 操作时。在这种情况下，同步 I/O 会更好。完成这些
// 任务的机制和实现细节会根据所使用的设备句柄类型以及应用程序的具体需求而有所不同。换句
// 话说，通常有多种方法可以解决问题。
//
// 同步和异步 I/O 的注意事项，如果文件或设备以同步 I/O 方式打开（即未指定 FILE_FLAG_OVERLAPPED），
// 后续对 WriteFile 等函数的调用可能会阻塞调用线程的执行，直到发生以下事件之一：
//  1.  I/O 操作完成（此例中，为数据写入）。
//  2.  发生 I/O 错误（例如，管道从另一端关闭）。
//  3.  调用本身存在错误（例如，一个或多个参数无效）。
//  4.  进程中的另一个线程使用被阻塞线程的线程句柄调用 CancelSynchronousIo 函数，这将
//      终止该线程的 I/O 操作，导致 I/O 操作失败。
//  5.  被阻塞的线程被系统终止；例如，进程本身被终止，或者另一个线程使用被阻塞线程的句
//      柄调用 TerminateThread 函数。这通常被视为最后的手段，不是良好的应用程序设计。
//
// 在某些情况下，这种延迟可能无法被应用程序的设计和目的所接受，因此应用程序设计者应考虑
// 使用异步 I/O，并结合适当的线程同步对象，例如 I/O 完成端口。有关线程同步的详细信息，
// 请参阅关于同步（About Synchronization）。
//
// 进程在调用 CreateFile 时通过在 dwFlagsAndAttributes 参数中指定 FILE_FLAG_OVERLAPPED
// 标志来以异步 I/O 方式打开文件。如果未指定 FILE_FLAG_OVERLAPPED，则文件以同步 I/O
// 方式打开。当文件以异步 I/O 方式打开后，需要将指向 OVERLAPPED 结构的指针传递给 ReadFile
// 和 WriteFile 的调用。在执行同步 I/O 时，此结构在调用 ReadFile 和 WriteFile 时不是
// 必需的。注意，如果以异步 I/O 方式打开文件或设备，使用该句柄对 WriteFile 等函数的后
// 续调用通常会立即返回，但也可以表现出与阻塞执行相关的同步行为。有关详细信息，可以参考：
// https://learn.microsoft.com/en-us/previous-versions/troubleshoot/windows/win32/asynchronous-disk-io-synchronous
//
// 尽管 CreateFile 是用于打开文件、磁盘卷、匿名管道以及其他类似设备的最常用函数，但也
// 可以使用其他系统对象（例如由 socket 或 accept 函数创建的套接字）的句柄类型来执行
// I/O 操作。通过调用 CreateFile 函数并使用 FILE_FLAG_BACKUP_SEMANTICS 属性，可以
// 获取目录对象的句柄。目录句柄几乎从不使用，备份应用程序是少数通常会使用它们的应用程序
// 之一。
//
// typedef struct _OVERLAPPED {
//      ULONG_PTR Internal;
//      ULONG_PTR InternalHigh;
//      union {
//          struct {
//              DWORD Offset;
//              DWORD OffsetHigh;
//          } DUMMYSTRUCTNAME;
//          PVOID Pointer;
//      } DUMMYUNIONNAME;
//      HANDLE hEvent;
// } OVERLAPPED, *LPOVERLAPPED;
//
// 在以异步 I/O 方式打开文件对象后，必须正确创建、初始化并将 OVERLAPPED 结构传递给
// ReadFile 和 WriteFile 的每次调用。在异步读取和写入操作中使用 OVERLAPPED 结构时，
// 请注意以下几点：
//  1.  在完成对文件对象的所有异步 I/O 操作之前，不要释放或修改 OVERLAPPED 结构或数据
//      缓冲区。
//  2.  如果将 OVERLAPPED 结构的指针声明为局部变量，则在完成对文件对象的所有异步 I/O
//      操作之前，不要退出局部函数。如果局部函数提前退出，OVERLAPPED 结构将超出作用
//      域，并且它将在该函数外部遇到的任何 ReadFile 或 WriteFile 函数中无法访问。
//
// 你还可以创建一个事件，并将其句柄放入 OVERLAPPED 结构中；然后可以使用等待函数通过等
// 待事件句柄来等待 I/O 操作完成。
//
// 如前所述，当使用异步句柄时，应用程序在决定何时释放与该句柄上指定 I/O 操作相关的资源
// 时应格外小心。如果句柄被提前释放，ReadFile 或 WriteFile 可能会错误地报告 I/O 操作
// 已完成。此外 WriteFile 函数有时也可能返回 TRUE 和 ERROR_SUCCESS，即使使用的是异步
// 句柄，习惯于同步 I/O 设计的程序员通常会在这一点释放数据缓冲区资源，因为返回 TRUE 和
// ERROR_SUCCESS 表示操作已完成。然而，如果使用 I/O 完成端口与这个异步句柄一起使用，即   *** 如果一个句柄与完成端口关联，即使异步请求以同步方式完成了操作，其结果任然会被添加到完成端口队列中
// 使 I/O 操作立即完成，也会发送一个完成数据包。换句话说，如果应用程序在 WriteFile 返
// 回 TRUE 和 ERROR_SUCCESS 之后以及在 I/O 完成端口例程中释放资源，它将出现双重释放错
// 误条件。在此例中，建议让完成端口例程完全负责此类资源的所有释放操作。
//
// 系统不会维护支持文件指针（即寻址设备）的文件和设备的异步句柄上的文件指针，因此必须在
// OVERLAPPED 结构的相关偏移数据成员中将文件位置传递给读取和写入函数。有关详细信息，请
// 参阅 WriteFile 和 ReadFile。对于同步句柄，系统会在读取或写入数据时维护文件指针位置，
// 也可以使用 SetFilePointer 或 SetFilePointerEx 函数进行更新。
//
// 应用程序还可以等待文件句柄以同步到一个 I/O 操作的完成，但这样做需要格外小心。每次启
// 动 I/O 操作时，操作系统都会将文件句柄设置为非信号状态。每次 I/O 操作完成时，操作系
// 统都会将文件句柄设置为信号状态。因此，如果应用程序启动了两个 I/O 操作并等待文件句柄，
// 当句柄被设置为信号状态时，将无法确定哪个操作已完成。如果应用程序必须在单个文件上执行
// 多个异步 I/O 操作，则应等待每个 I/O 操作的特定 OVERLAPPED 结构中的事件句柄，而不是
// 等待公共文件句柄。
//
// 取消 I/O 操作，要取消所有挂起的异步 I/O 操作，请使用以下方法之一：
//  1.  CancelIo：此函数仅取消调用线程为指定文件句柄发出的操作。
//  2.  CancelIoEx：此函数取消所有线程为指定文件句柄发出的操作。
//
// 使用 CancelSynchronousIo 取消挂起的同步 I/O 操作。ReadFileEx 和 WriteFileEx 函
// 数允许应用程序指定一个例程（请参阅 FileIOCompletionRoutine），在异步 I/O 请求完成
// 时执行。
//
// 可警报 I/O 是应用程序线程仅在处于可警报状态时处理异步 I/O 请求的方法。要了解线程何
// 时处于可警报状态，请考虑以下场景：
//  1.  线程通过调用 ReadFileEx 并传递一个指向回调函数的指针来启动异步读取请求。
//  2.  线程通过调用 WriteFileEx 并传递一个指向回调函数的指针来启动异步写入请求。
//  3.  线程调用一个从远程数据库服务器获取一行数据的函数。
//
// 在此场景中，对 ReadFileEx 和 WriteFileEx 的调用很可能在步骤 3 的函数调用之前返回。
// 当它们返回时，内核会将回调函数的指针放入线程的异步过程调用 (APC) 队列中。内核维护此
// 队列，专门用于存放返回的 I/O 请求数据，直到对应的线程能够处理它们。
//
// 当行获取完成且线程从函数返回时，其最高优先级是通过调用回调函数来处理队列中返回的 I/O
// 请求。为此，它必须进入可警报状态。线程只能通过调用以下函数之一并使用适当的标志来实现
// 这一点：
//  * SleepEx
//  * WaitForSingleObjectEx
//  * WaitForMultipleObjectsEx
//  * SignalObjectAndWait
//  * MsgWaitForMultipleObjectsEx
//
// 当线程进入可警报状态时，会发生以下事件：
//  1.  内核检查线程的 APC 队列。如果队列中包含回调函数指针，内核会从队列中移除该指针
//      并将其发送给线程。
//  2.  线程执行回调函数。
//  3.  步骤 1 和 2 会针对队列中剩余的每个回调函数指针重复执行。
//  4.  当队列为空时，线程将从使其进入可警报状态的函数返回。
//
// 在此场景中，一旦线程进入可警报状态，它将调用发送给 ReadFileEx 和 WriteFileEx 的回
// 调函数，然后从使其进入可警报状态的函数返回。如果线程在 APC 队列为空时进入可警报状态，
// 内核将暂停线程的执行，直到以下情况之一发生：
//  * 正在等待的内核对象被触发。
//  * 回调函数指针被放入 APC 队列。
//
// 使用可警报 I/O 的线程比简单地等待 OVERLAPPED 结构中的事件标志被设置能更高效地处理
// 异步 I/O 请求，而且可警报 I/O 机制比 I/O 完成端口更简单。然而，可警报 I/O 只将 I/O   *** 使用完成例程的可警报 I/O 比事件完成通知，能更高效的处理异步 I/O
// 请求的结果返回给发起它的线程。I/O 完成端口没有这个限制。                             *** 可警报 I/O 比完成端口更简单，但它只能将 I/O 的请求结果返回给发起它的线程
//
// 一般，我们能够采用以下两种模型来架构一个服务应用程序。串行模型（serial model），一
// 个线程等待一个客户发出请求，当请求达到时，线程会唤醒并对客户请求进行处理。并发模型
// （concurrent model），一个线程等待一个客户请求，并创建一个新的线程来处理请求。当新
// 线程正在处理客户请求时，原来的线程会进入下一次循环并等待另一个客户请求。当处理客户请
// 求的线程完成整个处理过程的时候，该线程就会终止。
//
// 并发模型的优点在于等待请求的线程只有很少的工作需要做，大多数时间它都处于睡眠状态。
// 当客户请求到达的时候，该线程会被唤醒，创建一个新的线程来处理请求，然后等待下一个客户
// 请求，这意味着能够对客户的请求进行快捷的处理。但是，如果同时处理许多客户请求，这意味
// 着系统中会有许多线程并发执行，由于所有这些线程都处于可运行状态，Windows 内核各可执行
// 线程之间会有大量时间进行上下文切换，以至于各线程都没有多少 CPU 时间来完成它们的任务。
// 为了将 Windows 打造成一个出色的服务器环境，Microsoft 实现了 I/O 完成端口内核对象。
//
// I/O 完成端口背后的理论是并发运行的线程数量必须有一个上限，也就是说，同时发出的 500     *** 完成端口的优势是，所有 I/O 请求的结果都可以关联到一个完成端口上，让所有线程处理
// 个客户请求不应该允许出现 500 个可执行的线程。那么，可运行线程的数量是多少才算合适      *** 完成端口还限制了并发运行线程的数量上限，避免系统执行大量的线程上下文切换（但线程池的线程数量一般要大于这个上限）
// 呢？无需考虑太长时间，我们就会意识到如果机器只有两个 CPU，那么允许可运行线程的数量     *** 完成端口使用后入先出的机制来唤醒等待的线程，让持续活跃的线程优先执行任务，可以提高处理器高速缓存效率
// 大于 2，每个处理器一个线程，将没有什么意义。一旦可运行线程的数量大于可用的 CPU 数量，
// 系统就必须花时间来执行线程上下文切换，而这会浪费宝贵的 CPU 周期，这也是并发模型的一
// 个潜在缺点。
//
// I/O 完成端口为在多处理器系统上处理多个异步 I/O 请求提供了一种高效的线程模型。当一个
// 进程创建一个 I/O 完成端口时，系统会为专门用于处理这些请求的线程创建一个关联的队列对
// 象。通过使用 I/O 完成端口与预先分配的线程池相结合，而不是在收到 I/O 请求时创建线程，
// 处理大量并发异步 I/O 请求的进程可以更快、更高效地完成任务。
//
// I/O 完成端口的工作原理，CreateIoCompletionPort 函数创建一个 I/O 完成端口，并将一个
// 或多个文件句柄与该端口关联。当其中一个文件句柄上的异步 I/O 操作完成时，I/O 完成数据
// 包会以先进先出 (FIFO) 的顺序排队到关联的 I/O 完成端口。这种机制的一个强大用途是将多
// 个文件句柄的同步点合并到一个对象中，尽管还有其他有用的应用。请注意，尽管数据包是以
// FIFO 的顺序排队的，但它们可能会以不同的顺序出队。
//
// 当一个文件句柄与完成端口关联时，传递的状态块直到数据包从完成端口移除时才会更新。唯一
// 的例外是原始操作以错误同步返回。一个线程（可以是主线程创建的线程或主线程本身）使用
// GetQueuedCompletionStatus 函数来等待完成端口中的完成数据包，而不是直接等待异步 I/O
// 完成。在 I/O 完成端口上阻塞执行的线程以后进先出 (LIFO) 的顺序释放，下一个完成数据包
// 从 I/O 完成端口的 FIFO 队列中拉取给该线程。这意味着，当一个完成数据包被释放给一个线
// 程时，系统会释放与该端口关联的最后一个（最近的）线程，并将最旧的 I/O 完成信息传递给
// 它。
//
// 尽管任何数量的线程都可以以指定的 I/O 完成端口调用 GetQueuedCompletionStatus，但当
// 一个指定的线程第一次调用 GetQueuedCompletionStatus 时，它就与指定的 I/O 完成端口
// 关联，直到发生以下三种情况之一。换句话说，一个线程最多只能与一个 I/O 完成端口关联。
//  1.  线程退出
//  2.  指定不同的 I/O 完成端口
//  3.  关闭 I/O 完成端口
//
// 当一个完成数据包被排队到 I/O 完成端口时，系统首先检查与该端口关联的运行线程数量。如
// 果运行线程的数量小于并发值，则允许等待线程（最近的一个）处理完成数据包。当一个运行线
// 程完成其处理时，它通常会再次调用 GetQueuedCompletionStatus，此时它要么返回下一个完
// 成数据包，要么在队列为空时等待。
//
// 线程可以使用 PostQueuedCompletionStatus 函数将完成数据包放入 I/O 完成端口的队列中。
// 这样做，完成端口不仅可以接收来自 I/O 系统的 I/O 完成数据包，还可以接收来自进程其他线
// 程的通信。PostQueuedCompletionStatus 函数允许应用程序将自己特殊的完成数据包排队到
// I/O 完成端口，而无需启动异步 I/O 操作。这对于，例如通知工作线程外部事件非常有用。
//
// I/O 完成端口句柄以及与该特定 I/O 完成端口关联的每个文件句柄都称为对 I/O 完成端口的
// 引用。当没有更多引用时，I/O 完成端口将被释放。因此，所有这些句柄都必须正确关闭，以释
// 放 I/O 完成端口及其关联的系统资源。在满足这些条件后，应用程序应通过调用 CloseHandle
// 函数关闭 I/O 完成端口句柄。注意，I/O 完成端口与创建它的进程相关联，不能在进程之间共
// 享。然而，同一个进程中的线程可以共享一个完成端口句柄。
//
// 线程和并发，需要仔细考虑的 I/O 完成端口最重要的属性是并发值。完成端口的并发值在使用
// CreateIoCompletionPort 创建时通过 NumberOfConcurrentThreads 参数指定。此值限制
// 了与完成端口关联的可运行线程数量。当与完成端口关联的可运行线程总数达到并发值时，系统
// 会阻止与该完成端口关联的后续线程的执行，直到可运行线程数量低于并发值。
//
// 最高效的情况是队列中存在等待的完成数据包，但由于端口达到其并发限制而无法满足等待的
// 线程。考虑并发值为一且多个线程在 GetQueuedCompletionStatus 函数调用中等待的情况。
// 在这种情况下，如果队列始终有完成数据包等待，当运行线程调用 GetQueuedCompletionStatus
// 时，它不会阻塞执行，因为如前所述，线程队列是 LIFO。相反，这个线程会立即捡起下一个排队
// 的完成数据包。不会发生线程上下文切换，因为运行线程持续捡起完成数据包，而其他线程无法
// 运行。注意，在前面的例子中，额外的线程似乎毫无用处且从未运行，但这假设运行线程从未被
// 其他机制置于等待状态、终止或以其他方式关闭其关联的 I/O 完成端口。在设计应用程序时，
// 要考虑所有这些线程执行的影响。
//
// 为并发值选择的最佳总体最大值是计算机上的 CPU 数量。如果您的事务需要长时间计算，较大
// 的并发值将允许更多线程运行。每个完成数据包可能需要较长时间才能完成，但同时会处理更多
// 的完成数据包。您可以结合分析工具尝试并发值，以实现应用程序的最佳效果。
//
// 系统还允许在 GetQueuedCompletionStatus 调用中等待的线程处理完成数据包，如果与同一
// I/O 完成端口关联的另一个运行线程因其他原因进入等待状态，例如 SuspendThread 函数。当   *** 当处于挂起状态的线程再次开始运行时，可能会有一段短暂的时间，活动线程的数量超过并发值
// 处于等待状态的线程再次开始运行时，可能会有一段短暂的时间，活动线程的数量超过并发值。
// 然而，系统通过不允许任何新活动线程运行，直到活动线程的数量低于并发值，迅速减少这个数
// 量。这是应用程序在其线程池中创建比并发值更多的线程的原因之一。线程池管理超出了本主题
// 的范围，但一个好的经验法则是，线程池中的线程数量至少是系统上处理器数量的两倍。有关线    *** 一个经验法则是，线程池中的线程数量至少是系统上处理器数量的两倍
// 程池的更多信息，请参阅线程池。
//
// 完成端口只允许同时唤醒指定数量的线程，那么为什么还要让更多的线程在线程池中等待呢？举
// 个例子，假设机器有 2 个 CPU，我们创建一个 I/O 完成端口时，告诉它同时最多只能有两个
// 线程来处理已完成的项。但我们创建了 4 个线程（CPU 数量的两倍），看起来有两个多余的线
// 程，但 I/O 完成端口是非常智能的。当完成端口唤醒一个线程的时候，会将该线程的线程标识
// 保存到线程执行列表中，如果执行线程切换到等待状态（Sleep、WaitFor*、SignalObjectAndWait、
// 一个异步 I/O 调用、或者任何导致线程变成不可运行状态的函数），那么完成端口会检测到这
// 一情况，将线程移动到线程暂停列表。此时线程执行列表会缩减，完成端口就可以释放另一个正
// 在等待的线程。如果一个已暂停的线程被唤醒，那么它会移动到执行列表，这意味着此时执行线
// 程的数量将大于最大允许的并发线程数量。完成端口会知道这一点，在执行线程数量降低到小于
// CPU 数量之前，它不会再唤醒任何线程。I/O 完成端口体系结构假定可运行线程的数量只会在
// 很短时间内高于最大允许的线程数量。
//
// 线程池中应该有多少线程才合适？有两个问题需要考虑，首先，当服务应用程序初始化的时候，
// 我们创建最少数量的线程，其次我们设置一个最大线程数量，这是因为创建太多线程会浪费系统
// 资源。我们可能想要用不同数量的线程来进行实验，但大多数服务使用启发式的算法来对它们的
// 线程池进行管理。例如，可以创建下面的变量来管理线程池： int thrd_min, thrd_max,
// thrd_cur, thrd_bsy 。在应用程序初始化的时候，可以创建 thrd_min 个线程，所有线程
// 都执行同一个线程函数。thrd_cur 指的是当前已经创建的线程数量，thrd_bsy 在线程等待时
// 减一，在线程唤醒时加一。当 thrd_cur == thrd_cur 并且 thrd_bsy < thrd_max 时，如
// 果 cpu usage < 75，可能可以考虑增加线程数量。如果线程等待超时，或 cpu usage > 90
// 并且 thrd_cur > thrd_min，可以考虑销毁当前线程。当前线程如果有未完成的 I/O 请求正
// 在处理时，仍然可以销毁。另外，我们必须确保线程池种总是至少有一个线程，否则客户请求将
// 永远得不到处理。
//
// 当一个线程终止时，系统会自动将该线程发出的所有待处理的 I/O 请求取消掉（取消队列中的
// 设备 I/O 请求）。在 Windows Vista 之前的版本，当线程向一个完成端口管理的设备发出
// I/O 请求时，存在一条硬性规定，即在请求完成之前，该线程必须不能终止，否则 Windows 会
// 将该线程发出的任何待处理请求都取消掉。而在 Windows Vista 中，已经不存在类似的规定，
// 线程现在可以发出请求并终止，请求仍然能够得到处理，处理结果将会被添加到完成端口的队列
// 中。
//
// 支持的 I/O 函数，以下函数可用于启动 I/O 操作，使其通过 I/O 完成端口完成操作。你必须
// 将 OVERLAPPED 结构的实例和之前与 I/O 完成端口关联的文件句柄传递给该函数，以启用 I/O
// 完成端口机制：
//  * AcceptEx
//  * ConnectNamedPipe
//  * DeviceIoControl
//  * LockFileEx
//  * ReadDirectoryChangesW
//  * ReadFile
//  * TransactNamedPipe
//  * WaitCommEvent
//  * WriteFile
//  * WSASendMsg
//  * WSASendTo
//  * WSASend
//  * WSARecvFrom
//  * LPFN_WSARECVMSG (WSARecvMsg)
//  * WSARecv
//
// Winsock 提供了两种套接字模式，阻塞模式和非阻塞模式。在阻塞模式下，I/O 操作完成之前，
// 执行操作的 Winsock 调用（例如 send 和 recv）会一直等待下去直到操作完成，不会立即返
// 回将控制权交还给程序。而在非阻塞模式下，Winsock 函数无论如何都会立即返回。
//
// 将一个套接字置为非阻塞模式之后，处理收发数据或处理连接的 Winsock API 调用会立即返回。   *** 非阻塞模型下，套接字操作函数无论如何都会立即返回
// 大多数情况下，这些调用在失败时会返回 WSAEWOULDBLOCK，这意味着请求的操作在调用期间没     *** 如果请求的操作无法立即完成，将返回 WSAEWOULDBLOCK，需要调用相同的函数稍后重试
// 有足够的时间来完成。例如，在系统的输入缓冲区中，尚不存在被挂起的数据，那么 recv 调用     *** 对于非阻塞的同步 I/O（如 select/poll/epoll），内核会通知调用者哪些操作已经可以进行，此时就可以去重试
// 就会返回 WSAEWOULDBLOCK。通常，需要重复调用同一个函数，直至获得成功的返回代码。非阻     *** 而对于真正的异步 I/O（如 windows iocp），返回 WSAEWOULDBLOCK 此错误仅仅表示此时排队的异步请求过多
// 塞套接字上的 WSAEWOULDBLOCK 场景：                                                  *** 对于真正的异步 I/O 只要操作可以成功启动就会返回 WSA_IO_PENDING，操作结果将通过完成端口进行通知
//      WSAAccept/accept                        无连接请求，等待连接到来
//      closesocket                             在大多数情况下，意味着使用 SO_LINGER 选项调用了 setsockopt，而且已设定了一个
//                                              非零的超时值
//      WSAConnect/connect                      连接已初始化，等待连接完成
//      WSARecv/recv/WSARecvFrom/recvfrom       无接收数据
//      WSASend/send/WSASendTo/sendto           无发送缓冲区可用
//
// 由于非阻塞调用会频繁返回 WSAEWOULDBLOCK，所以在任何时候，都应仔细检查所有返回代码，
// 并作好失败的准备。当返回 WSAEWOULDBLOCK 时，我们需要一个时机再次调用函数，为此
// Winsock 的套接字 I/O 模型可以帮助应用程序判断一个套接字何时可供读写。
//
// 阻塞和非阻塞套接字模式都存在着各自的优点和缺点，其中从概念的角度来说，阻塞套接字更容
// 易使用。但在应付建立连接的多个套接字时，或在数据的收发量不均、时间不定时、将显得极难
// 管理。而另一方面，由于需要编写更多的代码，以便在每个 winsock 调用中，对可能收到的
// WSAEWOULDBLOCK 进行处理，非阻塞套接字显得难于操作。在这些情况下，可考虑使用套接字
// I/O 模型，它将帮助应用程序通过一种异步方式，同时对一个或多个套接字上进行的通信加以
// 管理。
//
// 共有 6 种类型的套接字 I/O 模型，可让 Winsock 应用程序对 I/O 进行管理。它们包括：
// 阻塞（blocking）、选择（select）、异步选择（WSAAsyncSelect）、事件选择（WSAEventSelect）、
// 重叠（overlapped）、完成端口（completion port）。
//
// 重叠模型的基本设计原理是让应用程序使用重叠的数据结构，一次投递一个或多个 Winsock I/O
// 请求。针对提交的请求，在它们完成之后，应用程序可为它们提供服务。要想在一个套接字上使
// 用重叠 I/O 模型，首先必须创建一个设置了重叠标志的套接字。成功建好一个套接字，同时将
// 它与一个本地接口绑定到一起后，便可开始进行重叠 I/O 操作。方法是调用下列 Winsock 函数，
// 同时指定一个可选的 WSAOVERLAPPED 结构：
//      WSASend WSASendTo
//      WSARecv WSARecvFrom WSARecvMsg
//      WSAIoctl WSANSPIoctl
//      AcceptEx
//      ConnectEx
//      DisconnectEx
//      TransmitFile
//
// 如果开发的是一个以 Windows 为基础的应用程序，要进行窗口消息的管理，那么因为 WSAAyncSelect
// 本身便是以 Windows 消息模型借鉴来的，所以 WSAAyncSelect 模型是一种好的选择。采用这
// 种模型，程序一开始便具备了处理消息的能力。该模型的缺点是，用一个单窗口程序处理成千上    *** WSAAyncSelect 选择模型可以处理窗口消息的同时，在同一个窗口程序中处理套接字事件
// 万的套接字中的所有事件，将称为性能瓶颈，这意味着这个模型的伸缩性不太好。
//
// 要想使用 WSAAsyncSelect 模型，在应用程序中，首先必须用 CreateWindow 函数创建一个
// 窗口，再为该窗口提供一个窗口过程支持函数，亦可使用一个对话框，为其提供一个对话过程来
// 代替窗口过程，这是因为对话框本质也是窗口。
//
// int WSAAsyncSelect(SOCKET s, HWND hwnd, unsigned int msg, long event);
//
// 参数 s 表示感兴趣的套接字。hwnd 指定窗口句柄，表示网络事件发生之后，想要收到通知的
// 哪个窗口或对话框。msg 指定再发生网络事件时，打算接收的消息，该消息将被投递到由 hwnd
// 指定的窗口，通常应用程序需要将这些消息设置为比 WM_USER 大一个值，以避免网络窗口消息
// 与预定义的标准窗口消息发生混淆。event 表示一个位掩码，指定一系列感兴趣的网络事件组合，
// 大多数应用程序感兴趣的网络事件包括：FD_READ、FD_WRITE、FD_ACCEPT、FD_CONNECT、
// FD_CLOSE。例如：
//
// WSAAsyncSelect(s, hwnd, WM_SOCKET, FD_CONNECT|FD_READ|FD_WRITE|FD_CLOSE);
//
// 这样，应用程序便可在套接字 s 上，接收到有关连接、发送、接收、以及关闭套接字这一系列
// 网络事件的通知。若将 event 参数设置位 0，则相当于停止套接字上所有网络事件的通知。
//
// 为了使用重叠 I/O，每个函数都把 WSAOVERLAPPED 结构作为参数。若用一个 WSAOVERLAPPED    *** 如果传入 OVERLAPPED 结构作为函数参数，该操作都会使用重叠 I/O 来管理操作结果，不管套接字是否设为非阻塞
// 结构一起调用这些函数，函数会立即完成并返回，而不管套接字是否设置为阻塞模式，这些函数
// 依赖于 WSAOVERLAPPED 结构来管理一个 I/O 请求的完成。
//
// 应用程序主要有两种方法可以来管理重叠 I/O 请求的完成情况：等待事情对象通知（event       *** 对于重叠 I/O 模型（真正的异步 I/O），I/O 请求的操作结果可以通过三种方式进行管理
// object notification），或者通过完成例程（completion routines）。完成例程在重叠       1. 设置 OVERLAPPED 结构体中的 hEvent 成员，然后等待该事件的触发
// 请求完成后被调用。                                                                 2. 如果将完成例程作为参数传递给函数，完成例程将作为 APC 在线程处于警觉状态时调用，该方式不需要设置 hEvent
//                                                                                   3. 将对应句柄关联到一个完成端口中，对该句柄的 I/O 操作都将集中到完成端口中，该方式也不需要设置 hEvent
// 重叠 I/O 的事件通知方法要求将 Windows 事件对象与 WSAOVERLAPPED 结构关联在一起。若
// 使用一个 WSAOVERLAPPED 结构，调用像 WSASend 和 WSARecv 这样的 I/O 函数会立即返回。
// 稍后的某个时间，应用程序需要等待与 WSAOVERLAPPED 相关联的事件对象，判断某个重叠 I/O
// 请求的完成，WSAOVERLAPPED 为重叠 I/O 请求的初始化及其后续完成之间提供了一种通信媒介。
// WSAOVERLAPPED 结构体成员 Internal、InternalHigh、Offset、OffsetHigh 均由系统在内
// 部使用，不能由应用程序直接处理或使用，hEvent 成员则由应用程序将事件对象的句柄同操作
// 进行关联。
//
// 一个重叠 I/O 请求完成后，应用程序需要负责获取重叠 I/O 操作的结果。一般只需简单地调用
// WSAWaitForMultipleEvent 函数，便可判断重叠 I/O 操作是否完成，该函数会等待一段指定
// 的时间，等待一个或多个事件对象进入触发状态。WSAWaitForMultipleEvent 函数最多只能等
// 待 64 个事件对象。确认某个重叠请求完成之后，接着需要调用 WSAGetOverlappedResult
// 函数，判断这个重叠 I/O 是成功还是失败。
//
// BOOL WSAGetOverlappedResult(SOCKET s, LPWSAOVERLAPPED overlapped, LPDWORD transfer, BOOL wait, LPDWORD flags);
//
// 其中，s 表示重叠 I/O 操作对应的套接字，overlapped 表示重叠 I/O 操作对应的重叠结构，
// transfer 接收重叠 I/O 发送或接收操作实际传送的字节数，wait 用于决定函数是否应该等待
// 重叠操作的完成，如果不等待而且操作仍未完成，那么该函数会返回 FALSE 以及 WSA_IO_INCOMPLETE。
// 但就目前的情况来说，由于需要在已触发的事件上等待重叠操作完成，所以该参数无论怎么设置
// 效果都一样。最后一个参数 flags 负责接收结果标志，假如原理重叠调用是通过 WSARecv 或
// WSARecvFrom 函数进行的。如果 WSAGetOverlappedResult 返回成功，意味着重叠 I/O 操作
// 已成功完成，且 transfer 所指向的值进行了更新。若返回失败，那么可能由下述任何一个原因
// 造成。失败后， transfer 不会更新，应用程序应调用 WSAGetLastError 获取失败原因。
//
//  1.  重叠 I/O 操作仍处于挂起状态
//  2.  重叠操作已经完成，但含有错误
//  3.  传递给 WSAGetOverlappedResult 的参数有误，无法判断重叠操作的完成状态
//
// 完成例程是应用程序用来管理重叠 I/O 操作完成的另一种方法。完成例程其实就是一个函数，
// 我们将这些函数传递给重叠 I/O 请求，以供重叠 I/O 请求完成时由系统调用。它们的基本设计
// 宗旨，是通过调用者的线程，为已完成的 I/O 请求提供服务。除此之外，应用程序可通过完成
// 例程，继续进行重叠 I/O 的处理。
//
// 如果希望用完成例程为重叠 I/O 请求提供服务，应用程序必须为一个 I/O Winsock 函数绑定
// 一个完成例程，同时指定一个 WSAOVERLAPPED 结构，完成例程的函数原型如下。
//
// void CALLBACK CompletionRoutine(DWORD error, DWORD transfer, LPWSAOVERLAPPED overlapped, DWORD flags);
//
// 完成例程与事件对象通知，存在一个非常重要的区别，WSAOVERLAPPED 结构中的事件字段未被
// 使用。也就是说，不可以将一个事件对象同重叠请求关联到一起，用完成例程发出重叠 I/O 调用
// 之后，调用线程最终必须为完成例程提供服务。这样便要求我们将调用线程置于警觉的等待状态
// （alertable wait state），并在 I/O 操作完成后，对完成例程加以处理。WSAWaitForMultipleEvent
// 函数可用来将线程置于警觉等待状态，但这样做的缺点，我们还必须由一个事件对象可用于
// WSAWaitForMultipleEvent 函数。假定应用程序只用完成例程对重叠请求进行处理，便不大可
// 能有什么事件对象需要处理。作为一种变通方法，可用 SleepEx 函数将线程置为警觉状态。当
// 重叠 I/O 操作完成之后，警觉等待状态中线程会被唤醒，并调用其队列中的完成例程，最后返回
// WSA_IO_COMPLETION。
//
// 完成端口模型可以提供最后的伸缩性，这个模型非常适合用来处理数百乃至上千个套接字。从本
// 质上，完成端口模型要求创建一个 Windows 完成端口对象，该对象通过指定数量的线程，对重
// 叠 I/O 请求进行管理，以便为已经完成的重叠 I/O 请求提供服务。
//
// 要获取重叠 I/O 请求的执行结果，需要调用 GetQueuedCompletionStatus 函数，让一个或
// 多个线程在完成端口上等待。当一个工作线程从 GetQueuedCompletionStatus 调用中接收到
// I/O 完成通知后，在 completion_key 和 overlapped 参数中，包含必要的套接字信息，可
// 利用这些信息，通过完成端口继续在一个套接字上进行 I/O 处理。通过这些参数，可以获得两个
// 重要的套接字数据：基于句柄的数据（completion_key），以及基于单个 I/O 操作的数据。
//
// 基于单个 I/O 操作的数据，是工作线程处理每一个完成数据时，需要知道的信息。可以将 OVERLAPPED
// 结构作为基于单个 I/O 操作数据的第一个字段使用，例如可定义以下数据结构，实现对基于单个
// I/O 操作数据的管理。这样在每个需要 OVERLAPPED 参数的函数中，只需传递这个结构。
//      typedef struct {
//          OVERLAPPED Overlapped;
//          char Buffer[DATA_BUFSIZE];
//          int BufferLen;
//          int OperationType;
//      } PER_IO_DATA;
//
// 可以使用 OperationType 来指示被投递的操作类型，从而可以确定到底是哪个操作投递到了句
// 柄之上，这个字段可以设为表示读写等操作的值。这样，我们可以在同一个句柄上，同时管理多
// 个 I/O 操作（读/写、多个读、多个写等等）。或许大家会产生这样的疑问，在同一个套接字上
// 真的有必要同时投递多个 I/O 操作吗？答案在于系统的伸缩性，或者说扩展能力。例如每个处
// 理器都在执行一个工作线程，那么在同一个时候，完全可能有几个不同的处理器在同一个套接字
// 上，进行数据的收发操作。
//
// 这里强调一下 Windows 完成端口有关的一个重要的点，所有重叠操作可以确保按照应用程序安
// 排好的顺序执行，然而不能确保从完成端口返回的完成通知也按照相同的顺序返回。例如对先后
// 两个重叠 WSARecv 操作，如果一个应用程序给前者提供 10KB 缓冲，后者 12KB 缓冲，其中
// 10KB 先被填满，然后是 12KB 缓冲被填满。应用程序的工作线程调用 GetQueuedCompletionStatus
// 时可能先收到 12KB WSARecv 的通知。当然，只有在同一个套接字上投递多重操作时，这才是
// 一个问题。
//
// 对于一个给定的重叠操作，如果发生错误，GetQueuedCompletionStatus 将返回 FALSE。因为
// 完成端口是 Windows 采用的一种 I/O 构造机制，所以如果调用 GetLastError 或 WSAGetLastError，
// 则错误代码极有可能是一个 Windows 错误代码，而非 Winsock 错误代码。要想找到对等的
// Winsock 错误代码，可以指定套接字和 WSAOVERLAPPED 结构，对已完成的操作调用 WSAGetOverlappedResult，
// 之后 WSAGetLastError 将返回转换后的 Winsock 错误代码。
//
// https://learn.microsoft.com/en-us/windows/win32/api/ioapiset/nf-ioapiset-getqueuedcompletionstatus
//
// 向设备发出 I/O 请求，但不把该项已完成的 I/O 完成数据添加到 I/O 完成端口的队列中也是    *** 可以在 hEvent 成员位或上 1 表示不要将操作的完成通知添加到完成端口的完成队列中
// 有可能的。通常我们并不需要这样做，但这样做偶尔还是有用的，例如我们通过一个套接字发送
// 数据，但并不关心数据实际上到底有没有送达。为了发出一个在完成的时候不被添加到完成队列
// 中，我们必须在 OVERLAPPED 结构的 hEvent 成员中保存一个有效的事件句柄，并将它与 1
// 按位或：
//
//      Overlapped.hEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
//      Overlapped.hEvent = (HANDLE)((DWORD_PTR)Overlapped.hEvent | 1);
//      ReadFile(..., &Overlapped);
//      CloseHandle((HANDLE)((DWORD_PTR)Overlapped.hEvent & ~1));

void prh_impl_prevent_operation_enqueue_to_completion_port(OVERLAPPED *overlapped, HANDLE event) {
    overlapped->hEvent = (HANDLE)((DWORD_PTR)event | 1); // 低阶位被设置的有效事件句柄会阻止重叠 I/O 完成时将完成数据包排队到完成端口
}

// 如果一个设备有完成端口与之关联，那么当我们向它发出一个异步 I/O 请求时，Windows 会将    *** 如果一个句柄与完成端口关联，即使异步请求以同步方式完成了操作，其结果任然会被添加到完成端口队列中
// 请求结果添加到完成队列中，即使异步请求是以同步方式完成的，Windows 仍然会这样做，其     *** 这种维护编程模型一致性的行为会略微损失性能，可以 SetFileCompletionNotificationModes 和 SetFileIoOverlappedRange
// 目的是为了向开发人员提供一个一致的编程模型。但是，维护编程模型的一致性会略微损害性能，
// 这是因为已完成的请求信息必须被放到端口的完成队列中，线程也必须从端口的队列中取得这些
// 信息。为了能够略微提高性能，可以调用 SetFileCompletionNotificationModes 函数，并
// 传入 FILE_SKIP_COMPLETION_PORT_ON_SUCCESS 标志，以此告诉 Windows 不要将以同步方
// 式完成的异步请求添加到与设备相关联的完成端口中。对性能极其关注的开发人员，还可以考虑
// 使用 SetFileIoOverlappedRange 函数。
//
// HANDLE WINAPI CreateIoCompletionPort(
//      _In_     HANDLE    FileHandle,
//      _In_opt_ HANDLE    ExistingCompletionPort,
//      _In_     ULONG_PTR CompletionKey,
//      _In_     DWORD     NumberOfConcurrentThreads
// );
//
// 创建一个完成端口，并将其与指定的文件句柄关联，或者创建一个尚未与文件句柄关联的完成端
// 口，允许在稍后的时间进行关联。将打开的文件句柄实例与 I/O 完成端口关联，允许进程接收
// 涉及该文件句柄的异步 I/O 操作完成的通知。注意，这里使用的 “文件句柄” 是指代重叠 I/O
// 端点（an overlapped I/O endpoint）的系统抽象，而不仅仅是磁盘上的文件。任何支持重叠
// I/O 的系统对象，如网络端点（network endpoints）、TCP 套接字、命名管道、邮件槽（mail
// slots），都可以用作文件句柄。
//
// 参数 FileHandle 打开的文件句柄或 INVALID_HANDLE_VALUE。句柄必须是支持重叠 I/O 的
// 对象。如果提供了句柄，则必须是已打开的用于重叠 I/O 完成的对象。例如，使用 CreateFile
// 函数获取句柄时，必须指定 FILE_FLAG_OVERLAPPED 标志。如果指定 INVALID_HANDLE_VALUE，
// 函数将创建一个未与文件句柄关联的 I/O 完成端口。在这种情况下，ExistingCompletionPort
// 参数必须为 NULL，CompletionKey 参数将被忽略。
//
// 参数 ExistingCompletionPort 现有 I/O 完成端口的句柄或 NULL。如果此参数指定现有的
// I/O 完成端口，函数将将其与 FileHandle 参数指定的句柄关联。如果成功，函数返回现有
// I/O 完成端口的句柄；它不会创建新的 I/O 完成端口。如果此参数为 NULL，函数将创建一个
// 新的 I/O 完成端口，并且如果 FileHandle 参数有效，则将其与新的 I/O 完成端口关联。
// 否则，不会发生文件句柄关联。如果成功，函数返回新的 I/O 完成端口的句柄。
//
// 参数 CompletionKey 基于文件句柄的用户定义完成键，包含在每个 I/O 完成数据包中。参数
// NumberOfConcurrentThreads 操作系统可以同时处理 I/O 完成端口的 I/O 完成数据包的最
// 大线程数。如果 ExistingCompletionPort 参数不是 NULL，则忽略此参数。如果此参数为零，
// 系统允许与系统中的处理器数量一样多的并发运行线程。
//
// 返回值，如果函数成功，返回值是 I/O 完成端口的句柄：如果 ExistingCompletionPort 参
// 数为 NULL，返回值是新的句柄。如果 ExistingCompletionPort 参数是有效的 I/O 完成端
// 口句柄，返回值是相同的句柄。如果 FileHandle 参数是有效的句柄，该文件句柄现在与返回
// 的 I/O 完成端口关联。如果函数失败，返回值为 NULL。要获取扩展错误信息，请调用 GetLastError
// 函数。
//
// I/O 系统将 I/O 完成通知数据包发送到 I/O 完成端口，并在那里进行排队。I/O 完成端口
// 和它的句柄，与创建它的进程相关联，不能在进程之间共享。但是，单个完成端口句柄可以在
// 同一进程中的线程之间共享。
//
// CreateIoCompletionPort 可以以三种不同的模式使用：
//  1.  仅创建一个 I/O 完成端口而不与文件句柄关联。
//  2.  将现有的 I/O 完成端口与文件句柄关联。
//  3.  在单个调用中同时完成创建和关联。
//
// 要创建一个 I/O 完成端口而不与之关联，请将 FileHandle 参数设置为 INVALID_HANDLE_VALUE，
// ExistingCompletionPort 参数设置为 NULL，CompletionKey 参数设置为零（在这种情况下
// 被忽略）。将 NumberOfConcurrentThreads 参数设置为新 I/O 完成端口所需的并发值，或者
// 为零以获取默认值（系统中的处理器数量）。
//
// FileHandle 参数中传递的句柄可以是任何支持重叠 I/O 的句柄。最常见的是，这是使用
// FILE_FLAG_OVERLAPPED 标志通过 CreateFile 函数打开的句柄（例如，文件、邮件槽和管
// 道）。由其他函数（如 socket）创建的对象也可以与 I/O 完成端口关联。有关使用套接字的
// 示例，请参阅 AcceptEx。一个句柄只能与一个 I/O 完成端口关联，并且在关联后，句柄保持    *** 一个句柄只能与一个 I/O 完成端口关联，并且在关联后句柄保持与该 I/O 完成端口关联，直到它被关闭
// 与该 I/O 完成端口关联，直到它被关闭。有关 I/O 完成端口理论、用法和相关函数的详细信
// 息，请参阅 I/O Completion Ports。
//
// 可以通过多次调用 CreateIoCompletionPort，在 ExistingCompletionPort 参数中使用相
// 同的 I/O 完成端口句柄，并在每次调用时在 FileHandle 参数中使用不同的文件句柄，将多个
// 文件句柄与单个 I/O 完成端口关联。
//
// 使用 CompletionKey 参数帮助你的应用程序跟踪哪些 I/O 操作已完成。此值不会被 CreateIoCompletionPort
// 使用；相反，它在与 I/O 完成端口关联时附加到 FileHandle 参数中指定的文件句柄。此完成
// 键应对每个文件句柄唯一，并且它在整个内部排队过程中始终与文件句柄关联。当完成数据包到
// 达时，调用 GetQueuedCompletionStatus 函数获取。CompletionKey 参数还被 PostQueuedCompletionStatus
// 函数用于插入自己的特殊用途的完成数据包。
//
// 将打开的句柄实例与 I/O 完成端口关联后，它不能用于 ReadFileEx 或 WriteFileEx 函数，
// 因为这些函数有自己的异步 I/O 机制。
//
// 最好不要通过句柄继承或调用 DuplicateHandle 函数来共享与 I/O 完成端口关联的文件句柄。  *** 如果一个文件句柄关联到了完成端口，最后不要通过句柄继承或 DuplicateHandle 共享这个文件句柄
// 使用此类重复句柄执行的操作会产生完成通知，建议谨慎考虑。
//
// I/O 完成端口句柄和与该特定 I/O 完成端口关联的每个文件句柄都对 I/O 完成端口的进行了
// 引用。当没有更多引用时，I/O 完成端口被自动释放。因此，所有这些句柄都必须正确关闭，以
// 释放 I/O 完成端口及其关联的系统资源。在满足这些条件后，通过调用 CloseHandle 函数关
// 闭 I/O 完成端口句柄。
//
// 在 Windows 8 和 Windows Server 2012 中，此函数支持以下技术：
//      技术                                                            支持
//      Server Message Block (SMB) 3.0 protocol                         是
//      SMB 3.0 Transparent Failover (TFO)                              是
//      SMB 3.0 with Scale-out File Shares (SO)                         是
//      Cluster Shared Volume File System (CsvFS)                       是
//      Resilient File System (ReFS)                                    是
//
// CreateIoCompletionPort 不需要传 SECURITY_ATTRIBUTES 结构，在所有用来创建内核对象
// 的 Windows 函数中，CreateIoCompletionPort 大概是绝无仅有的。这是因为 I/O 完成端口
// 的设计初衷是只在一个进程中使用。

HANDLE prh_impl_create_completion_port(DWORD concurrent_thread_count) { // 传 0 表示系统处理器数量
    HANDLE completion_port = CreateIoCompletionPort(INVALID_HANDLE_VALUE, prh_null, 0, concurrent_thread_count);
    if (completion_port == prh_null) prh_abort_error(GetLastError());
    return completion_port;
}

void prh_impl_completion_port_attach(HANDLE completion_port, HANDLE file_handle, void *per_handle_completion_key) {
    assert(completion_port != prh_null);
    assert(file_handle != prh_null && file_handle != INVALID_HANDLE_VALUE);
    HANDLE exist_port = CreateIoCompletionPort(file_handle, completion_port, (ULONG_PTR)per_handle_completion_key, 0);
    if (exist_port != completion_port) prh_abort_error(GetLastError());
}

HANDLE prh_impl_create_completion_port_and_attach(DWORD concurrent_thread_count, HANDLE file_handle, void *per_handle_completion_key) {
    prh_impl_completion_port_attach(prh_impl_create_completion_port(concurrent_thread_count),
        file_handle, per_handle_completion_key);
}

void prh_impl_close_completion_port(HANDLE completion_port) {
    prh_impl_close_handle(completion_port);
}

// 当我们创建一个 I/O 完成端口的时候，系统内核实际上会创建 5 个不同的数据结构。分别是：
//  1.  设备列表或文件句柄列表，每条记录包含 (file_handle, completion_key)，添加文件
//      句柄时添加一项，文件句柄关闭时移除一项。
//  2.  I/O 完成队列（***先入先出***），每条记录包含 (bytes_transferred, completion_key,
//      overlapped, error)，当 I/O 请求完成或 PostQueuedCompletionStatus 被调用时
//      添加一项，完成端口移除线程等待队列中的一个线程时，会移除一项。当设备的一个异步
//      I/O 请求完成时，系统会检查设备是否与一个 I/O 完成端口相关联，如果是那么系统会
//      将该完成数据添加到完成队列的尾部。该数据包含已传输字节数、与句柄关联的完成键、
//      指向 I/O 请求的 OVERLAPPED 结构的指针、以及一个错误码。
//  3.  线程等待队列（***后入先出***），每条记录 (thread_id)，线程调用 GetQueuedCompletionStatus
//      时添加一项，满足以下条件时会移除一个线程：I/O 完成队列不为空，且正在运行的线程
//      数小于最大并发数时。 GetQueuedCompletionStatus 会先从 I/O 完成队列中删除对应
//      的一项完成数据，然后将 thread_id 转移到线程执行列表，最后函数返回。等待队列使
//      得 I/O 完成端口内核对象始终能够知道，有哪些线程当前正在等待，当端口中的完成队列
//      中出现一项的时候，该完成端口会唤醒线程等待队列中的一个线程。
//  4.  线程执行列表，每条记录包含 (thread_id)，当完成端口在线程等待队列中唤醒一个线
//      程，或者一个线程暂停列表中的一个线程被成功唤醒时，添加一项。当线程再次调用
//      GetQueuedCompletionStatus 时将线程转移到线程等待队列，或者线程调用一个函数将
//      自己挂起时将线程转移到线程暂停队列。
//  5.  线程暂停列表，每条记录包含 (thread_id)，当线程执行列表中的一个线程调用一个函数
//      将自己挂起时，线程转移到线程暂停队列。当暂停的线程被唤醒时，线程回到线程执行队列。
//
// 线程池中的所有线程应该执行同一个函数，一般来说，这个线程函数会先进行一些初始化，然后
// 进入一个循环，当服务进程被告知要停止的时候，这个循环也应该就此终止。在循环内部，线程
// 调用 GetQueuedCompletionStatus 切换到睡眠状态，来等待设备 I/O 请求的完成通知。
// GetQueuedCompletionStatus 基本上是将调用线程切换到睡眠状态，直到指定的完成端口有
// 完成数据出现，或者等待的事件出现超时。
//
// 移除 I/O 完成队列中完成数据是以先入先出的方式进行的，但可能没有预料的是，唤醒线程等待
// 队列中的线程是以后入先出的方式。例如，假设有 4 个线程在等待，如果出现了完成数据项，
// 那么最后一个调用 GetQueuedCompletionStatus 的线程会被唤醒来进行处理。当最后这个线
// 程完成处理后再次调用 GetQueuedCompletionStatus 进入等待队列，如果又出现一个完成数
// 据项，那么同一个线程会被唤醒来处理这个新的数据项。
//
// 如果 I/O 请求完成得足够慢，使得一个线程就能够将它们全部处理完，那么系统会不断地唤醒    *** 如果少量线程就能够将完成队列处理完，完成端口只会唤醒少量线程
// 同一个线程，而让其他线程继续睡眠。通过使用这种后入先出算法，系统可以将那些未被调度的
// 先出内存资源，例如栈空间，换出到磁盘，并将它们从处理器的高速缓存中清除。这意味着让许
// 多线程等待一个完成端口并不是什么坏事，如果正在等待的线程数量大于已完成的 I/O 请求数
// 量，那么系统会将多余的大多数资源换出内存。
//
// 一旦一个线程调用 GetQueuedCompletionStatus，该线程会与指定的完成端口关联，系统假定
// 被关联的线程都是以该完成端口的名义来完成工作的。有 3 中方式解除这种关联：线程退出，
// 线程用一个不同的完成端口句柄调用 GetQueuedCompletionStatus，销毁指定的完成端口。
//
// 在 Windows Vista 中，当我们调用 CloseHandle 关闭完成端口句柄时，系统会将所有正在
// 等待 GetQueuedCompletionStatus 的线程唤醒，并返回 FALSE。此时调用 GetLastError
// 会返回 ERROR_INVALID_HANDLE，线程可以通过这种方式来知道自己应该得体地退出。
//
// BOOL GetQueuedCompletionStatus(
//      [in]  HANDLE       CompletionPort,
//      [out] LPDWORD      lpNumberOfBytesTransferred,
//      [out] PULONG_PTR   lpCompletionKey,
//      [out] LPOVERLAPPED *lpOverlapped,
//      [in]  DWORD        dwMilliseconds
// );
//
// 尝试从指定的 I/O 完成端口获取一个 I/O 完成数据包。如果没有排队的完成数据包，该函数
// 将等待完成端口上关联 I/O 操作的完成。要一次性获取多个 I/O 完成数据包，可以调用函数
// GetQueuedCompletionStatusEx。成功返回非零值（TRUE），否则返回零（FALSE）。要获取
// 扩展错误信息，请调用 GetLastError。
//
// 参数 CompletionPort 完成端口的句柄。参数 lpNumberOfBytesTransferred 指向一个变量，
// 该变量接收完成的 I/O 操作传输的字节数。参数 lpCompletionKey 指向一个变量，该变量接
// 收与完成 I/O 操作的文件句柄关联的完成键值。完成键是在调用 CreateIoCompletionPort
// 时指定的基于文件句柄的键。
//
// 参数 lpOverlapped 指向一个变量，该变量接收完成 I/O 操作启动时指定的 OVERLAPPED 结
// 构的地址。即使你已经传递了一个与完成端口关联的文件句柄和有效的 OVERLAPPED 结构，应用
// 程序也可以阻止完成端口通知。这是通过为 OVERLAPPED 结构的 hEvent 成员指定一个有效的    *** 可以在 hEvent 成员位或上 1 表示不要将操作的完成通知添加到完成端口的完成队列中
// 事件句柄并设置其低阶位来完成的。低阶位被设置的有效事件句柄会阻止重叠 I/O 完成时将完     *** 低阶位被设置的有效事件句柄会阻止重叠 I/O 完成时将完成数据包排队到完成端口
// 成数据包排队到完成端口。
//
// 参数 dwMilliseconds 调用方愿意等待完成数据包出现的毫秒数。如果在指定时间内没有出现
// 完成数据包，函数将超时，返回 FALSE，并将 *lpOverlapped 设置为 NULL。如果 dwMilliseconds
// 是 INFINITE (0xFFFFFFFF)，函数将永远不会超时。如果 dwMilliseconds 是零且没有 I/O
// 操作可以出队，函数将立即超时。Windows XP、Windows Server 2003、Windows Vista、
// Windows 7、Windows Server 2008 和 Windows Server 2008 R2：dwMilliseconds 值包
// 括在低功耗状态下花费的时间。例如，超时会在计算机处于睡眠状态时继续倒计时。Windows 8
// 及更高版本、Windows Server 2012 及更高版本：dwMilliseconds 值不包括在低功耗状态下
// 花费的时间。例如，超时不会在计算机处于睡眠状态时继续倒计时。
//
// 此函数将线程与指定的完成端口关联。一个线程最多只能与一个完成端口关联。如果由于与之关
// 联的完成端口句柄在调用期间被关闭而导致 GetQueuedCompletionStatus 调用失败，函数将
// 返回 FALSE，*lpOverlapped 将为 NULL，GetLastError 将返回 ERROR_ABANDONED_WAIT_0。
// Windows Server 2003 和 Windows XP：在调用期间关闭完成端口句柄不会导致上述行为。函
// 数将继续等待，直到从端口移除条目或超时（如果指定的值不是 INFINITE）。
//
// 如果 GetQueuedCompletionStatus 函数成功，它将从完成端口弹出一个成功的 I/O 操作的
// 完成数据包，并将信息存储在以下参数指向的变量中：lpNumberOfBytes、lpCompletionKey
// 和 lpOverlapped。失败时（返回值为 FALSE），这些参数可能会包含特定的值组合，如下所示：
//  1.  如果 *lpOverlapped 为 NULL，函数没有从完成端口弹出完成数据包。在这种情况下，
//      函数不会将信息存储在 lpNumberOfBytes 和 lpCompletionKey 参数指向的变量中，它
//      们的值是不确定的。
//  2.  如果 *lpOverlapped 不为 NULL 且函数从完成端口弹出了一个失败的 I/O 操作的完成
//      数据包，函数将有关失败操作的信息存储在 lpNumberOfBytes、lpCompletionKey 和
//      lpOverlapped 指向的变量中。要获取扩展错误信息，请调用 GetLastError。

int prh_impl_completion_port_query(HANDLE completion_port, OVERLAPPED_ENTRY *entry, DWORD msec) {
    assert(completion_port != prh_null);
    assert(entry != prh_null); // 超时时间在 Windows 8 及更高版本上，不包含系统睡眠时间
    BOOL b = GetQueuedCompletionStatus(completion_port, &entry->dwNumberOfBytesTransferred, (PULONG_PTR)&entry->lpCompletionKey, &entry->lpOverlapped, msec);
    if (b) {
        entry->Internal = 0;
        return 1; // 操作成功
    }
    DWORD error_code = GetLastError();
    if (error_code != WAIT_TIMEOUT) prh_prerr(error_code); // 如果返回 ERROR_INVALID_HANDLE 表示完成端口已经关闭
    entry->Internal = error_code;
    return entry->lpOverlapped ? 1 : 0;
}

// 如果预计会不断收到大量的 I/O 请求，可以调用 GetQueuedCompletionStatusEx 函数来同
// 时获取多个 I/O 结果，而不必让许多线程等待完成端口，从而可以避免由此产生的上下文切换
// 所带来的开销。
//
// 最后一个参数 bAlertable，如果设为 FALSE，那么函数会一直等待一个已完成的 I/O 请求添
// 加到完成端口，或者指定的时间超时。如果设为 TRUE，如果队列中没有已完成的 I/O 请求，
// 那么线程将进入可提醒状态。
//
// BOOL WINAPI GetQueuedCompletionStatusEx(
//      _In_  HANDLE             CompletionPort,
//      _Out_ LPOVERLAPPED_ENTRY lpCompletionPortEntries,
//      _In_  ULONG              ulCount,
//      _Out_ PULONG             ulNumEntriesRemoved,
//      _In_  DWORD              dwMilliseconds,
//      _In_  BOOL               fAlertable
// );
//
// typedef struct _OVERLAPPED_ENTRY {
//      ULONG_PTR    lpCompletionKey;
//      LPOVERLAPPED lpOverlapped;
//      ULONG_PTR    Internal; // 保留，没有明确的含义，不应该使用
//      DWORD        dwNumberOfBytesTransferred;
// } OVERLAPPED_ENTRY, *LPOVERLAPPED_ENTRY;
//
// 同时检索多个完成端口条目。它等待与指定完成端口关联的 I/O 操作的完成。要逐个出队 I/O
// 完成数据包，请使用 GetQueuedCompletionStatus 函数。成功时返回非零值 TRUE，否则返回
// 零 FALSE。要获取扩展错误信息，请调用 GetLastError。
//
// 参数 lpCompletionPortEntries 输入时，指向一个预先分配的 OVERLAPPED_ENTRY 结构数组。
// 输出时，接收一个包含条目的 OVERLAPPED_ENTRY 结构数组。数组元素的数量由 ulNumEntriesRemoved
// 提供。每个 I/O 传输的字节数、指示每个 I/O 发生在哪个文件上的完成键以及每个原始 I/O
// 中使用的重叠结构地址都返回在 lpCompletionPortEntries 数组中。
//
// 参数 fAlertable 如果为 FALSE，函数会在超时结束或检索到条目之前不返回。如果参数为
// TRUE 且没有可用条目，函数将执行可警报等待。当系统将 I/O 完成例程（completion routine）
// 或 APC 添加到线程并执行该函数时，线程返回。当指定完成例程的 ReadFileEx 或 WriteFileEx
// 函数完成且调用线程是启动操作的线程时，完成例程会被排队到该线程。当调用 QueueUserAPC
// 时，APC 会被排队到指定线程。
//
// 此函数将线程与指定的完成端口关联。一个线程最多只能与一个完成端口关联。当至少有一个挂
// 起的 I/O 完成时，此函数返回 TRUE，但有可能一个或多个 I/O 操作失败。请注意，检查
// lpCompletionPortEntries 返回的条目确定哪些条目的 I/O 操作可能失败的责任在于此函数
// 的调用者，方法是查看每个 OVERLAPPED_ENTRY 中的 lpOverlapped 成员所包含的状态。
//
// 当没有 I/O 操作被出队时，此函数返回 FALSE。这通常意味着在处理此调用的参数时发生了错
// 误，或者 CompletionPort 句柄被关闭或无效。GetLastError 函数提供扩展错误信息。如果
// 由于与之关联的句柄被关闭而导致 GetQueuedCompletionStatusEx 调用失败，函数将返回
// FALSE，GetLastError 将返回 ERROR_ABANDONED_WAIT_0。服务器应用程序可能有多个线程
// 为同一个完成端口调用 GetQueuedCompletionStatusEx 函数。随着 I/O 操作的完成，它们
// 会以先进先出的顺序被排队到该端口。如果一个线程正在积极地在此调用上等待，那么一个或多
// 个排队的完成请求将只会满足该线程的调用。
//
// GetQueuedCompletionStatusEx 相比传统的 GetQueuedCompletionStatus，主要带来
// “一次等待，批量收割” 的能力，在高并发场景下可以显著减少系统调用次数和线程调度开销。
// 具体收益如下：
//
//  1.  一次可取回多个完成包
//      允许传入一个 _OVERLAPPED_ENTRY[] 数组，内核把当前已排队的完成包尽可能多地一次
//      性拷贝给你，上限由你自己指定（常见 64～256 个）。同样数目的 I/O 完成，系统调用
//      次数从 N → ⌈N / 数组长度⌉，降低 1~2 个数量级。
//  2.  天然负载均衡
//      当多个工作线程同时调用 GetQueuedCompletionStatusEx 时，内核采用轮转队列算法，
//      保证每个线程大致均等地拿到完成包，避免某一个线程忙死、其余线程空转的现象。
//  3.  减少用户/内核模式往返
//      批量返回意味着每包分摊的往返成本降低；在 10 Gbps、小包高 QPS 的测试中，可把
//      CPU 占用降低 10–30%。
//  4.  支持可唤醒的阻塞
//      仍可通过 dwMilliseconds 指定超时；也可配合 PostQueuedCompletionStatus 发
//      “退出” 包，线程统一返回，编码模型与旧 API 完全一致。
//  5.  对单个完成包的场景略慢
//      如果当前时刻队列里只有 1 个包，那么 Ex 版要多拷贝一次数组、做更多判断，实测会
//      比原版慢近一倍；所以很多框架会在 “最近几次只拿到 1 包” 时自动降级回 GetQueuedCompletionStatus。
//
// 连接数高、吞吐大：优先用 GetQueuedCompletionStatusEx，批量收割、均衡负载。连接数低、
// 完成稀疏：继续用 GetQueuedCompletionStatus，避免“杀鸡用牛刀”带来的额外开销。

int prh_impl_completion_port_ext_query(HANDLE completion_port, OVERLAPPED_ENTRY *entry, int count, DWORD msec) {
    assert(entry != prh_null);
    assert(count > 0);
    ULONG n = 0;
    if (!GetQueuedCompletionStatusEx(completion_port, entry, count, &n, msec, FALSE)) {
        DWORD error = GetLastError();
        if (error != WAIT_TIMEOUT) prh_prerr(error);
        return 0;
    }
    return n;
}

// I/O 完成端口并不一定要用于设备 I/O，它还是一项非常棒的技术用来进行线程间通信。在
// “可提醒 I/O” 中，我们调用 QueueUserAPC 允许线程将一个 APC 项添加到另一个线程的队
// 列中，I/O 完成端口也有一个类似的函数 PostQueuedCompletionStatus。该函数提供了一
// 种方式来与线程池中的所有线程进行通信。例如，当用户终止服务应用程序的时候，我们想要
// 让所有线程都干净地退出。但如果各线程还在等待完成端口但又没有已完成的 I/O 请求，那么
// 它们将无法被唤醒。通过为线程池种的每个线程都调用一次 PostQueuedCompletionStatus，
// 我们可以将它们都唤醒。每个线程会对 GetQueuedCompletionStatus 的返回值进行检查，
// 如果发现应用程序正在终止，那么它可以进行清理工作并正常地退出。
//
// 但是这种机制需要唤醒的线程不能再次调用 GetQueuedCompletionStatus 进行等待，这是
// 因为线程是以后入先出的方式被唤醒的。因此，为了确保线程池种的每个线程都能有机会得到
// 模拟的完成通知，我们还必须在应该程序种采用其他线程同步机制，否则同一个线程可能会多
// 次得到相同的通知。
//
// BOOL WINAPI PostQueuedCompletionStatus(
//      _In_     HANDLE       CompletionPort,
//      _In_     DWORD        dwNumberOfBytesTransferred,
//      _In_     ULONG_PTR    dwCompletionKey,
//      _In_opt_ LPOVERLAPPED lpOverlapped
// );
//
// 将一个 I/O 完成数据包发布到 I/O 完成端口。如果函数成功，返回值是非零值。如果函数失
// 败，返回值是零。要获取扩展错误信息，请调用 GetLastError。
//
// I/O 完成数据包将满足一个挂起的对 GetQueuedCompletionStatus 函数的调用。该函数返回
// 时会携带作为 PostQueuedCompletionStatus 调用的第二个、第三个和第四个参数传递的三个
// 值。系统不会使用或验证这些值。特别是，lpOverlapped 不必指向一个 OVERLAPPED 结构。

void prh_impl_completion_port_post(HANDLE completion_port, OVERLAPPED_ENTRY *entry) {
    assert(completion_port != prh_null);
    assert(entry != prh_null);
    BOOL b = PostQueuedCompletionStatus(completion_port, entry->dwNumberOfBytesTransferred, entry->lpCompletionKey, entry->lpOverlapped);
    if (!b) prh_prerr(GetLastError());
}

// BOOL GetOverlappedResult(
//      [in]  HANDLE       hFile,
//      [in]  LPOVERLAPPED lpOverlapped,
//      [out] LPDWORD      lpNumberOfBytesTransferred,
//      [in]  BOOL         bWait
// );
//
// GetOverlappedResult 函数用于检索指定文件、命名管道或通信设备上重叠操作的结果。若需
// 指定超时间隔或等待可警报线程，请使用 GetOverlappedResultEx。如果函数成功，返回值非
// 零。如果函数失败，返回值为零。要获取扩展错误信息，请调用 GetLastError。
//
// 参数 hFile 指向文件、命名管道或通信设备的句柄，是以下函数启动重叠操作时对应的句柄：
//      ReadFile
//      WriteFile
//      ConnectNamedPipe
//      TransactNamedPipe
//      DeviceIoControl
//      WaitCommEvent
//      ReadDirectoryChangesW
//      LockFileEx
//
// 参数 lpOverlapped 指向启动重叠操作时指定的 OVERLAPPED 结构。
//
// 参数 lpNumberOfBytesTransferred 指向一个变量，该变量接收实际由读取或写入操作传输
// 的字节数。对于 TransactNamedPipe 操作，这是从管道中读取的字节数。对于 DeviceIoControl
// 操作，这是设备驱动程序返回的输出数据字节数。对于 ConnectNamedPipe 或 WaitCommEvent
// 操作，此值未定义。
//
// 参数 bWait，如果此参数为 TRUE，且 lpOverlapped 结构的 Internal 成员为 STATUS_PENDING，
// 则函数不会返回，直到操作完成。如果此参数为 FALSE 且操作仍在挂起，则函数返回 FALSE，
// GetLastError 函数返回 ERROR_IO_INCOMPLETE。
//
// GetOverlappedResult 函数报告的结果是与指定句柄的最后一次重叠操作相关的结果，该操作
// 使用了指定的 OVERLAPPED 结构，并且操作结果已处于等待状态。当启动操作的函数返回 FALSE
// 且 GetLastError 函数返回 ERROR_IO_PENDING 时，表示操作处于挂起状态。当 I/O 操作处
// 于挂起状态时，启动操作的函数会将 OVERLAPPED 结构的 hEvent 成员重置为非触发状态。然
// 后，当挂起的操作完成时，系统将事件对象设置为触发状态。
//
// 如果 bWait 参数为 TRUE，GetOverlappedResult 通过等待事件对象处于触发状态来确定挂起
// 的操作是否已完成。如果 OVERLAPPED 结构的 hEvent 成员为 NULL，系统会使用 hFile 句柄
// 的状态来指示操作已完成，不推荐将该方法用于文件、命名管道或通信设备句柄。使用事件对象
// 更安全，因为在同一个文件、命名管道或通信设备上同时执行多个重叠操作时，可能会发生混淆。
// 在这种情况下，无法知道是哪个操作导致了对象状态的触发。
//
// BOOL GetOverlappedResultEx(
//      [in]  HANDLE       hFile,
//      [in]  LPOVERLAPPED lpOverlapped,
//      [out] LPDWORD      lpNumberOfBytesTransferred,
//      [in]  DWORD        dwMilliseconds,
//      [in]  BOOL         bAlertable
// );
//
// GetOverlappedResultEx 函数用于在指定的超时间隔内检索指定文件、命名管道或通信设备上
// 重叠操作的结果。调用线程可以执行可警报等待。如果函数成功，返回值非零。如果函数失败，
// 返回值为零。可以调用 GetLastError 获取扩展错误信息。常见的错误代码包括以下内容：
//      如果 dwMilliseconds 为零且操作仍在进行中，GetLastError 返回 ERROR_IO_INCOMPLETE。
//      如果 dwMilliseconds 非零且排队了 I/O 完成例程或 APC，GetLastError 返回 WAIT_IO_COMPLETION。
//      如果 dwMilliseconds 非零且指定的超时间隔到期，GetLastError 返回 WAIT_TIMEOUT。
//
// 参数 hFile 指向文件、命名管道或通信设备的句柄，是以下函数启动重叠操作时对应的句柄：
//      ReadFile
//      WriteFile
//      ConnectNamedPipe
//      TransactNamedPipe
//      DeviceIoControl
//      WaitCommEvent
//
// 参数 lpOverlapped 指向启动重叠操作时指定的 OVERLAPPED 结构。
//
// 参数 lpNumberOfBytesTransferred 指向一个变量，该变量接收实际由读取或写入操作传输的
// 字节数。对于 TransactNamedPipe 操作，这是从管道中读取的字节数。对于 DeviceIoControl
// 操作，这是设备驱动程序返回的输出数据字节数。对于 ConnectNamedPipe 或 WaitCommEvent
// 操作，此值未定义。
//
// 参数 dwMilliseconds 超时间隔，以毫秒为单位。dwMilliseconds 值不包括在低功耗状态下
// 花费的时间。例如，超时在计算机处于睡眠状态时不会继续倒计时。
//  -   如果 dwMilliseconds 为零且操作仍在进行中，函数将立即返回，GetLastError 函数返回 ERROR_IO_INCOMPLETE。
//  -   如果 dwMilliseconds 非零且操作仍在进行中，函数将等待，直到对象被触发、I/O 完成例程或 APC 被排队，或者超时间隔到期。可以
//      使用 GetLastError 获取扩展错误信息。
//  -   如果 dwMilliseconds 为 INFINITE，函数仅在对象被触发或 I/O 完成例程或 APC 被排队时返回。
//
// 参数 bAlertable，如果此参数为 TRUE 且调用线程处于等待状态，则当系统将 I/O 完成例程
// 或 APC 排队时，函数将返回。然后调用线程将运行该例程或函数。否则，函数不会返回，且完
// 成例程或 APC 函数不会被执行。当指定的 ReadFileEx 或 WriteFileEx 函数完成时，将排队
// 完成例程。仅当 bAlertable 为 TRUE 且调用线程是启动读取或写入操作的线程时，函数才会
// 返回并调用完成例程。当调用 QueueUserAPC 时，将排队 APC。
//
// GetOverlappedResultEx 函数与 GetOverlappedResult 的区别在于：dwMilliseconds 参
// 数可以指定操作的超时间隔，bAlertable 参数可以指定调用线程应执行可警报等待。
//
// GetOverlappedResultEx 函数报告的结果是与指定句柄的最后一次重叠操作相关的结果，该操
// 作使用了指定的 OVERLAPPED 结构，并且操作结果已处于等待状态。当启动操作的函数返回 FALSE
// 且 GetLastError 函数返回 ERROR_IO_PENDING 时，表示操作处于挂起状态。当 I/O 操作处
// 于挂起状态时，启动操作的函数会将 OVERLAPPED 结构的 hEvent 成员重置为非触发状态。然后，
// 当挂起的操作完成时，系统将事件对象设置为触发状态。
//
// 在 OVERLAPPED 结构中指定手动重置事件对象。如果使用自动重置事件对象，则在启动重叠操作
// 和调用 GetOverlappedResultEx 之间的间隔内，事件句柄不应在任何其他等待操作中指定。例
// 如，有时会在等待函数中指定事件对象以等待操作完成。当等待函数返回时，系统将自动重置事
// 件的状态设置为非触发状态，随后调用 GetOverlappedResultEx 并将 dwMilliseconds 参数
// 设置为 INFINITE，将导致函数无限期阻塞。
//
// 如果 OVERLAPPED 结构的 hEvent 成员为 NULL，系统会使用 hFile 句柄的状态来指示操作已
// 完成，此方法不应使用于文件、命名管道或通信设备句柄。使用事件对象更安全，因为在同一个
// 文件、命名管道或通信设备上同时执行多个重叠操作时，可能会发生混淆。在这种情况下，无法
// 知道是哪个操作导致了对象状态的触发。
//
// BOOL WSAAPI WSAGetOverlappedResult(
//      [in]  SOCKET          s,
//      [in]  LPWSAOVERLAPPED lpOverlapped,
//      [out] LPDWORD         lpcbTransfer,
//      [in]  BOOL            fWait,
//      [out] LPDWORD         lpdwFlags
// );
//
// WSAGetOverlappedResult 函数用于检索指定套接字上重叠操作的结果。如果 WSAGetOverlappedResult
// 成功，返回值为 TRUE。这意味着重叠操作已成功完成，并且 lpcbTransfer 指向的值已更新。
// 如果 WSAGetOverlappedResult 返回 FALSE，这意味着重叠操作尚未完成、操作完成但存在
// 错误，或者由于 WSAGetOverlappedResult 的一个或多个参数中的错误，无法确定重叠操作的
// 完成状态。失败时，lpcbTransfer 指向的值不会被更新。使用 WSAGetLastError 确定失败的
// 原因（无论是由 WSAGetOverlappedResult 函数还是相关的重叠操作引起的）。
//      WSANOTINITIALISED       在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN             网络子系统已失败。
//      WSAENOTSOCK             描述符不是套接字。
//      WSA_INVALID_HANDLE      WSAOVERLAPPED 结构的 hEvent 参数不包含有效的事件对象句柄。
//      WSA_INVALID_PARAMETER   一个参数不可接受。
//      WSA_IO_INCOMPLETE       fWait 参数为 FALSE，且 I/O 操作尚未完成。
//      WSAEFAULT               lpOverlapped、lpcbTransfer 或 lpdwFlags 参数中的一个或多个不在有效的用户地址空间中。如果在
//                              Windows Server 2003 及更早版本上，lpOverlapped、lpcbTransfer 或 lpdwFlags 参数为 NULL 指
//                              针，则返回此错误。
//
// 参数 s 标识套接字的描述符。这是在以下 Winsock 函数调用中启动重叠操作时指定的相同套
// 接字，这些函数支持重叠操作。这些函数包括：
//      AcceptEx
//      ConnectEx
//      DisconnectEx
//      TransmitFile
//      TransmitPackets
//      WSARecv
//      WSARecvFrom
//      LPFN_WSARECVMSG (WSARecvMsg)
//      WSASend
//      WSASendMsg
//      WSASendTo
//      WSAIoctl
//
// 参数 lpOverlapped 指向启动重叠操作时指定的 WSAOVERLAPPED 结构的指针。此参数不能为
// NULL 指针。
//
// 参数 lpcbTransfer 指向一个 32 位变量，该变量接收实际由发送或接收操作传输的字节数，
// 或者由 WSAIoctl 函数传输的字节数。此参数不能为 NULL 指针。
//
// 参数 fWait 一个标志，指定函数是否应等待挂起的重叠操作完成。如果为 TRUE，则函数不会
// 返回，直到操作完成。如果为 FALSE 且操作仍在挂起，则函数返回 FALSE，WSAGetLastError    *** WSAGetOverlappedResult 仅在重叠操作已完成时返回操作结果，如果操作未完成要么返回错误 WSA_IO_INCOMPLETE 要么进行等待（fWait 设为 TRUE）
// 函数返回 WSA_IO_INCOMPLETE。只有当重叠操作选择了基于事件的完成通知时，fWait 参数才    *** 只有当使用事件触发方式时，才能将 fWait 设为 TRUE，其他方式将导致不可预测的结果
// 可以设置为 TRUE。
//
// 参数 lpdwFlags 指向一个 32 位变量，该变量将接收一个或多个补充完成状态的标志。如果重    *** 参数 lpdwFlags 是套接字重叠 I/O 中一个额外的完成通知中的字段
// 叠操作是通过 WSARecv 或 WSARecvFrom 启动的，则此参数将包含 lpFlags 参数的结果值。    *** 此字段只有在使用 WSARecv/WSARecvFrom 函数，并且关注对应的标志位时才有用
// 此参数不能为 NULL 指针。
//
// WSAGetOverlappedResult 函数报告 s 参数中指定的套接字的 lpOverlapped 重叠操作的结
// 果。WSAGetOverlappedResult 函数传递套接字描述符和启动重叠函数时指定的 WSAOVERLAPPED
// 结构。当启动操作的函数返回 FALSE 且 WSAGetLastError 函数返回 WSA_IO_PENDING 时，
// 表示操作处于挂起状态。当类似 WSARecv 的 I/O 操作处于挂起状态时，启动操作的函数会将
// WSAOVERLAPPED 结构的 hEvent 成员重置为非触发状态。然后，当挂起的操作完成时，系统将
// 事件对象设置为触发状态。
//
// 如果 fWait 参数为 TRUE，WSAGetOverlappedResult 通过等待事件对象处于触发状态来确定
// 挂起的操作是否已完成。客户端可以将 fWait 参数设置为 TRUE，但前提是它在请求 I/O 操作
// 时选择了基于事件的完成通知。如果选择了其他形式的通知，则 WSAOVERLAPPED 结构的 hEvent
// 参数的使用方式不同，将 fWait 设置为 TRUE 会导致不可预测的结果。
//
// 如果在 Windows Vista 上调用 WSAGetOverlappedResult 函数时，lpOverlapped、lpcbTransfer
// 或 lpdwFlags 参数设置为 NULL 指针，将导致访问冲突。如果在 Windows Server 2003 及
// 更早版本上调用 WSAGetOverlappedResult 函数时，lpOverlapped、lpcbTransfer 或 lpdwFlags
// 参数设置为 NULL 指针，将返回 WSAEFAULT 错误代码。
//
// 注意，当线程退出时，所有 I/O 都将被取消。对于重叠套接字，如果在线程关闭之前操作未完
// 成，则挂起的异步操作可能会失败。有关更多信息，请参阅 ExitThread。
#include <winternl.h> // ULONG RtlNtStatusToDosError([in] NTSTATUS Status);

static HANDLE PRH_IMPL_IOCP;
typedef bool (*prh_iocp_complete_routine)(OVERLAPPED_ENTRY *entry);
typedef void (*prh_iocp_continue_routine)(void *overlapped);
typedef void (*prh_continue_routine)(void *post_req);

prh_static_assert(sizeof(ULONG_PTR) == sizeof(void *));
prh_static_assert(sizeof(HANDLE) == sizeof(void *));

prh_inline void prh_impl_iocp_set_continue_routine(OVERLAPPED *overlappped, prh_iocp_continue_routine iocp_continue) {
    // typedef struct _OVERLAPPED {     // minwinbase.h (included in WinBase.h)
    //     ULONG_PTR Internal;          // [out] Error Code
    //     ULONG_PTR InternalHigh;      // [out] Number of bytes transferred
    //     union {
    //         struct {
    //             DWORD Offset;        // [in] Low 32-bit file offset
    //             DWORD OffsetHigh;    // [in] High 32-bit file offset
    //         } DUMMYSTRUCTNAME;
    //         PVOID Pointer;
    //     } DUMMYUNIONNAME;
    //     HANDLE hEvent;               // [in] Event handle or data
    // } OVERLAPPED, *LPOVERLAPPED;
    assert(((prh_ptr)iocp_continue & 0x01) == 0); // 低阶位置一会阻止重叠 I/O 将完成数据包排队到完成端口
    overlapped->hEvent = (HANDLE)iocp_continue;
}

static bool prh_impl_iocp_entry_completed_from_port(OVERLAPPED_ENTRY *entry) { // 被 prh_impl_sched_thrd_iocp_entry_completed 函数调用
    if (prh_impl_iocp_continue_que_len() >= PRH_IOCP_GLOBAL.iocp_query_max_entries) return false;
    OVERLAPPED *overlapped = entry->lpOverlapped;
    assert(entry->Internal == overlapped->Internal);
    assert(entry->dwNumberOfBytesTransferred == overlapped->InternalHigh);
    if (overlapped->Internal) { // 内核会把 NTSTATUS 写进 Internal，成功时为 STATUS_SUCCESS(0)，失败时为对应错误码
        DWORD error_code = RtlNtStatusToDosError((NTSTATUS)overlapped->Internal); // 如果没有对应的系统错误码，将返回 ERROR_MR_MID_NOT_FOUND 317 (0x013D)
        prh_prerr(error_code);
        overlapped->Internal = error_code;
    }
    ((prh_iocp_continue_routine)overlapped->hEvent)(overlapped); // 调用 <operation>_completed_from_port 函数，该函数向 iocp_continue_que 投递一个线程任务
    return true;
}

void prh_impl_iocp_attach_handle(prh_handle handle) {
    prh_impl_completion_port_attach(PRH_IMPL_IOCP, handle, (void *)prh_impl_iocp_entry_completed_from_port);
}

void prh_impl_iocp_enqueue_completion_item(prh_iocp_complete_routine completion_key, void *overlapped) {
    OVERLAPPED_ENTRY overlapped_entry = {.lpCompletionKey = (ULONG_PTR)completion_key, .lpOverlapped = overlapped};
    prh_impl_completion_port_post(PRH_IMPL_IOCP, &overlapped_entry);
}

// RIO_CQ RIOCreateCompletionQueue(
//      DWORD QueueSize, // [1, RIO_MAX_CQ_SIZE]
//      PRIO_NOTIFICATION_COMPLETION NotificationCompletion
// );
//
// typedef enum _RIO_NOTIFICATION_COMPLETION_TYPE {
//      RIO_EVENT_COMPLETION = 1,
//      RIO_IOCP_COMPLETION = 2
// } RIO_NOTIFICATION_COMPLETION_TYPE, *PRIO_NOTIFICATION_COMPLETION_TYPE;
//
// typedef struct _RIO_NOTIFICATION_COMPLETION {
//      RIO_NOTIFICATION_COMPLETION_TYPE Type;
//      union {
//          struct {
//              HANDLE EventHandle;
//              BOOL   NotifyReset;
//          } Event;
//          struct {
//              HANDLE IocpHandle;
//              PVOID  CompletionKey;
//              PVOID  Overlapped;
//          } Iocp;
//      };
// } RIO_NOTIFICATION_COMPLETION, *PRIO_NOTIFICATION_COMPLETION;
//
// RIOCreateCompletionQueue 函数用于创建一个特定大小的 I/O 完成队列，以供 Winsock
// RIO 扩展使用。如果没有错误发生，RIOCreateCompletionQueue 函数返回一个引用新完成队
// 列的描述符。否则返回 RIO_INVALID_CQ，可以通过 WSAGetLastError 函数获取错误代码。
//      WSAEFAULT   系统在尝试使用指针参数时检测到无效的指针地址。
//      WSAEINVAL   向函数传递了无效参数。如果 QueueSize 参数小于 1 或大于 Mswsockdef.h 头文件中定义的 RIO_MAX_CQ_SIZE，则返回此错误。
//      WSAENOBUFS  无法分配足够的内存。如果根据 QueueSize 参数请求的完成队列无法分配足够的内存，则返回此错误。
//
// 参数 QueueSize 要创建的完成队列的大小，以条目数为单位。参数 NotificationCompletion，
// 基于 RIO_NOTIFICATION_COMPLETION 结构 Type 成员的类型，确定使用的通知完成类型（I/O
// 完成或事件通知）。
//  1.  如果 Type 成员设置为 RIO_EVENT_COMPLETION，则 RIO_NOTIFICATION_COMPLETION
//      结构的 Event 成员必须设置。
//  2.  如果 Type 成员设置为 RIO_IOCP_COMPLETION，则 RIO_NOTIFICATION_COMPLETION
//      结构的 Iocp 成员必须设置，并且 RIO_NOTIFICATION_COMPLETION 结构的 Iocp.Overlapped
//      成员不能为 NULL。
//  3.  如果 NotificationCompletion 参数为 NULL，则表示不使用通知完成，必须通过轮询来
//      确定完成。
//
// RIOCreateCompletionQueue 函数创建一个特定大小的 I/O 完成队列。完成队列的大小限制了
// 可以与完成队列关联的注册 I/O 套接字的集合。创建 RIO_CQ 时，NotificationCompletion
// 参数指向的 RIO_NOTIFICATION_COMPLETION 结构决定了应用程序将如何接收完成队列通知。
//
// 如果在创建完成队列时提供了 RIO_NOTIFICATION_COMPLETION 结构，则应用程序可以调用
// RIONotify 函数请求完成队列通知。通常，当完成队列不为空时会触发通知。这可能立即发生，
// 或者当下一个完成条目插入完成队列时发生。但是，发送和接收请求可以标记为 RIO_MSG_DONT_NOTIFY，
// 此类请求不会触发完成队列通知。如果完成队列中只有设置了 RIO_MSG_DONT_NOTIFY 标志的
// 条目，则不会触发完成队列通知。此外，当新条目进入完成队列时，只有当关联请求未设置
// RIO_MSG_DONT_NOTIFY 标志时，才会触发完成队列通知。仍然可以使用 RIODequeueCompletion
// 函数通过轮询检索任何已完成的请求。一旦完成队列通知触发，应用程序必须调用 RIONotify
// 函数才能接收另一个完成队列通知。当完成队列通知发生时，应用程序通常调用 RIODequeueCompletion
// 函数来获取已完成的发送或接收请求。
//
// 完成队列通知有两种选项：
//
// 事件句柄：如果 RIO_NOTIFICATION_COMPLETION 结构的 Type 成员设置为 RIO_EVENT_COMPLETION，
// 则使用事件句柄来发出完成队列通知。事件句柄通过 RIOCreateCompletionQueue 函数
// RIO_NOTIFICATION_COMPLETION 结构中的 EventNotify.EventHandle 成员提供。Event.EventHandle
// 成员应包含由 WSACreateEvent 或 CreateEvent 函数创建的事件的句柄。为了接收 RIONotify
// 完成通知，应用程序应使用 WSAWaitForMultipleEvents 或类似的等待例程等待指定的事件句
// 柄。调用 RIONotify 函数会触发对应的 RIO_CQ 事件的完成通知。传递给 RIOCreateCompletionQueue
// 函数的 RIO_NOTIFICATION_COMPLETION 结构中的 Event.NotifyReset 成员指示是否应在
// RIONotify 函数调用时重置事件。如果应用程序计划重置并重用事件，则可以通过将 Event.NotifyReset
// 成员设置为非零值来减少开销。这将导致事件在通知发生时由 RIONotify 函数自动重置，避免
// 了在 RIONotify 函数调用之间调用 WSAResetEvent 函数来重置事件。
//
// I/O 完成端口：如果 RIO_NOTIFICATION_COMPLETION 结构的 Type 成员设置为 RIO_IOCP_COMPLETION，
// 则使用 I/O 完成端口来发出完成队列通知。I/O 完成端口句柄通过 RIOCreateCompletionQueue
// 函数的 RIO_NOTIFICATION_COMPLETION 结构中的 Iocp.IocpHandle 成员提供。此 RIO_CQ
// 对 RIONotify 函数的调用将向对应的 RIO_CQ 完成端口排队一个条目，可以使用 GetQueuedCompletionStatus
// 或 GetQueuedCompletionStatusEx 函数检索该条目。排队的条目返回的 lpCompletionKey
// 参数值，对应于 RIO_NOTIFICATION_COMPLETION 结构的 Iocp.CompletionKey 成员中指定
// 的值，RIO_NOTIFICATION_COMPLETION 结构的 Iocp.Overlapped 成员是一个非 NULL 值。
//
// 就其使用而言，完成队列通知旨在唤醒等待的应用程序线程，以便线程可以检查完成队列。唤醒
// 和调度线程是有代价的，因此如果这种情况发生得太频繁，将对应用程序性能产生负面影响。提
// 供 RIO_MSG_DONT_NOTIFY 标志，以便应用程序可以控制这些事件的频率，并限制它们对性能的
// 过度影响。
//
// 注意，为了提高效率，对完成队列（RIO_CQ 结构）和请求队列（RIO_RQ 结构）的访问不受同
// 步原语保护。如果需要从多个线程访问完成队列或请求队列，则应通过临界区、轻量级读写锁或
// 类似的机制协调访问。单个线程访问时不需要锁定。不同线程可以访问不同的请求/完成队列，
// 无需锁定。只有当多个线程尝试访问同一个队列时，才需要同步。如果多个线程在同一个套接字
// 上发出发送和接收操作，也需要同步，因为发送和接收操作使用套接字的请求队列。
//
// 注意，必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_MULTIPLE_EXTENSION_FUNCTION_POINTER
// 操作码来获取 RIOCreateCompletionQueue 函数的函数指针。传递给 WSAIoctl 函数的输入
// 缓冲区必须包含 WSAID_MULTIPLE_RIO，这是一个全局唯一标识符（GUID），其值标识 Winsock
// RIO 扩展函数。成功时，WSAIoctl 函数返回的输出包含指向 RIO_EXTENSION_FUNCTION_TABLE
// 结构的指针，该结构包含指向 Winsock RIO 扩展函数的指针。SIO_GET_MULTIPLE_EXTENSION_FUNCTION_POINTER
// IOCTL 在 Ws2def.h 头文件中定义。WSAID_MULTIPLE_RIO GUID 在 Mswsock.h 头文件中定
// 义。
//
// typedef struct RIO_CQ_t* RIO_CQ, **PRIO_CQ;
//
// RIO_CQ 完成队列对象​​用于保存 Winsock RIO 网络发送操作和接收操作的完成通知。应用程序
// 可通过以下方式管理完成队列：应用程序可以调用 RIONotify 函数请求在 RIO_CQ 队列非空时
// 触发完成通知，或者以非阻塞方式随时调用 RIODequeueCompletion 对完成队列进行轮询。使
// 用 RIONotify 函数注册的通知机制，可以减少轮询的频率，提高性能。
//
// RIO_CQ 对象是通过调用 RIOCreateCompletionQueue 函数创建的。在创建时，应用程序必须
// 指定队列的大小，这决定了它可以容纳多少个完成条目。当应用程序调用 RIOCreateRequestQueue
// 函数以获取 RIO_RQ 句柄时，应用程序必须指定一个用于发送完成的 RIO_CQ 句柄和一个用于
// 接收完成的 RIO_CQ 句柄。当应该使用相同的队列进行发送和接收完成时，这些句柄可以相同。
// RIOCreateRequestQueue 函数还需要一个最大未完成的发送和接收操作数量，这些操作数量会
// 占用关联的完成队列的容量。如果队列没有足够的剩余容量，RIOCreateRequestQueue 调用将
// 因 WSAENOBUFS 错误而失败。
//
// INT RIONotify(
//      RIO_CQ CQ
// );
//
// RIONotify 函数用于为 Winsock RIO 注册完成通知，当调用该函数后，对应的完成队列如果
// 有操作完成，会根据完成队列对应的通知机制进行完成通知。若未发生错误，RIONotify 函数
// 返回 ERROR_SUCCESS；否则返回特定错误代码。
//      ​​WSAEINVAL     函数接收到无效参数。若传入的完成队列无效（如 RIO_INVALID_CQ）或发生内部错误时返回此错误。
//      WSAEALREADY​​   尝试对已有操作进行的非阻塞套接字继续请求操作。若前一次 RIONotify 请求尚未完成则返回此错误。
//
// ​参数​​ ​CQ​​ 指定对应的 I/O 完成队列。
//
// 该函数是应用程序获知请求已完成且待调用 RIODequeueCompletion 的机制。当 I/O 完成队
// 列非空且包含操作结果时，RIONotify 会设置触发通知行为的方法。只要让 RIO 完成队列在
// "有新完成包" 时主动唤醒你，就要先调用一次 RIONotify，调一次 RIONotify 只负责 “下一
// 次” 完成到达后的信号触发，调一次只生效一次，用完必须再调。每次 RIODequeueCompletion
// 把队列抽空后，必须再次调用 RIONotify，否则新完成包进来不会触发事件或 IOCP。消费完队
// 列就再按一次，让 RIO 在新完成包到达时重新点亮事件或 IOCP，否则通知链条会断掉。
//
// 三种通知模型与 RIONotify 的使用方式
//  模型            什么时候调 RIONotify            之后如何拿到完成结果
//  轮询            不调（或调了也不用等事件）       直接循环 RIODequeueCompletion
//  事件通知        每次消费完队列后再调一次         WaitForSingleObject(hev, …) 被唤醒，再 RIODequeueCompletion
//  IOCP 通知       同上，消费完再调                GetQueuedCompletionStatus(Ex) 返回，再 RIODequeueCompletion
//
//      // 1. 创建队列时指定通知对象
//      RIO_CQ cq = rio.RIOCreateCompletionQueue(queueSize, &event); // 或 &iocp
//      // 2. 初始投递一批 RIOReceive / RIOSend
//      for (...) rio.RIOReceive(rq, &buf, 1, 0, context);
//      // 3. 先调一次 RIONotify 启动 “信号-armed” 状态
//      rio.RIONotify(cq);
//      for (; ;) {
//          // 4. 等事件/IOCP
//          WaitForSingleObject(event, INFINITE); // 或 GetQueuedCompletionStatus
//          // 5. 收割
//          ULONG n;
//          while ((n = rio.RIODequeueCompletion(cq, results, MAX)) > 0) {
//              HandleCompletions(results, n);
//          }
//          // 6. 队列再次为空，重新装填准备发射（armed）
//          rio.RIONotify(cq);
//      }
//
// 完成队列的通知行为在其创建时即被确定。创建 RIO_CQ 时需向 RIOCreateCompletionQueue
// 函数传递 RIO_NOTIFICATION_COMPLETION 结构体：
//
// ​事件通知​​：将结构体的 Type 成员设为 RIO_EVENT_COMPLETION，Event.EventHandle 成员
// 应为 WSACreateEvent 或 CreateEvent 创建的事件句柄。应用程序需通过 WSAWaitForMultipleEvents
// 等例程等待该句柄。若需重复使用事件，可将 Event.NotifyReset 设为非零值以自动重置事件，
// 避免调用 WSAResetEvent。
//
// IOCP 通知​​：将 Type 设为 RIO_IOCP_COMPLETION，Iocp.IocpHandle 成员应为 CreateIoCompletionPort
// 创建的 IOCP 句柄。应用程序需调用 GetQueuedCompletionStatus(Ex)，并通过专用 OVERLAPPED
// 对象及 CompletionKey 区分不同队列的通知。
//
// 使用线程池的应用程序可通过线程池等待对象接收通知，此时应在调用 RIONotify 后立即调用
// SetThreadpoolWait。若顺序颠倒且依赖 RIONotify 清除事件对象，可能导致回调函数误触发。
//
// ​​线程安全​​，多线程通过 RIODequeueCompletion 访问同一 RIO_CQ 时，需使用临界区、轻量级
// 读写锁（slim reader writer lock）等互斥机制协调。若完成队列非共享，则无需互斥。
//
// ULONG RIODequeueCompletion(
//      RIO_CQ CQ,
//      PRIORESULT Array,
//      ULONG ArraySize
// );
//
// typedef struct _RIORESULT {
//      LONG      Status;
//      ULONG     BytesTransferred;
//      ULONGLONG SocketContext;
//      ULONGLONG RequestContext;
// } RIORESULT, *PRIORESULT;
//
// RIODequeueCompletion 函数用于从 I/O 完成队列中移除条目。如果没有错误发生，函数返回
// 从指定完成队列中移除的完成条目数。否则返回 RIO_CORRUPT_CQ，表示由于内存损坏或滥用
// RIO 函数，CQ 参数中传递的 RIO_CQ 的状态已损坏。
//
// 参数 CQ 指定 I/O 完成队列。参数 Array 指定 RIORESULT 结构数组，用于接收已出队的完
// 成通知。参数 ArraySize，Array 中可写入的最大条目数。
//
// RIODequeueCompletion 函数用于从 I/O 完成队列中移除发送和接收请求的条目，这些请求与
// Winsock RIO 扩展相关。
//
// RIODequeueCompletion 函数是应用程序了解已完成的发送和接收请求的机制。应用程序通常
// 在完成队列不为空时，根据 RIONotify 函数注册的方法接收通知后，调用 RIODequeueCompletion
// 函数。I/O 完成队列的通知行为在创建 RIO_CQ 时设置。
//
// 当 RIODequeueCompletion 函数完成时，Array 参数包含一个指向已出队的完成发送和接收请
// 求的 RIORESULT 结构体数组。返回的 RIORESULT 结构的成员提供了已完成请求的完成状态信
// 息和传输的字节数。每个返回的 RIORESULT 结构还包括一个套接字上下文和一个应用程序上下
// 文，可用于识别特定的已完成请求。
//
// 如果 CQ 参数中传递的 I/O 完成队列无效或已损坏，RIODequeueCompletion 函数返回 RIO_CORRUPT_CQ。
// 如果没有任何已完成的发送或接收请求需要出队，RIODequeueCompletion 函数返回零值。只有
// 在操作请求完成且被出队后，系统才会释放其缓冲区和缓冲区注册的关联，以及其配额费用。
//
// BOOL RIOResizeCompletionQueue(
//      RIO_CQ CQ,
//      DWORD QueueSize
// );
//
// RIOResizeCompletionQueue 函数用于调整 I/O 完成队列的大小，使其变大或变小。如果没有
// 错误发生，RIOResizeCompletionQueue 函数返回 TRUE。否则返回 FALSE，可以通过调用
// WSAGetLastError 函数获取特定的错误代码。
//      WSAEFAULT           系统在尝试使用指针参数时检测到无效的指针地址。如果 CQ 参数中指定的完成队列包含无效指针，则返回此错误。
//      WSAEINVAL           向函数传递了无效参数。如果 CQ 参数无效（例如 RIO_INVALID_CQ），或者 QueueSize 参数指定的队列大小大于 RIO_CQ_MAX_SIZE，则返回此错误。
//      WSAENOBUFS          无法分配足够的内存。如果无法为 QueueSize 参数指定的队列分配内存，则返回此错误。
//      WSAETOOMANYREFS     仍有太多操作引用 I/O 完成队列。此时无法将此 I/O 完成队列调整为更小的大小。
//
// 参数 CQ 标识要调整大小的现有 I/O 完成队列的描述符。参数 QueueSize 要调整到的新大小，
// 以条目数为单位。
//
// RIOResizeCompletionQueue 函数用于调整 I/O 完成队列的大小，使其变大或变小。如果 I/O
// 完成队列中已经包含完成条目，这些完成条目将被复制到新的完成队列中。                    *** 现存的完成条目会复制到新的完成队列中
//
// I/O 完成队列有一个所需的最小大小，这取决于与完成队列关联的请求队列的数量以及请求队列
// 上的发送和接收操作的数量。如果应用程序调用 RIOResizeCompletionQueue 函数并尝试将队
// 列设置得比 I/O 完成队列中现有的完成条目数量还小，则调用将失败，队列不会被调整大小。    *** 完成队列应维持一个最小的队列大小，可以满足关联的请求队列以及触发的发送和接收操作的数量
//
// 如果多个线程尝试使用 RIODequeueCompletion 或 RIOResizeCompletionQueue 函数访问同
// 一个 RIO_CQ，必须通过临界区、轻量级读写锁或类似的互斥机制协调访问。如果完成队列不共
// 享，则不需要互斥。
//
// VOID RIOCloseCompletionQueue(
//      RIO_CQ CQ
// );
//
// RIOCloseCompletionQueue 函数用于关闭一个现有的 I/O 完成队列，该队列用于保存通过
// Winsock RIO 发送操作和接收操作的完成通知。参数 CQ 指定一个现有的完成队列。
//
// RIOCloseCompletionQueue 函数关闭一个现有的 I/O 完成队列。CQ 参数中传递的 RIO_CQ
// 被内核锁定为写入状态（locked for writing by the kernel）。完成队列被标记为无效，     *** 完成队列关闭后，挂起操作的完成通知将被丢弃
// 因此无法添加新的完成条目。任何要添加的新完成条目将被静默丢弃。应用程序应跟踪任何挂起
// 的发送或接收操作。
//
// 如果在 CQ 参数中传递了一个无效的完成队列（例如 RIO_INVALID_CQ），RIOCloseCompletionQueue
// 函数将忽略它。
#include <mswsock.h>

static RIO_EXTENSION_FUNCTION_TABLE PRH_IMPL_RIO;
typedef struct prh_rio_cqueue prh_rio_cqueue;

prh_rio_cqueue *prh_impl_rio_cqueue_create(int queue_size, HANDLE completion_port, prh_ptr completion_key, void *overlapped) {
    assert(queue_size > 0 && queue_size <= RIO_MAX_CQ_SIZE); // mswsockdef.h #define RIO_MAX_CQ_SIZE 0x800_0000
    RIO_NOTIFICATION_COMPLETION completion;
    completion.Type = RIO_IOCP_COMPLETION;
    completion.Iocp.IocpHandle = completion_port;
    completion.Iocp.CompletionKey = (PVOID)completion_key;
    completion.Iocp.Overlapped = (PVOID)overlapped;
    RIO_CQ *rio_cq = PRH_IMPL_RIO.RIOCreateCompletionQueue(queue_size, &completion);
    prh_wsa_abort_if(rio_cq == prh_null);
    return (prh_rio_cqueue *)rio_cq;
}

void prh_impl_rio_cqueue_resize(prh_rio_cqueue *cqueue, int new_queue_size) {
    assert(new_queue_size > 0 && new_queue_size <= RIO_MAX_CQ_SIZE);
    BOOL b = PRH_IMPL_RIO.RIOResizeCompletionQueue((RIO_CQ)cqueue, new_queue_size);
    prh_wsa_prerr_if(b == FALSE);
}

void prh_impl_rio_cqueue_close(prh_rio_cqueue *cqueue) { // 如果传递一个无效完成队列（RIO_INVALID_CQ）将被忽略
    PRH_IMPL_RIO.RIOCloseCompletionQueue((RIO_CQ)cqueue);
}

void prh_impl_rio_notify(prh_rio_cqueue *cqueue) {
    // 应用程序可通过两种方式管理完成队列：应用程序可以调用 RIONotify 请求在 RIO_CQ
    // 队列非空时触发完成通知，或者以非阻塞方式随时调用 RIODequeueCompletion 对完成队
    // 列进行轮询。使用 RIONotify 函数注册的通知机制，可以减少轮询的频率，提高性能。
    INT n = PRH_IMPL_RIO.RIONotify((RIO_CQ)cqueue);
    prh_wsa_prerr_if(n != 0);
}

int prh_impl_rio_cqueue_query(prh_rio_cqueue *cqueue, RIORESULT *entry, int count) {
    // typedef struct _RIORESULT {
    //      LONG      Status;
    //      ULONG     BytesTransferred;
    //      ULONGLONG SocketContext;
    //      ULONGLONG RequestContext;
    // } RIORESULT, *PRIORESULT;
    assert(entry != prh_null && count > 0);
    ULONG n = PRH_IMPL_RIO.RIODequeueCompletion((RIO_CQ)cqueue, entry, count);
    prh_wsa_abort_if(n == RIO_CORRUPT_CQ);
    return (int)n;
}

// RIO_RQ RIOCreateRequestQueue(
//      SOCKET Socket,
//      ULONG MaxOutstandingReceive,
//      ULONG MaxReceiveDataBuffers,
//      ULONG MaxOutstandingSend,
//      ULONG MaxSendDataBuffers,
//      RIO_CQ ReceiveCQ,
//      RIO_CQ SendCQ,
//      PVOID SocketContext
// );
//
// RIOCreateRequestQueue 函数用于创建一个 RIO 套接字描述符，使用指定的套接字和 I/O 完
// 成队列，以供 Winsock RIO 扩展函数使用。如果没有错误发生，RIOCreateRequestQueue 函
// 数返回一个新的请求队列的描述符。否则返回 RIO_INVALID_RQ，可以通过调用 WSAGetLastError
// 函数获取特定的错误代码。
//      WSAEINVAL       向函数传递了无效参数。如果 ReceiveCQ 或 SendCQ 参数包含 RIO_INVALID_CQ，则返回此错误。如果 MaxOutstandingReceive
//                      和 MaxOutstandingSend 参数均为零，也返回此错误。如果 Socket 参数中的套接字正在初始化或关闭过程中，也返回此错误。
//      WSAENOBUFS      无法分配足够的内存。如果根据参数无法为请求队列分配足够的内存，则返回此错误。如果超出网络会话限制，也返回此错误。
//      WSAENOTSOCK     描述符不是套接字。如果 Socket 参数不是有效套接字，则返回此错误。
//      WSAEOPNOTSUPP   尝试的操作不支持引用的对象类型。如果 Socket 参数中的套接字类型不受支持（例如 SOCK_RAW），则返回此错误。
//
// 参数 Socket 标识套接字的描述符。
//
// 参数 MaxOutstandingReceive 允许在套接字上挂起的最大接收操作的数量。注意，对于大多
// 数应用程序，此参数通常是一个较小的数字。参数 MaxReceiveDataBuffers 套接字上的最大
// 接收数据缓冲区的数量。注意，对于 Windows 8 和 Windows Server 2012 此参数必须为 1。
//
// 参数 MaxOutstandingSend 允许在套接字上挂起的最大发送操作的数量。参数 MaxSendDataBuffers
// 套接字上的最大发送数据缓冲区的数量。注意，对于 Windows 8 和 Windows Server 2012，
// 此参数必须为 1。
//
// 参数 ReceiveCQ 表示用于保存接收请求完成通知的 I/O 完成队列。参数 SendCQ 表示用于保
// 存发送请求完成通知的 I/O 完成队列。此参数可以与 ReceiveCQ 参数具有相同的值。
//
// 参数 SocketContext，与该请求队列关联的套接字上下文。
//
// RIOCreateRequestQueue 函数使用指定的套接字和 I/O 完成队列创建一个 RIO 套接字描述符。
// 应用程序必须调用 RIOCreateRequestQueue 以获取 Winsock 套接字的 RIO_RQ，然后才能使
// 用 RIOSend、RIOSendEx、RIOReceive 或 RIOReceiveEx 函数。为了获取 RIO_RQ，Winsock
// 套接字必须与发送和接收的完成队列关联。
//
// 由于完成队列的大小是有限的，只有在保证不会超过总排队完成的容量时，套接字才可能与发送
// 和接收操作的完成队列关联。因此，通过调用 RIOCreateRequestQueue 函数为套接字建立了特
// 定的限制。这些限制既用于在 RIOCreateRequestQueue 调用期间验证完成队列中有足够的空间
// 来容纳套接字请求，也用于在请求发起时确保请求不会导致套接字超出其限制。
//
// 发送和接收队列可以与多个套接字关联。发送和接收队列的大小必须大于或等于所有附加套接字    *** 发送操作的完成队列和接收操作的完成队列，可以与多个套接字关联，直到套接字被关闭
// 的发送和接收大小。随着使用 closesocket 函数关闭套接字，请求队列被关闭，这些插槽将被
// 释放，供其他套接字使用。当应用程序完成对 RIO_RQ 的使用时，应用程序应调用 closesocket
// 函数关闭套接字并释放相关资源。
//
// typedef struct RIO_RQ_t* RIO_RQ, **PRIO_RQ;
//
// Winsock RIO 扩展函数主要在 RIO_RQ 对象上操作，而不是直接在套接字上。应用程序通过调
// 用 RIOCreateRequestQueue 函数为现有的套接字获取一个 RIO_RQ。输入的套接字必须通过在   *** 请求队列关联的套接字必须设置 WSA_FLAG_RIO 标志
// dwFlags 参数中设置 WSA_FLAG_RIO 标志调用 WSASocket 函数创建。
//
// 获取 RIO_RQ 对象后，底层套接字描述符仍然有效。应用程序可以继续使用底层套接字来设置和
// 查询套接字选项、发出 IOCTL 调用，最终关闭套接字。
//
// BOOL RIOResizeRequestQueue(
//      RIO_RQ RQ,
//      DWORD MaxOutstandingReceive,
//      DWORD MaxOutstandingSend
// );
//
// RIOResizeRequestQueue 函数用于调整请求队列的大小，使其变大或变小。如果没有错误发生，
// RIOResizeRequestQueue 函数返回 TRUE。否则返回，可以通过调用 WSAGetLastError 函数
// 获取特定的错误代码。
//      WSAEINVAL           向函数传递了无效参数。如果 RQ 参数无效（例如 RIO_INVALID_RQ），或者 MaxOutstandingReceive 和 MaxOutstandingSend 参数均为零，则返回此错误。
//      WSAENOBUFS          无法分配足够的内存。如果无法为调整大小后的请求队列分配内存，则返回此错误。
//      WSAETOOMANYREFS     仍有太多操作引用请求队列。此时无法将此请求队列调整为更小的大小。
//
// 参数 RQ 标识要调整大小的现有 RIO 套接字描述符（请求队列）。
//
// 参数 MaxOutstandingReceive 允许在套接字上挂起的最大接收操作数。此值可以大于或小于
// 原始数量。注意，对于大多数应用程序，此参数通常是一个较小的数字。
//
// 参数 MaxOutstandingSend 允许在套接字上挂起的最大发送操作数。此值可以大于或小于原始
// 数量。
//
// RIOResizeRequestQueue 函数用于调整请求队列的大小，使其变大或变小。如果请求队列中已
// 经包含条目，这些条目将被复制到新的请求队列中。
//
// 请求队列有一个所需的最小大小，这取决于当前条目数量（请求队列上的发送和接收操作数量）。
// 如果应用程序调用 RIOResizeRequestQueue 函数并尝试将队列设置得比现有条目数量还小，
// 则调用将失败，队列不会被调整大小。

typedef struct prh_rio_rqueue prh_rio_rqueue, *prh_rio_socket;

prh_rio_rqueue *prh_impl_rio_rqueue_create(prh_handle socket, prh_rio_cqueue *cqueue, void *socket_context) {
    RIO_RQ rio_rq = PRH_IMPL_RIO.RIOCreateRequestQueue(
        /* SOCKET Socket                */ (SOCKET)socket,
        /* ULONG MaxOutstandingReceive  */ 1, // 一个套接字同时只允许一个待完成的接收操作
        /* ULONG MaxReceiveDataBuffers  */ 1, // 一个套接字只使用一个缓冲区用于接收
        /* ULONG MaxOutstandingSend     */ 1, // 一个套接字同时只允许一个待完成的发送操作
        /* ULONG MaxSendDataBuffers     */ 1, // 一个套接字只使用一个缓冲区用于发送
        /* RIO_CQ ReceiveCQ             */ (RIO_CQ)cqueue, // 关联接收操作使用的完成队列
        /* RIO_CQ SendCQ                */ (RIO_CQ)cqueue, // 关联发送操作使用的完成队列
        /* PVOID SocketContext          */ (PVOID)socket_context
        );
    prh_wsa_abort_if(rio_rq == prh_null);
    return (prh_rio_rqueue *)rio_rq;
}

void prh_impl_rio_rqueue_resize(prh_rio_rqueue *rqueue, int max_out_recv, int max_out_send) {
    BOOL b = PRH_IMPL_RIO.RIOResizeRequestQueue((RIO_RQ)rqueue, max_out_recv, max_out_send);
    prh_wsa_prerr_if(b == FALSE);
}

// RIO_BUFFERID RIORegisterBuffer(
//      PCHAR DataBuffer,
//      DWORD DataLength
// );
//
// RIORegisterBuffer 函数用于注册一个 RIO_BUFFERID，以便与指定的缓冲区一起使用 Winsock
// RIO 扩展函数。如果没有错误发生，RIORegisterBuffer 函数返回一个注册的缓冲区描述符。
// 否则返回 RIO_INVALID_BUFFERID，可以调用 WSAGetLastError 函数获取特定的错误代码。
//      WSAEFAULT   系统在尝试使用指针参数时检测到无效的指针地址。如果 DataBuffer 参数传递了无效的缓冲区指针，则返回此错误。
//      WSAEINVAL   向函数传递了无效参数。如果 DataLength 参数为零，则返回此错误。
//
// 参数 DataBuffer 指向要注册的内存缓冲区的起始位置的指针。参数 DataLength 要注册的缓
// 冲区中的字节长度。
//
// RIORegisterBuffer 函数为指定的缓冲区创建一个注册缓冲区标识符。当缓冲区被注册时，包
// 含缓冲区的虚拟内存页面将被锁定在物理内存中。
//
// 如果注册了多个小的、不连续的缓冲区，这些缓冲区的物理内存占用可能实际上每个注册都相当
// 于一个完整的内存页面。在这种情况下，将多个请求缓冲区一起分配可能会更有益。
//
// 注册缓冲区本身也会占用少量的物理内存开销。因此，如果许多分配被聚合到一个更大的分配中，
// 通过聚合缓冲区注册，物理内存占用可能会进一步减少。在这种情况下，应用程序可能需要格外
// 小心，以确保最终注销了缓冲区，但不要在任何发送或接收请求仍然挂起时注销。
//
// 注册缓冲区的一部分通过 RIOSend、RIOSendEx、RIOReceive 和 RIOReceiveEx 函数的
// pData 参数传递，用于发送或接收数据。当不再需要缓冲区标识符时，调用 RIODeregisterBuffer
// 函数注销缓冲区标识符。
//
// VOID RIODeregisterBuffer(
//      RIO_BUFFERID BufferId
// );
//
// RIODeregisterBuffer 函数用于注销与 Winsock RIO 扩展函数一起使用的注册缓冲区。参数
// BufferId 标识一个注册缓冲区的描述符。
//
// RIODeregisterBuffer 函数注销一个注册缓冲区。当缓冲区被注销时，应用程序表示它已经完
// 成了对 BufferId 参数中传递的缓冲区标识符的使用。任何后续尝试使用此缓冲区标识符的其他
// 函数调用都将失败。如果注销了一个仍在使用的缓冲区，结果是未定义的。这被视为一个严重错    *** 注销一个仍在使用的缓冲区，结果未定义
// 误。在 RIODequeueCompletion 函数返回的 RIORESULT 结构中，状态将保持正常状态不变。
// 应用程序开发人员可以使用 Application Verifier 工具检测此错误条件。
//
// 如果在 BufferId 参数中传递了一个无效的缓冲区标识符，RIODeregisterBuffer 函数将忽略
// 它。
//
// typedef struct RIO_BUFFERID_t* RIO_BUFFERID, **PRIO_BUFFERID;
//
// typedef struct _RIO_BUF {
//      RIO_BUFFERID BufferId;
//      ULONG        Offset;
//      ULONG        Length;
// } RIO_BUF, *PRIO_BUF;
//
// Winsock RIO 扩展函数主要通过 RIO_BUFFERID 对象操作注册缓冲区。应用程序通过调用
// RIORegisterBuffer 函数为现有的缓冲区获取一个 RIO_BUFFERID。应用程序可以使用
// RIODeregisterBuffer 函数释放注册的缓冲区。
//
// 当现有的缓冲区通过 RIORegisterBuffer 函数注册为 RIO_BUFFERID 对象时，会从物理内存
// 中分配某些内部资源，并将现有的应用程序缓冲区锁定到物理内存中。调用 RIODeregisterBuffer
// 函数注销缓冲区，释放这些内部资源，并允许缓冲区从物理内存中解锁并释放。
//
// 使用 Winsock RIO 扩展函数反复注册和注销应用程序缓冲区可能会导致显著的性能下降。在设
// 计使用 Winsock RIO 扩展函数的应用程序中，应考虑以下缓冲区管理方法，以最小化应用程序
// 缓冲区的重复注册和注销：
//  1.  最大化缓冲区的重用。
//  2.  维护一个有限的未使用注册缓冲区池，供应用程序使用。
//  3.  维护一个有限的注册缓冲区池，并在这些注册缓冲区和其他未注册缓冲区之间执行缓冲区复制。
//
// RIO_BUFFERID 类型定义在 Mswsockdef.h 头文件中，该文件会自动包含在 Mswsock.h 头文
// 件中。不应直接使用 Mswsockdef.h 头文件。
//
// Winsock RIO 扩展函数通常在注册缓冲区的部分区间（有时称为缓冲区切片）上操作。需要使用
// 少量注册内存发送或接收网络数据的应用程序会使用 RIO_BUF 结构。通过注册一个大缓冲区，
// 然后根据需要使用缓冲区的小块，应用程序通常可以提高性能。RIO_BUF 结构可以描述单个缓冲
// 区注册中包含的任何连续内存段。
//
// 指向 RIO_BUF 结构的指针作为 pData 参数传递给 RIOSend、RIOSendEx、RIOReceive 和
// RIOReceiveEx 函数，用于发送或接收网络数据。应用程序不能仅仅通过使用大于原始注册缓冲
// 区的缓冲区切片值来调整注册缓冲区的大小。

typedef struct prh_impl_rio_buffer *prh_rio_buffer;

prh_rio_buffer prh_impl_rio_buffer_register(prh_byte *buffer, int length) {
    assert(buffer != prh_null && length > 0);
    // 当缓冲区被注册时，包含缓冲区的虚拟内存页面将被锁定在物理内存中。如果注册了多个小
    // 的、不连续的缓冲区，这些缓冲区的物理内存占用可能实际上每个注册都相当于一个完整的
    // 内存页面。在这种情况下，将多个请求缓冲区一起分配可能会更有益。注册缓冲区本身也会
    // 占用少量的物理内存开销。因此，如果许多分配被聚合到一个更大的分配中，通过聚合缓冲
    // 区注册，物理内存占用可能会进一步减少。
    RIO_BUFFERID buffer = PRH_IMPL_RIO.RIORegisterBuffer((PCHAR)buffer, length);
    prh_wsa_abort_if(buffer == prh_null);
    return (void *)buffer;
}

void prh_impl_rio_buffer_deregister(prh_rio_buffer buffer) { // 如果传递了一个无效的缓冲区标识符（RIO_INVALID_BUFFERID）将被忽略
    PRH_IMPL_RIO.RIODeregisterBuffer((RIO_BUFFERID)buffer);
}

static prh_rio_cqueue *PRH_IMPL_RIO_CQUEUE;
static prh_rio_buffer PRH_IMPL_RIO_BUFFER;
static prh_byte *PRH_IMPL_RIO_BUFBEG, *PRH_IMPL_RIO_BUFEND;

void prh_iocp_rio_notify(void) {
    prh_impl_rio_notify(PRH_IMPL_RIO_CQUEUE);
}

int prh_impl_iocp_rio_query(RIORESULT *entry, int count) {
    return prh_impl_rio_cqueue_query(PRH_IMPL_RIO_CQUEUE, entry, count);
}

prh_rio_socket prh_iocp_create_rio_socket(prh_handle socket) {
    return prh_impl_rio_rqueue_create(socket, PRH_IMPL_RIO_CQUEUE, (void *)socket);
}

// 指针长度     32-bit              64-bit
// 64  个字节    16 个指针（14）      8 个指针（6*）
// 128 个字节    32 个指针（30*）    16 个指针（14）
//  192个字节    48 个指针（46）     24 个指针（22）
// 256 个字节    64 个指针（62）     32 个指针（30*）
//  320个字节    80 个指针（78*）    40 个指针（38）
//  384个字节    96 个指针（94）     48 个指针（46）
//  448个字节    112个指针（110）    56 个指针（54*）
// 512 个字节    128个指针（126*）   64 个指针（62）
//  576个字节    144个指针（142）    72 个指针（70）
//  640个字节    160个指针（158）    80 个指针（78*）
//  704个字节    176个指针（174*）   88 个指针（86）
//  768个字节    192个指针（190）    96 个指针（94）
//  832个字节    208个指针（206）    104个指针（102*）
//  896个字节    224个指针（222*）   112个指针（110）
//  960个字节    240个指针（238）    120个指针（118）
// 1024个字节    256个指针（254）    128个指针（126*）
//
// 在 32 位机器上，128/512 个字节可保存 10/42 个 prh_iocp_thrd_req
// 在 64 位机器上，256/1024个字节可保存 10/42 个 prh_iocp_thrd_req
#define PRH_IMPL_THRD_QUE_BLOCK_SIZE_L0 ((int)(16 * sizeof(void *)))    //  64/128 字节
#define PRH_IMPL_THRD_QUE_BLOCK_SIZE_L1 ((int)(32 * sizeof(void *)))    // 128/256 字节
#define PRH_IMPL_THRD_QUE_BLOCK_SIZE_L2 ((int)(64 * sizeof(void *)))    // 256/512 字节
#define PRH_IMPL_THRD_QUE_BLOCK_SIZE_L3 ((int)(128 * sizeof(void *)))   // 512/1024字节

#ifndef PRH_THRD_TX_QUE_BLOCK_SIZE
#define PRH_THRD_TX_QUE_BLOCK_SIZE PRH_IMPL_THRD_QUE_BLOCK_SIZE_L1
#endif

prh_static_assert(PRH_THRD_TX_QUE_BLOCK_SIZE == PRH_IMPL_THRD_QUE_BLOCK_SIZE_L1 ||
                  PRH_THRD_TX_QUE_BLOCK_SIZE == PRH_IMPL_THRD_QUE_BLOCK_SIZE_L3);

#define PRH_IMPL_THRD_TX_QUE_BLOCK_END_OFFSET (PRH_THRD_TX_QUE_BLOCK_SIZE - 2 * (int)sizeof(void *))

typedef struct prh_atom_queue_block prh_atom_queue_block;

typedef struct { // 仅由生产者线程访问
    void **tail_block_tail_item; // 必须是第一个成员
    void **free_block_head_item;
} prh_atom_thrd_que_producer;

typedef struct { // 仅由消费者线程访问
    void **head_block_head_item; // 必须是第一个成员
    void **free_block_tail_item;
} prh_atom_thrd_que_consumer;

typedef struct { // 生产者和消费者线程共同访问
    prh_atom_int queue_length; // 必须是第一个成员
    prh_atom_int free_block_count;
} prh_atom_thrd_que_length;

typedef struct { // 仅由生产者线程访问
    void **tail_block_tail_item;
} prh_atom_thrd_rx_producer;

typedef struct { // 仅由消费者线程访问
    void **head_block_head_item;
} prh_atom_thrd_rx_consumer;

typedef struct { // 生产者和消费者线程共同访问
    prh_atom_int queue_length;
} prh_atom_thrd_rx_length;

typedef struct { // 仅由生产者线程访问
    void **head_block_head_item;
    void **tail_block_tail_item;
    prh_int free_block_count;
} prh_atom_thrd_rx_freed_queue;

prh_static_assert(prh_offsetof(prh_atom_thrd_rx_producer, tail_block_tail_item) == prh_offsetof(prh_atom_thrd_que_producer, tail_block_tail_item));
prh_static_assert(prh_offsetof(prh_atom_thrd_rx_consumer, head_block_head_item) == prh_offsetof(prh_atom_thrd_que_consumer, head_block_head_item));
prh_static_assert(prh_offsetof(prh_atom_thrd_rx_length, queue_length) == prh_offsetof(prh_atom_thrd_que_length, queue_length));
prh_static_assert(sizeof(prh_atom_thrd_rx_length) == sizeof(prh_atom_thrd_que_length) / 2);

typedef struct {
    void *post_req; // 必须是第一个成员
    prh_continue_routine continue_routine; // 必须是第二个成员
} prh_iocp_post_req;

prh_static_assert(sizeof(prh_iocp_post_req) == 2 * sizeof(void *));

#if prh_lit_endian
#define prh_impl_sched_coro_post_flag_field 0
#define prh_impl_sched_coro_post_subq_i_field 1
#define prh_impl_sched_coro_post_opcode_field 2
#else
#define prh_impl_sched_coro_post_flag_field (sizeof(void *) - 1)
#define prh_impl_sched_coro_post_subq_i_field (sizeof(void *) - 2)
#define prh_impl_sched_coro_post_opcode_field (sizeof(void *) - 3)
#endif

typedef struct {
    prh_byte bytes[sizeof(void *)];
    prh_ptr post_data;
} prh_coro_post_item;

prh_static_assert(sizeof(prh_coro_post_item) == 2 * sizeof(void *));

#define PRH_IMPL_SCHED_CORO_SUBQ_POST_FLAG 0x02
prh_static_assert((((prh_ptr)PRH_ATOM_DYNQUE_BLOCK_END) & PRH_IMPL_SCHED_CORO_SUBQ_POST_FLAG) == 0);
prh_static_assert((((prh_ptr)PRH_ATOM_DYNQUE_ITEM_FREE) & PRH_IMPL_SCHED_CORO_SUBQ_POST_FLAG) == 0);

#if prh_int_32
#define PRH_IMPL_THRD_POST_SEQN_MASK 0x00ffffff
typedef struct {
    void *post_req; // 必须是第一个成员
    prh_continue_routine continue_routine; // 必须是第二个成员
    prh_u32 post_seqn: 24, opcode: 8; // 必须是第三个成员
} prh_iocp_thrd_req;

typedef struct prh_coro_subq prh_coro_subq;
typedef struct prh_sched_only_data prh_sched_only_data;
typedef struct {
    prh_coro_subq *coro_subq; // 必须是第一个成员
    prh_ptr post_data; // 必须是第二个成员
    prh_u32 post_seqn: 24, opcode: 8; // 必须是第三个成员
} prh_coro_thrd_req;
#elif prh_int_64
#define PRH_IMPL_THRD_POST_SEQN_MASK 0xffffffff
typedef struct {
    void *post_req; // 必须是第一个成员
    prh_continue_routine continue_routine; // 必须是第二个成员
    prh_u32 post_seqn; prh_byte opcode; // 必须是第三个成员
} prh_iocp_thrd_req;

typedef struct prh_coro_subq prh_coro_subq;
typedef struct prh_sched_only_data prh_sched_only_data;
typedef struct {
    prh_coro_subq *coro_subq; // 必须是第一个成员
    prh_ptr post_data; // 必须是第二个成员
    prh_u32 post_seqn; prh_byte opcode; // 必须是第三个成员
} prh_coro_thrd_req;
#endif

prh_static_assert(sizeof(prh_iocp_thrd_req) == 3 * sizeof(void *));
prh_static_assert(sizeof(prh_coro_thrd_req) == 3 * sizeof(void *));

typedef struct { // 被工作线程和调度线程共享的线程数据
    prh_atom_thrd_que_length thrd_tx_que_length;                //  8   16
    prh_atom_thrd_rx_length thrd_rx_que_length;                 //  12  24
    bool thrd_wakeup_cond;                                      //  16  32
    prh_thrd_cond thrd_sleep_cond;                              //
} prh_iocp_share_thrd_data;

// 仅由工作线程访问的线程数据
//  prh_ptr impl_hdl_;                                          //  4   8   只读
//  prh_ptr extra_ptr;                                          //  8   16  只读
//  prh_u32 thrd_id: 31, created: 1;                            //  12  20  只读
typedef struct prh_thrd_struct(                                 //
    prh_atom_bool atom_thrd_exit;                               //  16  24  仅在程序退出时被调度线程写入一次，其他时间仅由工作线程访问
    prh_atom_thrd_que_producer thrd_tx_que_producer;            //  24  40  仅由工作线程访问
    prh_atom_thrd_rx_consumer thrd_rx_consumer;                 //  28  48  仅由工作线程访问
    prh_byte *linear_memory_buffer_top;                         //  32  56  只能释放最后分配的内存，只能线性地在一条绳索上滑动
    prh_byte *braver_memory_cache_line;                         //  36  64  分配了就分配了释放不了的内存，永远向前不能后退的内存，每次分配缓存行的整数倍
    prh_alignas(PRH_CACHE_LINE_SIZE) prh_iocp_share_thrd_data share_thrd_data;
) prh_iocp_thrd;

prh_static_assert(prh_offsetof(prh_iocp_thrd, share_thrd_data) == PRH_CACHE_LINE_SIZE);

typedef struct { // 被工作线程和调度线程共享的全局数据
    prh_atom_u32 post_seqn_seed;
    prh_atom_u32 cono_id_seed;
    prh_atom_bool keep_collect_tx_post;
    prh_atom_bool keep_alive_to_deliver_post;
    int thrd_wait_que_items;
    prh_iocp_share_thrd_data **thrd_wait_que; // 等待调度的工作线程后入先出指针队列
    prh_mutex thrd_wait_que_mutex;
} prh_iocp_shared_global;

static prh_alignas(PRH_CACHE_LINE_SIZE) prh_iocp_shared_global PRH_IOCP_SHARED_GLOBAL;

void *prh_impl_thrd_braver_memory_alloc(prh_unt size, prh_iocp_thrd *thrd) {
    assert(size > 0 && (size % PRH_CACHE_LINE_SIZE) == 0);
    void *alloc = thrd->braver_memory_cache_line;
    thrd->braver_memory_cache_line += size;
    return alloc;
}

void *prh_thrd_braver_memory_alloc(prh_unt size) {
    return prh_impl_thrd_braver_memory_alloc(size, (prh_iocp_thrd *)prh_thrd_self());
}

void *prh_thrd_linear_memory_push(prh_unt size) {
    assert(size > 0 && (size % sizeof(void *)) == 0);
    prh_iocp_thrd *thrd = (prh_iocp_thrd *)prh_thrd_self();
    void *alloc = thrd->linear_memory_buffer_top;
    thrd->linear_memory_buffer_top += size;
    return alloc;
}

void *prh_thrd_linear_memory_pop(prh_unt size) {
    assert(size > 0 && (size % sizeof(void *)) == 0);
    prh_iocp_thrd *thrd = (prh_iocp_thrd *)prh_thrd_self();
    thrd->linear_memory_buffer_top -= size;
    return thrd->linear_memory_buffer_top;
}

prh_inline prh_atom_queue_block *prh_impl_atom_queue_block_from_end(void **block_end, prh_unt block_end_offset) {
    return (prh_atom_queue_block *)((prh_byte *)block_end - block_end_offset);
}

prh_inline void **prh_impl_atom_queue_block_end_data(prh_atom_queue_block *block, prh_unt block_end_offset) {
    return (void **)((prh_byte *)block_end + block_end_offset);
}

prh_inline void **prh_impl_atom_queue_block_next(prh_atom_queue_block *block, prh_unt block_end_offset) {
    return (void **)((prh_byte *)block_end + block_end_offset + sizeof(void *));
}

prh_atom_queue_block *prh_impl_atom_queue_find_block_start(void **item, prh_unt block_end_offset) {
    if (item == prh_null) return prh_null;
    // 64 32 16 08 04 02 01 以 64 的倍数跳跃处理第一个内存块
    //  1  0  0  0  0  0  0  mask 63 0x3f
    //  0 + 64 = 0100_0000 & 1100_0000 = 64
    //  1 + 64 = 0100_0001 & 1100_0000 = 64
    // 63 + 64 = 0111_1111 & 1100_0000 = 64
    // 64 + 64 = 1000_0000 & 1100_0000 = 128
label_continue:
    item = (void **)((((prh_ptr)item + 64) & (~(prh_ptr)63)) - 2 * sizeof(void *));
    if (*item != PRH_ATOM_DYNQUE_BLOCK_END) goto label_continue;
    return prh_impl_atom_queue_block_from_end(item, block_end_offset);
}

void *prh_impl_atom_queue_malloc(prh_unt block_size) { // braver memory 已初始化为零
    void *block = prh_thrd_braver_memory_alloc(block_size);
    *prh_impl_atom_queue_block_end_data(block, block_size - 2 * sizeof(void *)) = PRH_ATOM_DYNQUE_BLOCK_END;
    return block;
}

prh_atom_queue_block *prh_impl_atom_queue_get_block(prh_atom_queue_block *free_block, prh_unt block_size) {
    if (free_block == prh_null) {
        free_block = prh_impl_atom_queue_malloc(block_size);
    } else {
        *prh_impl_atom_queue_block_next(free_block, block_size - 2 * sizeof(void *)) = prh_null;
    }
    return free_block;
}

typedef prh_atom_queue_block *(*prh_atom_thrd_que_block_alloc_routine)(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_length *l);
typedef void (*prh_atom_thrd_que_block_free_routine)(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_length *l, void **block_end);

void prh_impl_atom_thrd_tx_que_push_free_block(prh_atom_thrd_que_consumer *c, prh_atom_thrd_que_length *l, void **block_end) {
    prh_atom_queue_block *free_block = prh_impl_atom_queue_block_from_end(block_end, PRH_IMPL_THRD_TX_QUE_BLOCK_END_OFFSET);
    assert(free_block != prh_null && free_block != PRH_ATOM_DYNQUE_BLOCK_END);
    if (c->free_block_tail_item[0] == PRH_ATOM_DYNQUE_BLOCK_END) { // 如果当前内存块已满，将空闲块当作空闲队列的下一个内存块
        // 不需要修改 free_block->next 为空，因为总是可以通过 PRH_ATOM_DYNQUE_BLOCK_END 判断尾部，而且空闲块是通过 braver memory 分配的，不需要释放
        c->free_block_tail_item[1] = (void **)free_block;
        c->free_block_tail_item = (void **)free_block;
    } else { // 否则当前内存块还有位置，将空闲块插入空闲队列
        *c->free_block_tail_item++ = free_block;
        assert(*(c->free_block_tail_item - 1) == free_block); // 仅允许单生产者和单消费者
    }
    prh_atom_int_inc(&l->free_block_count); // 可用空闲块加一
}

prh_atom_queue_block *prh_impl_atom_thrd_tx_que_pop_free_block(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_length *l) {
    prh_atom_int *free_block_count = &l->free_block_count;
    if (!prh_atom_int_read(free_block_count)) return prh_null;
    prh_atom_queue_block *free_block;
    if (p->free_block_head_item[0] == PRH_ATOM_DYNQUE_BLOCK_END) { // 如果已到达当前内存块末尾，移动到下一个内存块
        free_block = prh_impl_atom_queue_block_from_end(p->free_block_head_item, PRH_IMPL_THRD_TX_QUE_BLOCK_END_OFFSET); // 需要释放的当前内存块，就是一个可用的空闲块
        p->free_block_head_item = (void **)p->free_block_head_item[1];
    } else {
        free_block = *p->free_block_head_item++;
        assert(free_block != prh_null && free_block != PRH_ATOM_DYNQUE_BLOCK_END);
        assert(*(p->free_block_head_item - 1) == free_block); // 仅允许单生产者和单消费者
    }
    prh_atom_int_dec(free_block_count); // 可用空闲块减一
    return free_block;
}

prh_atom_queue_block *prh_impl_atom_thrd_tx_que_alloc_block(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_length *l) {
    return prh_impl_atom_queue_get_block(prh_impl_atom_thrd_tx_que_pop_free_block(p, l), PRH_THRD_TX_QUE_BLOCK_SIZE);
}

void prh_atom_thrd_tx_que_init(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_consumer *c, prh_atom_thrd_que_length *l) {
    // 空闲块队列必须有一个隐藏的头节点，因为在仅剩一个空闲块的时候移除该空闲块时：
    //  1.  空闲队列消费者线程需要违法只修改头指针的规则，因为已经没有空闲块存在，尾指针也要改为空
    //  2.  这种修改无法做到不说，空闲队列消费者线程无法阻止空闲队列生产者线程继续在原有的空闲块上添加空闲块
    //  3.  只有总存在一个节点时，头指针总是在追赶尾指针，当头指针追赶到下一个节点时，上一个节点就可以自然而然的安全释放
    p->free_block_head_item = c->free_block_tail_item = prh_impl_atom_queue_malloc(PRH_THRD_TX_QUE_BLOCK_SIZE);
    prh_atom_int_init(&l->free_block_count, 0); // 先对 free block 进行初始化
    c->head_block_head_item = p->tail_block_tail_item = (void **)prh_impl_atom_queue_get_block(prh_null, PRH_THRD_TX_QUE_BLOCK_SIZE);
    prh_atom_int_init(&l->queue_length, 0);
}

void *prh_atom_thrd_que_push_begin(prh_atom_thrd_que_producer *p) {
    return (void *)p->tail_block_tail_item;
}

void prh_atom_thrd_que_push_end(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_length *l, int n, prh_atom_thrd_que_block_alloc_routine alloc) {
    prh_debug(void **tail_item = p->tail_block_tail_item);
    assert(*tail_item != prh_null && *tail_item != PRH_ATOM_DYNQUE_BLOCK_END);
    p->tail_block_tail_item += n;
    assert(*(p->tail_block_tail_item - n) == *tail_item); // 仅允许单生产者和单消费者
    if (p->tail_block_tail_item[0] == PRH_ATOM_DYNQUE_BLOCK_END) {
        p->tail_block_tail_item = (void **)p->tail_block_tail_item[1] = alloc(p, l);
    }
    prh_atom_int_inc(&l->queue_length); // 此步骤执行完毕以上更新必须对所有cpu生效
}

void *prh_atom_thrd_que_pop_begin(prh_atom_thrd_que_consumer *c, prh_atom_thrd_que_length *l) {
    if (!prh_atom_int_read(&l->queue_length)) return prh_null;
    assert(*c->head_block_head_item != prh_null && *c->head_block_head_item != PRH_ATOM_DYNQUE_BLOCK_END);
    return (void *)c->head_block_head_item;
}

void prh_atom_thrd_que_pop_end(prh_atom_thrd_que_consumer *c, prh_atom_thrd_que_length *l, int n, prh_atom_thrd_que_block_free_routine block_free) {
    prh_debug(void **head_item = c->head_block_head_item);
    c->head_block_head_item += n;
    assert(*(c->head_block_head_item - n) == *head_item); // 仅允许单生产者和单消费者
    if (c->head_block_head_item[0] == PRH_ATOM_DYNQUE_BLOCK_END) {
        void **next_block = (void **)c->head_block_head_item[1];
        block_free(c, l, c->head_block_head_item); // 需要将释放的空闲块还给生产者线程
        c->head_block_head_item = next_block;
    }
    if (l) prh_atom_int_dec(&l->queue_length); // 此步骤执行完毕以上更新必须对生产者cpu生效
}

bool prh_atom_thrd_tx_que_pops(prh_atom_thrd_que_consumer *c, prh_atom_thrd_que_length *l, bool (*cb)(void *priv, void *data), void *priv) {
    prh_atom_int *queue_length = &l->queue_length;
    prh_int len = prh_atom_int_read(queue_length), i;
    if (!len) return false;
    void **head_item = c->head_block_head_item;
    for (i = 0; i < len; i += 1) {
        if (!cb(priv, (void *)head_item)) {
            break; // 返回 true 表示移除该项，返回 false 表示不移除
        }
        head_item += 3;
        if (head_item[0] == PRH_ATOM_DYNQUE_BLOCK_END) {
            void **next_block = (void **)head_item[1]; // 需要将释放的空闲块还给生产者线程
            prh_impl_atom_thrd_tx_que_push_free_block(c, l, head_item);
            head_item = next_block;
        }
    }
    c->head_block_head_item = head_item;
    prh_atom_int_sub(queue_length, i); // 此步骤执行完毕以上更新必须对所有cpu生效
    assert(c->head_block_head_item == head_item); // 仅允许单生产者和单消费者
    return true;
}

void prh_atom_rx_freed_queue_push(prh_atom_rx_freed_queue *q, prh_atom_queue_block *free_block) {
    assert(free_block != prh_null && free_block != PRH_ATOM_DYNQUE_BLOCK_END);
    if (q->free_block_count == 0) {
        q->head_block_head_item = (void **)free_block;
label_assign_tail_block: // 不需要修改 free_block->next 为空，因为总是可以通过 PRH_ATOM_DYNQUE_BLOCK_END 判断尾部
        q->tail_block_tail_item = (void **)free_block;
    } else {
        if (q->tail_block_tail_item[0] == PRH_ATOM_DYNQUE_BLOCK_END) { // 如果当前内存块已满，将空闲块当作空闲队列的下一个内存块
            c->tail_block_tail_item[1] = (void **)free_block;
            goto label_assign_tail_block;
        } else { // 否则当前内存块还有位置，将空闲块插入空闲队列
            *q->tail_block_tail_item++ = free_block;
        }
    }
    q->free_block_count += 1; // 可用空闲块加一
}

prh_atom_queue_block *prh_impl_atom_rx_freed_queue_pop(prh_atom_rx_freed_queue *q, prh_unt block_end_offset) {
    if (q->free_block_count <= 0) return prh_null;
    prh_atom_queue_block *free_block;
    if (q->free_block_count == 1) {
        free_block = prh_impl_atom_queue_find_block_start(q->head_block_head_item, block_end_offset);
        q->head_block_head_item = q->tail_block_tail_item = prh_null;
    } else {
        if (q->head_block_head_item[0] == PRH_ATOM_DYNQUE_BLOCK_END) {
            free_block = prh_impl_atom_queue_block_from_end(p->head_block_head_item, block_end_offset);
            q->head_block_head_item = (void **)q->head_block_head_item[1]; // 如果已到达当前内存块末尾，移动到下一个内存块
        } else {
            head_block = *q->head_block_head_item++;
            assert(free_block != prh_null && free_block != PRH_ATOM_DYNQUE_BLOCK_END);
        }
    }
    q->free_block_count -= 1; // 可用空闲块减一
    return free_block;
}

void prh_impl_iocp_shared_global_init(prh_iocp_share_thrd_data **thrd_wait_que) {
    prh_atom_u32_init(&PRH_IOCP_SHARED_GLOBAL.post_seqn_seed, 0);
    prh_atom_bool_init(&PRH_IOCP_SHARED_GLOBAL.keep_collect_tx_post, false);
    prh_atom_bool_init(&PRH_IOCP_SHARED_GLOBAL.keep_alive_to_deliver_post, false);
    PRH_IOCP_SHARED_GLOBAL.thrd_wait_que = thrd_wait_que;
    PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_items = 0;
    prh_mutex_init(&PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_mutex);
}

void prh_impl_iocp_shared_global_free(void) {
    prh_mutex_free(&PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_mutex);
}

void prh_impl_iocp_thrd_init(prh_iocp_thrd *thrd, prh_atom_thrd_que_consumer *thrd_tx_que_consumer) {
    prh_atom_bool_init(&thrd->atom_thrd_exit, false);
    prh_atom_thrd_tx_que_init(&thrd->thrd_tx_que_producer, thrd_tx_que_consumer, &thrd->shard_thrd_data.thrd_tx_que_length);
    thrd->shard_thrd_data.thrd_wakeup_cond = false;
    prh_impl_thrd_cond_init(&thrd->shard_thrd_data.thrd_sleep_cond);
}

void prh_impl_iocp_thrd_attach_extra(prh_iocp_thrd *thrd, void *extra_ptr) {
    thrd->extra_ptr = extra_ptr;
}

void prh_impl_iocp_thrd_free(prh_thrd *thrd_ptr, int thrd_index) {
    prh_iocp_thrd *thrd = (prh_iocp_thrd *)thrd_ptr;
    prh_impl_thrd_cond_free(&thrd->shard_thrd_data.thrd_sleep_cond);
}

void prh_impl_iocp_thrd_wait_que_push(prh_iocp_share_thrd_data *thrd_data) {
    prh_mutex *mutex = &PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_mutex;
    prh_iocp_thrd **thrd_wait_queue = PRH_IOCP_SHARED_GLOBAL.thrd_wait_queue;
    prh_mutex_enter(mutex);
    thrd_wait_queue[PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_items++] = thrd_data;
    prh_mutex_exit(mutex);
}

prh_iocp_share_thrd_data *prh_impl_iocp_thrd_wait_que_pop(void) {
    prh_mutex *mutex = &PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_mutex;
    prh_iocp_thrd **thrd_wait_queue = PRH_IOCP_SHARED_GLOBAL.thrd_wait_queue;
    prh_iocp_thrd *thrd = prh_null;
    prh_mutex_enter(mutex);
    if (PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_items) { // 按后入先出的顺序唤醒线程
        thrd = thrd_wait_queue[--PRH_IOCP_SHARED_GLOBAL.thrd_wait_que_items];
    }
    prh_mutex_exit(mutex);
    return thrd;
}

bool prh_impl_sched_thrd_do_nothing_entry_complete(OVERLAPPED_ENTRY *entry) { // 被 prh_impl_sched_thrd_iocp_entry_completed 函数调用
    return true; // 该完成条目不需要消耗调度线程的完成队列，直接可以释放
}

void prh_impl_sched_thrd_complete_keep_collect_tx_post(void) {
    PRH_IOCP_GLOBAL.recv_keep_collect_tx_post_entry = false;
    prh_atom_bool *keep_collect_tx_post = &PRH_IOCP_SHARED_GLOBAL.keep_collect_tx_post;
    prh_atom_bool_write(keep_collect_tx_post, false);
    prh_impl_iocp_enqueue_completion_item(prh_impl_sched_thrd_do_nothing_entry_complete, keep_collect_tx_post);
}

bool prh_impl_sched_thrd_handle_keep_collect_tx_post(OVERLAPPED_ENTRY *entry) { // 被 prh_impl_sched_thrd_iocp_entry_completed 函数调用
    PRH_IOCP_GLOBAL.recv_keep_collect_tx_post_entry = true;
    return true; // 该完成条目不需要消耗调度线程的完成队列，直接可以释放
}

void prh_impl_iocp_keep_sched_alive_to_collect_tx_post(void) {
    // 工作线程投递任务后，只要确保有一个保活包存在于完成端口中，即可保证调度线程活跃
    prh_atom_bool *keep_collect_tx_post = &PRH_IOCP_SHARED_GLOBAL.keep_collect_tx_post;
    if (!prh_atom_bool_read(keep_collect_tx_post)) { // 这里可能 enqueue 多个也没问题
        prh_atom_bool_write(keep_collect_tx_post, true);
        prh_impl_iocp_enqueue_completion_item(prh_impl_sched_thrd_handle_keep_collect_tx_post, keep_collect_tx_post);
    }
}

bool prh_impl_sched_thrd_handle_keep_deliver_post(OVERLAPPED_ENTRY *entry) { // 被 prh_impl_sched_thrd_iocp_entry_completed 函数调用
    // 工作线程可能在这个位置检测到 keep_alive_to_deliver_post 为真，不会向完成端口投递保活包
    // 但是此时调度线程已经醒来，已经插入的线程任务（或休眠线程已经插入等待队列），会保证调度线程不会睡眠
    prh_atom_bool_write(&PRH_IOCP_SHARED_GLOBAL.keep_alive_to_deliver_post, false);
    return true; // 该完成条目不需要消耗调度线程的完成队列，直接可以释放
}

void prh_impl_iocp_keep_sched_alive_to_deliver_post(void) {
    // 工作线程进入睡眠后，以防还有分派的任务存在，确保调度线程是最后一个进入睡眠的线程
    prh_atom_u32 *keep_alive_to_deliver_post = &PRH_IOCP_SHARED_GLOBAL.keep_alive_to_deliver_post;
    if (!prh_atom_bool_read(keep_alive_to_deliver_post)) {
        prh_atom_bool_write(keep_alive_to_deliver_post, true);
        prh_impl_iocp_enqueue_completion_item(prh_impl_sched_thrd_handle_keep_deliver_post, keep_alive_to_deliver_post);
    }
}

void prh_impl_iocp_thrd_sleep(prh_iocp_share_thrd_data *thrd_data) {
    prh_thrd_cond *cond = &thrd_data->thrd_sleep_cond;
    prh_thrd_cond_lock(cond);
    if (thrd_data->thrd_wakeup_cond) {
        goto label_already_wakeup;
    }
    prh_impl_iocp_thrd_wait_que_push(thrd_data);
    prh_impl_iocp_keep_sched_alive_to_deliver_post(); // 以防还有分派的任务存在，但是工作线程和调度线程都进入了睡眠
label_continue_waiting:
    prh_impl_plat_cond_wait(cond);
    if (!thrd_data->thrd_wakeup_cond) {
        goto label_continue_waiting;
    }
label_already_wakeup:
    thrd_data->thrd_wakeup_cond = false;
    prh_thrd_cond_unlock(cond);
}

bool prh_impl_iocp_thrd_wakeup(prh_iocp_share_thrd_data *thrd_data) {
    if (thrd_data == prh_null) return false;
    prh_thrd_cond *cond = &thrd_data->thrd_sleep_cond;
    prh_thrd_cond_lock(cond);
    thrd_data->thrd_wakeup_cond = true;
    prh_thrd_cond_unlock(cond);
    prh_thrd_cond_signal(cond);
    return true;
}

#define PRH_IMPL_IOCP_QUERY_ENTRY_COUNT 8

typedef struct {
    bool single_thread_program;
    int concurrent_thread_count;
    int iocp_query_max_entries;
    int sched_collect_que_size;
    int thrd_linear_memory_size;
    int thrd_braver_memory_size;
} prh_iocp_config;

typedef struct {
    prh_atom_thrd_que_consumer thrd_tx_que_consumer;
    prh_atom_thrd_que_length *thrd_tx_que_length;
} prh_sched_thrd_tx_que_consumer;

typedef prh_fixed_arrque_ptr(prh_iocp_thrd_req) prh_iocp_continue_que_ptr;
typedef prh_fixed_arrque_ptr(prh_iocp_post_req) prh_post_collect_que_ptr;
typedef struct { // 仅由调度线程访问的数据
    int concurrent_threads;                             // 只读
    int iocp_query_max_entries;                         // 只读
    int thrd_linear_memory_size;                        // 只读
    int thrd_braver_memory_size;                        // 只读
    bool single_thread_program;                         // 只读
    bool recv_keep_collect_tx_post_entry;               // 可写，仅由调度线程访问
    prh_u32 cfmd_post_seqn;                             // 可写，仅由调度线程访问
    prh_simple_thrds *iocp_thrds;                       // 只读
    prh_iocp_thrd *sched_thrd;                          // 只读
    void *sched_linear_buffer;                          // 只读
    void *sched_braver_buffer;                          // 只读
    void *overlapped_entry_array;                       // 只读，指向的内容仅被调度线程访问
    void *rio_result_entry_array;                       // 只读，指向的内容仅被调度线程访问
    prh_iocp_continue_que_ptr iocp_continue_que;        // 只读，指向的内容仅被调度线程访问
    prh_sched_thrd_tx_que_consumer *thrd_tx_que;        // 只读，指向的内容仅由调度线程访问
    prh_sched_thrd_tx_que_consumer *thrd_tx_que_end;    // 只读，指向的内容仅由调度线程访问
    prh_post_collect_que_ptr post_collect_que;          // 只读，指向的内容仅被调度线程访问
    prh_atom_ext_mult_rd_arrque *post_dispatch_que;     // 只读，指向的内容被工作线程和调度线程访问，指针基本仅由调度线程访问，工作线程仅在线程初始化时访问一次
    prh_atom_rx_freed_queue coro_freed_block_que;       // 可写，仅由调度线程访问
} prh_iocp_global;

static prh_alignas(PRH_CACHE_LINE_SIZE) prh_iocp_global PRH_IOCP_GLOBAL;

static bool prh_impl_iocp_rio_socket_completion(OVERLAPPED_ENTRY *entry) { // 被 prh_impl_sched_thrd_iocp_entry_completed 函数调用
    RIORESULT *rio_result_entry_array = PRH_IOCP_GLOBAL.rio_result_entry_array;
    int max_count = prh_impl_iocp_continue_que_empty_items();
    if (max_count > 0) {
        int n = prh_impl_iocp_rio_query(rio_result_entry_array, max_count);
        // typedef struct _RIORESULT {
        //      LONG      Status;
        //      ULONG     BytesTransferred;
        //      ULONGLONG SocketContext;
        //      ULONGLONG RequestContext;
        // } RIORESULT, *PRIORESULT;
        for (int i = 0; i < n; i += 1) {
            RIORESULT *entry = rio_result_entry_array + i;
            DWORD error_code = entry->Status;
            if (error_code) prh_prerr(error_code);
            prh_impl_iocp_entry_completed_from_port((OVERLAPPED *)(prh_ptr)entry->RequestContext, error_code, entry->BytesTransferred);
        }
    }
    prh_iocp_rio_notify();
    return true;
}

void prh_iocp_rio_init(int cqueue_size, prh_byte *register_trx_buffer, int buffer_length) {
    assert(register_trx_buffer != prh_null && ((prh_ptr)register_trx_buffer % PRH_CACHE_LINE_SIZE) == 0);
    assert(buffer_length > 0 && (buffer_length % PRH_CACHE_LINE_SIZE) == 0);
    PRH_IMPL_RIO_CQUEUE = prh_impl_rio_cqueue_create(cqueue_size, PRH_IMPL_IOCP, (prh_ptr)prh_impl_iocp_rio_socket_completion, (void *)&PRH_IMPL_RIO_CQUEUE);
    PRH_IMPL_RIO_BUFFER = prh_impl_rio_buffer_register(register_trx_buffer, buffer_length);
    PRH_IMPL_RIO_BUFBEG = register_trx_buffer;
    PRH_IMPL_RIO_BUFEND = register_trx_buffer + buffer_length;
}

void prh_impl_iocp_rio_free(void) {
    prh_impl_rio_cqueue_close(PRH_IMPL_RIO_CQUEUE);
    prh_impl_rio_buffer_deregister(PRH_IMPL_RIO_BUFFER);
}

bool prh_impl_sched_thrd_iocp_entry_completed(OVERLAPPED_ENTRY *entry) {
    // typedef struct _OVERLAPPED_ENTRY {
    //     ULONG_PTR lpCompletionKey;
    //     LPOVERLAPPED lpOverlapped;
    //     ULONG_PTR Internal;
    //     DWORD dwNumberOfBytesTransferred;
    // } OVERLAPPED_ENTRY, *LPOVERLAPPED_ENTRY;
    //
    // typedef struct _OVERLAPPED {     // minwinbase.h (included in WinBase.h)
    //     ULONG_PTR Internal;          // [out] Error Code
    //     ULONG_PTR InternalHigh;      // [out] Number of bytes transferred
    //     union {
    //         struct {
    //             DWORD Offset;        // [in] Low 32-bit file offset
    //             DWORD OffsetHigh;    // [in] High 32-bit file offset
    //         } DUMMYSTRUCTNAME;
    //         PVOID Pointer;
    //     } DUMMYUNIONNAME;
    //     HANDLE hEvent;               // [in] Event handle or data
    // } OVERLAPPED, *LPOVERLAPPED;
    //
    // #define WSAEVENT                HANDLE
    // #define LPWSAEVENT              LPHANDLE
    // #define WSAOVERLAPPED           OVERLAPPED
    // typedef struct _OVERLAPPED *    LPWSAOVERLAPPED; // winsock2.h
    //
    // 三个成员，Offset OffsetHigh hEvent 必须在调用异步操作函数之前进行初始化，其他
    // 两个成员 Internal InternalHigh 由驱动程序来设置，当 I/O 操作完成时我们可以检
    // 查它们的值。当使用可提醒 I/O 操作完成时，设备驱动程序不会试图去触发一个事件对象。
    // 实际上，此时设备根本就没有用到 OVERLAPPED 结构的 hEvent 成员，因此如果需要，我
    // 们可以将 hEvent 据为己用。
    //
    // Internal 成员用来保存已处理的 I/O 请求的错误码，一旦我们发出一个异步 I/O 请求，
    // 设备驱动程序立即将 Internal 设为 STATUS_PENDING，表示没有错误操作尚未开始。实
    // 际上，WinBase.h 中定义的 HasOverlappedIoCompleted 宏允许我们检查一个异步 I/O
    // 操作是否已经完成（Internal != STATUS_PENDING）。
    //
    // 在最初设计 OVERLAPPED 结构的时候，Microsoft 决定不公开 Internal 和 InternalHigh
    // 成员。随着时间的推移，Microsoft 认识到这些成员中包含的信息会对开发人员有用，因此
    // 把它们公开了。但是 Microsoft 没有改变这些成员的名字，这是因为操作系统的源代码频
    // 繁地用到它们，而 Microsoft 并不想为此修改源代码。由于现在 Microsoft 已经公开了
    // Internal 和 Internal High 成员，因此 GetOverlappedResult 函数（获取 lpNumberOfBytesTransferred
    // 并设置错误码）就不怎么有用了。
    prh_iocp_complete_routine completion_routine = (prh_iocp_complete_routine)entry->lpCompletionKey;
    assert(completion_routine != prh_null);
    assert(entry->lpOverlapped != prh_null);
    return completion_routine(entry); // 调用完成键 lpCompletionKey 对应的 prh_iocp_complete_routine 函数
}

int prh_impl_sched_thrd_query_iocp_entries(OVERLAPPED_ENTRY *overlapped_entry, int count, bool keep_sched_thrd_alive) {
    return prh_impl_completion_port_ext_query(PRH_IMPL_IOCP, overlapped_entry, count, keep_sched_thrd_alive ? 0 : INFINITE);
}

#define PRH_IMPL_SCHED_POST_REQ_REMOVED ((void *)(prh_ptr)(-1))
#define PRH_IMPL_SCHED_THRD_SYNCED_EXEC 0x02

typedef bool (*prh_sched_thrd_synced_routine)(prh_iocp_thrd_req *thrd_req);

void prh_impl_iocp_thrd_post(void *post_req, prh_continue_routine continue_routine, prh_byte opcode) {
    // 工作线程投递任务给调度线程分派，每个工作线程都有一个独立的任务队列供自己使用。工作线程投递的每个任务，
    // 都使用一个全局的原子整数自加进行编号。调度线程每一轮调度，最多只处理固定数量的任务，例如 [cfmd_post_seqn, cfmd_post_seqn + N)，
    // 每一轮最多只有在此区间内的任务被处理。在处理时，调度线程首先将范围内的任务，按编号顺序收集到一个大小固
    // 定的队列中（post_collect_que），然后分派到各线程争抢的任务分派队列中（post_dispatch_que）
    assert(post_req != prh_null);
    prh_iocp_thrd *thrd = (prh_iocp_thrd *)prh_thrd_self();
    prh_iocp_thrd_req *thrd_req = prh_atom_thrd_que_push_begin(&thrd->thrd_tx_que_producer);
    thrd_req->post_req = post_req;
    thrd_req->continue_routine = continue_routine;
    thrd_req->post_seqn = prh_atom_u32_fetch_inc(&PRH_IOCP_SHARED_GLOBAL.post_seqn_seed);
    thrd_req->opcode = opcode;
    prh_atom_thrd_que_push_end(&thrd->thrd_tx_que_producer, &thrd->share_thrd_data.thrd_tx_que_length, 3, prh_impl_atom_thrd_tx_que_alloc_block);
    prh_impl_iocp_keep_sched_alive_to_collect_tx_post();
}

void prh_iocp_thrd_post(void *post_req, prh_continue_routine continue_routine) {
    assert(((prh_ptr)post_req & PRH_IMPL_SCHED_THRD_SYNCED_EXEC) == 0);
    prh_impl_iocp_thrd_post(post_req, continue_routine, 0);
}

void prh_coro_thrd_post(prh_coro_subq *coro_subq, void *post_data, prh_byte opcode) {
    assert(((prh_ptr)coro_subq & PRH_IMPL_SCHED_THRD_SYNCED_EXEC) == 0);
    assert(opcode != 0); // opcode 如果为零，对应的消息将不会投递
    prh_impl_iocp_thrd_post(coro_subq, (prh_continue_routine)post_data, opcode);
}

void prh_sched_thrd_synced_post(void *post_req, prh_sched_thrd_synced_routine continue_routine) {
    assert(((prh_ptr)post_req & PRH_IMPL_SCHED_THRD_SYNCED_EXEC) == 0);
    prh_impl_iocp_thrd_post((void *)((prh_ptr)post_req & PRH_IMPL_SCHED_THRD_SYNCED_EXEC), continue_routine, 0);
}

void prh_sched_thrd_synced_ext_post(void *post_req, prh_sched_thrd_synced_routine continue_routine, prh_byte opcode) {
    assert(((prh_ptr)post_req & PRH_IMPL_SCHED_THRD_SYNCED_EXEC) == 0);
    prh_impl_iocp_thrd_post((void *)((prh_ptr)post_req & PRH_IMPL_SCHED_THRD_SYNCED_EXEC), continue_routine, opcode);
}

int prh_impl_iocp_continue_que_len(void) {
    return (int)prh_fixed_arrque_len(PRH_IOCP_GLOBAL.iocp_continue_que);
}

int prh_impl_iocp_continue_que_empty_items(void) {
    return (int)prh_fixed_arrque_empty_items(PRH_IOCP_GLOBAL.iocp_continue_que);
}

void prh_impl_iocp_sched_thrd_post(void *post_req, prh_continue_routine continue_routine) { // 在 prh_impl_sched_thrd_iocp_entry_completed 函数中被调用
    assert(prh_impl_iocp_continue_que_empty_items() > 0);
    prh_iocp_thrd_req *continue_item = prh_fixed_arrque_unchecked_push(PRH_IOCP_GLOBAL.iocp_continue_que);
    continue_item->post_req = post_req;
    continue_item->continue_routine = continue_routine;
    continue_item->post_seqn = prh_atom_u32_fetch_inc(&PRH_IOCP_SHARED_GLOBAL.post_seqn_seed);
}

// 在 32 位机器上， 64/128/256 个字节可以分配 7/15/31 个 prh_coro_post_item
// 在 64 位机器上，128/256/512 个字节可以分配 7/15/31 个 prh_coro_post_item
#ifndef PRH_SCHED_CORO_RX_BLOCK_SIZE
#define PRH_SCHED_CORO_RX_BLOCK_SIZE PRH_IMPL_THRD_QUE_BLOCK_SIZE_L0
#endif

prh_static_assert((PRH_IMPL_THRD_QUE_BLOCK_SIZE_L0 % PRH_CACHE_LINE_SIZE) == 0);
prh_static_assert((PRH_SCHED_CORO_RX_BLOCK_SIZE) > 0 && ((PRH_SCHED_CORO_RX_BLOCK_SIZE) % PRH_IMPL_THRD_QUE_BLOCK_SIZE_L0) == 0);

#define PRH_IMPL_SCHED_CORO_RX_BLOCK_END_OFFSET ((PRH_SCHED_CORO_RX_BLOCK_SIZE) - 2 * (int)sizeof(void *))
bool prh_impl_sched_thrd_dispatch_coro_post(prh_iocp_thrd_req *thrd_req);

prh_atom_queue_block *prh_impl_atom_sched_coro_que_alloc_block(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_length *l) {
    return prh_impl_atom_queue_get_block(prh_impl_atom_rx_freed_queue_pop(&PRH_IOCP_GLOBAL.coro_freed_block_que), PRH_SCHED_CORO_RX_BLOCK_SIZE);
}

void prh_impl_atom_sched_coro_que_push_end(prh_atom_thrd_rx_producer *p, prh_atom_thrd_rx_length *l, int n) {
    prh_atom_thrd_que_push_end((prh_atom_thrd_que_producer *)p, (prh_atom_thrd_que_length *)l, n, prh_impl_atom_sched_coro_que_alloc_block);
}

bool prh_impl_sched_thrd_synced_free_block(prh_iocp_thrd_req *thrd_req) {
    prh_atom_queue_block *free_block = (prh_atom_queue_block *)thrd_req->post_req;
    while (free_block) {
        prh_atom_queue_block *next_block = *prh_impl_atom_queue_block_next(free_block, PRH_IMPL_SCHED_CORO_RX_BLOCK_END_OFFSET);
        prh_atom_rx_freed_queue_push(&PRH_IOCP_GLOBAL.coro_freed_block_que, free_block);
        free_block = next_block;
    }
    return false;
}

void prh_impl_coro_begin_free_block_chain(prh_atom_queue_block *block_chain) {
    prh_sched_thrd_synced_post(block_chain, prh_impl_sched_thrd_synced_free_block);
}

void prh_impl_atom_sched_coro_que_free_block(prh_atom_thrd_que_producer *p, prh_atom_thrd_que_length *l, void **block_end) {
    prh_atom_queue_block *free_block = prh_impl_atom_queue_block_from_end(block_end, PRH_IMPL_SCHED_CORO_RX_BLOCK_END_OFFSET);
    *prh_impl_atom_queue_block_next(free_block, PRH_IMPL_SCHED_CORO_RX_BLOCK_END_OFFSET) = prh_null; // 仅释放当前内存块
    prh_impl_coro_begin_free_block_chain(free_block); // 需要将释放的空闲块还给生产者线程
}

void prh_atom_sched_coro_que_free(prh_atom_thrd_rx_consumer *c) {
    prh_atom_queue_block *head_block = prh_impl_atom_queue_find_block_start(c->head_block_head_item, PRH_IMPL_SCHED_CORO_RX_BLOCK_END_OFFSET);
    prh_impl_coro_begin_free_block_chain(head_block);
    c->head_block_head_item = prh_null;
}

int prh_impl_sched_thrd_collect_que_len(void) {
    return (int)prh_fixed_arrque_len(PRH_IOCP_GLOBAL.post_collect_que);
}

int prh_impl_sched_thrd_collect_que_empty_items(void) {
    return (int)prh_fixed_arrque_empty_items(PRH_IOCP_GLOBAL.post_collect_que);
}

void prh_impl_sched_thrd_collect_que_push(prh_iocp_post_req *post_req, prh_u32 index) {
    prh_post_collect_que_ptr post_collect_que = PRH_IOCP_GLOBAL.post_collect_que;
    *prh_fixed_arrque_unchecked_push_at(post_collect_que, index) = *post_req;
}

prh_iocp_post_req *prh_impl_sched_thrd_collect_que_pop(void) {
    prh_post_collect_que_ptr post_collect_que = PRH_IOCP_GLOBAL.post_collect_que;
    if (prh_fixed_arrque_len(post_collect_que) == 0) return prh_null;
    prh_iocp_post_req *post_req = prh_impl_fixed_arrque_top(post_collect_que);
    if (post_req->post_req == prh_null) return prh_null; // 头部已分配序号的线程任务还未被成功收集
    prh_impl_fixed_arrque_pop(post_collect_que);
    PRH_IOCP_GLOBAL.cfmd_post_seqn = (PRH_IOCP_GLOBAL.cfmd_post_seqn + 1) & PRH_IMPL_THRD_POST_SEQN_MASK;
    return post_req;
}

bool prh_impl_sched_thrd_collect_each_post_req(void *collect_seqn_range, prh_iocp_thrd_req *thrd_req) {
    prh_u32 index = thrd_req->post_seqn - PRH_IOCP_GLOBAL.cfmd_post_seqn; // post_seqn 最大值绕回也成立
    if (index >= (prh_u32)collect_seqn_range) return false;
    prh_ptr post_req = thrd_req->post_req;
    if (post_req & PRH_IMPL_SCHED_THRD_SYNCED_EXEC) {
        thrd_req->post_req = (void *)(post_req & ~((prh_ptr)PRH_IMPL_SCHED_THRD_SYNCED_EXEC));
        if (!((prh_sched_thrd_synced_routine)(thrd_req->continue_routine))(thrd_req)) {
            thrd_req->post_req = PRH_IMPL_SCHED_POST_REQ_REMOVED;
        }
    } else if (thrd_req->opcode) {
        if (!prh_impl_sched_thrd_dispatch_coro_post(thrd_req)) {
            thrd_req->post_req = PRH_IMPL_SCHED_POST_REQ_REMOVED;
        }
    }
    prh_impl_sched_thrd_collect_que_push((prh_iocp_post_req *)thrd_req, index);
    return true;
}

prh_u32 prh_impl_sched_thrd_collect_seqn_range(prh_u32 curr_post_seed) {
    // 对于 post_seqn < curr_post_seed 的 post，这些 post 已经分配了序号，但是对应的线程可能还未来得及将其插入到 thrd_tx_que 队列中
    // 因此需要维护一个已经确认收集并且已经投递到 post_dispatch_que 的 post 序号 cfmd_post_seqn，用来跟踪哪些 post 已经确认被投递
    // cfmd_post_seqn 必须按序号一个一个进行递增，每次将 post_collect_que 头部的一个非空的 post 投递到 post_dispatch_que，cfmd_post_seqn 都加一
    prh_u32 cfmd_post_seqn = PRH_IOCP_GLOBAL.cfmd_post_seqn;
    prh_u32 collect_seqn_range = curr_post_seed - cfmd_post_seqn;
    int collect_que_empty_items = prh_impl_sched_thrd_collect_que_empty_items();
    return (collect_que_empty_items < collect_seqn_range) ? collect_que_empty_items : collect_seqn_range;
}

prh_u32 prh_impl_sched_thrd_curr_post_seed(void) {
    return prh_atom_u32_read(&PRH_IOCP_SHARED_GLOBAL.post_seqn_seed) & PRH_IMPL_THRD_POST_SEQN_MASK;
}

int prh_impl_sched_thrd_collect_post(void) {
    prh_u32 curr_post_seed = PRH_IOCP_GLOBAL.prev_post_seed_processed = prh_impl_sched_thrd_curr_post_seed();
    void *collect_seqn_range = (void *)(prh_ptr)prh_impl_sched_thrd_collect_seqn_range(curr_post_seed);
    if (collect_seqn_range) {
        prh_iocp_continue_que_ptr iocp_continue_que = PRH_IOCP_GLOBAL.iocp_continue_que;
        prh_iocp_thrd_req *continue_item; // 收集调度线程完成端口中的任务
        while ((continue_item = prh_fixed_arrque_top(iocp_continue_que)) && prh_impl_sched_thrd_collect_each_post_req(collect_seqn_range, continue_item)) {
            prh_impl_fixed_arrque_pop(iocp_continue_que);
        }
        prh_sched_thrd_tx_que_consumer *q = PRH_IOCP_GLOBAL.thrd_tx_que;
        prh_sched_thrd_tx_que_consumer *thrd_tx_que_end = PRH_IOCP_GLOBAL.thrd_tx_que_end;
        for (; q < thrd_tx_que_end; q += 1) { // 收集各线程各自独立投递的线程任务
            prh_atom_thrd_tx_queue_pops(&q->thrd_tx_que_consumer, q->thrd_tx_que_length, prh_impl_sched_thrd_collect_each_post_req, collect_seqn_range);
        }
    }
    return prh_impl_sched_thrd_collect_que_len();
}

int prh_impl_sched_thrd_dispatch_que_len(void) {
    return (int)prh_atom_ext_mult_rd_arrque_len(PRH_IOCP_GLOBAL.post_dispatch_que);
}

void prh_impl_sched_thrd_dispatch_post(void) {
    prh_atom_ext_mult_rd_arrque *post_dispatch_que = PRH_IOCP_GLOBAL.post_dispatch_que;
    prh_atom_mult_rd_arrque_view view;
    if (prh_atom_ext_mult_rd_arrque_push_begin(post_dispatch_que, &view)) {
        for (int i = 0; i < (int)view.empty_items; i += 1) {
            prh_iocp_post_req *post_req = prh_impl_sched_thrd_collect_que_pop();
            if (post_req == prh_null) break;
            if (post_req->post_req != PRH_IMPL_SCHED_POST_REQ_REMOVED) {
                prh_atom_ext_mult_rd_arrque_push_item(post_dispatch_que, &view, (prh_ptr)post_req->post_req, (prh_ptr)post_req->continue_routine);
            }
            post_req->post_req = prh_null; // 移除的元素必须清零
        }
        prh_atom_ext_mult_rd_arrque_push_end(post_dispatch_que, &view);
    }
}

static void prh_impl_sched_thrd_routine(prh_thrd *thrd_ptr) {
    OVERLAPPED_ENTRY *overlapped_entry = PRH_IOCP_GLOBAL.overlapped_entry_array;
    OVERLAPPED_ENTRY *entry_end = prh_null, *entry_ptr = prh_null;
    int entry_array_size = PRH_IOCP_GLOBAL.iocp_query_max_entries;
    int entry_count = 0, dispatch_que_posts;
    bool sched_thrd_need_wakeup = true;

    for (; ;) {
        if (entry_ptr >= entry_end) { // 接收完成端口中待处理的完成条目，每次最多获取固定大小的完成条目，只有当前一次所有 entry 都处理完毕，才开始新一轮接收
            if ((entry_count = prh_impl_sched_thrd_query_iocp_entries(overlapped_entry, entry_array_size, sched_thrd_need_wakeup))) {
                entry_ptr = overlapped_entry;
                entry_end = overlapped_entry + entry_count;
            }
        }

        for (; entry_ptr < entry_end; entry_ptr += 1) { // 每个完成条目的处理都会向调度线程的 iocp_continue_que 固定队列投递一个线程任务
            if (!prh_impl_sched_thrd_iocp_entry_completed(entry_ptr)) {
                break;
            }
        }

        if (prh_impl_sched_thrd_collect_post()) { // 按序号收集完成端口投递的和各线程投递的任务到调度线程持有的 post_collect_que 队列中，然后分派到各线程争抢的 post_dispatch_que 队列中
            prh_impl_sched_thrd_dispatch_post();
        }

        dispatch_que_posts = prh_impl_sched_thrd_dispatch_que_len(); // 如果存在已分派的任务和睡眠的线程，以后入先出的顺序唤醒线程去处理分派的任务
        while (dispatch_que_posts > 0 && prh_impl_iocp_thrd_wakeup(prh_impl_iocp_thrd_wait_que_pop())) {
            dispatch_que_posts -= 1;
        }

        if (prh_impl_sched_thrd_collect_que_len()) {
            sched_thrd_need_wakeup = true; // 收集的任务还未分派，需要时刻跟踪 post_dispatch_que 可用大小进行分派
        } else if (PRH_IOCP_GLOBAL.cfmd_post_seqn != prh_impl_sched_thrd_curr_post_seed()) {
            sched_thrd_need_wakeup = true; // 已收集的任务都已分派，但还存在新投递的任务没有收集和分派
        } else {
            sched_thrd_need_wakeup = false; // 所有的任务都已经收集和分派，调度线程可以休息，留下工作线程处理分派队列中的任务
        }

        if (PRH_IOCP_GLOBAL.recv_keep_collect_tx_post_entry && !sched_thrd_need_wakeup) {
            prh_impl_sched_thrd_complete_keep_collect_tx_post(); // 如果调度线程是活跃的，工作线程不需要投递保活包
        }
    }
}

void prh_impl_create_thrd_memory(prh_iocp_thrd *thrd) {
    if (PRH_IOCP_GLOBAL.thrd_linear_memory_size > 0) {
        thrd->linear_memory_buffer_top = prh_virtual_alloc(PRH_IOCP_GLOBAL.thrd_linear_memory_size);
    }
    if (PRH_IOCP_GLOBAL.thrd_braver_memory_size > 0) {
        thrd->braver_memory_cache_line = prh_virtual_alloc(PRH_IOCP_GLOBAL.thrd_braver_memory_size);
    }
}

static int prh_impl_worker_thrd_routine(prh_thrd *thrd_ptr) {
    prh_atom_ext_mult_rd_arrque *post_dispatch_que = PRH_IOCP_GLOBAL.post_dispatch_que;
    prh_iocp_thrd *thrd = (prh_iocp_thrd *)thrd_ptr;
    prh_atom_bool *atom_thrd_exit = &thrd->atom_thrd_exit;
    void *linear_memory, *braver_memory;
    bool thrd_is_exit = false;

    prh_impl_create_thrd_memory(thrd);
    linear_memory = thrd->linear_memory_buffer_top;
    braver_memory = thrd->braver_memory_cache_line;

    for (; ;) {
        prh_iocp_post_req post;
        while (prh_atom_ext_mult_rd_arrque_pop(post_dispatch_que, &post)) {
            post.continue_routine(post.post_req); // 调用被 <operation>_complete 或 <operation>_completed_from_port 设置的函数
        }
        if (prh_atom_bool_read(atom_thrd_exit)) {
            if (thrd_is_exit) break;
            thrd_is_exit = true; // 程序退出时，给工作线程最后一次运行的机会
        } else {
            prh_impl_iocp_thrd_sleep(&thrd->share_thrd_data); // 进入睡眠，等待调度线程唤醒
        }
    }

    prh_debug(printf("[thrd %02d] exit\n", prh_thrd_id(thrd_ptr)));
    if (linear_memory) prh_virtual_free(linear_memory);
    if (braver_memory) prh_virtual_free(braver_memory);
    return 0;
}

void prh_impl_iocp_global_init(void) {
    DWORD concurrent_thread_count = 1; // 仅由调度线程等待操作完成
    PRH_IMPL_IOCP = prh_impl_create_completion_port(concurrent_thread_count);
}

void prh_impl_iocp_global_free(void) {
    prh_simp_thrd_free(&PRH_IOCP_GLOBAL.thrds, prh_impl_iocp_thrd_free);
    prh_impl_close_completion_port(PRH_IMPL_IOCP);
    prh_impl_iocp_rio_free();
    prh_impl_iocp_shared_global_free();
    if (PRH_IOCP_GLOBAL.sched_linear_buffer) prh_virtual_free(PRH_IOCP_GLOBAL.sched_linear_buffer);
    if (PRH_IOCP_GLOBAL.sched_braver_buffer) prh_virtual_free(PRH_IOCP_GLOBAL.sched_braver_buffer);
}

void prh_impl_iocp_init(prh_iocp_config *config) {
    prh_iocp_config default_config = {0};
    if (config == prh_null) config = &default_config;
    int concurrent_thread_count = config->concurrent_thread_count;
    int iocp_query_max_entries = config->iocp_query_max_entries;
    int collect_que_size = config->sched_collect_que_size;
    int dispatch_que_size;
    int iocp_thrd_count;

    prh_sys_info *sys_info = prh_get_sys_info();
    PRH_IOCP_GLOBAL.single_thread_program = config->single_thread_program;
    if (concurrent_thread_count <= 0) {
        concurrent_thread_count = sys_info->processor_count;
        if (concurrent_thread_count > 1) {
            concurrent_thread_count -= 1; // 主线程是调度线程，并行执行的工作线程数量需要减去1个
        } else {
            concurrent_thread_count = 0;
            PRH_IOCP_GLOBAL.single_thread_program = true;
        }
    }

    iocp_thrd_count = concurrent_thread_count + 1;
    PRH_IOCP_GLOBAL.concurrent_threads = concurrent_thread_count;
    assert(concurrent_thread_count >= 0 && concurrent_thread_count < PRH_THRD_INDEX_MASK);

    if (iocp_query_max_entries <= 0) iocp_query_max_entries = PRH_IMPL_IOCP_QUERY_ENTRY_COUNT;
    iocp_query_max_entries = prh_to_power_of_2(iocp_query_max_entries); // 需要作为 iocp_continue_que 的大小
    PRH_IOCP_GLOBAL.iocp_query_max_entries = iocp_query_max_entries;

    if (collect_que_size <= 0) collect_que_size = 2 * iocp_query_max_entries; // 收集完成端口任务和线程投递的任务
    dispatch_que_size = 2 * collect_que_size; // 至少要 >= collect_que_size，因为实际的 dispatch_que_size 比 2 的幂少一个，因此至少是 collect_que_size 的两倍

    if (config->thrd_linear_memory_size <= 0) config->thrd_linear_memory_size = PRH_VMEM_RESERVE_UNIT;
    if (config->thrd_braver_memory_size <= 0) config->thrd_braver_memory_size = PRH_VMEM_RESERVE_UNIT;
    assert((config->thrd_linear_memory_size % PRH_VMEM_RESERVE_UNIT) == 0);
    assert((config->thrd_braver_memory_size % PRH_VMEM_RESERVE_UNIT) == 0);

    PRH_IOCP_GLOBAL.thrd_linear_memory_size = config->thrd_linear_memory_size;
    PRH_IOCP_GLOBAL.thrd_braver_memory_size = config->thrd_braver_memory_size;
    PRH_IOCP_GLOBAL.cfmd_post_seqn = 0;
    memset(&PRH_IOCP_GLOBAL.coro_freed_block_que, 0, sizeof(PRH_IOCP_GLOBAL.coro_freed_block_que));

    // 创建调度线程
    PRH_IOCP_GLOBAL.iocp_thrds = prh_simp_thrd_init(0, concurrent_thread_count, sizeof(prh_iocp_thrd));
    PRH_IOCP_GLOBAL.sched_thrd = (prh_iocp_thrd *)prh_simp_thrd_main(PRH_IOCP_GLOBAL.iocp_thrds);
    prh_impl_iocp_thrd_init(PRH_IOCP_GLOBAL.sched_thrd, &PRH_IOCP_GLOBAL.thrd_tx_que->thrd_tx_que_consumer);
    PRH_IOCP_GLOBAL.thrd_tx_que->thrd_tx_que_length = &PRH_IOCP_GLOBAL.sched_thrd.share_thrd_data.thrd_tx_que_length;
    prh_impl_create_thrd_memory(PRH_IOCP_GLOBAL.sched_thrd);
    PRH_IOCP_GLOBAL.sched_linear_buffer = PRH_IOCP_GLOBAL.sched_thrd->linear_memory_buffer_top;
    PRH_IOCP_GLOBAL.sched_braver_buffer = PRH_IOCP_GLOBAL.sched_thrd->braver_memory_cache_line;

    // 分配的内存仅被调度线程访问
    prh_int overlapped_entry_array_bytes = prh_round_cache_line_size(sizeof(OVERLAPPED_ENTRY) * iocp_query_max_entries);
    prh_int rio_result_entry_array_bytes = prh_round_cache_line_size(sizeof(RIORESULT) * iocp_query_max_entries);
    prh_int iocp_continue_que_bytes = prh_round_cache_line_size(prh_fixed_arrque_alloc_size(iocp_query_max_entries, sizeof(prh_iocp_thrd_req)));
    prh_int post_collect_que_bytes = prh_round_cache_line_size(prh_fixed_arrque_alloc_size(collect_que_size, sizeof(prh_iocp_post_req)));
    prh_int thrd_tx_que_consumer_bytes = prh_round_cache_line_size(sizeof(prh_sched_thrd_tx_que_consumer) * iocp_thrd_count);
    prh_int post_dispatch_que_bytes = prh_round_cache_line_size(prh_atom_mult_rd_arrque_alloc_size(dispatch_que_size, sizeof(prh_iocp_post_req)));
    prh_int thrd_wait_que_bytes = prh_round_cache_line_size(concurrent_thread_count * sizeof(void *));
    prh_byte *sched_thrd_buffer = prh_impl_thrd_braver_memory_alloc(overlapped_entry_array_bytes + rio_result_entry_array_bytes + iocp_continue_que_bytes +
        post_collect_que_bytes + thrd_tx_que_consumer_bytes + post_dispatch_que_bytes + thrd_wait_que_bytes, PRH_IOCP_GLOBAL.sched_thrd);

    PRH_IOCP_GLOBAL.overlapped_entry_array = sched_thrd_buffer;
    sched_thrd_buffer += overlapped_entry_array_bytes;
    PRH_IOCP_GLOBAL.rio_result_entry_array = sched_thrd_buffer;
    sched_thrd_buffer += rio_result_entry_array_bytes;

    PRH_IOCP_GLOBAL.iocp_continue_que = (prh_iocp_continue_que_ptr)sched_thrd_buffer;
    prh_fixed_arrque_init(PRH_IOCP_GLOBAL.iocp_continue_que, iocp_query_max_entries);
    sched_thrd_buffer += iocp_continue_que_bytes;

    PRH_IOCP_GLOBAL.post_collect_que = (prh_post_collect_que_ptr)sched_thrd_buffer;
    prh_fixed_arrque_init(PRH_IOCP_GLOBAL.post_collect_que, collect_que_size);
    sched_thrd_buffer += post_collect_que_bytes;

    PRH_IOCP_GLOBAL.thrd_tx_que = (prh_sched_thrd_tx_que_consumer *)sched_thrd_buffer;
    PRH_IOCP_GLOBAL.thrd_tx_que_end = PRH_IOCP_GLOBAL.thrd_tx_que + iocp_thrd_count;
    sched_thrd_buffer += thrd_tx_que_consumer_bytes;

    prh_atom_ext_mult_rd_arrque *post_dispatch_que = (prh_atom_ext_mult_rd_arrque *)thrd_shared_buffer;
    prh_atom_ext_mult_rd_arrque_init(post_dispatch_que, dispatch_que_size);
    PRH_IOCP_GLOBAL.post_dispatch_que = post_dispatch_que;
    thrd_shared_buffer += post_dispatch_que_bytes;

    prh_impl_iocp_shared_global_init((prh_iocp_share_thrd_data **)thrd_shared_buffer);
    thrd_shared_buffer += thrd_wait_que_bytes;

    // 创建工作线程并启动
    for (int i = 0; i < concurrent_thread_count; i += 1) {
        prh_iocp_thrd *iocp_thrd = prh_simp_thrd_create(PRH_IOCP_GLOBAL.iocp_thrds);
        prh_impl_iocp_thrd_init(iocp_thrd, &PRH_IOCP_GLOBAL.thrd_tx_que[i + 1].thrd_tx_que_consumer);
        PRH_IOCP_GLOBAL.thrd_tx_que[i + 1].thrd_tx_que_length = iocp_thrd->share_thrd_data.thrd_tx_que_length;
        prh_simp_thrd_sched(PRH_IOCP_GLOBAL.iocp_thrds, iocp_thrd, prh_impl_worker_thrd_routine, 0);
    }
}

void prh_iocp_startup(prh_iocp_config *config) {
    prh_impl_iocp_global_init();
    prh_impl_iocp_init(config);

    prh_iocp_thrd *sched_thrd = PRH_IOCP_GLOBAL.sched_thrd;
    prh_real_assert(sched_thrd == (prh_iocp_thrd *)prh_thrd_self()); // 必须从主线程启动

    prh_impl_sched_thrd_routine(sched_thrd); // 启动调度线程
    prh_simp_thrd_join_except_main(PRH_IOCP_GLOBAL.thrds, prh_impl_iocp_thrd_free);
    prh_debug(printf("[thrd %02d] exit\n", prh_thrd_id(sched_thrd)));

    prh_impl_iocp_global_free();
}

#elif defined(prh_plat_linux)
#include <sys/types.h>
#include <sys/ioctl.h>
#include <sys/epoll.h>

#define PRH_MAX_SAME_TIME_POSTS_EPOLL_TO_EACH_FILE_DESCRIPTOR 2
typedef struct prh_epoll_port prh_epoll_port;
typedef enum {
    PRH_EPEV_ADDED, // 特定文件描述符添加完毕
    PRH_EPEV_READY, // 特定文件描述符上有事件发生
    PRH_EPEV_MAX_NUM,
} prh_epoll_event;

void prh_epoll_init(int max_num_fds_hint, int poll_fds_each_time);
void prh_epoll_add_tcp_accept(prh_tcplisten *listen, prh_cono_subq *subq);
void prh_epoll_add_tcp_connect(prh_tcpsocket *tcp, prh_cono_subq *subq);
void prh_epoll_add_tcp_socket(prh_tcpsocket *tcp, prh_cono_subq *subq);
void prh_epoll_receive_events(prh_tcpsocket *tcp);
void prh_epoll_wait_tx_data(prh_epoll_port *port);
void prh_epoll_wait_rx_data(prh_epoll_port *port);
void prh_epoll_del_and_close(prh_epoll_port *port);
void prh_epoll_exit(void);

// EPOLL API 是 Linux 专有的特性，首次出现是在 Linux 2.6 版中。同 I/O 多路复用 API
// 一样，epoll api 允许进程同时检查多个文件描述符，看其中任意一个是否能执行 I/O 操作。
// 同信号驱动 I/O 一样，当同时检查大量文件描述符时，epoll 能提供更好的性能。实际上 I/O
// 多路复用、信号驱动 I/O 以及 epoll 都是用来实现同一个目标的技术，即同时检查多个文件
// 描述符，看它们是否已经准备好执行 I/O 操作，准确地说，是看 I/O 系统调用是否可以非阻塞
// 地执行。文件描述符就绪状态的转化是通过一些 I/O 事件来触发的，比如输入数据到达，套接字
// 连接建立完成，或者是之前满载的套接字发送缓冲区在 TCP 发送数据传送到对端之后有了剩余
// 空间。同时检查多个文件描述符在类似网络服务器的应用中很有用处，或者是那些必须同时检查
// 终端以及管道或套接字输入的应用程序。需要注意的是这些技术都不会执行实际的I/O操作，它们
// 只是告诉我们某个文件描述符已经处于就绪状态了，这时需要调用其他的系统调用来完成实际的
// I/O操作。
//
// 这里没有介绍的一种 I/O 模型是 POSIX 异步 I/O （AIO）。POSIX AIO 允许进程将 I/O
// 操作排列到一个文件中，当操作完成后得到通知。POSIX AIO 的优点在于最初的 I/O 调用将
// 立刻返回，因此进程不会一直等待数据传输到内核或者等待操作完成。这使得进程可以同 I/O
// 操作一起并行处理其他任务（包括未来可能进入队列的其他I/O操作）。对于特定类型的应用，
// POSIX AIO 能提供有用的性能优势。目前，Linux 在 glibc 中提供有基于线程的 POSIX
// AIO 实现，并且正在朝着内核化的 POSIX AIO 实现而努力，这应该能提供更好的伸缩性能。
//
// 同 epoll 一样，信号驱动 I/O 可以让应用程序高效地检查大量的文件描述符。然而 epoll
// 有着信号驱动 I/O 没有的一些优点：避免了处理信号的复杂性；可以指定想要检查的事件类型，
// 例如读就绪或者写就绪；可以选择一水平触发或边缘触发的形式来通知进程。为了不同系统的
// 可移植性，一个名为 libevent 的软件层库提供了文件描述符 I/O 事件的抽象，已经移植到
// 了多个 UNIX 系统中。Libevent 的底层机制能够以透明的方式，应用各种I/O模型：select、
// poll、信号驱动I/O或者epoll，同样也支持 Solaris 专有的 /dev/poll 接口和 BSD 系统
// 的 kqueue 接口。对于最基础的 select() 和 poll() 在 UNIX 系统中已经存在很长时间，
// 相比其他技术，它最主要的优势是可移植性，但是缺点在于当同时检查大量的（数百或数千个）
// 文件描述符时性能延展性不佳。
//
// 在讨论I/O机制之前，我们需要先区分两种文件描述符准备就绪的通知模式。水平触发通知：如果
// 文件描述符上可以非阻塞地执行I/O系统调用，此时认为它已经就绪。边缘触发通知：如果文件
// 描述符自上次状态检查以来有了新的I/O活动，比如新的输入，此时需要触发通知。其中 select
// 和 poll 使用的是水平触发，信号驱动I/O使用的是边缘触发，epoll 默认使用水平触发但也
// 支持边缘触发。
//
// 当采用水平触发通知时，我们可以在任意时刻检查文件描述符的就绪状态。这表示当我们确定了
// 文件描述符就绪态时，比如存在有输入的数据，就可以对其执行一些I/O操作。水平触发模式
// 因为可以在任意时刻重复检查I/O状态，就没有必要每次就绪后必须尽可能多地执行I/O，因为即
// 使执行少量的I/O或者不执行，下次检查就绪状态都还在，可以继续再执行。
//
// 但是如果使用边缘触发，只有当I/O事件发生时我们才会收到通知，在另一个I/O事件到了前不会
// 再收到任何新的通知。另外，当文件描述符收到I/O事件通知时，通常我们并不知道要处理多少
// I/O，例如有多少字节可读。因此，采用边缘触发通知的程序通常要按照以下规则来设计。
//
// （一）在收到一个I/O事件通知后，程序在某个时刻应该在相应的文件描述符上尽可能多地执行
// I/O，比如尽可能多地读取字节。如果程序没这么做，那么就可能失去执行I/O的机会。因为直到
// 产生另一个I/O事件为止，在此之前程序都不会再接收到通知了，因此也就不知道此时应该执行
// I/O操作。这将导致数据丢失或者程序中出现阻塞。这里提到的程序在“某个时刻”应该执行尽可能
// 多的I/O操作，是因为有时候我们确定了文件描述符处于就绪状态时，可能并不适合马上执行所有
// 的I/O操作。原因是因为如果我们仅对一个文件描述符执行大量的I/O操作，可能会让其他文件
// 描述符处于饥饿状态。
//
// （二）如果程序采用循环来对文件描述符执行尽可能多的I/O，而文件描述符又被置为可阻塞的，
// 那么最终当没有更多的I/O可执行时，I/O系统调用就会阻塞。基于这个原因，每个被检查的文件
// 描述符通常都应该设为非阻塞模式，在得到I/O事件通知后重复执行I/O操作，直到相应的系统
// 调用，比如 read() write() 以错误码 EAGAIN 或 EWOULDBLOCK 的形式失败。
//
// 这里的 I/O 模型通常和非阻塞I/O（O_NONBLOCK标志）一起使用，下面列出了一些例子，以说
// 明为什么这么做会很有用：非阻塞I/O通常和提供有边缘触发通知机制的I/O模型一起使用；如果
// 多个进程（线程）在同一个打开的文件描述符上执行I/O操作，那么从某个特定进程的角度来看，
// 文件描述符的就绪状态可能会在通知就绪和执行后续I/O调用之间发生改变，结果就是一个阻塞
// 式的I/O调用将阻塞，进行再也不能去检查其他的文件描述符；尽管水平触发模式的API通知我们
// 流式套接字的文件描述符已经写就绪了，如果我们在单个write()或send()调用中写入足够大块
// 的数据，那么该调用将阻塞；在非常罕见的情况下，水平触发型API比如select和poll，会返回
// 虚假的就绪通知，它们会错误地通知我们文件描述符已经就绪了，这可能式由内核bug造成的，
// 或非普通情况下的设计方案所期望的行为。一个BSD系统上的监听套接字的虚假就绪通知的例子，
// 如果客户端先连接到服务器的监听套接字上，然后再重置连接，服务器的select()调用在这两个
// 事件之间将提示监听套接字为可读就绪，但随后当客户端重置连接后，服务器端的accept()调用
// 阻塞。
//
// Linux 的 epoll（event poll）API 的主要优点：当检查大量的文件描述符时，epoll 的性能
// 延展性比 select() 和 poll() 高很多；另外 epoll 既支持水平触发也支持边缘触发；而于
// 信号驱动I/O相比，epoll 可以避免复杂的信号处理流程 ，例如信号队列溢出时的处理，还更
// 灵活，可以指定我们希望检查的事件类型，例如检查读就绪、写就绪、或两者同时指定。
//
// epoll api 的核心数据结构称作 epoll 实例，它和一个打开的文件描述符相关联。这个文件
// 描述符不是用来做I/O操作的，它只是内核数据结构的句柄，该数据结构记录了在进程中声明过
// 的感兴趣的文件描述符列表，兴趣列表（interest list），还维护了处于 I/O 就绪态的文件
// 描述符列表，就绪列表（ready list）。就绪列表中的成员是兴趣列表的子集。epoll api
// 由以下三个系统调用组成：epoll_create 创建一个 epoll 实例，返回代表该实例的文件描述
// 符；epoll_ctl 操作同 epoll 实例相关联的兴趣列表；epoll_wait 返回与 epoll 实例
// 相关联的就绪列表中的成员。通过 epoll_ctl 可以增加新的描述符到列表中，或移除已有的文
// 件描述符。
//
// https://www.man7.org/linux/man-pages/man2/epoll_create.2.html
// https://www.man7.org/linux/man-pages/man7/epoll.7.html
//
// #include <sys/epoll.h>
// int epoll_create(int size); Linux 2.6, glibc 2.3.2.
// int epoll_create1(int flags); Linux 2.6.27, glibc 2.9.
//
// epoll_create() creates a new epoll(7) instance. Since Linux 2.6.8, the size
// argument is ignored, but must be greater than zero. epoll_create1() is the
// same as epoll_create(). The following value can be included in flags to
// obtain different behavior: EPOLL_CLOEXEC.
//
// 参数 flags 可以设置为 0 或者 EPOLL_CLOEXEC 标志，如果 flags 为 0，则 epoll_create1()
// 与 epoll_create() 的行为相同，只是省略了过时的 size 参数。EPOLL_CLOEXEC 标志会给
// epoll 文件描述符设置 FD_CLOEXEC 标志，这确保在执行 exec 系统调用时，该文件描述符不
// 会被继承到子进程中。详情可以参考 open(2) 中对 O_CLOEXEC 标志的描述。在多线程环境中，
// 如果不设置 FD_CLOEXEC 标志，子进程可能会意外地继承父进程的文件描述符，这可能导致安全
// 问题或资源泄漏。即在创建 epoll 文件描述符的同时就设置好“关闭执行”标志，避免多线程竞争
// 导致该标志设置失效，设置此标志后，子进程不能访问这个在父进程中的文件描述符。
//
// 如果不是一创建就设置，使用单独的 fcntl(2) 设置 FD_CLOEXEC 标志可能会导致竞争条件。
// 例如，一个线程打开一个文件描述符并尝试使用 fcntl(2) 设置其关闭执行标志，而另一个线程
// 同时执行 fork(2) 和 execve(2)。根据执行顺序，这种竞争条件可能导致 open() 返回的文
// 件描述符意外地泄露到由 fork(2) 创建的子进程中。
//
// 成功返回一个文件描述符，非负数，失败返回-1和errno。可能错误：
//      EINVAL - 参数 size 或 flags 非法。
//      EMFILE - 进程达到最大打开的文件描述符数量。Prior to Linux 2.6.29, a
//          /proc/sys/fs/epoll/max_user_instances kernel parameter limited
//          live epolls for each real user ID, and caused epoll_create() to
//          fail with EMFILE on overrun. 版本 2.6.29 之前，有内核参数限制每个真
//          实用户ID中活动的 epoll 最大数量。
//      ENFILE - 系统达到最大可打开的文件描述符总数。
//      ENOMEM - 没有足够的内存空间用于创建内核对象。
//
// 默认情况下，程序中打开的所有文件描述符在 exec() 执行新程序的过程中保持打开并有效。这
// 通常很实用，因为文件描述符在新程序中自动有效，让新程序无需再去了解文件名或重新打开。但
// 一些情况下在执行 exec() 前确保关闭某些特定的文件描述符，尤其是在特权进程中调用 exec()
// 来启动一个未知程序时，或启动程序并不需要这些已打开的文件描述符时，从安全编程的角度出发，
// 应当在加载新程序之前关闭那些不必要的文件描述符。为此，内核为每个文件描述符提供了执行时
// 关闭标志，如果设置了这一标志，如果调用 exec() 成功会自动关闭该文件描述符，如果调用
// exec() 失败则文件描述符会继续保持打开。系统调用 fork() 允许一进程（父进程）创建一新
// 进程（子进程），子进程几乎是父进程的翻版（可认为父进程一分为二了），它获得了父进程的栈、
// 数据段、堆和执行文本段的拷贝。执行 fork() 时，子进程会获得父进程所有文件描述符的副本，
// 这些副本的创建方式类似于 dup()，这也意味着父子进程中对应的描述符均指向相同的打开文件句
// 柄。文件句柄包含了当前文件偏移量以及文件状态标志，因此这些属性是在父子进程间共享的，例
// 如子进程如果更新了文件偏移量，那么这种改变也会影响到父进程中相应的描述符。系统调用
// exec() 用于执行一个新程序，它将新程序加载到当前进程中，这将丢弃现存的程序段，并为新程
// 序重新创建栈、数据段以及堆。
//
// 通过进程的 /proc/pid/fdinfo 目录中 epoll 文件描述符的条目，可以查看正通过一个 epoll
// 文件描述符监控的文件描述符集合。请参阅 proc(5) 以获取更多详细信息。假如 epfd 的值为
// 5，当前进程 pid 为 1234，则可以查看： cat /proc/1234/fdinfo/5 。
//
// kcmp(2) 的 KCMP_EPOLL_TFD 操作可用于测试一个文件描述符是否在一个 epoll 实例中：
//      if (kcmp(getpid(), getpid(), KCMP_EPOLL_TFD, epfd, fd) == 0) {
//          printf("fd is in the epoll instance\n");
//      }
//
// https://www.man7.org/linux/man-pages/man2/epoll_ctl.2.html
// https://www.man7.org/linux/man-pages/man3/epoll_event.3type.html
// https://www.man7.org/linux/man-pages/man2/ioctl_eventpoll.2.html
//
// #include <sys/epoll.h> // epoll_ctl 返回 0 表示成功，返回 -1 表示失败 errno
// int epoll_ctl(int epfd, int op, int fd, struct epoll_event *_Nullable event);
// struct epoll_event { // 该结构体指定内核在文件描述符就绪时，需要保存和返回的数据
//     uint32_t      events;  /* Epoll events */ 设置关注的事件类型和事件标志
//     epoll_data_t  data;    /* User data variable */
// };
// union epoll_data {
//     void     *ptr;
//     int       fd;
//     uint32_t  u32;
//     uint64_t  u64;
// };
// typedef union epoll_data epoll_data_t;
//
// 从 epoll 的兴趣列表中新增、删除、或修改对应的文件描述符 fd，该描述符可以是代表管道、
// FIFO、套接字、POSIX 消息队列、inotify 实例、终端、设备、甚至是另一个 epoll 实例的
// 文件描述符（例如我们可以为受检查的描述符建立起一种层次关系）。但是，这里的 fd 不能是
// 普通文件或目录的文件描述符，会出现 EPERM 错误。epoll 支持所有在 poll(2) 中支持的
// 文件描述符。
//      EPOLL_CTL_ADD - 如果兴趣列表中已经存在该文件描述符，报 EEXIST 错误。
//      EPOLL_CTL_MOD - 如果文件描述符不在兴趣列表中，会报 ENOENT 错误。
//      EPOLL_CTL_DEL - 如果文件描述符不在兴趣列表中，会报 ENOENT 错误。如果要兼容
//          Linux 2.6.9 之前的版本，event 参数虽然会被忽略，但不能传递空指针。
//          Before Linux 2.6.9, the EPOLL_CTL_DEL operation required a non-null
//          pointer in event, even though this argument is ignored. Since Linux
//          2.6.9, event can be specified as NULL when using EPOLL_CTL_DEL.
//          Applications that need to be portable to kernels before Linux 2.6.9
//          should specify a non-null pointer in event.
//          关闭一个文件描述符，会自动将其从所有的 epoll 实例的兴趣列表中移除。其实具体
//          的，epoll 实例中保存的文件描述符是位于内核中的文件描述（file description），
//          用户空间中可以存在多个文件描述符（file descriptor）指向这个内核中的文件描述，
//          只有所有用户空间中的执行同一个文件描述的文件描述符都关闭了，内核才知道此时
//          已经没有引用的用户空间的程序，可以将文件描述回收。因此准确的说，当所有指向
//          打开的文件描述的文件描述符都被关闭后，这个打开的文件描述才从 epoll 的兴趣
//          列表中移除。
//
// 参数 events 是比特位，可以或上零个或多个事件类型（event type），事件类型也会在文件
// 描述符就绪时被 epoll_wait 返回，还可以或上事件标志（event flag），事件标志会影响
// 文件描述符就绪的触发行为，但不会被 epoll_wait 返回。事件类型包括：
//      EPOLLIN - 文件可以进行 read 操作，读取非优先级数据。
//      EPOLLPRI - There is an exceptional condition on the file descriptor.
//          See the discussion of POLLPRI in poll(2). 文件描述符上有异常条件，这
//          通常用于检测和读取紧急数据（如带外数据），具体可能包括：
//          •  There is out-of-band data on a TCP socket (see tcp(7)).
//          •  A pseudoterminal master in packet mode has seen a state
//             change on the slave (see ioctl_tty(2)).
//          •  A cgroup.events file has been modified (see cgroups(7)).
//      EPOLLOUT - 文件可以进行 write 操作
//      EPOLLERR - 关联文件描述符有错误事件发生，或当管道的读取端已经关闭时写入端也会
//          也会触发该事件。 This event is also reported for the write end of a
//          pipe when the read end has been closed.
//          错误事件总会被 epoll_wait 上报，调用 epoll_ctl 设置该类型是不必须的。
//          epoll_wait(2) will always report for this event; it is not necessary
//          to set it in events when calling epoll_ctl().
//      EPOLLRDHUP (Linux 2.6.17) - Stream socket peer closed connection, or
//          shut down writing half of connection. (This flag is especially
//          useful for writing simple code to detect peer shutdown when using
//          edge-triggered monitoring.) 对方挂断事件，即流式套接字对端关闭了连接，或
//          关闭了连接的写入部分。这个标志特别适用于使用边缘触发监控对端的关闭情况。
//      EPOLLHUP - 文件描述符发生了挂断事件，epoll_wait(2) 总是会上报这个事件，因此
//          不需要特别设置。从管道或流式套接字等通道进行读取操作时，这个事件仅表示对端
//          关闭了其端的通道，只有当通道中所有未处理的数据都会消费后，后续的读取操作
//          才会返回0（文件尾）。例如读取标准输入流 STDIN_FILENO，在终端上的写入端输入
//          CTRL+D 表示 EOF，来关闭写入端的通道。
//          Note that when reading from a channel such as a pipe or a stream
//          socket, this event merely indicates that the peer closed its end of
//          the channel. Subsequent reads from the channel will return 0 (end
//          of file) only after all outstanding data in the channel has been
//          consumed.
//          只要关联的文件已经关闭或已经断开连接，或者读取端检测到对端关闭了写入端，都会
//          触发该事件。EPOLLRDHUP 适用于精确检测对端关闭连接的场景，EPOLLHUP 适用于
//          需要处理文件描述符不再可用的场景。
//
// 可用的事件标志包括：
//      EPOLLET - 默认是水平触发（level-triggered），设置该值表示边缘触发（edge-triggered）。
//      EPOLLONESHOT (Linux 2.6.2) - 一次性通知，当 epoll_wait 通知完后，会将对应的
//          文件描述符设为禁用不会再报告任何事件，如果要继续监控，需要调用 epoll_ctl
//          EPOLL_CTL_MOD 重新启用文件描述符并设置新的事件掩码。
//      EPOLLWAKEUP (Linux 3.5) - If EPOLLONESHOT and EPOLLET are clear and the
//          process has the CAP_BLOCK_SUSPEND capability, ensure that the system
//          does not enter "suspend" or "hibernate" while this event is pending
//          or being processed. 如果没有设置 EPOLLET 和 EPOLLONESHOT，EPOLLWAKEUP
//          确保 CAP_BLOCK_SUSPEND 能力的进程在文件描述符对应的事件待处理或处理期间，
//          系统不会进入“挂起”或“休眠”状态。适用于需要在事件处理期间防止系统进入低功耗
//          状态的场景，例如后台服务或实时应用程序。事件被视为“处理中”的时间是从 epoll_wait(2)
//          返回事件开始，直到下一次对同一个 epoll 文件描述符调用 epoll_wait(2)，或者
//          关闭该文件描述符，或者使用 EPOLL_CTL_DEL 移除事件文件描述符，或者使用
//          EPOLL_CTL_MOD 清除事件文件描述符的 EPOLLWAKEUP。
//          如果 EPOLLWAKEUP 被设置，但调用进程不具备 CAP_BLOCK_SUSPEND 能力，EPOLLWAKEUP
//          标志将被静默忽略。一个健壮的应用程序在尝试使用 EPOLLWAKEUP 标志时，应该先
//          检查它是否具有 CAP_BLOCK_SUSPEND 能力。
//          Capabilities are a per-thread attribute. CAP_BLOCK_SUSPEND (since
//          Linux 3.5) Employ features that can block system suspend (epoll(7)
//          EPOLLWAKEUP, /proc/sys/wake_lock).
//      https://www.man7.org/linux/man-pages/man7/epoll.7.html
//          如果系统通过 /sys/power/autosleep 处于自动睡眠模式，并且发生了一个事件，该
//          事件使设备从睡眠状态中唤醒，设备驱动程序将只保持设备唤醒状态，直到该事件被排队。
//          为了使设备在发生的事件被处理并在处理完成之前，一直保持唤醒状态，需要使用 epoll_ctl(2)
//          的 EPOLLWAKEUP 标志。
//          当 EPOLLWAKEUP 标志设置在 struct epoll_event 的 events 字段中时，系统将
//          从事件被排队的那一刻起保持唤醒状态，通过返回事件的 epoll_wait(2) 调用，直到
//          随后的 epoll_wait(2) 调用。如果事件需要在那之后的时间内保持系统唤醒，那么应
//          该在第二次 epoll_wait(2) 调用之前获取一个单独的 wake_lock。
//      EPOLLEXCLUSIVE (Linux 4.5) - 设置独占唤醒模式，适用于需要避免多个 epoll 实例
//          同时唤醒引发“雷鸣事件”，从而减少资源竞争和性能问题。雷鸣般的牧群问题（thundering
//          herd problems）。
//          同一个文件描述符可能被添加到多个 epoll 实例中，如果这些 epoll 实例都设置了
//          EPOLLEXCLUSIVE，那么只有至少一个 epoll 会被唤醒。而默认没有设置 EPOLLEXCLUSIVE
//          的情况下，所有epoll 都会被唤醒。
//          If the same file descriptor is in multiple epoll instances, some
//          with the EPOLLEXCLUSIVE flag, and others without, then events will
//          be provided to all epoll instances that did not specify EPOLLEXCLUSIVE,
//          and at least one of the epoll instances that did specify EPOLLEXCLUSIVE.
//          如果其中一些设置了，而另外一些没有设置，没有设置的所有 epoll 都会收到通知，
//          设置了的只有至少一个收到通知。
//          以下值可以与 EPOLLEXCLUSIVE 一起指定：EPOLLIN、EPOLLOUT、EPOLLWAKEUP 和
//          EPOLLET，也可以指定 EPOLLHUP 和 EPOLLERR，但这不是必需的。在 events 中指
//          定其他值会导致 EINVAL 错误。
//          EPOLLEXCLUSIVE 可能只能在 EPOLL_CTL_ADD 操作中使用，尝试在 EPOLL_CTL_MOD
//          操作中使用它会导致错误。如果已经使用 epoll_ctl() 设置了 EPOLLEXCLUSIVE，
//          那么对同一 epfd 和 fd 对的后续 EPOLL_CTL_MOD 操作将导致错误。同样，如果在
//          events 中指定 EPOLLEXCLUSIVE 并将 epoll 实例作为目标文件描述符传入也会失
//          败。在所有这些情况下，错误都是 EINVAL。
//          A call to epoll_ctl() that specifies EPOLLEXCLUSIVE in events and
//          specifies the target file descriptor fd as an epoll instance will
//          likewise fail.
//      https://www.man7.org/linux/man-pages/man7/epoll.7.html
//          如果多个线程（或者进程，如果子进程通过 fork(2) 继承了 epoll 文件描述符）在
//          epoll_wait(2) 中阻塞，等待同一个 epoll 文件描述符，且关注列表中一个标记为
//          边缘触发（EPOLLET）通知的文件描述符准备就绪，那么只有一个线程（或进程）会从
//          epoll_wait(2) 中被唤醒。这在某些场景下提供了一个有用的优化，用于避免 thundering
//          herd 唤醒。
//          1. 多个线程等待同一个 epfd，边缘触发文件描述符如果就绪，只会通知一个线程
//          2. 多个进程等待同一个 epfd，边缘触发文件描述符如果就绪，只会通知一个进程
//          3. 多个 epfd 关注同一个 fd，如果该文件描述符就绪，没有给该 fd 设置独占标志
//             的所有 epfd 都会被唤醒，所有给 fd 设置了独占标志的 epfd 只有至少一个被
//             唤醒
//
// #include <sys/capability.h> // Link with -lcap
// bool prh_impl_epoll_cap_block_suspend_get(void) {
//     assert(CAP_IS_SUPPORTED(CAP_BLOCK_SUSPEND));
//     cap_t caps = cap_get_proc();
//     assert(caps != prh_null);
//     cap_flag_value_t cap_set = CAP_CLEAR;
//     prh_zeroret(cap_get_flag(caps, CAP_BLOCK_SUSPEND, CAP_EFFECTIVE, &cap_set));
//     prh_zeroret(cap_free(caps));
//     return cap_set == CAP_SET;
// }
// void prh_impl_epoll_cap_block_suspend_set(void) {
//     assert(CAP_IS_SUPPORTED(CAP_BLOCK_SUSPEND));
//     cap_t caps = cap_get_proc();
//     assert(caps != prh_null);
//     cap_flag_value_t cap_set = CAP_CLEAR;
//     prh_zeroret(cap_get_flag(caps, CAP_BLOCK_SUSPEND, CAP_EFFECTIVE, &cap_set));
//     prh_defer_if(cap_set == CAP_SET,);
//     prh_zeroret(cap_get_flag(caps, CAP_SETPCAP, CAP_EFFECTIVE, &cap_set));
//     prh_defer_if(cap_set != CAP_SET, prh_prerr(CAP_SETPCAP));
//     cap_value_t cap_list[1] = {CAP_BLOCK_SUSPEND};
//     prh_zeroret(cap_set_flag(caps, CAP_EFFECTIVE, 1, cap_list, CAP_SET));
//     prh_zeroret(cap_set_proc(caps)); // 设置 CAP_BLOCK_SUSPEND 需要具有相应的权限，通常只有 root 用户或具有 CAP_SETPCAP 权限的用户才能设置其他能力。
// label_defer:
//     prh_zeroret(cap_free(caps));
// }
//
// 可能返回的错误：
//      EBADF - epfd 或 fd 是非法文件描述符。
//      EEXIST - EPOLL_CTL_ADD 一个已经注册的 fd。
//      EINVAL - epfd 不是一个 epoll 文件描述符, 或者 fd 与 epfd 相同，或者提供的 op
//          操作不被支持。不允许一起指定的事件类型，指定了 EPOLLEXCLUSIVE 标志。
//          EPOLL_CTL_MOD 操作一起指定了 EPOLLEXCLUSIVE 标志。如果 epfd fd 对之前
//          设置了 EPOLLEXCLUSIVE 标志，再 EPOLL_CTL_MOD 进行修改。设置了 EPOLLEXCLUSIVE
//          并且 fd 指向另一个 epoll 实例。
//      ELOOP - EPOLL_CTL_ADD 添加一个指向另一个 epoll 实例的 fd，导致 epoll 实例
//          引用循环，或者 epoll 的嵌套深度超过了 5 次。
//      ENOENT - EPOLL_CTL_MOD 或 EPOLL_CTL_DEL 一个没有注册的 fd。
//      ENOMEM - 没有足够的内存空间来完成对应的操作。
//      ENOSPC - The limit imposed by /proc/sys/fs/epoll/max_user_watches was
//          encountered while trying to register (EPOLL_CTL_ADD) a new file
//          descriptor on an epoll instance. See epoll(7) for further details.
//          注册的监控个数达到 epoll 用户配置的最大值。因为每个注册到 epoll 实例的文件
//          描述符需要占用一小段不能被交换的内核内存空间，因此内核提供了一个接口用来定义
//          每个用户可以注册到 epoll 实例上的文件描述符总数。这个上限值可以通过 max_user_watches
//          文件来查看和修改。默认的上限值根据可用的系统内存来计算得出，参考 epoll(7)
//          用户手册页。
//      https://www.man7.org/linux/man-pages/man7/epoll.7.html
//          以下接口可用于限制 epoll 消耗的内核内存量：
//          /proc/sys/fs/epoll/max_user_watches (自 Linux 2.6.28 起可用)
//          它指定一个用户可以在系统上所有 epoll 实例中注册的文件描述符总数的限制。
//          在 32 位内核上，每个注册的文件描述符大约占用 90 字节；在 64 位内核上，大约
//          占用 160 字节。
//          Currently, the default value for max_user_watches is 1/25 (4%) of
//          the available low memory, divided by the registration cost in bytes.
//          当前 max_user_watches 的默认值是，例如64位系统可用低内存为 1GB，那么其值
//          为 1GB * 0.04 / 160-byte ≈ 26214。
//      EPERM - 文件描述符指向的目标文件不支持 epoll，例如是一个普通文件或目录。
//
// #include <sys/epoll.h>
// #include <sys/ioctl.h>
// struct epoll_params {
//     uint32_t busy_poll_usecs;    /* Number of usecs to busy poll */
//     uint16_t busy_poll_budget;   /* Max packets per poll */
//     uint8_t prefer_busy_poll;    /* Boolean preference  */
//     /* pad the struct to a multiple of 64 bits */
//     uint8_t __pad;   必须为零，这是一个填充字段，用于对齐和扩展性。
// }; // 成功返回 0，失败返回 -1 和 errno，Linux 6.9 glibc 2.40
// int ioctl(int epfd, EPIOCSPARAMS, const struct epoll_params *argp);
// int ioctl(int epfd, EPIOCGPARAMS, struct epoll_params *argp);
//
// 获取（EPIOCGPARAMS）和设置（EPIOCSPARAMS）epoll 的参数，通过合理配置这些参数，可以
// 优化网络处理的性能，特别是在高负载的系统中。epoll_params 结构体用于配置 epoll 的参数，
// 特别是在 Linux 6.9 及更高版本中引入的忙碌轮询（busy polling）功能。
// busy_poll_usecs - 表示网络协议栈将进行忙碌轮询的微秒数，在此时间段内，网络设备将被反
//      复轮询以获取数据包，该值不能超过 INT_MAX。
// busy_poll_budget - 表示网络协议栈在每次轮询尝试中可取出的最大数据包数量，该值不能超
//      过 NAPI_POLL_WEIGHT（截至 Linux 6.9，其值为 64），除非进程以 CAP_NET_ADMIN
//      权限运行。
// prefer_busy_poll - 如果启用，这表示向网络协议栈表明忙碌轮询是处理网络数据的首选方法，
//      网络栈应给予应用程序进行忙碌轮询的机会。如果没有此选项，非常繁忙的系统可能会继续
//      通过正常的 IRQ 触发 softIRQ 和 NAPI 的方法进行网络处理。
// 另见 linux.git/Documentation/networking/napi.rst
//      linux.git/Documentation/admin-guide/sysctl/net.rst
//
// 可能的错误：
//      EOPNOTSUPP - 内核的编译版本不支持忙碌轮询（busy poll）功能
//      EINVAL - epfd 是一个非法的文件描述符，__pad 参数不是零，busy_poll_usecs 超
//          过 INT_MAX 的大小，prefer_busy_poll 不是 0 也不是 1
//      EPERM - 运行线程没有 CAP_NET_ADMIN 能力并且指定的 busy_poll_budget 超过
//          NAPI_POLL_WEIGHT 的大小
//      EFAULT - 传入的 argp 是一个非法地址
//
// https://www.man7.org/linux/man-pages/man2/epoll_wait.2.html
//
// #include <sys/epoll.h> // 返回 0 表示超时返回并没有任何就绪文件描述符，大于 0 表示就绪文件描述符的个数，返回 -1 表示错误
// int epoll_wait(int epfd, struct epoll_event events[.maxevents], int maxevents, int timeout); // Linux 2.6, glibc 2.3.2
// int epoll_pwait(... int timeout, const sigset_t *_Nullable sigmask); // Linux 2.6.19, glibc 2.6
// int epoll_pwait2(... const struct timespec *_Nullable timeout, const sigset_t *_Nullable sigmask); // Linux 5.11
//
// 系统调用 epoll_wait() 返回 epoll 实例中处于就绪状态的文件描述符信息，单次调用能返回
// 多个就绪文件描述符的信息。数组 events 的空间由调用者负责申请，其能包含的元素个数由
// maxevents 参数指定，maxevents 参数必须大于零。每个数组元素，返回的都是单个就绪文件
// 描述符的信息，events 字段返回了在该描述符上已经发生的事件类型。如果 timeout 设置为
// -1 则表示一直阻塞，直到兴趣列表中的文件描述符有事件发生，或者调用被信号处理函数中断。
// 如果等于 0 则表示执行一次非阻塞式检查。如果大于 0 表示最多阻塞 timeout 毫秒，使用的
// 是 CLOCK_MONOTONIC 时钟，注意时间会近似到系统时钟的颗粒度，并且内核调度的延迟会让阻
// 塞间隔超长一小段时间。另外 epoll_pwait2 提供纳秒级别的等待时间，如果传递空指针则表示
// 一直阻塞。
//
// 在 Linux 2.6.37 之前，大于大约 LONG_MAX / HZ 毫秒的超时值会被当作 -1（无穷大）。
// 因此，例如，在一个 sizeof(long) 为 4 且内核 HZ 值为 1000 的系统上，这意味着大于
// 35.79 分钟的超时值会被当作无穷大，即 2147483647 / 1000。HZ 表示内核的时钟频率，在
// 许多系统上，HZ 的默认值为 1000。
//
// epoll_pwait 可以完全的让应用程序安全的等待文件描述符就绪，或者接收到一个信号。如果
// 提供的参数 sigmask 为空，epoll_pwait 等价于 epoll_wait。下面的 epoll_pwait 调用：
//      ready = epoll_pwait(epfd, &events, n, timeout, &sigmask);
// 等价于原子的执行以下代码：
//      sigset_t origmask;
//      pthread_sigmask(SIG_SETMASK, &sigmask, &origmask);
//      ready = epoll_wait(epfd, &events, maxevents, timeout);
//      pthread_sigmask(SIG_SETMASK, &origmask, NULL);
// 原始的 epoll_pwait() 和 epoll_pwait2() 系统调用有一个第六个参数，size_t sigsetsize，
// 它指定了 sigmask 参数的大小（以字节为单位）。Glibc 的 epoll_pwait() 包装函数将这个
// 参数指定为一个固定值 sizeof(sigset_t)。
//
// 在多线程程序中，可以一个线程 epoll_wait() 一边检测，另一个线程使用 epoll_ctl() 来添
// 加或修改感兴趣的文件描述符。需要注意的是，可以在一个当前关注列表为空的 epoll 实例上调
// 用 epoll_wait()，或者因为其他线程关闭或移除了文件描述符，导致关注列表变为空。调用将阻
// 塞，直到另一个线程将某个文件描述符添加到关注列表中，并且该文件描述符准备就绪。
// While one thread is blocked in a call to epoll_wait(), it is possible for
// another thread to add a file descriptor to the waited-upon epoll instance.
// If the new file descriptor becomes ready, it will cause the epoll_wait() call
// to unblock.
//
// 如果在调用 epoll_wait() 时有超过 maxevents 个文件描述符准备就绪，那么连续的 epoll_wait()
// 调用将依次轮询这些准备就绪的文件描述符。这种行为有助于避免饥饿场景，即一个进程因为专注
// 于一组已经就绪的文件描述符，而未能注意到其他文件描述符也已经就绪。
//
// 可能的错误：
//      EBADF - epfd 是一个非法的文件描述符
//      EFAULT - events 指向的内存区域没有写权限
//      EINTR - 在收到文件描述符事件或超时之前，调用被信号处理函数中断，参考 signal(7)
//      EINVAL - epfd 不是一个合法的 epoll 文件描述符，或者 maxevents 小于等于 0
//
// 当采用边缘触发通知时避免出现文件描述符饥饿现象：假设我们采用边缘触发通知监控多个文件
// 描述符，其中一个处于就绪状态的文件描述符上有着大量的输入存在，可能是一个不间断的输入
// 流。如果在检测到该文件描述符处于就绪状态后，就通过非阻塞式的读操作将所有的输入都读取，
// 那么此时就会有使其他文件描述符处于饥饿状态的风险，因为非阻塞式的不断读取可能因为输入
// 的不断到来一直读取不完或花费很长时间才读完。该问题的一种解决方案是让应用程序维护一个
// 列表，列表中存放着已经被通知为就绪状态的文件描述符，通过一个循环按照如下方式不断处理：
// （一）调用 epoll_wait() 检查文件描述符，将处于就绪态的描述符添加到应用程序维护的列表
// 中。如果没有就绪的文件描述符，应用程序就继续处理已经处于就绪态的文件描述符。
// （二）在应用程序维护的列表中，只在已经就绪的文件描述符上进行一定限度的I/O操作，可能是
// 轮转方式循环处理（round-robin），而不是每次 epoll_wait() 调用后都从列表开头开始处理。
// 当相关非阻塞I/O系统调用出现 EAGAIN 或 EWOULDBLOCK 时，文件描述符就可以从维护列表中
// 移除。
// （三）尽管采用这种方法需要做一些额外的编程工作，但是除了能避免出现文件描述符饥饿现象外，
// 我们还能获得其他益处。比如，我们可以在上述循环中加入其他的步骤，比如处理定时器以及用
// sigwaitinfo() 或其他类似的机制来接收信号。
//
// 因为信号驱动I/O也是采用边缘触发通知机制，因此也需要考虑文件描述符饥饿的情况。与之相反，
// 在采用水平触发通知机制的应用程序中，考虑文件描述符饥饿的情况并不是必须的。因为我们可以
// 采用水平触发通知在非阻塞式的文件描述符上通过循环连续地检查描述符的就绪状态，然后在下一
// 次检查文件描述符的状态前在处于就绪态的描述符上做一些I/O处理就可以了。
//
// https://www.man7.org/linux/man-pages/man7/epoll.7.html
//
// 可能的陷阱及避免方法：（一）饥饿（边缘触发），如果有巨大数值的 I/O 空间，尝试耗尽它可
// 能会导致其他文件无法得到处理，从而造成饥饿（这个问题并不特定于 epoll）。解决方案是维护
// 一个就绪列表，并在其关联的数据结构中标记文件描述符为就绪，从而使应用程序记住哪些文件需
// 要处理，并在所有就绪文件之间轮询，这也支持忽略后续收到的已就绪文件的事件。
// （二）如果使用事件缓存，如果你使用事件缓存或存储从 epoll_wait(2) 返回的所有文件描述符，
// 则确保提供一种动态标记其关闭的方法。假设你从 epoll_wait(2) 收到 100 个事件，而在事件
// #47 中，一个条件导致事件 #13 被关闭。如果你直接移除其结构并调用 close(2) 关闭对应的
// 文件描述符，那么你的事件缓存可能仍然会显示该文件描述符有事件等待。解决这个问题的一个方
// 法是在处理事件 47 时，调用 epoll_ctl(EPOLL_CTL_DEL) 删除文件描述符 13 并调用 close(2)，
// 然后将其关联的数据结构标记为已移除，并将其添加到清理列表中。如果你在批量处理中发现另一
// 个事件为文件描述符 13，你将发现该文件描述符之前已被移除，因此不会产生混淆。
//
// 问题与解答
// 1. 如何区分关注列表（interest list）中注册的文件描述符？
//      在区分时使用的键是用户空间文件描述符编号（file descriptor number）和内核打开的
//      文件描述（open file description 或 open file handle）的组合。
// 2. 如果在同一个 epoll 实例中注册同一个文件描述符两次会发生什么？
//      你可能会收到 EEXIST 错误。然而，可以将一个重复的（dup(2)、dup2(2)、fcntl(2)
//      F_DUPFD）文件描述符添加到同一个 epoll 实例中。如果重复的文件描述符用不同的事件
//      掩码注册，这可以是一种有用的事件过滤技术。
// 3. 两个 epoll 实例可以等待同一个文件描述符吗？如果是，事件会报告给两个 epoll 文件描述符吗？
//      是的，事件会报告给两个。然而，正确实现这一点可能需要谨慎编程。
// 4. epoll 文件描述符本身可以被 poll/epoll/select 吗？
//      可以。如果一个 epoll 文件描述符有等待的事件，它将表示为可读。
// 5. 如果试图将一个 epoll 文件描述符放入自己的文件描述符集中会发生什么？
//      epoll_ctl(2) 调用会失败（EINVAL）。然而，你可以将一个 epoll 文件描述符添加到
//      另一个 epoll 文件描述符集中。
// 6. 我可以将一个 epoll 文件描述符通过 UNIX 域套接字发送给另一个进程吗？
//      可以，但这没有意义，因为接收进程不会有关注列表中文件描述符的副本。
// 7. 关闭一个文件描述符会导致它从所有 epoll 关注列表中移除吗？
//      是的，但请注意以下要点。文件描述符是对打开文件描述的引用，参见 open(2)。每当文件
//      描述符通过 dup(2)、dup2(2)、fcntl(2) F_DUPFD 或 fork(2) 复制时，都会创建一个
//      指向相同打开文件描述的新文件描述符。一个打开文件描述会一直存在，直到所有引用它的
//      文件描述符都被关闭。
//      只有在所有引用底层打开文件描述的文件描述符都被关闭后，文件描述符才会从关注列表中
//      移除。这意味着，即使一个属于关注列表的文件描述符已经被关闭，如果还有其他引用相同
//      底层文件描述的文件描述符保持打开状态，事件仍可能为该文件描述符报告。为了避免这种
//      情况发生，必须在复制文件描述符之前，显式地从关注列表中移除该文件描述符（使用
//      EPOLL_CTL_DEL）。或者，应用程序必须确保所有文件描述符都被关闭（这可能很困难，如
//      果文件描述符被库函数在幕后通过 dup(2) 或 fork(2) 复制）。
// 8. 如果在两次 epoll_wait(2) 调用之间发生多个事件，它们是合并还是分别报告？
//      它们将被合并。
// 9. 对文件描述符的操作会影响已经收集但尚未报告的事件吗？
//      在已经存在的文件描述符上，你只能执行两种操作，移除在这种情况下没有意义，修改将重
//      新读取可用的 I/O。
// 10. 使用 EPOLLET 标志（边缘触发行为）时，我需要持续读取/写入文件描述符，直到遇到 EAGAIN 吗？
//      从 epoll_wait(2) 接收到事件，表示这样的文件描述符已准备好进行请求的 I/O 操作。
//      你应该认为它一直可用，直到下一次（非阻塞）读取/写入返回 EAGAIN。何时以及如何使用
//      文件描述符完全取决于你。
//      对于分组（packed-oriented）或令牌导向（token-oriented）的文件，例如数据报套接
//      字、处于规范模式的终端，检测读取/写入 I/O 空间结束的唯一方法是继续读取/写入，直
//      到遇到 EAGAIN。
//      对于流导向（stream-oriented）文件，例如管道、FIFO、流套接字，也可以通过检查从
//      目标文件描述符读取/写入的数据量来检测读取/写入 I/O 空间耗尽的情况。例如，如果你
//      通过调用 read(2) 要求读取一定数量的数据，而 read(2) 返回的字节数较少，你可以确
//      信该文件描述符的读取 I/O 空间已经耗尽，写入时使用 write(2) 也是如此。如果不能
//      保证监控的文件描述符总是引用流导向的文件，则避免使用后一种技术。
// 11. 边缘触发文件描述符就绪后，在进行 read(2) 的期间，又有新的数据到来，后续的 read(2)
//     操作会直接读到新来的数据吗，还是必须再一次 epoll_wait(2) 后才能读到新的数据？
//     对于 write(2) 呢，也一样吗？
//
// 有关线程安全：epoll_ctl() 和 epoll_wait() 本身线程安全的，内核会用锁保护epoll实
// 例。例如线程A阻塞在epoll_wait()时，线程B/C可以并发地对同一个epfd调用epoll_ctl()
// 进行添加/修改/删除，因此并发epoll_ctl()并不会破坏数据也不会死锁。但是要注意的是，
// 例如线程B关闭文件描述符close(fd)之后，线程A仍对其进行 epoll_wait()，可能错过事件
// 或发生EBADF。若必须多线程操作同一个epoll实例epfd，确保fd生命周期由引用计数或统一
// 线程管理。关闭文件描述符的顺序，一般是先epoll_ctl(DEL)，再close(fd)，因为若先
// close(fd)，再 epoll_ctl(DEL) 时fd可能已被内核回收并复用了，导致EBADF或误操作其他
// 文件。Linux文档明确指出，对已关闭的fd进行 epoll 操作，结果未定义。当然，如果你确保
// 所有线程再也不会对该fd做任何epoll调用，可以先close，但一般仍推荐先DEL的顺序，因为
// 简单且无坑。
//
// 不像poll那样每次都需要用户提供跟踪的文件描述符集合，epoll会自动跟踪文件描述符集合，
// 并且只把有事件发送的就绪集合上报给用户，用户不需要每次都要遍历整个文件描述符列表。
// 文件描述符一经加入就一直由epoll自动负责监控，用户只需要在感兴趣的时候去查看当前有什
// 么事件已经就绪，直到文件描述符需要关闭，将文件描述符从epoll中移除，并最后关闭文件
// 描述符。

void prh_impl_epoll_add(int epfd, int fd, prh_u32 events, void *priv) {
    struct epoll_event event;
    event.events = events;
    event.data.ptr = priv;
    prh_real_zeroret_or_errno(epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &event));
}

void prh_impl_epoll_mod(int epfd, int fd, prh_u32 events, void *priv) {
    struct epoll_event event;
    event.events = events;
    event.data.ptr = priv;
    prh_real_zeroret_or_errno(epoll_ctl(epfd, EPOLL_CTL_MOD, fd, &event));
}

void prh_impl_epoll_del(int epfd, int fd) {
    struct epoll_event event; // Linux 2.6.9 之前的版本，event 参数虽然会被忽略，但不能传递空指针
    prh_real_zeroret_or_errno(epoll_ctl(epfd, EPOLL_CTL_DEL, fd, &event));
}

int prh_impl_epoll_create(void) {
    int epfd = epoll_create1(EPOLL_CLOEXEC);
    assert(epfd >= 0);
    return epfd;
}

int prh_impl_epoll_wait(int epfd, void *events, int count) {
    int n = epoll_wait(epfd, events, count, 0);
    prh_debug(prh_preno_if(n < 0 && errno != EINTR));
    return n;
}

// 协程间消息的1对1模式，两个协程间的通信，发送消息的原则是，请求协程将消息直接写到执行
// 协程（当然第一次消息发送做不到），执行协程读取属于自己的内存，然后执行对应的操作，然
// 后将结果也写到自己的内存中，然后告诉请求协程去读取。这样，执行协程大部分时间都只访问
// 自己的内存（除了第一次消息），内存访问效率会很高，当然如果还能满足，在同一个线程完成
// 所有的任务，效率会更高。从整体看，内存的修改只发生在，执行协程内的很小一部分区域，不
// 会导致大范围的内存缓存失效。而且，两个协程所有的消息交互都限定在了这一个小区域内，将
// 这个小区域对齐到内存缓存行的边界，执行效率会更高。

#define PRH_MAX_SAME_TIME_POSTS_UPPER_TO_EPOLL_PER_FILE_DESCRIPTOR 4 // MOD(1) WAIT(2) DEL(1)，ADD会同步等待，EXIT使用全局epoll_exit
typedef enum { // 因为每次WAIT都会将所有就绪文件描述符检查一遍，因此不需要周期性EPOLL
    PRH_EPAC_ADD,     // 向 epoll 添加文件描述符
    PRH_EPAC_MOD,     // 修改文件描述符监听事件
    PRH_EPAC_TX_WAIT, // 等待文件描述符可写
    PRH_EPAC_RX_WAIT, // 等待文件描述符可读
    PRH_EPAC_DEL,     // 删除并关闭特定文件描述符
    PRH_EPAC_EXIT,    // 释放 epoll 实例退出协程
    PRH_EPAC_MAX_NUM
} prh_epoll_action;

#define PRH_EPAC_INDEX_TX_WAIT 0
#define PRH_EPAC_INDEX_RX_WAIT 1
#define PRH_EPAC_INDEX_DEL     2
#define PRH_EPAC_INDEX_MOD     3
#define PRH_EPEV_INDEX_ADDED   0
#define PRH_EPEV_INDEX_READY   1

typedef struct prh_epoll_port { // 保存在内核epoll_data.ptr和上层用户结构体中，在add时分配在del时释放
    prh_cono_pdata action; // PRH_EPAC_TX_WAIT 0 PRH_EPAC_RX_WAIT 1 PRH_EPAC_DEL 2 PRH_EPAC_MOD 3
    prh_cono_pdata event; // PRH_EPEV_ADDED 0 PRH_EPEV_READY 1
    prh_handle handle;
    prh_int wait_i; // -1 表示没有在等待
    prh_u32 events;
    prh_u32 update;
} prh_epoll_port;

typedef prh_arrdyn(prh_epoll_port*) prh_epoll_port_array;
typedef struct prh_impl_epoll {
    int epfd, fds_count;
    int poll_fds_each_time; // 估计同一时间最多有多少个文件描述符会同时有事件发生
    struct epoll_event *events; // 如果发生事件的文件描述符很多，但指定了很小的 poll_fds_each_time 值，则需要执行很多次 epoll_wait() 系统调用
    prh_epoll_port_array wait; // 只有在wait才会上报READY
    prh_cono_pdata epoll_exit;
} prh_impl_epoll;

static prh_impl_epoll *PRH_IMPL_EPOLL;

typedef void (*prh_impl_epoll_procedurecess)(prh_impl_epoll *epoll, prh_cono_pdata *pdata);
void prh_impl_process_epac_add(prh_impl_epoll *epoll, prh_cono_pdata *pdata);
void prh_impl_process_epac_mod(prh_impl_epoll *epoll, prh_cono_pdata *pdata);
void prh_impl_process_epac_wait(prh_impl_epoll *epoll, prh_cono_pdata *pdata);
void prh_impl_process_epac_del(prh_impl_epoll *epoll, prh_cono_pdata *pdata);
void prh_impl_process_epac_exit(prh_impl_epoll *epoll, prh_cono_pdata *pdata);

static prh_impl_epoll_procedurecess PRH_IMPL_EPFN[PRH_EPAC_MAX_NUM] = {
    prh_impl_process_epac_add,
    prh_impl_process_epac_mod,
    prh_impl_process_epac_wait,
    prh_impl_process_epac_wait,
    prh_impl_process_epac_del,
    prh_impl_process_epac_exit,
};

typedef struct {
    prh_cono_pdata head;
    prh_cono_subq *from_subq;
    prh_u32 events;
} prh_data_epac_add;

// 上层协程请求向EPOLL添加文件描述符

prh_inline prh_cono_subq *prh_impl_epoll_recv_subq(void) {
    return prh_cono_get_subq((prh_spawn_data *)PRH_IMPL_EPOLL, 0);
}

void prh_impl_epac_add(prh_epoll_port **port, prh_cono_subq *subq, prh_handle fd, prh_u32 events) {
    prh_data_epac_add from;
    from.head.subq = prh_impl_epoll_recv_subq();
    from.head.u.value = (prh_u32)(int)fd;
    from.from_subq = subq;
    from.events = events;
    prh_cono_post_data(&from.head, 0, PRH_EPAC_ADD);
    prh_pwait_data data = prh_cono_subq_pwait(subq->subq_i);
    assert(data.opcode == PRH_EPEV_ADDED);
    *port = (prh_epoll_port *)((prh_byte *)data.pdata - prh_offsetof(prh_epoll_port, event));
}

void prh_epoll_add_tcp_accept(prh_tcplisten *listen, prh_cono_subq *subq) { // 接收连接，错误
    prh_u32 events = EPOLLIN | EPOLLET; // EPOLLERR 和 EPOLLHUP 默认会设置
    prh_impl_epac_add(&listen->epoll_port, subq, listen->sock, events);
}

void prh_epoll_add_tcp_connect(prh_tcpsocket *tcp, prh_cono_subq *subq) {
    prh_u32 events = EPOLLOUT | EPOLLET; // EPOLLERR 和 EPOLLHUP 默认会设置
    prh_impl_epac_add(&tcp->epoll_port, subq, tcp->sock, events);
}

void prh_epoll_mod_tcp_connect(prh_tcpsocket *tcp) {
    prh_epoll_port *port = tcp->epoll_port;
    prh_cono_pdata *action = &port->action;
    action->u.value = EPOLLIN | EPOLLOUT | EPOLLRDHUP | EPOLLET; // EPOLLERR 和 EPOLLHUP 会默认会设置
    prh_cono_post(action, PRH_EPAC_INDEX_MOD);
}

void prh_epoll_add_tcp_socket(prh_tcpsocket *tcp, prh_cono_subq *subq) { // 连接，断连，读取，写入，错误
    prh_u32 events = EPOLLIN | EPOLLOUT | EPOLLRDHUP | EPOLLET; // EPOLLERR 和 EPOLLHUP 会默认会设置
    prh_impl_epac_add(&tcp->epoll_port, subq, tcp->sock, events);
}

void prh_epoll_receive_events(prh_tcpsocket* tcp) {
    prh_u32 events = tcp->epoll_port->events;
    if (events & EPOLLIN) {
        tcp->epoll_in = true;
    }
    if (events & EPOLLOUT) {
        tcp->epoll_out = true;
    }
    if (events & EPOLLRDHUP) { // 对端设备关闭了写入端并发了FIN，连接处于半关闭
        tcp->epoll_rdhup = true;
    }
    if (events & EPOLLHUP) { // 双方都关闭了写入端，不能再继续读写
        tcp->epoll_hup = true;
    }
    if (events & EPOLLERR) {
        tcp->epoll_err = true;
    }
}

void prh_impl_report_epev_added(prh_epoll_port *port) {
    prh_cono_post(&port->event, PRH_EPEV_INDEX_ADDED);
}

void prh_impl_process_epac_add(prh_impl_epoll *epoll, prh_cono_pdata *pdata) {
    prh_data_epac_add *from = (prh_data_epac_add *)pdata;
    int fd = (int)from->head.u.value;
    int alloc_size = prh_round_cache_line_size(sizeof(prh_epoll_port));
    prh_epoll_port *port = prh_cache_line_aligned_malloc(alloc_size);
    assert(port != prh_null);
    memset(port, 0, sizeof(prh_epoll_port));
    port->action.subq = prh_impl_epoll_recv_subq();
    port->action.opcode[PRH_EPAC_INDEX_TX_WAIT] = PRH_EPAC_TX_WAIT;
    port->action.opcode[PRH_EPAC_INDEX_RX_WAIT] = PRH_EPAC_RX_WAIT;
    port->action.opcode[PRH_EPAC_INDEX_DEL] = PRH_EPAC_DEL;
    port->action.opcode[PRH_EPAC_INDEX_MOD] = PRH_EPAC_MOD;
    port->event.subq = from->from_subq;
    port->event.opcode[PRH_EPEV_INDEX_ADDED] = PRH_EPEV_ADDED;
    port->event.opcode[PRH_EPEV_INDEX_READY] = PRH_EPEV_READY;
    port->handle = fd;
    port->wait_i = -1;
    epoll->fds_count += 1;
    prh_impl_epoll_add(PRH_IMPL_EPOLL->epfd, fd, from->events, port);
    prh_impl_report_epev_added(port);
}

void prh_impl_process_epac_mod(prh_impl_epoll *epoll, prh_cono_pdata *pdata) {
    prh_epoll_port *port = (prh_epoll_port *)pdata;
    prh_u32 events = pdata->u.value;
    int fd = (int)port->handle;
    prh_impl_epoll_mod(PRH_IMPL_EPOLL->epfd, fd, events, port);
}

// 删除并关闭特定文件描述符

void prh_epoll_del_and_close(prh_epoll_port *port) {
    prh_cono_post(&port->action, PRH_EPAC_INDEX_DEL);
}

void prh_impl_process_epac_del(prh_impl_epoll *epoll, prh_cono_pdata *pdata) {
    prh_epoll_port *port = (prh_epoll_port *)pdata;
    int fd = (int)port->handle;
    prh_int wait_i = port->wait_i;
    prh_impl_epoll_del(epoll->epfd, fd);
    prh_impl_close_handle(fd);
    if (wait_i != -1) { // 删除数组中等待的文件描述符
        prh_epoll_port_array *array = &epoll->wait;
        prh_epoll_port **begin = prh_arrdyn_begin(array);
        prh_epoll_port **curr = begin + wait_i;
        prh_epoll_port *last = *(begin + array->size - 1);
        assert(*curr == port);
        *curr = last;
        last->wait_i = wait_i;
        port->wait_i = -1;
        array->size -= 1;
    }
    prh_aligned_free(port);
    epoll->fds_count -= 1;
}

// 上层协程请求EPOLL去问询文件描述符是否有事件到达

void prh_epoll_wait_tx_data(prh_epoll_port *port) {
    prh_cono_post(&port->action, PRH_EPAC_INDEX_TX_WAIT);
}

void prh_epoll_wait_rx_data(prh_epoll_port *port) {
    prh_cono_post(&port->action, PRH_EPAC_INDEX_RX_WAIT);
}

void prh_impl_report_epev_ready(prh_epoll_port *port) {
    port->events = port->update;
    port->update = 0;
    prh_cono_post(&port->event, PRH_EPEV_INDEX_READY);
}

bool prh_impl_epac_poll_events(prh_impl_epoll *epoll) {
    int poll_fds_each_time = epoll->poll_fds_each_time;
    struct epoll_event *start = epoll->events;
    struct epoll_event *event;
    int n, epfd = epoll->epfd;
    bool updated = false;
    prh_epoll_port *port;
    while ((n = prh_impl_epoll_wait(epfd, start, poll_fds_each_time)) > 0) {
        for (event = start; event < start + n; event += 1) {
            port = event->data.ptr;
            port->update |= event->events;
            updated = true;
        }
        if (n < poll_fds_each_time) {
            break;
        }
    }
    return updated;
}

void prh_impl_epoll_add_waiting(prh_impl_epoll *epoll, prh_epoll_port *port) {
    if (port->wait_i != -1) return; // 已经在等待队列中
    prh_epoll_port_array *array = &epoll->wait;
    prh_int wait_i = array->size;
    *prh_arrdyn_push_back(array) = port;
    port->wait_i = wait_i;
}

void prh_impl_epoll_check_and_report(prh_impl_epoll *epoll) {
    prh_epoll_port_array *array = &epoll->wait;
    prh_epoll_port **p = prh_arrdyn_begin(array);
    prh_epoll_port **end = prh_arrdyn_end(array);
    prh_epoll_port *port, *last;
    while (p < end) {
        port = *p;
        if (port->update) {
            *p = last = *--end;
            last->wait_i = port->wait_i;
            port->wait_i = -1;
            array->size -= 1; // 删除当前元素，将最后一个元素移动到当前位置
            prh_impl_report_epev_ready(port);
        } else {
            p += 1;
        }
    }
}

void prh_impl_process_epac_wait(prh_impl_epoll *epoll, prh_cono_pdata *pdata) {
    prh_epoll_port *port = (prh_epoll_port *)pdata;
    if (port->update) { // 该文件描述符上，已经有事件更新
        prh_impl_report_epev_ready(port);
        return;
    }
    bool updated = prh_impl_epac_poll_events(epoll);
    if (port->update) {
        prh_impl_report_epev_ready(port);
    } else {
        prh_impl_epoll_add_waiting(epoll, port);
    }
    if (updated) {
        prh_impl_epoll_check_and_report(epoll);
    }
}

// 释放EPOLL实例并退出协程

void prh_epoll_exit(void) {
    prh_cono_pdata *epoll_exit = &PRH_IMPL_EPOLL->epoll_exit;
    epoll_exit->subq = prh_impl_epoll_recv_subq();
    prh_cono_post_data(epoll_exit, 0, PRH_EPAC_EXIT);
}

void prh_impl_process_epac_exit(prh_impl_epoll *epoll, prh_cono_pdata *pdata) {
    assert(epoll->fds_count == 0); // 所有添加的文件描述符都已经删除和关闭
    prh_impl_close_handle(epoll->epfd);
    PRH_IMPL_EPOLL = prh_null;
    prh_arrdyn_free(&epoll->wait);
}

// EPOLL协程循环和初始化

prh_cono_proc prh_impl_epoll_procedure(void) {
    prh_impl_epoll *epoll = prh_cono_spwan_data();
    prh_pwait_data data = {0};
    while (data.opcode != PRH_EPAC_EXIT) {
        data = prh_cono_pwait();
        assert(data.opcode < PRH_EPAC_MAX_NUM);
        PRH_IMPL_EPFN[data.opcode](epoll, data.pdata);
    }
}

#if PRH_DEBUG
#define PRH_EPOLL_STACK_SIZE 512
#else
#define PRH_EPOLL_STACK_SIZE 256
#endif

#define PRH_EPOLL_FDS_EACH_TIME 32

void prh_epoll_init(int max_num_fds_hint, int poll_fds_each_time) {
    int maxudsize, initial_wait_array_size, initial_active_fds_at_same_time, initial_subq_total_posts;
    prh_impl_epoll *epoll;
    if (PRH_IMPL_EPOLL) {
        return;
    }
    if (poll_fds_each_time <= 0) {
        poll_fds_each_time = PRH_EPOLL_FDS_EACH_TIME;
    }
    if (max_num_fds_hint > 0 && (max_num_fds_hint /= 4)) { // 根据二八定律使用25%
        initial_wait_array_size = max_num_fds_hint;
        initial_active_fds_at_same_time = max_num_fds_hint;
    } else {
        initial_wait_array_size = 2;
        initial_active_fds_at_same_time = 2;
    }
    maxudsize = sizeof(prh_impl_epoll) + sizeof(struct epoll_event) * poll_fds_each_time;
    initial_subq_total_posts = initial_active_fds_at_same_time * PRH_MAX_SAME_TIME_POSTS_UPPER_TO_EPOLL_PER_FILE_DESCRIPTOR;
    PRH_IMPL_EPOLL = epoll = prh_cono_spawx(prh_impl_epoll_procedure, PRH_EPOLL_STACK_SIZE, maxudsize, 1, initial_subq_total_posts);
    epoll->epfd = prh_impl_epoll_create();
    epoll->poll_fds_each_time = poll_fds_each_time;
    epoll->events = (struct epoll_event *)(epoll + 1);
    prh_arrdyn_init(&epoll->wait, initial_wait_array_size);
    prh_cono_start((prh_spawn_data *)epoll, false);
}
#else

#endif
#endif // PRH_IOCP_IMPLEMENTATION
#endif // PRH_IOCP_INCLUDE

#ifdef PRH_CONO_INCLUDE
#define PRH_IMPL_CONO_SCHEDULE_STRATEGY_V3 1
#define PRH_IMPL_CONO_SCHEDULE_STRATEGY_V2 1

#define prh_cono_proc prh_fastcall(void)
prh_fastcall_typedef(void, prh_conoproc_t)(void);
typedef struct prh_real_cono prh_real_cono;
typedef struct prh_spawn_data prh_spawn_data;
typedef struct prh_await_data prh_await_data;
extern prh_thread_local prh_real_cono *PRH_IMPL_CONO_SELF;
void prh_impl_cross_thread_coro_yield(prh_real_cono *cono);

void prh_cono_main(int thrd_start_id, int num_thread, prh_conoproc_t main_proc, int stack_size);
void *prh_cono_spawn(prh_conoproc_t proc, int stack_size, int maxudsize);
void *prh_cono_spawx(prh_conoproc_t proc, int stack_size, int maxudsize, prh_byte subq_n, int init_items);
void *prh_cono_spawx_fixed_subq(prh_conoproc_t proc, int stack_size, int maxudsize, prh_byte subq_n, int init_items);
void *prh_cono_await(void); // 等待一个或多个子协程YIELD结果
void prh_cono_start(prh_spawn_data *cono_spawn_data, bool await_cono_yield); // 启动子协程
void prh_cono_continue(prh_await_data *cono_await_data); // 获取子协程结果后，让子协程继续执行

#if PRH_IMPL_CONO_SCHEDULE_STRATEGY_V3 == 0
typedef struct prh_cono_pdata prh_cono_pdata;
typedef struct { prh_cono_pdata *pdata; prh_byte subq_i; prh_byte opcode; } prh_pwait_data;
typedef prh_arrque(prh_cono_pdata *) prh_pdata_rxq;
typedef struct { void *cono; prh_unt subq_i: 8, post_count: prh_int_bits - 8; } prh_cono_subq;

typedef struct prh_cono_pdata {
    prh_cono_subq *subq;
    prh_byte opcode[4];
    union { prh_u32 size; prh_u32 value; } u;
} prh_cono_pdata;

prh_cono_subq *prh_cono_get_subq(prh_spawn_data *cono_spawn_data, prh_byte subq_i);
prh_cono_subq *prh_cono_self_subq(prh_byte subq_i);
void prh_cono_post(prh_cono_pdata *pdata, prh_byte opcode_i); // 向目的协程发送请求数据或执行结果
void prh_cono_post_data(prh_cono_pdata *pdata, prh_byte opcode_i, prh_byte opcode);
prh_pwait_data prh_cono_pwait(void); // 等待其他协程发来的数据，只需要等待数据即可，发送数据的协程无需yield，可以继续无干扰执行
prh_pwait_data prh_cono_subq_pwait(prh_byte subq); // 只等待其他协程发到某个子队列中的数据

prh_inline prh_coro *prh_impl_coro_from_cono(prh_real_cono *cono) {
    return (prh_coro *)((prh_byte *)cono - prh_impl_coro_size);
}

prh_inline prh_real_cono *prh_impl_cono_from_coro(prh_coro *coro) {
    return (prh_real_cono *)((prh_byte *)coro + prh_impl_coro_size);
}

prh_inline void prh_cono_yield(void) {
    prh_impl_cross_thread_coro_yield(PRH_IMPL_CONO_SELF);
    prh_soro_yield((prh_soro *)prh_impl_coro_from_cono(PRH_IMPL_CONO_SELF));
}
#else
typedef struct {
    prh_ptr post_data;
    prh_byte opcode;
    prh_byte subq_i;
} prh_pwait_data;

prh_inline void prh_cono_yield(void) {
    prh_impl_cross_thread_coro_yield(PRH_IMPL_CONO_SELF);
    prh_soro_yield((prh_soro *)PRH_IMPL_CONO_SELF);
}
#endif

#ifdef PRH_CONO_IMPLEMENTATION
#ifndef PRH_CONO_DEBUG
#define PRH_CONO_DEBUG PRH_DEBUG
#endif

#if PRH_IMPL_CONO_SCHEDULE_STRATEGY_V3 == 0

// 协程发送消息时，先将消息存到本地线程队列，由特权线程负责获取每个线程的消息，分配到在
// 不同线程中执行的协程，这样每个协程可以在任意的线程中切换执行，而消息队列的维护可以做
// 到总是一对一的线程访问。
//
// 而如果为了内存缓存效率，一个协程一旦创建成功就一直在某个线程中执行，这种情况下，两个
// 协程之间的消息发送，也可以做到线程一对一的，而且如果两个线程位于同一线程，还可以无障
// 碍访问。相比于上面使用特权线程的方案，固定线程执行的方案可能性能更佳。但为了防止协程
// 饥饿，固定线程的方案，需要实现某种抢占执行方式。！！！不能实现一对一，因为可能多个协
// 程向同一个目标协程发送消息。

typedef struct {
    prh_real_cono *head;
    prh_real_cono *tail;
} prh_cono_quefit;

typedef struct prh_cono_thrd prh_cono_thrd;
struct prh_real_cono {
    // 仅由执行线程访问
    prh_i32 cono_id;
    prh_byte yield_state;
    prh_byte subq_n;
    prh_byte wait_que;
    prh_byte await: 1, pwait: 1, uncond_run: 1; // uncond_run 挂起后恢复时无条件执行
    void (*subq_push)(prh_real_cono *cono, prh_cono_pdata *pdata);
    prh_real_cono *caller;
    prh_real_cono *callee; // 只会在协程挂起时被特权线程修改，不存在竞争
    prh_pwait_data *pwait_data;
    // 仅由特权线程访问，协程可能会插入到特权维护的就绪队列/等待队列，或协程维护的子协程执行结果返回队列
    prh_cono_quefit callee_que; // 挂起的返回执行结果的子协程队列
    prh_pdata_rxq post_que;
    prh_cono_subq *cono_subq; // 请求数据或执行结果接收队列
    prh_real_cono *cono_chain; // 使用relaxed quefit是因为，想将被其他线程修改的内容放在一起
    prh_cono_thrd *assign_thrd;
};

prh_thread_local prh_real_cono *PRH_IMPL_CONO_SELF;

prh_inline int prh_impl_cono_size(void) {
    return (int)prh_round_16_byte(sizeof(prh_real_cono));
}

void *prh_cono_spwan_data(void) {
    return (prh_byte *)PRH_IMPL_CONO_SELF + prh_impl_cono_size();
}

prh_inline void *prh_impl_get_spawn_data(prh_real_cono *cono) {
    return (prh_byte *)cono + prh_impl_cono_size();
}

prh_inline prh_real_cono *prh_impl_cono_from_data(void *data) {
    return (prh_real_cono *)((prh_byte *)data - prh_impl_cono_size());
}

prh_inline void prh_impl_cono_init(prh_real_cono *cono, prh_i32 cono_id) {
    cono->cono_id = cono_id;
}

void prh_impl_fixed_subq_push(prh_real_cono *cono, prh_cono_pdata *pdata) {
    prh_pdata_rxq *q = &cono->post_que;
    *prh_arrque_unchecked_push(q) = pdata;
}

void prh_impl_vsize_subq_push(prh_real_cono *cono, prh_cono_pdata *pdata) {
    prh_pdata_rxq *q = &cono->post_que;
    *prh_arrque_auto_grow_push(q) = pdata;
}

prh_inline void prh_impl_cono_free(prh_real_cono *cono) {
    assert(prh_relaxed_quefit_empty(&cono->callee_que));
    assert(cono->post_que.size == 0);
    if (cono->subq_push == prh_impl_vsize_subq_push) {
        prh_arrque_free(&cono->post_que);
    }
    prh_impl_coro_free(prh_impl_coro_from_cono(cono));
}

prh_inline bool prh_impl_cono_finished(prh_real_cono *cono) {
    return prh_impl_coro_from_cono(cono)->rspoffset == 0;
}

struct prh_cono_thrd prh_thrd_struct(
    bool thrd_pending_work;
    prh_atom_hive_fbqfix free_block_q;
    prh_atom_hive_quefix cono_req_que; // 由当前线程写入，由特权线程读取
    prh_atom_hive_quefix post_req_que;
    prh_atom_ptr ready_cono; // 由特权线程写入，由特权线程窃取清空，或由当前协程读取清空
    prh_cond_sleep cond_sleep;
); // 每个线程尽量指定在单一的CPU上运行避免线程切换

prh_real_cono **prh_impl_thrd_grabbed_cono(prh_cono_thrd *thrd) {
    return (prh_real_cono **)&thrd->extra_ptr;
}

void prh_impl_cono_thrd_init(prh_cono_thrd *thrd) {
    prh_atom_hive_fbqfix_init(&thrd->free_block_q);
    prh_atom_hive_quefix_init(&thrd->cono_req_que, &thrd->free_block_q);
    prh_atom_hive_quefix_init(&thrd->post_req_que, &thrd->free_block_q);
    prh_atom_ptr_init(&thrd->ready_cono, prh_null);
    prh_impl_init_cond_sleep(&thrd->cond_sleep);
}

void prh_impl_cono_thrd_free(prh_thrd *thrd, int thrd_index) {
    prh_cono_thrd *cono_thrd = (prh_cono_thrd *)thrd;
    prh_real_assert(prh_atom_hive_quefix_empty(&cono_thrd->cono_req_que));
    prh_real_assert(prh_atom_hive_quefix_empty(&cono_thrd->post_req_que));
    prh_real_assert(prh_atom_ptr_read(&cono_thrd->ready_cono) == prh_null);
    prh_atom_hive_quefix_free(&cono_thrd->cono_req_que);
    prh_atom_hive_quefix_free(&cono_thrd->post_req_que);
    prh_atom_hive_fbqfix_free(&cono_thrd->free_block_q);
    prh_impl_free_cond_sleep(&cono_thrd->cond_sleep);
}

typedef enum {
    PRH_CONO_NULL = 0, // 非法协程
    PRH_CONO_ROOT = 1, // 特权协程在特权线程中直接执行，并没有创建一个真正的协程
    PRH_FIXED_CONO_MAX,
} prh_impl_cono_id;

typedef struct {
    prh_simple_thrds *thrds; // 初始化后只读
    prh_real_cono *main_entry_cono; // 初始化后只读
    prh_real_cono *fixed_cono[PRH_FIXED_CONO_MAX]; // 初始化后只读
    // 仅特权线程读写
    prh_cono_quefit ready_queue;
    prh_i32 cono_id_seed;
    // 多线程读写
    prh_atom_ptr privilege_thread;
    prh_atom_bool term_signal;
    prh_atom_int num_sleep;
} prh_cono_struct;

static prh_cono_struct PRH_IMPL_CONO_STRUCT;
prh_fastcall(void) prh_impl_asm_cono_call(void);

prh_inline void prh_impl_cono_load(prh_coro *coro, prh_conoproc_t proc) {
    prh_impl_coro_load_stack(coro, (prh_ptr)proc, (prh_ptr)prh_impl_asm_cono_call);
}

prh_real_cono *prh_impl_cono_create(prh_conoproc_t proc, int stack_size, int maxudsize) {
    prh_coro *coro = prh_impl_coro_alloc(stack_size, sizeof(prh_cono_thrd), maxudsize);
    prh_real_cono *real_cono = prh_impl_cono_from_coro(coro);
    prh_impl_cono_load(coro, proc);
#if PRH_CONO_DEBUG
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[cono   ] %p create -- lower %p (left %d) rsp %p coro %p (size %d) data %p (size %d) -- stack %d\n",
        (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, prh_impl_coro_extend_size(0), coro->userdata, (int)prh_round_16_byte(maxudsize), stack_size);
#endif
    return coro;
}

prh_cono_struct *prh_impl_cono_struct_init(int thrd_start_id, int num_threads, prh_conoproc_t main_proc, int stack_size) {
    prh_cono_struct *s = &PRH_IMPL_CONO_STRUCT;
    prh_simple_thrds *thrds = prh_simp_thrd_init(thrd_start_id, num_threads, );
    s->thrds = thrds;
    s->main_entry_cono = prh_impl_cono_create(main_proc, stack_size, 0);
    prh_impl_cono_thrd_init((prh_cono_thrd *)prh_simp_thrd_main(thrds));
    prh_atom_ptr_init(&s->privilege_thread, prh_null);
    prh_atom_bool_init(&s->term_signal, false);
    prh_atom_int_init(&s->num_sleep, 0);
    return s;
}

void prh_impl_fixed_cono_init(prh_real_cono *cono, prh_i32 cono_id) {
    prh_impl_cono_init(cono, cono_id);
    assert(cono_id < PRH_FIXED_CONO_MAX);
    PRH_IMPL_CONO_STRUCT.fixed_cono[cono_id] = cono;
}

prh_real_cono *prh_impl_get_fixed_coro(prh_int cono_id) {
    assert(cono_id < PRH_FIXED_CONO_MAX);
    return PRH_IMPL_CONO_STRUCT.fixed_cono[cono_id];
}

void prh_impl_cono_struct_free(void) {
    prh_cono_struct *s = &PRH_IMPL_CONO_STRUCT;
    prh_real_assert(prh_relaxed_quefit_empty(&s->ready_queue));
    for (int i = 0; i < PRH_FIXED_CONO_MAX; i += 1) {
        prh_real_cono *fixed_cono = s->fixed_cono[i];
        if (fixed_cono) prh_impl_cono_free(fixed_cono);
    }
    prh_impl_cono_free(s->main_entry_cono);
    prh_simp_thrd_free(&PRH_IMPL_CONO_STRUCT.thrds, prh_impl_cono_thrd_free);
}

// 要实现无锁且省去N*M爆炸内存，必须有一个线程担任中间角色，请求者与中间角色是一对一的，
// 中间角色与执行者也是一对一的，从而能够实现无锁。但中间角色的加入，必然带来一定延迟，
// 因此必须保证中间角色负责的中转任务即使在任务繁重的情况下，也能很快的高优先级完成。因
// 此必须有一个线程偏向性的来执行这些任务，避免所有线程都被一些费时任务霸占，导致轻量任
// 务被迫挨饿。
//
// 可以让主线程偏重执行这个任务，轻量执行时间短且优先级高的任务都属于此类。基本类型的原子
// 操作可以实现N个线程的竞争执行，但对于队列等复杂数据结构的无锁操作需要依赖一个线程读一
// 个线程写的一对一模型。如果不依靠一对一模型，N个线程同时竞争，一个任务就需要维护N个数据
// 结构，这样每个线程才能无锁的互不干扰的对这个任务进行读写。相当于用内存隔离来避免线程的
// 访问竞争，但是有M个任务就必须爆炸式的分配N*M份内存，在嵌入式等内存短缺的平台上不是一
// 种好的解决方案。
//
// 使用一对一的单生产者和单消费者的模式，请求线程将请求数据暂存到自己的发送队列，作为中间
// 角色的特权线程，遍历全部线程的发送队列，将发送队列中的请求数据转发到执行协程的接收队列
// 中，此执行协程此时可能正在某个线程中执行自己的任务，但如果执行协程没有在执行需要将该协
// 程添加到等待队列中去进行调度。
//
// root 协程执行轻量的高优先级任务，主线程完全偏向执行这个协程，另外所有其他线程可以平等
// 地像执行其他普通协程一样竞争执行这个协程，执行 root 协程的线程也被称为特权线程。主线
// 程除了最高优先级执行 root 协程外，还可以安排执行其他特殊的轻量高优先级任务。
//
// 协程间消息通信汇总：父协程也可理解为请求协程，子协程也可理解为执行协程
// 1. 子协程创建时给特权协程发送创建消息（只需给特权协程发送消息）
//          父协程的状态：挂起，等待特权协程创建好子协程后分配给线程执行，协程记录在子协程中
//          子协程的状态：还未创建，等待特权协程创建好之后直接分配给线程执行，协程记录在请求消息中
// 2. 如果创建独立的公共执行协程，有父协程的话父协程会等待执行协程创建，然后给执行协程发送消息之后才能等待执行协程，如果没有父协程也就不会挂起父协程，特权协程也不会直接执行父协程（只需给特权协程发送消息）
//          子协程的状态：还未创建，等待特权协程创建好之后直接分配给线程执行，协程记录在请求消息中
// 3. 需要提交结果的子协程给父协程发送消息提交结果（需要给父协程发送消息，然后父协程给特权协程发送消息）
//          父协程的状态：未知
//          子协程的状态：挂起，等待父协程处理消息，然后父协程给特权协程发送消息直接执行子协程
// 4. 如果父协程处理完子协程提交的结果后，也需要继续给子协程数据通信（父协程给特权协程发送消息）
//          父协程的状态：处理完子协程递交的结果后，直接将相关数据写入子协程，然后给特权协程发送消息直接执行子协程
//          子协程的状态：需要提交结果的子协程，一般执行完一次父协程给的任务后就会执行完毕，如果是多次执行任务，需要父协程继续提交任务直到父协程明确不需要继续执行任务后结束
// 5. 如果子协程不需要给父协程递交结果（需要父协程给请求协程发送消息）
//          子协程的状态：挂起后，如果已经执行完毕则释放协程，否则等待请求协程发送任务请求消息
// 6. 子协程给父协程发送消息递交结果，或者父协程给执行协程发送消息请求任务，此时目标协程因为状态未知，需要特殊处理
// 7. 第一种情况，子协程执行完任务后挂起，可以不给父进程发送消息，而是交由特权线程处理
//          子协程的状态：挂起后给特权协程发送消息，表示等待父协程的WAIT挂起，只要父协程WAIT挂起就直接执行父协程
//          特权协程实现：收到子协程的消息后，将其挂到父协程的WAIT队列中，当父协程WAIT挂起时，给特权线程发送消息，特权线程收到消息后取出一个子协程让父协程去执行，当然优先分配给当前线程执行
// 8. 第二种情况：不需要提交结果的执行协程没有任务执行时，也会给特权线程发送消息，特权协程也会取出一个请求数据直接分配执行协程直接执行
//          清求协程状态：请求协程发送请求数据给特权协程，特权协程将数据挂到执行协程的WAIT队列中，然后等待执行协程的WAIT挂起
//          执行协程状态：当执行协程执行完当前任务挂起后，给特权协程发送消息，特权协程收到消息后，取出一个数据直接执行执行协程
//          特权协程实现：如果执行协程先挂起，但队列中已经没有要处理的任务了，就会设置idle_wait标记，下次接收到请求数据就直接激活执行协程的执行

typedef enum {
    PRH_CONO_CONTINUE,
    PRH_CONO_START, // 启动新建协程
    PRH_CONO_YIELD, // 协程挂起或协程结束
    PRH_CONO_AWAIT, // 等待一个或多个协程YIELD结果
    PRH_CONO_PWAIT, // 等待接收请求数据或执行结果，请求数据和执行结果通过 prh_cono_post() 发送
    PRH_YIELD_STATE_NUM
} prh_impl_yield_state;

typedef void (*prh_impl_cono_req_func)(prh_real_cono *req_cono, prh_cono_quefit *ready_queue);
void prh_impl_privilege_process_continue_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue);
void prh_impl_privilege_process_start_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue);
void prh_impl_privilege_process_yield_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue);
void prh_impl_privilege_process_await_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue);
void prh_impl_privilege_process_pwait_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue);

static prh_impl_cono_req_func PRH_IMPL_YIELD_STATE_PROCESS[PRH_YIELD_STATE_NUM] = {
    prh_impl_privilege_process_continue_req,
    prh_impl_privilege_process_start_req,
    prh_impl_privilege_process_yield_req,
    prh_impl_privilege_process_await_req,
    prh_impl_privilege_process_pwait_req,
};

#if PRH_CONO_DEBUG
const char *prh_impl_yield_state_string(int yield_state) {
    const char *state_string[PRH_YIELD_STATE_NUM] = {
        "CONTINUE", "START", "YIELD", "AWAIT", "PWAIT",
    };
    return state_string[yield_state];
}
#endif

void prh_impl_send_cono_req(prh_real_cono *req_cono, prh_byte yield_state) {
    prh_cono_thrd *thrd = (prh_cono_thrd *)prh_thrd_self();
#if PRH_CONO_DEBUG
    if (yield_state != PRH_CONO_START) { // 需要启动的新建协程的 cono_id 此时还没有分配
        printf("[thrd %02d] cono %02d request %s\n", prh_thrd_self_id(), req_cono->cono_id, prh_impl_yield_state_string(yield_state));
    }
#endif
    req_cono->yield_state = yield_state;
    prh_atom_hive_quefix_push(&thrd->cono_req_que, req_cono);
}

void prh_cono_post(prh_cono_pdata *pdata, prh_byte opcode_i) { // 向目的协程发送数据，目标协程以及目标协程接收数据的子队列信息填写在pdata中
    prh_cono_thrd *thrd = (prh_cono_thrd *)prh_thrd_self();
    assert(((prh_ptr)pdata & 0x3) == 0 && opcode_i < sizeof(pdata->opcode));
    prh_atom_hive_quefix_push(&thrd->post_req_que, (void *)(((prh_ptr)pdata) | opcode_i));
}

void prh_cono_post_data(prh_cono_pdata *pdata, prh_byte opcode_i, prh_byte opcode) {
    pdata->opcode[opcode_i] = opcode;
    prh_cono_post(pdata, opcode_i);
}

void prh_impl_cross_thread_coro_yield(prh_real_cono *cono) {
    cono->yield_state = PRH_CONO_YIELD;
}

prh_fastcall(void *) prh_impl_asm_cono_finish(prh_coro *coro) {
    prh_impl_cross_thread_coro_yield(prh_impl_cono_from_coro(coro));
    return prh_impl_asm_soro_finish(coro);
}

void prh_impl_cono_wait(prh_real_cono *cono, prh_byte yield_state) {
    cono->yield_state = yield_state;
    prh_soro_yield((prh_soro *)prh_impl_coro_from_cono(cono));
}

void *prh_cono_spawn(prh_conoproc_t proc, int stack_size, int maxudsize) {
    prh_real_cono *cono = prh_impl_cono_create(proc, stack_size, maxudsize);
    return prh_coro_data(coro);
}

void *prh_cono_spawx(prh_conoproc_t proc, int stack_size, int maxudsize, prh_byte subq_n, int init_items) {
    maxudsize = prh_round_ptrsize(maxudsize);
    int alloc = maxudsize + sizeof(prh_cono_subq) * subq_n; // subq 放在用户数据的最后面
    prh_real_cono *cono = prh_impl_cono_from_data(prh_cono_spawn(proc, stack_size, alloc));
    prh_byte *cono_spawn_data = prh_impl_get_spawn_data(cono);
    prh_cono_subq *cono_subq = (prh_cono_subq *)(cono_spawn_data + maxudsize);
    for (int i = 0; i < subq_n; i += 1) {
        prh_cono_subq *curr_subq = cono_subq + i;
        curr_subq->cono = cono;
        curr_subq->subq_i = (prh_byte)i;
    }
    cono->subq_push = prh_impl_vsize_subq_push;
    cono->cono_subq = cono_subq;
    cono->subq_n = subq_n;
    prh_arrque_init(&cono->post_que, init_items); // 数组容量总是2的幂
    return cono_spawn_data;
}

void *prh_cono_spawx_fixed_subq(prh_conoproc_t proc, int stack_size, int maxudsize, prh_byte subq_n, int init_items) {
    assert(prh_is_power_of_2(init_items));
    maxudsize = prh_round_ptrsize(maxudsize); // 数组容量必须是2的幂
    int alloc = maxudsize + sizeof(prh_cono_subq) * subq_n + sizeof(void *) * init_items; // subq 放在用户数据的最后面
    prh_real_cono *cono = prh_impl_cono_from_data(prh_cono_spawn(proc, stack_size, alloc));
    prh_byte *cono_spawn_data = prh_impl_get_spawn_data(cono);
    prh_cono_subq *cono_subq = (prh_cono_subq *)(cono_spawn_data + maxudsize);
    for (int i = 0; i < subq_n; i += 1) {
        prh_cono_subq *curr_subq = cono_subq + i;
        curr_subq->cono = cono;
        curr_subq->subq_i = (prh_byte)i;
    }
    cono->subq_push = prh_impl_fixed_subq_push;
    cono->cono_subq = cono_subq;
    cono->subq_n = subq_n;
    cono->post_que.arrque = (prh_cono_pdata **)((prh_byte *)cono_subq + sizeof(prh_cono_subq) * subq_n);
    cono->post_que.capacity = init_items;
    return cono_spawn_data;
}

prh_cono_subq *prh_cono_get_subq(prh_spawn_data *cono_spawn_data, prh_byte subq_i) {
    prh_real_cono *cono = prh_impl_cono_from_data(cono_spawn_data);
    assert(subq_i < cono->subq_n);
    return cono->cono_subq + subq_i;
}

prh_cono_subq *prh_cono_self_subq(prh_byte subq_i) {
    prh_real_cono *cono = PRH_IMPL_CONO_SELF;
    assert(subq_i < cono->subq_n);
    return cono->cono_subq + subq_i;
}

void prh_impl_callee_continue(prh_real_cono *caller) {
    prh_real_cono *callee = caller->callee;
    if (callee) {
        caller->callee = prh_null;
        prh_impl_send_cono_req(callee, PRH_CONO_CONTINUE);
    }
}

void prh_cono_continue(prh_await_data *cono_await_data) {
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    assert(caller->callee == prh_impl_cono_from_data(cono_await_data));
    prh_impl_callee_continue(caller);
}

#define PRH_IMPL_CALLER_YIELD_WHEN_CREATE_NEW_CORO 0

#if PRH_IMPL_CALLER_YIELD_WHEN_CREATE_NEW_CORO
void prh_cono_start(prh_spawn_data *cono_spawn_data, bool await_cono_yield) {
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    prh_real_cono *callee = prh_impl_cono_from_data(cono_spawn_data);
    if (await_cono_yield) {
        callee->caller = caller;
    }
    caller->start_callee = callee;
    prh_impl_cono_wait(caller, PRH_CONO_START);
}
#else
void prh_cono_start(prh_spawn_data *cono_spawn_data, bool await_cono_yield) {
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    prh_real_cono *callee = prh_impl_cono_from_data(cono_spawn_data);
    if (await_cono_yield) {
        callee->caller = caller;
    }
#if PRH_CONO_DEBUG
    printf("[thrd %02d] cono %02d create %p\n", prh_thrd_self_id(), caller->cono_id, (void *)callee);
#endif
    prh_impl_send_cono_req(callee, PRH_CONO_START);
}
#endif

void *prh_cono_await(void) { // 协程挂起时必须设置原因，然后回到 prh_impl_cono_execute() 真正进入了挂起状态，然后发送消息给特权线程，去检查挂起的原因是否可以继续执行
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    prh_impl_cono_wait(caller, PRH_CONO_AWAIT);
    return prh_impl_get_spawn_data(caller->callee);
}

prh_pwait_data prh_cono_subq_pwait(prh_byte subq) { // 协程挂起时必须设置原因，然后回到 prh_impl_cono_execute() 真正进入了挂起状态，然后发送消息给特权线程，去检查挂起的原因是否可以继续执行
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    caller->wait_que = subq; // 只接收特定子队列收到的数据，或者0xff表示接收所有子队列收到的数据
    assert(subq == 0xff || subq < caller->subq_n);
    prh_pwait_data pwait_data;
    caller->pwait_data = &pwait_data;
    prh_impl_cono_wait(caller, PRH_CONO_PWAIT);
    return pwait_data;
}

prh_pwait_data prh_cono_pwait(void) { // 等待其他协程发来的请求数据或执行结果，只等待数据，发送数据的协程无需挂起可继续执行
    return prh_cono_subq_pwait(0xff);
}

void prh_impl_cono_wakeup_all_thrd(void) {
    prh_simple_thrds *thrds = PRH_IMPL_CONO_STRUCT.thrds;
    prh_simp_thrd_for_begin(prh_cono_thrd, thrds, prh_simp_thrd_begin(thrds), prh_simp_thrd_end(thrds))
        prh_thrd_wakeup(&it->cond_sleep);
    prh_simp_thrd_for_end()
}

void prh_impl_cono_term_signal(void) {
    prh_atom_bool_write(&PRH_IMPL_CONO_STRUCT.term_signal, true);
    prh_impl_cono_wakeup_all_thrd();
}

void prh_impl_privilege_process_continue_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue) {
    if (prh_impl_cono_finished(req_cono)) {
        if (req_cono == PRH_IMPL_CONO_STRUCT.main_entry_cono) {
            prh_impl_cono_term_signal();
        } else {
#if PRH_CONO_DEBUG
            printf("[thrd %02d] cono %02d finished\n", prh_thrd_self_id(), req_cono->cono_id);
#endif
            prh_impl_cono_free(req_cono);
        }
    } else if (req_cono->uncond_run) { // 无条件执行
        prh_relaxed_quefit_push(ready_queue, req_cono, cono_chain);
    } else {
        prh_abort_error(__LINE__); // 子协程提交执行结果后要么执行完毕，要么无条件继续执行
    }
}

#if PRH_IMPL_CALLER_YIELD_WHEN_CREATE_NEW_CORO
void prh_impl_privilege_process_start_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue) {
    prh_real_cono *callee = req_cono->start_callee;
    prh_impl_cono_init(callee, ++PRH_IMPL_CONO_STRUCT.cono_id_seed); // 初始化新协程
    callee->assign_thrd = req_cono->assign_thrd;
#if PRH_CONO_DEBUG
    printf("[thrd %02d] cono %02d created by cono %02d\n", prh_thrd_self_id(), callee->cono_id, req_cono->cono_id);
#endif
    prh_relaxed_quefit_push(ready_queue, callee, cono_chain); // 优先调度新建协程
    prh_relaxed_quefit_push(ready_queue, req_cono, cono_chain);
}
#else
void prh_impl_privilege_process_start_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue) {
    prh_real_cono *callee = req_cono;
    prh_impl_cono_init(callee, ++PRH_IMPL_CONO_STRUCT.cono_id_seed); // 初始化新协程
#if PRH_CONO_DEBUG
    printf("[thrd %02d] cono %02d %p created\n", prh_thrd_self_id(), callee->cono_id, (void *)callee);
#endif
    prh_relaxed_quefit_push(ready_queue, callee, cono_chain);
}
#endif

void prh_impl_privilege_await_success(prh_cono_quefit *ready_queue, prh_real_cono *cono, prh_real_cono *callee) {
    cono->callee = callee;
    cono->await = false; // 将结果提交给请求协程，并立即调度其执行
    prh_relaxed_quefit_push(ready_queue, cono, cono_chain);
}

void prh_impl_privilege_process_yield_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue) {
    prh_real_cono *caller = req_cono->caller;
    if (caller) { // 需要提交执行结果给请求协程
        if (caller->await) { // 请求协程正在等待执行结果，且其结果队列为空
            prh_impl_privilege_await_success(ready_queue, caller, req_cono);
        } else { // 将执行协程插入请求协程的结果队列中，等待请求下一次WAIT挂起继续执行
            prh_relaxed_quefit_push(&caller->callee_que, req_cono, cono_chain);
        }
    } else { // 执行协程不需要将结果提交给请求协程，执行结束或者看继续怎么处理
        prh_impl_privilege_process_continue_req(req_cono, ready_queue);
    }
}

void prh_impl_privilege_process_await_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue) {
    prh_real_cono *callee; // 等待执行协程的执行结果
    prh_relaxed_quefit_pop(&req_cono->callee_que, callee, cono_chain);
    if (callee) { // 协程给特权发送消息，都会挂起等待特权调度继续执行，因此协程的请求都是顺序的，对于一个协程不可能同时有多个等待执行的请求存在
        prh_impl_privilege_await_success(ready_queue, req_cono, callee); // 有结果存在，直接交给请求协程继续执行
    } else {
        req_cono->await = true; // 暂时没有执行结果可以处理，等待下一次执行协程的结果
    }
}

prh_inline void prh_impl_privilege_pwait_success(prh_cono_quefit *ready_queue, prh_real_cono *cono) {
    cono->pwait = false; // 将请求数据或执行结果提交给等待协程，并立即调度其执行
    prh_relaxed_quefit_push(ready_queue, cono, cono_chain);
}

void *prh_impl_privilege_receive_pdata(prh_real_cono *cono, prh_byte wait_que) {
    prh_pdata_rxq *post_que = &cono->post_que;
    if (wait_que == 0xff) {
        return prh_arrque_pop(post_que);
    }
    prh_cono_subq *subq = cono->cono_subq + wait_que;
    if (subq->post_count == 0) {
        return prh_null;
    }
    prh_int head = prh_impl_arrque_head_index(post_que);
    for (prh_int i = 0; i < post_que->size; i += 1) {
        void *data = post_que->arrque[head];
        prh_cono_pdata *pdata = (prh_cono_pdata *)(((prh_ptr)data >> 2) << 2);
        if (pdata->subq == subq) {
            assert(pdata->subq->subq_i == wait_que);
            return data;
        }
        head = prh_impl_arrque_npos(post_que, head + 1);
    }
    return prh_null;
}

void prh_impl_privilege_process_pwait_req(prh_real_cono *req_cono, prh_cono_quefit *ready_queue) {
    void *data = prh_impl_privilege_receive_pdata(req_cono, req_cono->wait_que);
    if (data == prh_null) {
        req_cono->pwait = true;
    } else {
        prh_cono_pdata *pdata = (prh_cono_pdata *)(((prh_ptr)data >> 2) << 2);
        prh_cono_subq *subq = pdata->subq;
        assert(subq->cono == req_cono);
        prh_pwait_data *pwait_data = req_cono->pwait_data;
        pwait_data->pdata = pdata;
        pwait_data->subq_i = (prh_byte)subq->subq_i;
        pwait_data->opcode = pdata->opcode[(prh_ptr)data & 0x3];
        prh_impl_privilege_pwait_success(ready_queue, req_cono);
        assert(subq->post_count > 0);
        subq->post_count -= 1;
    }
}

bool prh_impl_privilege_post_data_process(void *priv, void *data) { // 处理各个线程发送给不同协程的数据
    prh_cono_pdata *pdata = (prh_cono_pdata *)(((prh_ptr)data >> 2) << 2);
    prh_cono_subq *subq = pdata->subq;
    prh_real_cono *dest = subq->cono;
    if (dest->pwait && (dest->wait_que == 0xff || dest->wait_que == subq->subq_i)) {
        prh_pwait_data *pwait_data = dest->pwait_data;
        pwait_data->pdata = pdata;
        pwait_data->subq_i = (prh_byte)subq->subq_i;
        pwait_data->opcode = pdata->opcode[(prh_ptr)data & 0x3];
        prh_impl_privilege_pwait_success((prh_cono_quefit *)priv, dest);
    } else {
        dest->subq_push(dest, (prh_cono_pdata *)data);
        subq->post_count += 1;
    }
    return true;
}

bool prh_impl_privilege_yield_state_process(void *priv, void *data) {
    prh_real_cono *req_cono = data;
    prh_cono_quefit *ready_queue = priv;
    assert(req_cono->yield_state < PRH_YIELD_STATE_NUM);
    PRH_IMPL_YIELD_STATE_PROCESS[req_cono->yield_state](req_cono, ready_queue);
    return true;
}

// 当前算法是，特权协程会给所有线程分配一个协程，当线程执行完当前的协程后，会自动继续
// 执行分配的协程，如果线程没有分配到协程，会去抢特权线程执行权，然后如果自己没有分配
// 到任务，会从其他线程争抢一个协程来执行。
//
// 是否可以做成，由线程自己争抢特权只给自己分配协程，这样线程不需要去访问其他线程的内
// 存，内存访问效率会更高。这样线程的逻辑就很简单，能抢到特权就继续执行，然后分发自己
// 线程中的消息，然后给自己分配一个协程执行，抢不到特权就释放当前时间片或主动让出一段
// 时间继续抢，直到抢到一次为止，如果发现没有协程需要处理就进入睡眠。然后将CPU密集型
// 的协程，可以打上一个标记，让主线程监控对应执行线程的执行时间，如果执行时间太长，则
// 每隔规定的时间打断一次，避免其他协程饥饿。（第二版）
//
// 可以让线程的个数为2的幂，协程根据编号始终分配给固定的线程执行。另外还有一个优先协程
// 队列，各个线程都会优先执行自己的优先协程，使用1:1的关系，即先执行一个优先协程再执行
// 一个非优先协程。这样也会减少各线程抢特权的碰撞机会，因为每次线程抢到特权，可以将整个
// 属于自己的协程都拿来执行，包括自己的优先协程，且属于自己的协程可以在对应的线程内分配
// 协程栈。这种情况下，主线程需要高优先级负责，将各线程内的消息及时转发。另外，这种方
// 法导致一个线程中等待的协程饥饿，因为在第二版中，线程总是只执行一个协程，当这个协程
// 执行相对较长时，等待的协程会被其他线程执行。（第三版）

bool prh_impl_privilege_task_v2(prh_cono_thrd *curr_thrd) {
    prh_atom_ptr *privilege_thread = &PRH_IMPL_CONO_STRUCT.privilege_thread;
    prh_cono_quefit *ready_queue = &PRH_IMPL_CONO_STRUCT.ready_queue;
    prh_real_cono *ready_cono;
    bool prev_empty;

    if (!prh_atom_ptr_weak_write_non_null(privilege_thread, curr_thrd)) { // 获取特权
        return false;
    }

    prh_real_cono **grabbed_cono = prh_impl_thrd_grabbed_cono(curr_thrd);
    prev_empty = prh_relaxed_quefit_empty(ready_queue);

    prh_atom_hive_quefix_pops(&curr_thrd->cono_req_que, prh_impl_privilege_yield_state_process, ready_queue);
    prh_atom_hive_quefix_pops(&curr_thrd->post_req_que, prh_impl_privilege_post_data_process, ready_queue);
    *grabbed_cono = prh_null;
    prh_relaxed_quefit_pop(ready_queue, ready_cono, cono_chain);
    *grabbed_cono = ready_cono;

    if (ready_cono && prev_empty && prh_relaxed_quefit_not_empty(ready_queue)) {
        prh_impl_cono_wakeup_all_thrd();
    }

#if PRH_CONO_DEBUG
    if (ready_cono) {
        printf("[thrd %02d] cono %02d grabbed from thrd %d\n", prh_thrd_self_id(), ready_cono->cono_id, prh_thrd_id(curr_thrd));
    }
#endif

    prh_atom_ptr_write(privilege_thread, prh_null); // 释放特权
    return true;
}

bool prh_impl_privilege_task(prh_cono_thrd *curr_thrd, bool strong_check) {
    prh_atom_ptr *privilege_thread = &PRH_IMPL_CONO_STRUCT.privilege_thread;
    prh_cono_quefit *ready_queue = &PRH_IMPL_CONO_STRUCT.ready_queue;
    prh_simple_thrds *thrds = PRH_IMPL_CONO_STRUCT.thrds;
    prh_cono_thrd *main_thrd = (prh_cono_thrd *)prh_simp_thrd_main(thrds);
    prh_real_cono *ready_cono;

    if (!prh_atom_ptr_weak_write_non_null(privilege_thread, curr_thrd)) { // 获取特权
        return false;
    }

    prh_real_cono **grabbed_cono = prh_impl_thrd_grabbed_cono(curr_thrd);
    if (strong_check) {
        *grabbed_cono = prh_null;
        curr_thrd->thrd_pending_work = false;
    }

    prh_thrd *thrd_begin = prh_simp_thrd_begin(thrds);
    prh_thrd *thrd_end = prh_simp_thrd_end(thrds);
    prh_simp_thrd_for_begin(prh_cono_thrd, thrds, thrd_begin, thrd_end) // 处理特权消息，将就绪协程插入就绪队列
        if (it->created == 0) continue; // TODO: 原子访问 created
        prh_atom_hive_quefix_pops(&it->cono_req_que, prh_impl_privilege_yield_state_process, ready_queue);
        prh_atom_hive_quefix_pops(&it->post_req_que, prh_impl_privilege_post_data_process, ready_queue);
    prh_simp_thrd_for_end()

    prh_cono_thrd *thrd_it = (prh_cono_thrd *)thrd_begin;
    for (; ;) { // 将就绪队列中的协程分配给线程执行
        prh_relaxed_quefit_pop(ready_queue, ready_cono, cono_chain);
        if (ready_cono == prh_null) break;
        prh_cono_thrd *thrd = ready_cono->assign_thrd;
        if (thrd && thrd->created && prh_atom_ptr_strong_write_non_null(&thrd->ready_cono, ready_cono)) {
#if PRH_CONO_DEBUG
            printf("[thrd %02d] cono %02d => orig thrd %02d\n", prh_thrd_self_id(), ready_cono->cono_id, prh_thrd_id(thrd));
#endif
            prh_thrd_wakeup(&thrd->cond_sleep);
            continue; // 尽量将协程分配在同一个线程中执行，保证空间访问局部性
        }
        for (; (prh_thrd *)thrd_it < thrd_end; thrd_it = (prh_cono_thrd *)prh_simp_thrd_next(thrds, (prh_thrd *)thrd_it)) { // 将协程分配给空闲线程
            if (thrd_it->created && prh_atom_ptr_strong_write_non_null(&thrd_it->ready_cono, ready_cono)) {
                ready_cono->assign_thrd = thrd_it;
#if PRH_CONO_DEBUG
                printf("[thrd %02d] cono %02d => idle thrd %02d\n", prh_thrd_self_id(), ready_cono->cono_id, prh_thrd_id(thrd_it));
#endif
                prh_thrd_wakeup(&thrd_it->cond_sleep);
                ready_cono = prh_null;
                break;
            }
        }
        if (ready_cono) { // 没有足够的线程处理该协程，将协程重新插入就绪队列，并退出循环
            prh_relaxed_quefit_push_front(ready_queue, ready_cono, cono_chain);
            break;
        }
    }

    if (strong_check && curr_thrd != main_thrd && !curr_thrd->ready_cono) { // 如果当前线程没有分配到协程，从其他线程争抢已分配的协程来执行
        thrd_it = (prh_cono_thrd *)thrd_begin; // 主线程不需要争抢任务，如果就绪队列里面有任务，第一个分配的线程就是主线程，如果就绪队列里已经没有任务了，表示任务都已经分配完毕了，不需要主线程帮忙
        for (; (prh_thrd *)thrd_it < thrd_end; (prh_cono_thrd *)prh_simp_thrd_next(thrds, (prh_thrd *)thrd_it)) {
            if (thrd_it->created && (ready_cono = prh_atom_ptr_read(&thrd_it->ready_cono)) && prh_atom_ptr_weak_write(&thrd_it->ready_cono, (void **)&ready_cono, prh_null)) {
#if PRH_CONO_DEBUG
                printf("[thrd %02d] cono %02d grabbed from thrd %d\n", prh_thrd_self_id(), ready_cono->cono_id, prh_thrd_id(thrd_it));
#endif
                *grabbed_cono = ready_cono; // 不赋值给 curr_thrd->ready_cono 是避免刚抢的协程又被别的线程抢掉
                ready_cono->assign_thrd = curr_thrd;
                break;
            }
        }
    }

    if (strong_check && curr_thrd == main_thrd) {
        if (curr_thrd->ready_cono) {
            curr_thrd->thrd_pending_work = true;
        } else {
            // 如果不进行下面的检查，会发生所有线程都睡眠的情况，例如：
            // 1. 主线程唤醒，抢到特权，将一个子协程分配给第二个线程处理
            // 2. 第二个线程唤醒，处理完这个子协程再睡眠，然后主线程将入口协程分配给第二个线程
            // 3. 第二个线程唤醒，处理入口协程，创建一个新协程到消息队列，因为抢不到特权而睡眠
            // 4. 主线程处理完特权任务后，没有检查各线程中是否还有等待的消息，就退出特权然后睡眠
            // 5. 此时所有线程都睡眠，但线程中还有特处理的消息
            thrd_it = (prh_cono_thrd *)thrd_begin;
            for (; (prh_thrd *)thrd_it < thrd_end; (prh_cono_thrd *)prh_simp_thrd_next(thrds, (prh_thrd *)thrd_it)) { // 查看各线程是否还有遗留的未处理的消息
                if (thrd_it->created && (!prh_atom_hive_quefix_empty(&thrd_it->cono_req_que) || !prh_atom_hive_quefix_empty(&thrd_it->post_req_que))) {
                    curr_thrd->thrd_pending_work = true;
                    break;
                }
            }
        }
    }

    prh_atom_ptr_write(privilege_thread, prh_null); // 释放特权
    return true;
}

void prh_impl_cono_execute(prh_real_cono *cono) {
    prh_coro *coro = prh_impl_coro_from_cono(cono);
    // 继续执行协程，协程每次挂起时都会设置原因（YIELD/AWAIT/PWAIT）
    prh_byte prev_yield_state = cono->yield_state;
    PRH_IMPL_CONO_SELF = cono;
    prh_impl_soro_start(cono->cono_id, coro); // 继续执行当前协程，直到协程再次挂起
    PRH_IMPL_CONO_SELF = prh_null;
    if (prev_yield_state == PRH_CONO_AWAIT) { // 上次挂起之后这次继续执行，是因为等到了子协程的执行结果，此次继续执行需要读取子协程的执行结果，读取完毕之后此次执行过程可以立即调用prh_impl_callee_continue()让子协程继续执行
        prh_impl_callee_continue(cono); // 如果在执行过程中没有调用prh_impl_callee_continue()，这里提供了最后的保底机会继续让协程执行
    }
    // 协程再次挂起，通知特权线程处理挂起的协程，其等待的原因是否可以满足，是否能够继续执行
    prh_impl_send_cono_req(cono, cono->yield_state);
}

int prh_impl_cono_thrd_proc_v2(prh_thrd* thrd) {
    prh_cono_thrd *cono_thrd = (prh_cono_thrd *)thrd;
    prh_atom_bool *term_signal = &PRH_IMPL_CONO_STRUCT.term_signal;
    prh_atom_int *num_sleep = &PRH_IMPL_CONO_STRUCT.num_sleep;
    prh_real_cono **grabbed_cono = prh_impl_thrd_grabbed_cono(cono_thrd);
    prh_debug(int privilege_acquire_count = 0);

    for (; ;) {
        while (!prh_impl_privilege_task_v2(cono_thrd)) { // 至少抢到一次特权
            prh_debug(privilege_acquire_count += 1);
            prh_thrd_sleep(0, 0);
        }
        if (*grabbed_cono) {
            prh_impl_cono_execute(*grabbed_cono);
            continue;
        }
        if (prh_atom_bool_read(term_signal)) {
            if (!prh_thrd_try_sleep(&cono_thrd->cond_sleep)) {
                continue;
            }
            break;
        }
        prh_debug(printf("[thrd %02d] sleep %d\n", prh_thrd_id(thrd), privilege_acquire_count));
        prh_atom_int_inc(num_sleep);
        prh_thrd_cond_sleep(&cono_thrd->cond_sleep);
        prh_atom_int_dec(num_sleep);
        prh_debug(printf("[thrd %02d] wakeup\n", prh_thrd_id(thrd)));
        prh_debug(privilege_acquire_count = 0);
    }

    return 0;
}

int prh_impl_cono_thrd_proc(prh_thrd* thrd) {
    prh_cono_thrd *cono_thrd = (prh_cono_thrd *)thrd;
    prh_cono_thrd *main_thrd = (prh_cono_thrd *)prh_simp_thrd_main(PRH_IMPL_CONO_STRUCT.thrds);
    prh_atom_ptr *thrd_ready_cono = &cono_thrd->ready_cono;
    prh_real_cono **grabbed_cono = prh_impl_thrd_grabbed_cono(cono_thrd);
    prh_real_cono *ready_cono;
    bool req_que_not_empty;
#if PRH_CONO_DEBUG
    int atom_write_succ = 0;
    int atom_write_fail = 0;
#endif

    for (; ;) {
        while ((ready_cono = prh_atom_ptr_read(thrd_ready_cono))) {
label_cont_execute:
            if (prh_atom_ptr_weak_write(thrd_ready_cono, (void **)&ready_cono, prh_null)) {
#if PRH_CONO_DEBUG
                atom_write_succ += 1;
#endif
                prh_impl_cono_execute(ready_cono);
            } else { // 自己的任务可能被别的线程抢掉
#if PRH_CONO_DEBUG
                atom_write_fail += 1;
#endif
                prh_impl_privilege_task(cono_thrd, false);
            }
        }
        if (prh_impl_privilege_task(cono_thrd, true) && *grabbed_cono) {
            prh_impl_cono_execute(*grabbed_cono);
        }
        if ((ready_cono = prh_atom_ptr_read(thrd_ready_cono))) {
            goto label_cont_execute; // 被安排新任务，或在没抢到特权的情况下，可能被其他特权线程安排任务
        }
        // 如果在特权线程处理完待处理消息并将要退出的前一刻，当前线程又向消息队列投递了
        // 消息，此时特权线程包括所有其他线程可能都进入睡眠，遗留一些消息得不到处理，因
        // 此当前线程在睡眠前，必须先检查是否还有消息未处理，有的话就必须保证主线程不能
        // 睡，让主线程兜底，主线程会至少抢到特权一次，保证当前线程调用 prh_thrd_wakeup
        // 之后，主线程至少会最后一次重新检查未处理的消息。
        if ((req_que_not_empty = !prh_atom_hive_quefix_empty(&cono_thrd->cono_req_que))) {
            prh_thrd_wakeup(&main_thrd->cond_sleep);
        }
        if (prh_atom_bool_read(&PRH_IMPL_CONO_STRUCT.term_signal)) {
            if (!prh_thrd_try_sleep(&cono_thrd->cond_sleep)) {
                continue;
            }
            if (req_que_not_empty) {
                continue; // 如果还有消息未处理，不能退出线程
            }
            break;
        }
#if PRH_CONO_DEBUG
        printf("[thrd %02d] sleep %d %d\n", prh_thrd_id(thrd), atom_write_succ, atom_write_fail);
#endif
        prh_thrd_cond_sleep(&cono_thrd->cond_sleep);
#if PRH_CONO_DEBUG
        printf("[thrd %02d] wakeup\n", prh_thrd_id(thrd));
#endif
    }

    return 0;
}

void prh_impl_cono_main_proc_v2(prh_cono_thrd* main_thrd) {
    prh_simple_thrds *thrds = PRH_IMPL_CONO_STRUCT.thrds;
    prh_real_cono **grabbed_cono = prh_impl_thrd_grabbed_cono(main_thrd);
    prh_debug(int privilege_acquire_count = 0);

    for (; ;) {
        while (!prh_impl_privilege_task_v2(main_thrd)) { // 至少抢到一次特权
            prh_debug(privilege_acquire_count += 1);
            prh_thrd_sleep(0, 0);
        }
        if (*grabbed_cono) {
            prh_impl_cono_execute(*grabbed_cono);
            continue;
        }
        if (prh_atom_bool_read(&PRH_IMPL_CONO_STRUCT.term_signal)) {
            if (!prh_thrd_try_sleep(&main_thrd->cond_sleep)) {
                continue;
            }
            prh_simp_thrd_join_except_main(thrds, prh_impl_cono_thrd_free);
#if PRH_CONO_DEBUG
            printf("[thrd %02d] exit\n", prh_thrd_id(main_thrd));
#endif
            break;
        }
        prh_debug(printf("[thrd %02d] sleep %d\n", prh_thrd_id(main_thrd), privilege_acquire_count));
        prh_thrd_cond_sleep(&main_thrd->cond_sleep);
        prh_debug(printf("[thrd %02d] wakeup\n", prh_thrd_id(main_thrd)));
        prh_debug(privilege_acquire_count = 0);
    }
}

void prh_impl_cono_main_proc(prh_cono_thrd* main_thrd) {
    prh_simple_thrds *thrds = PRH_IMPL_CONO_STRUCT.thrds;
    prh_atom_ptr *thrd_ready_cono = &main_thrd->ready_cono;
    prh_real_cono *ready_cono;

    for (; ;) {
        while ((ready_cono = prh_atom_ptr_read(thrd_ready_cono))) {
            if (prh_atom_ptr_weak_write(thrd_ready_cono, (void **)&ready_cono, prh_null)) {
                prh_impl_cono_execute(ready_cono);
            }
            prh_impl_privilege_task(main_thrd, false);
        }
        while (!prh_impl_privilege_task(main_thrd, true)) ; // 为了兜底，主线程必须抢到一次特权
        if (main_thrd->thrd_pending_work) {
            continue;
        }
        if (prh_atom_bool_read(&PRH_IMPL_CONO_STRUCT.term_signal)) {
            if (!prh_thrd_try_sleep(&main_thrd->cond_sleep)) {
                continue;
            }
            prh_simp_thrd_join_except_main(thrds, prh_impl_cono_thrd_free);
#if PRH_CONO_DEBUG
            printf("[thrd %02d] exit\n", prh_thrd_id(main_thrd));
#endif
            break;
        }
#if PRH_CONO_DEBUG
        printf("[thrd %02d] sleep\n", prh_thrd_id(main_thrd));
#endif
        prh_thrd_cond_sleep(&main_thrd->cond_sleep);
#if PRH_CONO_DEBUG
        printf("[thrd %02d] wakeup\n", prh_thrd_id(main_thrd));
#endif
    }
}

void prh_cono_main(int thrd_start_id, int num_thread, prh_conoproc_t main_proc, int stack_size) {
    prh_cono_struct *s = prh_impl_cono_struct_init(thrd_start_id, num_thread, main_proc, stack_size);
    prh_cono_quefit *ready_queue = &s->ready_queue;
    prh_simple_thrds *thrds = s->thrds;
    prh_cono_thrd *main_thrd = (prh_cono_thrd *)prh_simp_thrd_main(thrds);

    // 将入口协程加入就绪队列，程序的执行从入口协程执行开始
    prh_relaxed_quefit_push(ready_queue, s->main_entry_cono, cono_chain);

    for (int i = 0; i < num_thread; i += 1) { // 启动所有线程
        prh_cono_thrd *cono_thrd = prh_simp_thrd_create(thrds);
        prh_impl_cono_thrd_init(cono_thrd);
#if PRH_IMPL_CONO_SCHEDULE_STRATEGY_V2
        prh_simp_thrd_sched(thrds, cono_thrd, prh_impl_cono_thrd_proc_v2, 0);
#else
        prh_simp_thrd_sched(thrds, cono_thrd, prh_impl_cono_thrd_proc, 0);
#endif
    }

#if PRH_IMPL_CONO_SCHEDULE_STRATEGY_V2
    prh_impl_cono_main_proc_v2(main_thrd); // 启动主线程
#else
    prh_impl_cono_main_proc(main_thrd); // 启动主线程
#endif

    prh_impl_cono_struct_free();
}

#else // PRH_IMPL_CONO_SCHEDULE_STRATEGY_V3

typedef struct prh_coro_subq {
    prh_byte subq_i; prh_atom_u16 subq_len;
} prh_coro_subq;

#define PRH_IMPL_SUBQ_PADDING_SIZE (sizeof(void *) / sizeof(prh_coro_subq))

typedef struct { // 协程线程与调度线程共享的协程数据
    prh_atom_thrd_rx_length callee_rx_que_length;
    prh_atom_thrd_rx_length coro_post_que_length;
    prh_coro_subq coro_subq[PRH_IMPL_SUBQ_PADDING_SIZE]; // 需要在 userdata 之前额外保存 prh_real_cono
} prh_share_coro_data;

typedef struct prh_sched_only_data { // 仅由调度线程访问的协程数据
    prh_atom_thrd_rx_producer callee_rx_que_producer;           // +1p  4   8
    prh_atom_thrd_rx_producer coro_post_que_producer;           // +1p  8   16
    prh_atom_thrd_rx_length *callee_rx_que_length;              // +1p  12  24
    prh_atom_thrd_rx_length *coro_post_que_length;              // +1p  16  32
    prh_real_cono *running_thread;                              // +1p  20  40
    struct prh_sched_only_data *caller;                         // +1p  24  48
    bool coro_await, coro_pwait, subq_pwait; prh_byte wait_que; // +1p  28  56
} prh_sched_only_data;

prh_static_assert(prh_offsetof(prh_share_coro_data, coro_subq) == 2 * sizeof(void *));
prh_static_assert(sizeof(prh_share_coro_data) == 3 * sizeof(void *));
prh_static_assert(sizeof(prh_sched_only_data) <= 8 * sizeof(void *));

struct prh_real_cono {
    union { prh_impl_coro coro; prh_byte a[prh_impl_coro_size]; } base; // +16  16  16
    prh_atom_sched_coro_que_consumer callee_rx_que_consumer;            // +1p  20  24
    prh_atom_sched_coro_que_consumer coro_post_que_consumer;            // +1p  24  32
    prh_continue_routine routine_after_yield;                           // +1p  28  40
    prh_u32 wait_callee_count, freed_item_count;                        // +8   36  48
    prh_byte data_offset, subq_num, wait_que, uncond_run, has_caller;   // +*p  44  56
    prh_alignas(PRH_CACHE_LINE_SIZE) prh_sched_only_data sched_only_data;
    prh_alignas(PRH_CACHE_LINE_SIZE) prh_share_coro_data share_coro_data;
};

#define prh_impl_cono_fixed_size (PRH_CACHE_LINE_SIZE * 3)
#define prh_impl_cono_fixed_extend_size (prh_impl_cono_fixed_size - prh_impl_coro_size)
#define prh_impl_cono_waited_callee(cono) (cono)->base.coro.userdata
prh_static_assert(prh_offsetof(prh_real_cono, callee_rx_que_consumer) == prh_impl_coro_size);
prh_static_assert(prh_offsetof(prh_real_cono, sched_only_data) == 64);
prh_static_assert(prh_offsetof(prh_real_cono, share_coro_data) == 128);
prh_fastcall(void) prh_impl_asm_cono_call(void);

prh_inline prh_real_cono *prh_impl_cono_from_spawn_data(void *spawn_data) {
    return *(prh_real_cono **)((void **)spawn_data - 1);
}

prh_inline void *prh_impl_spawn_data_from_cono(prh_real_cono *cono) {
    return (prh_byte *)cono + cono->data_offset * PRH_CACHE_LINE_SIZE;
}

prh_inline prh_real_cono *prh_impl_cono_from_sched_only_data(prh_sched_only_data *sched_only_data) {
    return (prh_real_cono *)((prh_byte *)sched_only_data - prh_offsetof(prh_real_cono, sched_only_data));
}

prh_inline prh_sched_only_data *prh_impl_sched_only_data_from_subq(prh_coro_subq *coro_subq) {
    return (prh_sched_only_data *)((prh_byte *)(coro_subq - coro_subq->subq_i) - prh_offsetof(prh_share_coro_data, share_coro_data.coro_subq) - PRH_CACHE_LINE_SIZE);
}

int prh_impl_cono_extend_size(prh_byte subq_num) {
    int share_coro_data_size = (int)(sizeof(prh_share_coro_data) + subq_num * sizeof(prh_coro_subq));
    if (share_coro_data_size <= PRH_CACHE_LINE_SIZE) return prh_impl_cono_fixed_extend_size;
    int exceeded_size = share_coro_data_size - PRH_CACHE_LINE_SIZE;
    return prh_impl_cono_fixed_extend_size + (int)prh_round_cache_line_size(exceeded_size);
}

int prh_impl_cono_struct_size(prh_byte subq_num) {
    int share_coro_data_size = (int)(sizeof(prh_share_coro_data) + subq_num * sizeof(prh_coro_subq));
    if (share_coro_data_size <= PRH_CACHE_LINE_SIZE) return prh_impl_cono_fixed_size;
    int exceeded_size = share_coro_data_size - PRH_CACHE_LINE_SIZE;
    return prh_impl_cono_fixed_size + (int)prh_round_cache_line_size(exceeded_size);
}

// 当 start 一个需要 await_cono_yield 的子协程时，caller 协程需要创建 callee_rx_que
void prh_impl_sched_thrd_init_callee_rx_que(prh_real_cono *cono) {
    prh_atom_thrd_rx_producer *p = &cono->sched_only_data.callee_rx_que_producer;
    if (p->tail_block_tail_item == prh_null) {
        void **block = (void **)prh_impl_atom_queue_get_block(prh_null, PRH_SCHED_CORO_RX_BLOCK_SIZE);
        cono->callee_rx_que_consumer.head_block_head_item = p->tail_block_tail_item = block;
    }
}

// 当 spwan 一个拥有 subq 的协程时，该协程需要创建 coro_post_que
void prh_impl_sched_thrd_init_coro_post_que(prh_real_cono *cono) {
    prh_atom_thrd_rx_producer *p = &cono->sched_only_data.coro_post_que_producer;
    if (p->tail_block_tail_item == prh_null) {
        void **block = (void **)prh_impl_atom_queue_get_block(prh_null, PRH_SCHED_CORO_RX_BLOCK_SIZE);
        cono->coro_post_que_consumer.head_block_head_item = p->tail_block_tail_item = block;
    }
}

void prh_impl_cono_init(prh_real_cono *cono, prh_byte subq_num) {
    prh_share_coro_data *share_coro_data = &cono->share_coro_data;
    prh_atom_thrd_rx_length *callee_rx_que_length = &share_coro_data->callee_rx_que_length;
    prh_atom_thrd_rx_length *coro_post_que_length = &share_coreo_data->coro_post_que_length;
    prh_atom_int_init(&callee_rx_que_length->queue_length, 0);
    prh_atom_int_init(&coro_post_que_length->queue_length, 0);
    prh_coro_subq *coro_subq = share_coro_data->coro_subq;
    for (int i = 0; i < subq_num; i += 1) {
        coro_subq[i].subq_i = i;
        prh_atom_u16_init(&coro_subq[i].subq_len, 0);
    }

    prh_sched_only_data *sched_only_data = &cono->sched_only_data;
    sched_only_data->callee_rx_que_length = callee_rx_que_length;
    sched_only_data->coro_post_que_length = coro_post_que_length;
    // coro_size 和 data_size 都已初始化为零
    cono->subq_num = subq_num;
}

void prh_impl_cono_free(prh_real_cono *cono) {
    prh_atom_sched_coro_que_free(&cono->callee_rx_que_consumer);
    prh_atom_sched_coro_que_free(&cono->coro_post_que_consumer);
}

void prh_impl_cono_reset(prh_real_cono *cono, prh_conoproc_t proc) {
    prh_byte subq_num = cono->subq_num, data_offset = cono->data_offset;
    memset((prh_byte *)cono + prh_impl_coro_size, 0, prh_impl_cono_extend_size(subq_num));
    prh_impl_coro_load_stack(coro, (prh_ptr)proc, (prh_ptr)prh_impl_asm_cono_call);
    prh_impl_cono_init(cono, subq_num);
    cono->data_offset = data_offset;
}

void prh_atom_sched_coro_que_push_callee(prh_sched_only_data *sched_only_data, void *callee) {
    prh_atom_thrd_rx_producer *p = &sched_only_data->callee_rx_que_producer;
    *p->tail_block_tail_item = callee;
    prh_impl_atom_sched_coro_que_push_end(p, sched_only_data->callee_rx_que_length, 1);
}

// 不好为每个子队列都维护一个链表，因为必须为每个子队列预先都分配一个头节点，且每个子队列都必须保存一个头节点和尾节点成员以及长度
// 浪费空间，而且可能用处不大，因为只在一些特殊的情况下才专门去等待特定的子队列，这些情况对应子队列都会很快投递消息，即使线性查找也不会花太多时间
void prh_atom_sched_coro_que_push_post(prh_coro_subq *coro_subq, prh_ptr post_data) {
    prh_sched_only_data *sched_only_data = prh_impl_sched_only_data_from_subq(coro_subq);
    prh_atom_thrd_rx_producer *p = &sched_only_data->coro_post_que_producer;
    prh_coro_post_item *tail = (prh_coro_post_item *)p->tail_block_tail_item;
    tail->bytes[prh_impl_sched_coro_post_flag_field] = PRH_IMPL_SCHED_CORO_SUBQ_POST_FLAG;
    tail->bytes[prh_impl_sched_coro_post_subq_i_field] = coro_subq->subq_i;
    tail->post_data = post_data; assert(((prh_ptr)*(void **)tail) & PRH_IMPL_SCHED_CORO_SUBQ_POST_FLAG);
    prh_impl_atom_sched_coro_que_push_end(p, sched_only_data->coro_post_que_length, 2);
    prh_atom_u16_inc(&coro_subq->subq_len); // 此步骤执行完毕以上更新必须对消费者cpu生效
}

prh_real_cono *prh_atom_sched_coro_que_pop_callee(prh_real_cono *cono) {
    prh_atom_thrd_rx_consumer *c = &cono->callee_rx_que_consumer;
    prh_atom_thrd_rx_length *l = &cono->share_coro_data.callee_rx_que_length;
    prh_real_cono **callee = (void **)prh_atom_thrd_que_pop_begin((prh_atom_thrd_que_consumer *)c, (prh_atom_thrd_que_length *)l);
    if (*callee == prh_null) return prh_null;
    prh_atom_thrd_que_pop_end((prh_atom_thrd_que_consumer *)c, (prh_atom_thrd_que_length *)l, 1, prh_impl_atom_sched_coro_que_free_block);
    return *callee;
}

void prh_impl_atom_sched_coro_que_pop_head_items(prh_real_cono *cono, prh_atom_thrd_rx_length *l) {
    prh_atom_sched_coro_que_consumer *c = &cono->coro_post_que_consumer;
    prh_atom_thrd_que_pop_end((prh_atom_thrd_que_consumer *)c, (prh_atom_thrd_que_length *)l, 2, prh_impl_atom_sched_coro_que_free_block);
    while (cono->freed_item_count && c->head_block_head_item[0] == PRH_ATOM_DYNQUE_ITEM_FREE) {
        cono->freed_item_count -= 1;
        prh_atom_thrd_que_pop_end((prh_atom_thrd_que_consumer *)c, prh_null, 2, prh_impl_atom_sched_coro_que_free_block);
    }
}

bool prh_atom_sched_coro_que_pop_post(prh_real_cono *cono, prh_pwait_data *data) {
    prh_atom_thrd_rx_consumer *c = &cono->coro_post_que_consumer;
    prh_atom_thrd_rx_length *l = &cono->share_coro_data.coro_post_que_length;
    prh_coro_post_item *coro_post = prh_atom_thrd_que_pop_begin((prh_atom_thrd_que_consumer *)c, (prh_atom_thrd_que_length *)l);
    if (coro_post == prh_null) return false;
    prh_byte subq_i = coro_post->bytes[prh_impl_sched_coro_post_subq_i_field];
    data->subq_i = subq_i; data->post_data = coro_post->post_data;
    data->opcode = coro_post->bytes[prh_impl_sched_coro_post_opcode_field]; assert(subq_i < cono->subq_num);
    prh_coro_subq *coro_subq = cono->share_coro_data.coro_subq + subq_i; assert(subq_i == coro_subq->subq_i);
    prh_impl_atom_sched_coro_que_pop_head_items(cono, l); assert(prh_atom_u16_read(&coro_subq->subq_len) > 0);
    prh_atom_u16_dec(&coro_subq->subq_len); // 此步骤执行完毕以上更新必须对生产者cpu生效
    return true;
}

prh_coro_post_item *prh_impl_atom_sched_coro_que_find_post(prh_coro_post_item *coro_post, prh_int total_posts, prh_byte subq_i) {
    for (coro_post += 1; --total_posts > 0; coro_post += 1) {
        if (*(void **)coro_post == PRH_ATOM_DYNQUE_BLOCK_END) {
            coro_post = *((void **)coro_post + 1);
        }
        if (coro_post->bytes[prh_impl_sched_coro_post_subq_i_field] == subq_i) {
            return coro_post;
        }
    }
    prh_impl_abort(__LINE__); // subq_len 大于零，必须存在对应的消息
    return prh_null;
}

bool prh_atom_sched_coro_que_ext_pop_post(prh_real_cono *cono, prh_byte subq_i, prh_pwait_data *data) {
    assert(subq_i < cono->subq_num);
    prh_coro_subq *coro_subq = cono->share_coro_data.coro_subq + subq_i;
    assert(subq_i == coro_subq->subq_i);
    if (!prh_atom_u16_read(&coro_subq->subq_len)) return false;
    prh_coro_post_item *coro_post = cono->coro_post_que_consumer.head_block_head_item;
    prh_atom_thrd_rx_length *l = &cono->share_coro_data.coro_post_que_length;
    assert(prh_atom_int_read(&l->queue_length) > 0);
    if (coro_post->bytes[prh_impl_sched_coro_post_subq_i_field] == subq_i) {
        data->post_data = coro_post->post_data;
        data->opcode = coro_post->bytes[prh_impl_sched_coro_post_opcode_field];
        prh_impl_atom_sched_coro_que_pop_head_items(cono, l);
    } else {
        coro_post = prh_impl_atom_sched_coro_que_find_post(coro_post, prh_atom_int_read(&l->queue_length), subq_i);
        data->post_data = coro_post->post_data;
        data->opcode = coro_post->bytes[prh_impl_sched_coro_post_opcode_field];
        *(void **)coro_post = PRH_ATOM_DYNQUE_ITEM_FREE;
        cono->freed_item_count += 1;
        prh_atom_int_dec(&l->queue_length);
    }
    data->subq_i = subq_i;
    prh_atom_u16_dec(&coro_subq->subq_len); // 此步骤执行完毕以上更新必须对生产者cpu生效
    return true;
}

prh_coro *prh_impl_cono_create(prh_conoproc_t proc, int stack_size, int maxudsize, int subq_num) {
    int cono_extend_size = prh_impl_cono_extend_size(subq_num);
    void *coro_stack = prh_cache_line_aligned_malloc(prh_impl_coro_cache_line_aligned_alloc_size(stack_size, cono_extend_size, maxudsize));
    prh_coro *coro = prh_impl_coro_cache_line_aligned_init(coro_stack, stack_size, cono_extend_size, maxudsize);
    prh_impl_coro_load_stack(coro, (prh_ptr)proc, (prh_ptr)prh_impl_asm_cono_call);
    void *userdata = coro->userdata;
#if PRH_DEBUG
    char *rsp = (char *)coro - prh_impl_asm_stack_init_depth();
    struct prh_impl_coro_guard *guard = prh_impl_coro_guard(coro);
    printf("[cono   ] %p create -- lower %p (left %d) rsp %p coro %p (size %d) data %p (size %d) -- stack %d\n",
        (void *)coro, (void *)guard, (int)(rsp - (char *)(guard + 1)), (void *)rsp,
        (void *)coro, (prh_impl_coro_size + cono_extend_size), userdata, (int)prh_round_cache_line_size(maxudsize), stack_size);
#endif
    *((void **)((void **)userdata - 1)) = coro;
    int times_of_cache_line_size = prh_impl_cono_struct_size(subq_num) / PRH_CACHE_LINE_SIZE;
    ((prh_real_cono *)coro)->data_offset = (prh_byte)times_of_cache_line_size; assert(times_of_cache_line_size <= 255);
    return coro;
}

void *prh_cono_spawn(prh_conoproc_t proc, int stack_size, int maxudsize) {
    prh_coro *coro = prh_impl_cono_create(proc, stack_size, maxudsize, 0);
    void *userdata = coro->userdata;
    prh_impl_cono_init((prh_real_cono *)coro, 0);
    prh_impl_cono_waited_callee((prh_real_cono *)coro) = prh_null;
    return userdata;
}

void *prh_cono_ext_spawn(prh_conoproc_t proc, int stack_size, int maxudsize, prh_byte subq_num) {
    prh_coro *coro = prh_impl_cono_create(proc, stack_size, maxudsize, subq_num);
    void *userdata = coro->userdata;
    prh_impl_cono_init((prh_real_cono *)coro, subq_num);
    prh_impl_cono_waited_callee((prh_real_cono *)coro) = prh_null;
    return userdata;
}

void prh_impl_cono_execute(void *post_req) {
    prh_real_cono *cono = (prh_real_cono *)post_req;
    PRH_IMPL_CONO_SELF = cono; // 继续执行协程，协程只有三种挂起原因（YIELD/AWAIT/PWAIT）
    prh_impl_soro_start(cono->cono_id, prh_impl_coro_from_cono(cono)); // 继续执行当前协程，直到协程再次挂起
    PRH_IMPL_CONO_SELF = prh_null;
    cono->routine_after_yield(post_ptr);
}

prh_inline bool prh_impl_cono_finished(prh_real_cono *cono) {
    return cono->head.coro.rspoffset == 0;
}

bool prh_impl_cono_continue_process(prh_real_cono *req_cono) {
    bool coro_continue_run = false;
    if (prh_impl_cono_finished(req_cono)) {
        if (req_cono == PRH_IMPL_CONO_STRUCT.main_entry_cono) {
            prh_impl_cono_term_signal();
        } else {
#if PRH_CONO_DEBUG
            printf("[thrd %02d] cono %p finished\n", prh_thrd_self_id(), req_cono);
#endif
            prh_impl_cono_free(req_cono);
        }
    } else if (req_cono->uncond_run) { // 无条件执行
        prh_iocp_thrd_post(req_cono, prh_impl_cono_execute);
        coro_continue_run = true;
    } else {
        prh_abort_error(__LINE__); // 子协程提交执行结果后要么执行完毕，要么无条件继续执行
    }
    return coro_continue_run;
}

void prh_impl_callee_continue(prh_real_cono *caller) {
    prh_real_cono *callee = prh_impl_cono_waited_callee(caller);
    prh_impl_cono_waited_callee(caller) = prh_null;
    if (prh_impl_cono_continue_process(callee)) {
        caller->wait_callee_count += 1;
    }
}

bool prh_impl_cono_sched_thrd_synced_init_caller_and_execute(prh_iocp_thrd_req *thrd_req) {
    prh_real_cono *caller = (prh_real_cono *)thrd_req->post_req;
    prh_impl_sched_thrd_init_callee_rx_que(caller);
    thrd_req->continue_routine = prh_impl_cono_execute;
    return true;
}

bool prh_impl_cono_sched_thrd_synced_init_callee_and_execute(prh_iocp_thrd_req *thrd_req) {
    prh_real_cono *callee = (prh_real_cono *)thrd_req->post_req;
    prh_impl_sched_thrd_init_coro_post_que(callee);
    thrd_req->continue_routine = prh_impl_cono_execute;
    return true;
}

void prh_impl_cono_begin_caller_yield_callee_run(void *post_req) {
    prh_real_cono *caller = (prh_real_cono *)post_req;
    prh_real_cono *callee = prh_impl_cono_waited_callee(caller);
    prh_impl_cono_waited_callee(caller) = prh_null; // 清除临时保存的 callee
    prh_iocp_thrd_post(caller, prh_impl_cono_execute);
    prh_sched_thrd_synced_post(caller, prh_impl_cono_sched_thrd_synced_init_caller_and_execute);
    prh_impl_cono_execute(callee); // 当前协程线程立即执行 callee
}

void prh_cono_start(prh_spawn_data *cono_spawn_data, bool await_cono_yield) {
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    prh_real_cono *callee = prh_impl_cono_from_spawn_data(cono_spawn_data);
#if PRH_CONO_DEBUG
    prh_u32 coro_id = prh_atom_u32_fetch_inc(PRH_IOCP_SHARED_GLOBAL.cono_id_seed) + 1;
    printf("[thrd %02d] cono %p create callee %02d %p\n", prh_thrd_self_id(), caller, coro_id, callee);
#endif
    if (await_cono_yield && callee->subq_num == 0) { // 当创建的 callee 有自己的 subq 时，一般不需要挂起才能传递执行结果，因为它可以通过 subq 实时传递结果，不需要暂停
        callee->has_caller = true;
        callee->sched_only_data.caller = &caller->sched_only_data; // 保证调度线程只访问 sched_only_data 部分的数据
        prh_impl_cono_waited_callee(caller) = callee; // 临时保存 callee
        caller->wait_callee_count += 1;
        caller->routine_after_yield = prh_impl_cono_begin_caller_yield_callee_run;
        prh_soro_yield((prh_soro *)caller);
    } else if (callee->subq_num) { // 当创建一个拥有 subq 的协程时，该协程需要创建 coro_post_que
        prh_sched_thrd_synced_post(callee, prh_impl_cono_sched_thrd_synced_init_callee_and_execute); // 继续执行当前协程，新创建的 callee 协程让其他线程执行
    } else { // 继续执行当前协程，新创建的 callee 协程让其他线程执行
        prh_iocp_thrd_post(callee, prh_impl_cono_execute);
    }
}

bool prh_impl_cono_sched_thrd_synced_yield_req(prh_iocp_thrd_req *thrd_req) {
    prh_real_cono *callee = (prh_real_cono *)thrd_req->post_req; // 保证调度线程只访问 sched_only_data 部分的数据
    assert(callee->sched_only_data.caller != prh_null);
    prh_sched_only_data *caller = callee->sched_only_data.caller;
    prh_atom_sched_coro_que_push_callee(caller, callee);
    if (caller->coro_await) {
        caller->coro_await = false;
        thrd_req->post_req = prh_impl_cono_from_sched_only_data(caller);
        thrd_req->continue_routine = prh_impl_cono_execute;
        return true; // 让等到 callee 的 caller 协程继续执行
    }
    return false; // caller 没有在等待，callee 插入到 callee_rx_que 之后无需做其他事
}

void prh_impl_cono_begin_yield_req(void *post_req) {
    prh_real_cono *callee = (prh_real_cono *)post_req;
    if (callee->has_caller) { // 需要提交执行结果给请求协程
        prh_sched_thrd_synced_post(callee, prh_impl_cono_sched_thrd_synced_yield_req);
    } else { // 执行协程不需要将结果提交给请求协程，执行结束或者看继续怎么处理
        prh_impl_cono_continue_process(callee);
    }
}

void prh_impl_cross_thread_coro_yield(prh_real_cono *cono) {
    cono->routine_after_yield = prh_impl_cono_begin_yield_req;
}

prh_fastcall(void *) prh_impl_asm_cono_finish(prh_coro *coro) {
    prh_impl_cross_thread_coro_yield((prh_real_cono *)coro);
    return prh_impl_asm_soro_finish(coro);
}

prh_inline bool prh_impl_sched_thrd_caller_rx_que_empty(prh_sched_only_data *sched_only_data) {
    return prh_atom_int_read(sched_only_data->callee_rx_que_length) <= 0;
}

prh_inline bool prh_impl_sched_thrd_coro_post_que_empty(prh_sched_only_data *sched_only_data) {
    return prh_atom_int_read(sched_only_data->coro_post_que_length) <= 0;
}

prh_inline bool prh_impl_sched_thrd_one_coro_subq_empty(prh_coro_subq *coro_subq) {
    return prh_atom_u16_read(&coro_subq->subq_len) == 0;
}

bool prh_impl_cono_sched_thrd_synced_await_req(prh_iocp_thrd_req *thrd_req) {
    prh_real_cono *caller = (prh_real_cono *)thrd_req->post_req;
    prh_sched_only_data *sched_only_data = &caller->sched_only_data;
    if (prh_impl_sched_thrd_caller_rx_que_empty(sched_only_data)) {
        sched_only_data->coro_await = true; // 暂时没有执行结果可以处理，等待下一次执行协程的结果
        return false;
    }
    thrd_req->continue_routine = prh_impl_cono_execute;
    return true; // 已经有待处理的 callee，让 caller 继续执行
}

void prh_impl_cono_begin_await_req(void *caller) {
    prh_sched_thrd_synced_post(caller, prh_impl_cono_sched_thrd_synced_await_req);
}

void *prh_cono_await(void) {
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    if (prh_impl_cono_waited_callee(caller)) { // 上次挂起之后此次继续执行，是因为等到了子协程的执行结果，这里子协程的执行结果已经处理完毕
        prh_impl_callee_continue(caller); // 这里继续调用 await 等待新的子协程执行结果，旧的子协程可以继续执行
    }
    if (caller->wait_callee_count <= 0) {
        return prh_null; // 所有 callee 都处理完毕，不必继续等待
    }
    prh_real_cono *callee = prh_atom_sched_coro_que_pop_callee(caller);
    if (callee == prh_null) {
        cono->routine_after_yield = prh_impl_cono_begin_await_req;
        prh_soro_yield((prh_soro *)caller);
        callee = prh_atom_sched_coro_que_pop_callee(caller);
        prh_real_assert(callee != prh_null);
    }
    prh_impl_cono_waited_callee(caller) = callee;
    caller->wait_callee_count -= 1;
    return prh_impl_spawn_data_from_cono(callee);
}

bool prh_impl_sched_thrd_dispatch_coro_post(prh_iocp_thrd_req *thrd_req) {
    prh_coro_subq *coro_subq = ((prh_coro_thrd_req *)thrd_req)->coro_subq;
    prh_atom_sched_coro_que_push_post(coro_subq, ((prh_coro_thrd_req *)thrd_req)->post_data);
    prh_sched_only_data *sched_only_data = prh_impl_sched_only_data_from_subq(coro_subq);
    if (sched_only_data->coro_pwait) {
        sched_only_data->coro_pwait = false;
    } else if (sched_only_data->subq_pwait && sched_only_data->wait_que == coro_subq->subq_i) {
        sched_only_data->subq_pwait = false;
    } else { // 协程没有在等待，任务投递到队列之后无需做其他事
        return false;
    }
    thrd_req->post_req = prh_impl_cono_from_sched_only_data(sched_only_data);
    thrd_req->continue_routine = prh_impl_cono_execute;
    return true; // 让等到任务的协程继续执行
}

void prh_cono_post(prh_coro_subq *coro_subq, void *post_data, prh_byte opcode) {
    prh_coro_thrd_post(coro_subq, post_data, opcode);
}

bool prh_impl_cono_sched_thrd_synced_pwait_req(prh_iocp_thrd_req *thrd_req) {
    prh_real_cono *caller = (prh_real_cono *)thrd_req->post_req;
    prh_sched_only_data *sched_only_data = &caller->sched_only_data;
    if (prh_impl_sched_thrd_coro_post_que_empty(sched_only_data)) {
        sched_only_data->coro_pwait = true; // 暂时没有任务可以处理，等待后续任务的投递
        return false;
    }
    thrd_req->continue_routine = prh_impl_cono_execute;
    return true; // 已经有待处理的任务，让 caller 继续执行
}

void prh_impl_cono_begin_pwait_req(void *caller) {
    prh_sched_thrd_synced_post(caller, prh_impl_cono_sched_thrd_synced_pwait_req);
}

void prh_impl_cono_pwait_data(prh_real_cono *caller, prh_pwait_data *data) {
    if (!prh_atom_sched_coro_que_pop_post(caller, data)) {
        cono->routine_after_yield = prh_impl_cono_begin_pwait_req;
        prh_soro_yield((prh_soro *)caller);
    }
    if (!prh_atom_sched_coro_que_pop_post(caller, data)) {
        prh_impl_abort(__LINE__);
    }
}

bool prh_impl_cono_sched_thrd_synced_subq_pwait_req(prh_iocp_thrd_req *thrd_req) {
    prh_real_cono *caller = (prh_real_cono *)thrd_req->post_req;
    prh_sched_only_data *sched_only_data = &caller->sched_only_data;
    prh_byte wait_que = thrd_req->opcode;
    if (prh_impl_sched_thrd_one_coro_subq_empty(caller->share_coro_data.coro_subq + wait_que)) {
        sched_only_data->subq_pwait = true; // 子队列中暂时没有任务可以处理，等待后续任务的投递
        sched_only_data->wait_que = wait_que;
        return false;
    }
    thrd_req->continue_routine = prh_impl_cono_execute;
    return true; // 已经有待处理的 callee，让 caller 继续执行
}

void prh_impl_cono_begin_subq_pwait_req(void *caller) {
    prh_sched_thrd_synced_ext_post(caller, prh_impl_cono_sched_thrd_synced_subq_pwait_req, caller->wait_que);
}

void prh_impl_cono_ext_pwait_data(prh_real_cono *caller, prh_byte subq_i, prh_pwait_data *data) {
    if (!prh_atom_sched_coro_que_ext_pop_post(caller, subq_i, data)) {
        caller->wait_que = subq_i;
        cono->routine_after_yield = prh_impl_cono_begin_subq_pwait_req;
        prh_soro_yield((prh_soro *)caller);
    }
    if (!prh_atom_sched_coro_que_ext_pop_post(caller, subq_i, data)) {
        prh_impl_abort(__LINE__);
    }
}

prh_pwait_data prh_cono_ext_pwait(int subq_i) {
    prh_real_cono *caller = PRH_IMPL_CONO_SELF;
    prh_pwait_data data;
    if (subq_i == -1) {
        prh_impl_cono_pwait_data(caller, &data);
    } else {
        assert(subq_i >= 0 && subq_i < caller->subq_num);
        prh_impl_cono_ext_pwait_data(caller, (prh_byte)subq_i, &data);
    }
    return data;
}

prh_pwait_data prh_cono_pwait(void) {
    return prh_cono_ext_pwait(-1);
}

#endif // PRH_IMPL_CONO_SCHEDULE_STRATEGY_V3

#ifdef PRH_TEST_IMPLEMENTATION
void prh_impl_cono_test(void) {

}
#endif // PRH_TEST_IMPLEMENTATION
#endif // PRH_CONO_IMPLEMENTATION
#endif // PRH_CONO_INCLUDE

#ifdef PRH_FILE_INCLUDE

#ifdef PRH_FILE_IMPLEMENTATION
#if defined(prh_plat_windows)

#else
// 所有执行 I/O 操作的系统调用都以文件描述符，一个非负整数，来指代打开的文件。文件描述符
// 可以表示所有类型的已打开文件，包括管道（pipe）、FIFO、套接字、终端、设备、普通文件。
// 文件描述符的分配基于进程，不同的进程对文件描述符的分配互不干扰。有三个始终打开的文件描
// 述符 0 1 2，分别表示标准输入（STDIN_FILENO）、表示输出（STDOUT_FILENO）、错误输出
// （STDERR_FILENO）。更确切的说，每个程序都继承了 shell 文件描述符的副本，在程序执行
// 之前，shell 代表这个程序为其打开了这3各文件描述符。在 shell 的日常交互中，这3个文件
// 描述符是始终打开的，这3个文件描述符通常执行 shell 运行所在的终端。这3个文件描述符可以
// 对其进行重定向。可以使用 0 1 2 来代表这 3 个文件描述符，但是例如使用 freopen 对标准
// 输出 stdout 进行重定向，无法保证 stdout 变量值仍然为 1。另外如果关闭了 0 1 2 文件
// 描述符，在创建新的文件描述符时会重用这些已经释放的文件描述符。
//
// O_DIRECT 标志可能会对用户空间缓冲区的长度和地址以及 I/O 的文件偏移量施加对齐限制。在
// Linux 中，对齐限制因文件系统和内核版本而异，甚至可能完全不存在。对未对齐的 O_DIRECT
// I/O 的处理方式也各不相同；它们可能会因 EINVAL 错误而失败，或者回退到缓冲 I/O。
// 自 Linux 6.1 起，可以使用 statx(2) 和 STATX_DIOALIGN 标志查询文件的 O_DIRECT 支持
// 和对齐限制。对 STATX_DIOALIGN 的支持因文件系统而异；请参见 statx(2)。某些文件系统提
// 供了自己的接口来查询 O_DIRECT 对齐限制，例如 xfsctl(3) 中的 XFS_IOC_DIOINFO 操作。
// 应尽量使用 STATX_DIOALIGN，只要它可用。如果以上方法均不可用，则只能根据文件系统的已知
// 特性、单个文件、底层存储设备以及内核版本来假设直接 I/O 支持和对齐限制。在 Linux 2.4
// 中，基于块设备的大多数文件系统要求文件偏移量以及所有 I/O 段的长度和内存地址都是文件系
// 统块大小的倍数（通常是 4096 字节）。在 Linux 2.6.0 中，这一限制放宽到了块设备的逻辑
// 块大小（通常是 512 字节）。可以通过 ioctl(2) 的 BLKSSZGET 操作或在 shell 中使用以下
// 命令来确定块设备的逻辑块大小：sudo blockdev --getss /dev/sda 。
//
// 不应在 fork(2) 系统调用期间并行执行 O_DIRECT I/O，如果内存缓冲区是私有映射（即使用
// mmap(2) 的 MAP_PRIVATE 标志创建的映射；这包括在堆上分配的内存和静态分配的缓冲区）。
// 无论是通过异步 I/O 接口提交的，还是由进程中的其他线程执行的，所有此类 I/O 都应在调用
// fork(2) 之前完成。未能做到这一点可能会导致父进程和子进程中出现数据损坏和未定义行为。
// 如果 O_DIRECT I/O 的内存缓冲区是使用 shmat(2) 或带有 MAP_SHARED 标志的 mmap(2)
// 创建的，则此限制不适用。同样，如果使用 madvise(2) 将内存缓冲区标记为 MADV_DONTFORK，
// 确保它在 fork(2) 之后不会被子进程使用，此限制也不适用。
//
// O_DIRECT 标志最初是在 SGI IRIX 中引入的，它在 IRIX 中的对齐限制与 Linux 2.4 类似。
// IRIX 还有一个 fcntl(2) 调用来查询适当的对齐方式和大小。FreeBSD 4.x 引入了一个同名的
// 标志，但没有对齐限制。Linux 2.4.10 添加了对 O_DIRECT 的支持。较旧的 Linux 内核会忽
// 略此标志。某些文件系统可能未实现该标志，在这种情况下，如果使用了该标志，open() 将因
// EINVAL 错误而失败。
//
// 应用程序应避免对同一文件混合使用 O_DIRECT 和普通 I/O，尤其是对同一文件中重叠的字节区
// 域。即使文件系统在这种情况下正确处理了一致性问题，整体 I/O 吞吐量也可能会比单独使用任
// 何一种模式都要慢。同样，应用程序应避免将文件的 mmap(2) 与对同一文件的直接 I/O 混合使
// 用。
//
// O_DIRECT 与 NFS 的行为将与本地文件系统不同。较旧的内核，或者以某些方式配置的内核，可
// 能不支持这种组合。NFS 协议不支持将该标志传递给服务器，因此 O_DIRECT I/O 只会在客户端
// 绕过页面缓存；服务器可能仍然会缓存 I/O。客户端会要求服务器使 I/O 同步，以保留 O_DIRECT
// 的同步语义。在这种情况下，某些服务器的性能可能会很差，尤其是当执行小 I/O 操作时。某些
// 服务器还可以配置为对客户端撒谎，声称 I/O 已到达稳定存储；这将避免性能损失，但可能会在
// 服务器断电时对数据完整性带来一定风险。Linux NFS 客户端对 O_DIRECT I/O 没有任何对齐
// 限制。总之，O_DIRECT 是一个潜在的强大工具，应谨慎使用。建议应用程序将 O_DIRECT 的使
// 用视为一个默认禁用的性能选项。
#endif // POSIX IMPLEMENTATION
#ifdef PRH_TEST_IMPLEMENTATION

#endif // PRH_TEST_IMPLEMENTATION
#endif // PRH_FILE_IMPLEMENTATION
#endif // PRH_FILE_INCLUDE

#ifdef PRH_SOCK_INCLUDE
#define prh_port_any ((prh_u16)0)
#define prh_loopback ((char *)0)
#define prh_addr_any ((char *)1)
#define prh_ipv6_loopback ((char *)2)
#define prh_ipv6_addr_any ((char *)3)
#define PRH_IPV4_BYTE_ARRAY 0x10000000 // prh_byte ipv4[4] = {127, 0, 0, 1};
#define PRH_IPV6_BYTE_ARRAY 0x20000000 // prh_byte ipv6[16] = { ... };
#define PRH_IMPL_TXRX_BYTES 0x7ffff000 // Linux

#define PRH_ERROR       0xE0
#define PRH_ETIMEOUT    0xE1
#define PRH_EREFUSED    0xE2
#define PRH_EUNREACH    0xE3
#define PRH_EUNAVAIL    0xE4
#define PRH_ENOTSUPP    0xE5
#define PRH_ENAMERES    0xE6

#define PRH_AF_IPV4 0
#define PRH_AF_IPV6 1
#define PRH_TCP 0
#define PRH_UDP 1

typedef prh_ptr prh_handle;

typedef enum {
    PRH_SUCCESS = 0x00,
    PRH_FAILURE,
    PRH_NOTCONN,
    PRH_INVALID,
    PRH_IGNORED,
    PRH_ISINUSE,
    PRH_UNREACH,
    PRH_TIMEOUT,
    PRH_REFUSED,
    PRH_RESETED,
    PRH_ABORTED,
    PRH_OPEXIST,
    PRH_OPABORT,
    PRH_RXCLOSE,
    PRH_TXCLOSE,
    PRH_DISCONN,
} prh_error_enum;

#define PRH_EBIND_ADDRINUSE PRH_ISINUSE

#define PRH_ECONN_FAILURE PRH_FAILURE // 操作无法执行，套接字模块没有启动，内存不足，网卡崩溃，不能绑定到本地地址，指定的套接字操作正在执行或者已经连接
#define PRH_ECONN_INVALID PRH_INVALID // 无效参数，无效内存，无效远程地址，无效地址长度，accept前未调用listen
#define PRH_ECONN_UNREACH PRH_UNREACH // 找不到到达远程主机的路由
#define PRH_ECONN_TIMEOUT PRH_TIMEOUT // 已到达目标主机，但目标主机在规定的时间内没有响应
#define PRH_ECONN_REFUSED PRH_REFUSED // 连接被目标主机拒绝，可能目标主机没有运行服务程序
#define PRH_ECONN_RESETED PRH_RESETED // 连接被对方重置而终止

#define PRH_ESEND_FAILURE PRH_FAILURE
#define PRH_ESEND_INVALID PRH_INVALID
#define PRH_ESEND_TXCLOSE PRH_TXCLOSE // 数据发送已经关闭
#define PRH_ESEND_DISCONN PRH_DISCONN // 连接因故障或被重置已经终止

#define PRH_ERECV_FAILURE PRH_FAILURE
#define PRH_ERECV_INVALID PRH_INVALID
#define PRH_ERECV_RXCLOSE PRH_RXCLOSE // 数据接收已经关闭
#define PRH_ERECV_DISCONN PRH_DISCONN // 连接因故障或被重置已经终止

typedef struct {
    prh_byte client_connect: 1, server_accept: 1, opened: 1, conn_closed: 1, l_closing: 1, l_hup: 1, r_hup: 1;
    prh_byte tx_pending: 1, rx_pending: 1;
} prh_impl_tcp_flags;

struct tcp_callback;
struct tcp_socket {
    /* +5p +4p */ OVERLAPPED open_close_tx_node; // 只有 opened 之后才能 close/tx，只有 tx 完才能 close
    /* +5p +4p */ OVERLAPPED rx_node;
    /* +1p +1p */ prh_handle socket;
    /* +1p +1p */ struct tcp_callback *callback;
    /* +1p +1p */ void *context;
    /* +1p +1p */ prh_impl_tcp_flags flags;
    /* +0p +0p */ prh_byte family;
    /* +1p +0p */ prh_u16 l_port, r_port;
    /* +4p +2p */ prh_u32 l_addr, l_addr_tail[3];
    /* +4p +2p */ prh_u32 r_addr, r_addr_tail[3];
};  /* 23p 16p (32-bit) 92-byte (64-bit) 128-byte */

#define PRH_TCP_SOCKET_STRUCT_SIZE (2 * PRH_CACHE_LINE_SIZE)
prh_static_assert(sizeof(struct tcp_socket) <= PRH_TCP_SOCKET_STRUCT_SIZE);

prh_inline struct tcp_socket *prh_impl_tcp_socket_from_rx_node(OVERLAPPED *overlapped) {
    return (void *)((prh_byte *)overlapped - prh_offsetof(struct tcp_socket, rx_node));
}

struct tcp_callback {
    void (*conn_rsp)(void *context, prh_u32 conn_error, struct tcp_socket *tcp);
    void (*send_rsp)(void *context, prh_u32 send_error, prh_u32 bytes_transferred);
    void (*recv_rsp)(void *context, prh_u32 recv_error, prh_u32 bytes_transferred);
    void (*disc_rsp)(void *context);
};

struct tcp_listen {
    /* +1p +1p */ prh_handle socket;
    /* +1p +1p */ struct tcp_callback *callback;
    /* +1p +1p */ void *context;
    /* +1p +1p */ prh_alloc_free alloc;
    /* +1p +1p */ prh_snode accept_idle_chain;
    /* +1p +1p */ int outgoing_accept_reqs; // 可以同时发出的接收连接请求的数量
    /* +1p +0p */ int same_time_connections; // 可以同时服务的最大客户连接数量
    /* +1p +1p */ int accept_rate_per_second;
    /* +1p +0p */ int connection_count; // 仅在调度线程进行更新
    /* +1p +1p */ int curr_outgoing_reqs;
    /* +1p +0p */ prh_byte family, quit;
};  /* 11p  8p (32-bit) 44-byte (64-bit) 64-byte */

#define PRH_TCP_LISTEN_STRUCT_SIZE PRH_CACHE_LINE_SIZE
prh_static_assert(sizeof(struct tcp_listen) <= PRH_TCP_LISTEN_STRUCT_SIZE);

struct prh_impl_accept_v4_req {
    /* +5p +4p */ OVERLAPPED overlapped;
    /* +1p +1p */ struct tcp_socket *accept;
    /* +8p +4p */ struct sockaddr_in addr[2];
    /* +8p +4p */ prh_byte padding[32]; // AcceptEx本地和远程地址缓冲区必须比对应的协议地址多16字节
};  /* 23p 13p (32-bit) 92-byte (64-bit) 104-byte */

struct prh_impl_accept_v6_req {
    /* +5p +4p */ OVERLAPPED overlapped;
    /* +1p +1p */ struct tcp_socket *accept;
    /* +14 +7p */ struct sockaddr_in6 addr[2];
    /* +8p +4p */ prh_byte padding[32]; // AcceptEx本地和远程地址缓冲区必须比对应的协议地址多16字节
};  /* 28p 16p (32-bit) 112-byte (64-bit) 128-byte */

#define PRH_TCP_ACCEPT_STRUCT_SIZE (2 * PRH_CACHE_LINE_SIZE)
prh_static_assert(sizeof(struct sockaddr_in) <= 16);
prh_static_assert(sizeof(struct sockaddr_in6) <= 28);

struct prh_impl_accept_req {
    prh_ptr overlapped[PRH_TCP_ACCEPT_STRUCT_SIZE / sizeof(void *)];
};

prh_static_assert(sizeof(struct prh_impl_accept_req) == PRH_TCP_ACCEPT_STRUCT_SIZE);
prh_static_assert(sizeof(struct prh_impl_accept_v4_req) <= PRH_TCP_ACCEPT_STRUCT_SIZE);
prh_static_assert(sizeof(struct prh_impl_accept_v6_req) <= PRH_TCP_ACCEPT_STRUCT_SIZE);

typedef struct {
    prh_handle sock;
    prh_cono_subq *upper_subq;
    prh_epoll_port *epoll_port;
    prh_byte ipv6: 1, addr_any: 1, quit: 1;
    prh_u16 port;
    prh_u32 addr;
    prh_u32 addr_[3];
} prh_tcplisten;

typedef prh_arrfit(prh_byte) prh_byte_arrfit;
typedef struct {
    prh_handle sock;
    prh_cono_subq *upper_subq;
    prh_byte_arrfit txbuf;
    prh_byte_arrfit rxbuf;
    prh_epoll_port *epoll_port;
    prh_u32 txbuf_cur;
    prh_i32 error_code;
    prh_byte ipv6: 1, server_accepted_socket: 1, conn_wait_open: 1, drained: 1, tx_done: 1, close_req: 1, local_closed: 1, closed: 1;
    prh_byte epoll_in: 1, epoll_out: 1, epoll_rdhup: 1, epoll_hup: 1, epoll_err: 1;
    prh_u16 l_port;
    prh_u16 p_port;
    prh_u32 l_addr;
    prh_u32 l_addr_[3];
    prh_u32 p_addr;
    prh_u32 p_addr_[3];
    prh_sockaddr local;
    prh_sockaddr peer;
} prh_tcpsocket;

void prh_sock_tcp_listen(prh_tcplisten *listen, const char *host, prh_u16 port, int backlog);
void prh_ipv6_sock_tcp_listen(prh_tcplisten *listen, const char *host, prh_u16 port, int backlog);
void prh_sock_tcp_connect(prh_tcpsocket *tcp, const char *host, prh_u16 port);
bool prh_sock_tcp_accept(prh_tcplisten *listen, prh_tcpsocket *new_connection);
bool prh_sock_tcp_send(prh_tcpsocket *tcp);
bool prh_sock_tcp_recv(prh_tcpsocket *tcp);

#ifdef PRH_SOCK_IMPLEMENTATION
#if defined(prh_plat_windows)
#include <winsock2.h>
#define PRH_INVASOCK INVALID_SOCKET
#define prh_wsa_prerr() prh_impl_prerr(__LINE__, WSAGetLastError())
#define prh_wsa_prerr_if(expr) if (expr) { prh_wsa_prerr(); }
#define prh_wsa_abort_if(expr) if (expr) { prh_impl_abort_error(__LINE__, WSAGetLastError()); }
#define prh_wsa_abort_error() prh_impl_abort_error(__LINE__, WSAGetLastError())
#else
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <netdb.h>
#define PRH_INVASOCK (-1)
#endif

void prh_impl_tcp_bind(prh_handle sock, struct sockaddr_in *addr, int addrlen);
void prh_impl_tcp_listen(prh_handle sock, int backlog);
void prh_sock_ipv6_address(const char *ip_string, prh_byte *ipv6_16_byte);
prh_u32 prh_sock_ipv4_address(const char *ip_string);
prh_handle prh_impl_tcp_socket(int family);
prh_u16 prh_sock_local_port(prh_handle sock, int addrlen);

void prh_impl_sock_tcp_listen(prh_tcplisten *tcp, struct sockaddr_in *addr, int backlog) {
    int family = addr->sin_family;
    int addrlen = (family == AF_INET) ? sizeof(struct sockaddr_in) : sizeof(struct sockaddr_in6);
    prh_handle sock = prh_impl_tcp_socket(family);
    tcp->sock = sock;
    prh_impl_tcp_bind(sock, addr, addrlen);
    if (tcp->port == prh_port_any) {
        tcp->port = prh_sock_local_port(sock, addrlen);
    }
    prh_impl_tcp_listen(sock, backlog);
}

void prh_sock_tcp_listen(prh_tcplisten *tcp, const char *host, prh_u16 port, int backlog) {
    struct sockaddr_in in = {0};
    prh_u32 addr_any = 0; // htonl(INADDR_ANY)
    in.sin_family = AF_INET;
    in.sin_port = htons(port);
    if (host == prh_loopback) {
        prh_byte *ipv4_addr = (prh_byte *)&in.sin_addr.s_addr; // htonl(INADDR_LOOPBACK)
        ipv4_addr[0] = 127;
        ipv4_addr[3] = 1;
    } else if (host != prh_addr_any) {
        in.sin_addr.s_addr = prh_sock_ipv4_address(host);
    }
    tcp->port = port;
    tcp->addr = in.sin_addr.s_addr;
    tcp->addr_any = (in.sin_addr.s_addr == addr_any); // 内核将等到TCP套接字已连接时才选择一个本地IP地址
    prh_impl_sock_tcp_listen(tcp, &in, backlog);
}

void prh_ipv6_sock_tcp_listen(prh_tcplisten *tcp, const char *host, prh_u16 port, int backlog) {
    struct sockaddr_in6 in6 = {0};
    struct in6_addr ipv6_addr_any = {{0}}; // in6addr_any
    in6.sin6_family = AF_INET6;
    in6.sin6_port = htons(port);
    if (host == prh_loopback) {
        prh_byte *ipv6_addr = (prh_byte *)&in6.sin6_addr; // in6addr_loopback
        ipv6_addr[15] = 1;
    } else if (host != prh_addr_any) {
        prh_sock_ipv6_address(host, in6.sin6_addr.s6_addr);
    }
    tcp->port = port;
    tcp->ipv6 = true;
    memcpy(&tcp->addr, in6.sin6_addr.s6_addr, 16);
    if (memcmp(&in6.sin6_addr, &ipv6_addr_any, sizeof(struct in6_addr)) == 0) {
        tcp->addr_any = true; // 内核将等到TCP套接字已连接时才选择一个本地IP地址
    }
    prh_impl_sock_tcp_listen(tcp, (struct sockaddr_in *)&in6, backlog);
}

#if defined(prh_plat_windows)
// https://learn.microsoft.com/en-us/windows/win32/debug/system-error-code-lookup-tool
// https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-erref/596a1078-e883-4972-9bbc-49e60bebca55
// https://learn.microsoft.com/en-us/windows/win32/api/errhandlingapi/nf-errhandlingapi-getlasterror
// https://learn.microsoft.com/en-us/windows/win32/debug/system-error-codes--9000-11999-
// https://learn.microsoft.com/en-us/windows/win32/api/winsock/nf-winsock-wsagetlasterror
// https://learn.microsoft.com/en-us/windows/win32/winsock/windows-sockets-error-codes-2
// https://learn.microsoft.com/en-us/windows/win32/winsock/handling-winsock-errors
//
// All Windows Sockets error constants are biased by WSABASEERR from the "normal"：
// WSABASEERR               10000 (0x2710)
// WSAEFAULT                10014 (0x271E)
// WSAEINVAL                10022 (0x2726)
// WSAEALREADY              10037 (0x2735)
// WSAENOTSOCK              10038 (0x2736)
// WSAEAFNOSUPPORT          10047 (0x273F)
// WSAEADDRINUSE            10048 (0x2740)
// WSAEADDRNOTAVAIL         10049 (0x2741)
// WSAENETDOWN              10050 (0x2742) 套接字操作遇到网络故障。这可能表明网络系统出现了严重故障、网络接口或本地网络本身出现了问题。
// WSAENETUNREACH           10051 (0x2743) 尝试对一个不可达的网络执行套接字操作。这通常意味着本地软件没有找到到达远程主机的路由。
// WSAENOBUFS               10055 (0x2747)
// WSAEISCONN               10056 (0x2748)
// WSAETIMEDOUT             10060 (0x274C) 连接因对方在一段时间内未正确响应而失败，或者已建立的连接因连接的主机未响应而失败。
// WSAECONNREFUSED          10061 (0x274D) 连接被目标主机拒绝，可能目标主机没有运行服务端程序
// WSAEHOSTUNREACH          10065 (0x2751) 没有到主机的路由。尝试对一个不可达的主机执行套接字操作，参阅 WSAENETUNREACH
// WSANOTINITIALISED        10093 (0x276D)
//
// WSA_INVALID_HANDLE       6
//      指定的事件对象句柄无效。
//      应用程序尝试使用事件对象，但指定的句柄无效。
// WSA_NOT_ENOUGH_MEMORY    8
//      内存不足。
//      应用程序使用了一个直接映射到 Windows 函数的 Windows 套接字函数。Windows 函数
//      表明缺少所需的内存资源。
// WSA_INVALID_PARAMETER    87
//      一个或多个参数无效。
//      应用程序使用了一个直接映射到 Windows 函数的 Windows 套接字函数。Windows 函数
//      表明一个或多个参数存在问题。
// WSA_OPERATION_ABORTED    995
//      重叠操作已终止。
//      由于套接字关闭或在 WSAIoctl 中执行 SIO_FLUSH 命令，重叠操作被取消。
// WSA_IO_INCOMPLETE        996
//      重叠 I/O 事件对象未处于信号状态。
//      应用程序尝试确定尚未完成的重叠操作的状态。使用 WSAGetOverlappedResult（将 fWait
//      标志设置为 FALSE）以轮询模式确定重叠操作完成的应用程序，在操作完成之前会收到此
//      错误代码。
// WSA_IO_PENDING           997
//      重叠操作稍后完成。
//      应用程序启动了一个无法立即完成的重叠操作。操作完成后将给出完成指示。
// WSAEINTR                 10004
//      中断的函数调用。
//      阻塞操作被 WSACancelBlockingCall 调用中断。
// WSAEBADF                 10009
//      文件句柄无效。
//      提供的文件句柄无效。
// WSAEACCES                10013
//      拒绝访问。
//      尝试以禁止的方式访问套接字。例如，在未使用 setsockopt（SO_BROADCAST）设置广播
//      权限的情况下，使用广播地址进行 sendto 操作。
//      WSAEACCES 错误的另一个可能原因是，在调用 bind 函数（在 Windows NT 4.0 SP4 及
//      更高版本上）时，另一个应用程序、服务或内核模式驱动程序已绑定到同一地址并具有独占
//      访问权限。这种独占访问是 Windows NT 4.0 SP4 及更高版本的新功能，通过使用
//      SO_EXCLUSIVEADDRUSE 选项实现。
// WSAEFAULT                10014
//      错误的地址。
//      系统在尝试使用调用的指针参数时检测到无效的指针地址。如果应用程序传递了无效的指
//      针值，或者缓冲区长度太小，就会出现此错误。例如，如果参数的长度（是一个 sockaddr
//      结构）小于 sizeof(sockaddr），就会出现此错误。
// WSAEINVAL                10022
//      无效的参数。
//      提供了无效的参数（例如，在调用 setsockopt 函数时指定了无效的级别）。在某些情况
//      下，它还指套接字的当前状态——例如，在未监听的套接字上调用 accept。
// WSAEMFILE                10024
//      打开的文件过多。
//      打开的套接字过多。每个实现可能都有一个最大套接字句柄数量限制，可以是全局的、每个
//      进程的或每个线程的。
// WSAEWOULDBLOCK           10035
//      资源暂时不可用。
//      此错误是从未阻塞套接字的操作返回的，这些操作无法立即完成，例如在套接字上没有排
//      队的数据可供读取时调用 recv。这是一个非致命错误，稍后应重试该操作。在非阻塞
//      SOCK_STREAM 套接字上调用 connect 时，返回 WSAEWOULDBLOCK 是正常的，因为需要
//      一些时间来建立连接。
// WSAEINPROGRESS           10036
//      操作正在进行中。
//      当前正在执行阻塞操作。Windows 套接字只允许一个阻塞操作（每个任务或线程）处于未
//      完成状态，如果在该操作完成之前调用任何其他函数（无论是否引用该套接字或其他套接
//      字），该函数将因 WSAEINPROGRESS 错误而失败。
// WSAEALREADY              10037
//      操作已在进行中。
//      尝试在非阻塞套接字上进行操作，但该操作已在进行中——例如，在已经连接的非阻塞套接字
//      上调用 connect 第二次，或者取消已经取消或完成的异步请求（WSAAsyncGetXbyY）。
// WSAENOTSOCK              10038
//      在非套接字上执行套接字操作。
//      尝试在不是套接字的对象上执行操作。要么套接字句柄参数未引用有效的套接字，要么在
//      select 调用中，fd_set 的成员无效。
// WSAEDESTADDRREQ          10039
//      需要目的地址。
//      在套接字操作中省略了必需的地址。例如，如果使用 sendto 调用并指定远程地址为
//      ADDR_ANY，则会返回此错误。
// WSAEMSGSIZE              10040
//      消息过长。
//      在数据报套接字上发送的消息大于内部消息缓冲区或某些网络限制，或者用于接收数据报
//      的缓冲区小于数据报本身。
// WSAEPROTOTYPE            10041
//      协议类型错误。
//      在套接字函数调用中指定的协议不支持请求的套接字类型语义。例如，不能在 SOCK_STREAM
//      类型的套接字上调用 ARPA Internet UDP 协议。
// WSAENOPROTOOPT           10042
//      无效的协议选项。
//      在 getsockopt 或 setsockopt 调用中指定了未知、无效或不支持的选项或级别。
// WSAEPROTONOSUPPORT       10043
//      协议不支持。
//      请求的协议尚未配置到系统中，或者不存在其实现。例如，套接字调用请求 SOCK_DGRAM
//      类型的套接字，但指定了流协议。
// WSAESOCKTNOSUPPORT       10044
//      套接字类型不支持。
//      在该地址族中不支持指定的套接字类型。例如，在套接字调用中可以选择可选类型 SOCK_RAW，
//      但实现可能根本不支持 SOCK_RAW 套接字。
// WSAEOPNOTSUPP            10045
//      操作不支持。
//      尝试对引用的对象执行不支持的操作。通常，当尝试在无法支持该操作的套接字描述符上
//      接受连接时会发生此错误，例如，在数据报套接字上尝试接受连接。
// WSAEPFNOSUPPORT          10046
//      协议族不支持。
//      协议族尚未配置到系统中，或者不存在其实现。此消息与 WSAEAFNOSUPPORT 略有不同，
//      但在大多数情况下可以互换使用，所有返回这些消息的 Windows 套接字函数也指定了
//      WSAEAFNOSUPPORT。
// WSAEAFNOSUPPORT          10047
//      地址族不受协议族支持。
//      使用了与请求的协议不兼容的地址。所有套接字都与关联的地址族（例如，AF_INET 用于
//      Internet 协议）和通用协议类型（例如，SOCK_STREAM）一起创建。如果在套接字调用中
//      显式指定了错误的协议，或者在套接字上使用了错误族别的地址（例如，在 sendto 中），
//      则会返回此错误。
// WSAEADDRINUSE            10048
//      地址已在使用中。
//      通常，每个套接字地址（协议/IP 地址/端口）只允许使用一次。如果应用程序尝试将套接
//      字绑定到已被现有套接字使用的 IP 地址/端口，或者绑定到未正确关闭的套接字，或者绑
//      定到仍在关闭过程中的套接字，就会出现此错误。对于需要绑定多个套接字到同一端口号的
//      服务器应用程序，可以考虑使用 setsockopt（SO_REUSEADDR）。客户端应用程序通常无
//      需调用 bind——connect 会自动选择一个未使用的端口。当使用通配符地址（涉及 ADDR_ANY）
//      调用 bind 时，可能会延迟出现 WSAEADDRINUSE 错误，直到提交特定地址。这可能发生
//      在稍后的另一个函数调用中，包括 connect、listen、WSAConnect 或 WSAJoinLeaf。
// WSAEADDRNOTAVAIL         10049
//      无法分配请求的地址。
//      请求的地址在其上下文中无效。通常，这是由于尝试将套接字绑定到本地计算机无效的地址
//      导致的。这也可能发生在 connect、sendto、WSAConnect、WSAJoinLeaf 或 WSASendTo
//      中，当远程地址或端口对远程计算机无效时（例如，地址或端口为 0）。
// WSAENETDOWN              10050
//      网络已关闭。
//      套接字操作遇到了已死的网络。这可能表明网络系统（即 Windows 套接字 DLL 运行的基
//      础协议栈）、网络接口或本地网络本身出现了严重故障。
// WSAENETUNREACH           10051
//      网络不可达。
//      尝试对不可达网络执行套接字操作。通常，这意味着本地软件不知道到达远程主机的路由。
// WSAENETRESET             10052
//      网络已重置。
//      由于在操作进行期间，通过保持活动检测到故障，连接被中断。如果尝试在已失败的连接上
//      设置 SO_KEEPALIVE，也可能返回此错误。
// WSAECONNABORTED          10053
//      软件导致连接中断。
//      已建立的连接被主机计算机上的软件中断，可能是由于数据传输超时或协议错误。
// WSAECONNRESET            10054
//      连接被对等方重置。
//      现有的连接被远程主机强制关闭。这通常是因为远程主机上的对等应用程序突然停止、主机
//      重新启动、主机或远程网络接口被禁用，或者远程主机使用了硬关闭（有关 SO_LINGER 选
//      项的更多信息，请参阅 setsockopt）。如果由于保持活动检测到故障而导致连接中断，也
//      可能出现此错误。如果连接因保持活动检测到故障而中断，则正在进行的操作将返回 WSAENETRESET，
//      后续操作将返回 WSAECONNRESET。
// WSAENOBUFS               10055
//      没有缓冲区空间。
//      由于系统缺少缓冲区空间或队列已满，无法执行套接字操作。
// WSAEISCONN               10056
//      套接字已连接。
//      在已连接的套接字上发出了连接请求。某些实现还可能在已连接的 SOCK_DGRAM 套接字上
//      调用 sendto 时返回此错误（对于 SOCK_STREAM 套接字，sendto 中的 to 参数被忽略），
//      尽管其他实现认为这是合法的。
// WSAENOTCONN              10057
//      套接字未连接。
//      由于套接字未连接且（在数据报套接字上调用 sendto 时）未提供地址，拒绝了发送或接
//      收数据的请求。任何其他类型的操作也可能返回此错误——例如，在连接已中断的情况下设置
//      SO_KEEPALIVE。
// WSAESHUTDOWN             10058
//      套接字关闭后无法发送。
//      由于套接字已在该方向上关闭，拒绝了发送或接收数据的请求。通过调用 shutdown 请求
//      套接字的部分关闭，这表明发送或接收（或两者）已被停止。
// WSAETOOMANYREFS          10059
//      引用过多。
//      对某些内核对象的引用过多。
// WSAETIMEDOUT             10060
//      连接超时。
//      由于连接方在一段时间内未正确响应，连接尝试失败，或者已建立的连接因连接主机未响应
//      而失败。
// WSAECONNREFUSED          10061
//      连接被拒绝。
//      由于目标计算机主动拒绝，无法建立连接。这通常是由于尝试连接到远程主机上未激活的服
//      务导致的——即没有运行服务器应用程序。
// WSAELOOP                 10062
//      无法转换名称。
//      无法转换名称。
// WSAENAMETOOLONG          10063
//      名称过长。
//      名称组件或名称过长。
// WSAEHOSTDOWN             10064
//      主机已关闭。
//      由于目标主机已关闭，套接字操作失败。本地主机上的网络活动尚未启动。这些条件更有可
//      能通过 WSAETIMEDOUT 错误来指示。
// WSAEHOSTUNREACH          10065
//      无法到达主机。
//      尝试对不可达主机执行套接字操作。参见 WSAENETUNREACH。
// WSAENOTEMPTY             10066
//      目录不为空。
//      无法删除非空目录。
// WSAEPROCLIM              10067
//      进程过多。
//      Windows 套接字实现可能对可以同时使用它的应用程序数量有限制。如果达到限制，WSAStartup
//      可能会因该错误失败。
// WSAEUSERS                10068
//      用户配额超出。
//      用户配额已用完。
// WSAEDQUOT                10069
//      磁盘配额超出。
//      磁盘配额已用完。
// WSAESTALE                10070
//      文件句柄引用已过时。
//      文件句柄引用不再可用。
// WSAEREMOTE               10071
//      项目是远程的。
//      项目不可用。
// WSASYSNOTREADY           10091
//      网络子系统不可用。
//      如果 Windows 套接字实现无法在此时运行，因为其运行所依赖的基础系统当前不可用，WSAStartup
//      将返回此错误。用户应检查：
//      当前路径中是否有适当的 Windows 套接字 DLL 文件。
//      是否没有同时使用多个 Windows 套接字实现。如果系统中存在多个 Winsock DLL 文件，
//      请确保路径中的第一个是适用于当前加载的网络子系统的文件。
//      阅读 Windows 套接字实现文档，确保所有必要的组件已正确安装并配置。
// WSAVERNOTSUPPORTED       10092
//      Winsock.dll 版本超出范围。
//      当前 Windows 套接字实现不支持应用程序请求的 Windows 套接字规范版本。检查是否有
//      旧的 Windows 套接字 DLL 文件被访问。
// WSANOTINITIALISED        10093
//      尚未成功执行 WSAStartup。
//      应用程序尚未调用 WSAStartup，或者 WSAStartup 调用失败。应用程序可能正在访问当
//      前活动任务未拥有的套接字（即，尝试在任务之间共享套接字），或者 WSACleanup 被调用的次数过多。
// WSAEDISCON               10101
//      正在进行正常关闭。
//      由 WSARecv 和 WSARecvFrom 返回，表明远程方已启动正常关闭序列。
// WSAENOMORE               10102
//      没有更多结果。
//      WSALookupServiceNext 函数无法返回更多结果。
// WSAECANCELLED            10103
//      调用已取消。
//      在该调用仍在处理时，调用了 WSALookupServiceEnd 函数。该调用已被取消。
// WSAEINVALIDPROCTABLE     10104
//      过程调用表无效。
//      服务提供程序过程调用表无效。服务提供程序向 Ws2_32.dll 返回了无效的过程表。通常，
//      这是因为其中一个函数指针为 NULL。
// WSAEINVALIDPROVIDER      10105
//      服务提供程序无效。
//      请求的服务提供程序无效。此错误由 WSCGetProviderInfo 和 WSCGetProviderInfo32
//      函数返回，如果指定的协议条目无法找到，也会返回此错误。如果服务提供程序返回的版本
//      号不是 2.0，也会返回此错误。
// WSAEPROVIDERFAILEDINIT   10106
//      服务提供程序初始化失败。
//      无法加载或初始化请求的服务提供程序。如果服务提供程序的 DLL 无法加载（LoadLibrary
//      失败）或者提供程序的 WSPStartup 或 NSPStartup 函数失败，将返回此错误。
// WSASYSCALLFAILURE        10107
//      系统调用失败。
//      应该永远不会失败的系统调用失败了。这是一个通用错误代码，可在多种条件下返回。
//      如果应永不失败的系统调用失败（例如，WaitForMultipleObjects 失败，或者在操作协
//      议/命名空间目录时某个注册表函数失败），将返回此错误。
//      如果提供程序未返回 SUCCESS 且未提供扩展错误代码，也会返回此错误。这可能表明服务
//      提供程序实现存在错误。
// WSASERVICE_NOT_FOUND     10108
//      未找到服务。
//      未知服务。无法在指定的命名空间中找到服务。
// WSATYPE_NOT_FOUND        10109
//      未找到类类型。
//      未找到指定的类。
// WSA_E_NO_MORE            10110
//      没有更多结果。
//      WSALookupServiceNext 函数无法返回更多结果。
// WSA_E_CANCELLED          10111
//      调用已取消。
//      在该调用仍在处理时，调用了 WSALookupServiceEnd 函数。该调用已被取消。
// WSAEREFUSED              10112
//      数据库查询被拒绝。
//      数据库查询因被主动拒绝而失败。
// WSAHOST_NOT_FOUND        11001
//      未找到主机。
//      未知主机。名称不是官方主机名或别名，或者无法在正在查询的数据库中找到。此错误也可
//      能出现在协议和服务查询中，表示无法在相关数据库中找到指定的名称。
// WSATRY_AGAIN             11002
//      非权威主机未找到。
//      这是主机名解析期间的临时错误，表明本地服务器未从权威服务器收到响应。稍后重试可能
//      会成功。
// WSANO_RECOVERY           11003
//      这是不可恢复的错误。
//      在数据库查询期间发生了某种不可恢复的错误。这可能是因为数据库文件（例如，BSD 兼容
//      的 HOSTS、SERVICES 或 PROTOCOLS 文件）无法找到，或者 DNS 请求被服务器以严重错
//      误返回。
// WSANO_DATA               11004
//      有效名称，无请求类型的数据记录。
//      请求的名称在数据库中有效且已找到，但未找到正在解析的正确关联数据。通常，这是在主
//      机名到地址转换尝试（使用 gethostbyname 或 WSAAsyncGetHostByName）中使用 DNS
//      （域名服务器）时出现的。返回了 MX 记录，但未返回 A 记录——表明主机本身存在，但无
//      法直接到达。
// WSA_QOS_RECEIVERS        11005
//      QoS 接收方。
//      至少有一个 QoS 预留已到达。
// WSA_QOS_SENDERS          11006
//      QoS 发送方。
//      至少有一个 QoS 发送路径已到达。
// WSA_QOS_NO_SENDERS       11007
//      没有 QoS 发送方。
//      没有 QoS 发送方。
// WSA_QOS_NO_RECEIVERS     11008
//      没有 QoS 接收方。
//      没有 QoS 接收方。
// WSA_QOS_REQUEST_CONFIRMED 11009
//      QoS 请求已确认。
//      QoS 预留请求已确认。
// WSA_QOS_ADMISSION_FAILURE 11010
//      QoS 准入错误。
//      由于资源不足，QoS 错误发生。
// WSA_QOS_POLICY_FAILURE   11011
//      QoS 策略失败。
//      由于策略系统无法在现有策略内分配请求的资源，QoS 请求被拒绝。
// WSA_QOS_BAD_STYLE        11012
//      QoS 样式错误。
//      遇到了未知或冲突的 QoS 样式。
// WSA_QOS_BAD_OBJECT       11013
//      QoS 对象错误。
//      在过滤规范或提供程序特定缓冲区的一般部分中遇到了问题。
// WSA_QOS_TRAFFIC_CTRL_ERROR 11014
//      QoS 流量控制错误。
//      在将通用 QoS 请求转换为本地强制执行的 TC API 请求时，底层流量控制（TC）API 出
//      现错误。这可能是由于内存不足或内部 QoS 提供程序错误导致的。
// WSA_QOS_GENERIC_ERROR    11015
//      QoS 通用错误。
//      QoS 通用错误。
// WSA_QOS_ESERVICETYPE     11016
//      QoS 服务类型错误。
//      在 QoS 流量规范中找到了无效或无法识别的服务类型。
// WSA_QOS_EFLOWSPEC        11017
//      QoS 流量规范错误。
//      在 QoS 结构中找到了无效或不一致的流量规范。
// WSA_QOS_EPROVSPECBUF     11018
//      无效的 QoS 提供程序特定缓冲区。
//      无效的 QoS 提供程序特定缓冲区。
// WSA_QOS_EFILTERSTYLE     11019
//      无效的 QoS 过滤样式。
//      使用了无效的 QoS 过滤样式。
// WSA_QOS_EFILTERTYPE      11020
//      无效的 QoS 过滤类型。
//      使用了无效的 QoS 过滤类型。
// WSA_QOS_EFILTERCOUNT     11021
//      QoS 过滤器计数错误。
//      在 FLOWDESCRIPTOR 中指定了错误数量的 QoS FILTERSPEC。
// WSA_QOS_EOBJLENGTH       11022
//      无效的 QoS 对象长度。
//      在 QoS 提供程序特定缓冲区中指定了具有无效 ObjectLength 字段的对象。
// WSA_QOS_EFLOWCOUNT       11023
//      QoS 流量计数错误。
//      在 QoS 结构中指定了错误数量的流量描述符。
// WSA_QOS_EUNKOWNPSOBJ     11024
//      未知的 QoS 提供程序特定对象。
//      在 QoS 提供程序特定缓冲区中找到了未知对象。
// WSA_QOS_EPOLICYOBJ       11025
//      无效的 QoS 策略对象。
//      在 QoS 提供程序特定缓冲区中找到了无效的策略对象。
// WSA_QOS_EFLOWDESC        11026
//      无效的 QoS 流量描述符。
//      在流量描述符列表中找到了无效的 QoS 流量描述符。
// WSA_QOS_EPSFLOWSPEC      11027
//      无效的 QoS 提供程序特定流量规范。
//      在 QoS 提供程序特定缓冲区中找到了无效或不一致的流量规范。
// WSA_QOS_EPSFILTERSPEC    11028
//      无效的 QoS 提供程序特定过滤规范。
//      在 QoS 提供程序特定缓冲区中找到了无效的 FILTERSPEC。
// WSA_QOS_ESDMODEOBJ       11029
//      无效的 QoS 形状丢弃模式对象。
//      在 QoS 提供程序特定缓冲区中找到了无效的形状丢弃模式对象。
// WSA_QOS_ESHAPERATEOBJ    11030
//      无效的 QoS 整形速率对象。
//      在 QoS 提供程序特定缓冲区中找到了无效的整形速率对象。
// WSA_QOS_RESERVED_PETYPE  11031
//      保留的 QoS 策略元素类型。
//      在 QoS 提供程序特定缓冲区中找到了保留的策略元素。
//
// 若 Winsock 在其规范中更新或增添了一个新函数，该函数名将带有 WSA 前缀。比如，建立套
// 接字的 Winsock 1 函数只是被简单称为 socket，而 Winsock 2 引入该函数的新版本时，其
// 命名为 WSAScoket，该函数可以使用 Winsock 2 中出现的一些新特性。但注意，该命名规则
// 有几个例外，如 WSAStartup WSACleanup WSARecvEx WSAGetLastError 都属于 Winsock
// 1.1 规范函数。
//
// 在使用 Winsock 前，必须了解需要哪些文件和库。旧版本可以使用 winsock.h，链接库文件
// wsock32.lib。新版本包含头文件 winsock2.h，链接库文件 ws2_32.lib。另外还有一个头文
// 件 mswsock.h，该头文件用于微软专用编程扩展，这些扩展通常用于高效 Winsock 应用程序
// 的开发，此时还必须链接 mswsock.dll。
//
// 每个 Winsock 应用都必须加载合适的 Winsock DLL 版本，如果调用一个 Winsock 函数之前
// 没有加载 Winsock 库，这个函数就会返回一个 SOCKET_ERROR，错误信息是 WSANOTINITIALISED。
// 加载 Winsock 库通过调用 WSAStartup 函数实现。
//
// int WSAStartup(
//      [in]  WORD      wVersionRequired,
//      [out] LPWSADATA lpWSAData
// );
//
// 参数 wVersionRequired 指定 Windows 套接字规范的最高版本。高字节指定次版本号；低字
// 节指定主版本号。
//
// 如果成功，WSAStartup 函数返回零。否则，它返回以下列出的错误代码之一。WSAStartup 函
// 数直接在返回值中返回扩展错误代码。不需要调用 WSAGetLastError 函数，也不应使用它。
//  * WSASYSNOTREADY - 底层网络子系统尚未准备好进行网络通信。
//  * WSAVERNOTSUPPORTED - 请求的 Windows 套接字支持版本未被此特定 Windows 套接字实
//    现提供。
//  * WSAEINPROGRESS - 一个阻塞的 Windows 套接字 1.1 操作正在进行中。
//  * WSAEPROCLIM - 已达到 Windows 套接字实现支持的任务数量限制。
//  * WSAEFAULT - lpWSAData 参数不是一个有效的指针。
//
// typedef struct WSAData {
//      WORD           wVersion;
//      WORD           wHighVersion;
//      char           szDescription[WSADESCRIPTION_LEN + 1];
//      char           szSystemStatus[WSASYS_STATUS_LEN + 1];
//      unsigned short iMaxSockets;
//      unsigned short iMaxUdpDg;
//      char           *lpVendorInfo;
// } WSADATA;
//
// 字段 wVersion 为 Ws2_32.dll 期望调用方使用的 Windows 套接字规范版本。高字节指定次
// 版本号，低字节指定主版本号。字段 wHighVersion 为 Ws2_32.dll 能够支持的 Windows 套
// 接字规范的最高版本。高字节指定次版本号，低字节指定主版本号。当传递给 WSAStartup 函数
// 的 wVersionRequested 参数请求的版本是 Ws2_32.dll 能够支持的最高版本时，此值与 wVersion
// 成员的值相同。
//
// 字段 iMaxSockets 可以打开的最大套接字数量。对于 Windows 套接字 2 及更高版本，应忽
// 略此成员。iMaxSockets 成员保留用于与 Windows 套接字规范 1.1 兼容，但在开发新应用程
// 序时不应使用。没有单一值可以适用于所有底层服务提供程序。Windows 套接字的架构在版本 2
// 中发生了变化，以支持多个提供程序，WSADATA 结构不再适用于单一供应商的堆栈。
//
// 字段 iMaxUdpDg 最大数据报消息大小。对于 Windows 套接字 2 及更高版本，此成员被忽略。
// iMaxUdpDg 成员保留用于与 Windows 套接字规范 1.1 兼容，但在开发新应用程序时不应使用。
// Windows 套接字的架构在版本 2 中发生了变化，以支持多个提供程序，WSADATA 结构不再适用
// 于单一供应商的堆栈。对于特定 Windows 套接字服务提供程序和套接字类型的实际最大消息大
// 小，应用程序应在创建套接字后使用 getsockopt 获取 SO_MAX_MSG_SIZE 选项的值。
//
// 字段 lpVendorInfo 指向供应商特定信息。对于 Windows 套接字 2 及更高版本，应忽略此成
// 员。lpVendorInfo 成员保留用于与 Windows 套接字规范 1.1 兼容。Windows 套接字的架构
// 在版本 2 中发生了变化，以支持多个提供程序，WSADATA 结构不再适用于单一供应商的堆栈。
// 需要访问供应商特定配置信息的应用程序应使用 getsockopt 获取 PVD_CONFIG 选项的值以获
// 取供应商特定信息。
//
// 字段 szDescription[WSADESCRIPTION_LEN + 1]，Ws2_32.dll 将 Windows 套接字实现的
// 描述复制到其中的以 NULL 结尾的 ASCII 字符串。文本（最多 256 个字符）可以包含任何字
// 符，但不能包含控制字符和格式化字符。应用程序最有可能使用此成员的方式是将其（可能截断）
// 显示在状态消息中。
//
// 字段 szSystemStatus[WSASYS_STATUS_LEN + 1]，Ws2_32.dll 将相关的状态或配置信息复
// 制到其中的以 NULL 结尾的 ASCII 字符串。Ws2_32.dll 应仅在信息可能对用户或支持人员有
// 用时使用此参数。不应将此成员视为 szDescription 参数的扩展。
//
// WSAStartup 函数启动一个进程对 Windows 套接字 DLL 的使用。WSAStartup 函数通过 lpWSAData
// 参数返回指向 WSADATA 结构的指针。当前版本的 Windows 套接字规范在 WSADATA 结构的
// wHighVersion 成员中返回的是 2.2 版本，主版本号存储在低字节中，次版本号存储在高字节
// 中。当前版本的 Winsock DLL（Ws2_32.dll）支持请求以下版本的 Windows 套接字规范的应
// 用程序：1.0 1.1 2.0 2.1 2.2。根据应用程序请求的版本，上述版本号之一将作为主版本号存
// 储在低字节中，次版本号存储在高字节中，返回在 WSADATA 结构的 wVersion 成员中。注意，
// 如果在成功调用 WSAStartup 后，wVersion 中的值至少为 2，则应用程序应忽略 WSADATA 中
// 的 iMaxsockets、iMaxUdpDg 和 lpVendorInfo 成员。这是因为 Windows 套接字的架构在
// 版本 2 中发生了变化，以支持多个提供程序，WSADATA 不再适用于单一供应商的堆栈。引入了
// 两个新的套接字选项以提供特定于提供程序的信息：SO_MAX_MSG_SIZE（替代 iMaxUdpDg 成员）
// 和 PVD_CONFIG（允许进行任何其他特定于提供程序的配置）。
//
// int WSACleanup();
//
// WSACleanup 函数终止对 Winsock 2 动态链接库（Ws2_32.dll）的使用。如果操作成功，返
// 回值为零。否则，返回值为 SOCKET_ERROR，可以通过调用 WSAGetLastError 获取特定的错误
// 编号。在多线程环境中，WSACleanup 会终止该进程内所有线程的 Windows 套接字操作。
//  * WSANOTINITIALISED - 在调用此函数之前，必须先成功调用 WSAStartup。
//  * WSAENETDOWN - 网络子系统已失败。
//  * WSAEINPROGRESS - 一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程
//    序仍在处理回调函数。
//
// 应用程序或 DLL 在使用 Windows 套接字服务之前，必须先成功调用 WSAStartup。当完成对
// Windows 套接字的使用后，应用程序或 DLL 必须调用 WSACleanup 以从 Windows 套接字实
// 现中注销自身，并允许实现释放为应用程序或 DLL 分配的任何资源。
//
// 调用 WSACleanup 时，该进程内任何线程发出的任何挂起的阻塞或异步 Windows 套接字调用
// 将被取消，不会发布任何通知消息或触发任何事件对象。该进程内任何线程发出的任何挂起的重
// 叠发送或接收操作（例如，使用重叠套接字的 WSASend、WSASendTo、WSARecv 或 WSARecvFrom）
// 也会被取消，不会设置事件对象或调用完成例程（如果指定了）。在这种情况下，挂起的重叠操
// 作将以 WSA_OPERATION_ABORTED 错误状态失败。
//
// 在调用 WSACleanup 时处于打开状态的套接字将被重置并自动释放，就像调用了 closesocket
// 一样。已经使用 closesocket 关闭但仍有待发送的挂起数据的套接字可能会受到 WSACleanup
// 调用的影响。在这种情况下，如果 WS2_32.DLL 在应用程序退出时从内存中卸载，挂起的数据
// 可能会丢失。为了确保所有挂起的数据都被发送，应用程序应该使用 shutdown 关闭连接，然后
// 等待关闭完成，再调用 closesocket 和 WSACleanup。所有资源和内部状态（如排队的未发布
// 或已发布消息）都必须被释放，以便可供下一个用户使用。
//
// 对于每次成功的 WSAStartup 调用，都必须有一次 WSACleanup 调用。只有最后一次 WSACleanup
// 函数调用才会执行实际的清理操作。之前的调用只是简单地减少 WS2_32.DLL 中的内部引用计
// 数。注意 WSACleanup 不会注销可能已通过 Windows 套接字命名空间提供程序（如对等名称
// 解析协议 PNRP 命名空间提供程序）注册的名称（例如对等名称）。
//
// 在 Windows 套接字 1.1 中，从阻塞钩子中调用 WSACleanup 并且未检查返回代码是一个常见
// 的编程错误。如果 Winsock 1.1 应用程序需要在挂起的阻塞调用期间退出，应用程序必须先使
// 用 WSACancelBlockingCall 取消阻塞调用，然后在控制权返回到应用程序后调用 WSACleanup。
// 在 Windows 套接字 2 中，这个问题不存在，WSACancelBlockingCall 函数已被移除。
//
// WSACleanup 函数通常会导致特定于协议的辅助 DLL 被卸载。因此，不应从应用程序 DLL 的
// DllMain 函数中调用 WSACleanup 函数。这可能会导致死锁。有关详细信息，请参阅 DLL 主
// 函数。

void prh_impl_wsasocket_cleanup(void) {
    if (WSACleanup() != 0) prh_wsa_prerr();
}

void prh_impl_wsasocket_startup(void) {
    WSADATA wsa_data; // MAKEWORD(lowbyte, highbyte)
    int error = WSAStartup(MAKEWORD(2, 2), &wsa_data);
    if (error != 0) {
        prh_prerr(error);
        return;
    }
    if (LOBYTE(wsaData.wVersion) != 2 || HIBYTE(wsaData.wVersion) != 2) {
        prh_error(PRH_EVERSION);
        prh_impl_wsasocket_cleanup();
        return;
    }
    prh_zeroret(atexit(prh_impl_wsasocket_cleanup));
}

// Windows TCP/IP 服务提供程序支持的扩展函数的 GUID 值在 Mswsock.h 头文件中定义。这些
// GUID 的可能值如下：
//     WSAID_ACCEPTEX                  AcceptEx 扩展函数。
//     WSAID_CONNECTEX                 ConnectEx 扩展函数。
//     WSAID_DISCONNECTEX              DisconnectEx 扩展函数。
//     WSAID_GETACCEPTEXSOCKADDRS      GetAcceptExSockaddrs 扩展函数。
//     WSAID_TRANSMITFILE              TransmitFile 扩展函数。
//     WSAID_TRANSMITPACKETS           TransmitPackets 扩展函数。
//     WSAID_WSARECVMSG                LPFN_WSARECVMSG (WSARecvMsg) 扩展函数。
//     WSAID_WSASENDMSG                WSASendMsg 扩展函数。
//
// 注意必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_EXTENSION_FUNCTION_POINTER
// 操作码来获取 AcceptEx 函数的函数指针。传递给 WSAIoctl 函数的输入缓冲区必须包含 WSAID_ACCEPTEX，
// 这是一个全局唯一标识符（GUID），其值标识 AcceptEx 扩展函数。成功时，WSAIoctl 函数
// 返回的输出包含指向 AcceptEx 函数的指针。WSAID_ACCEPTEX GUID 在 Mswsock.h 头文件中
// 定义。
//
// 注意，必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_EXTENSION_FUNCTION_POINTER
// 操作码来获取 GetAcceptExSockaddrs 函数的函数指针。传递给 WSAIoctl 函数的输入缓冲区
// 必须包含 WSAID_GETACCEPTEXSOCKADDRS，这是一个全局唯一标识符（GUID），其值标识
// GetAcceptExSockaddrs 扩展函数。成功时，WSAIoctl 函数返回的输出包含指向 GetAcceptExSockaddrs
// 函数的指针。WSAID_GETACCEPTEXSOCKADDRS GUID 在 Mswsock.h 头文件中定义。
//
// 注意，必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_EXTENSION_FUNCTION_POINTER
// 操作码来获取 ConnectEx 函数的函数指针。传递给 WSAIoctl 函数的输入缓冲区必须包含 WSAID_CONNECTEX，
// 这是一个全局唯一标识符（GUID），其值标识 ConnectEx 扩展函数。成功时，WSAIoctl 函数
// 返回的输出包含指向 ConnectEx 函数的指针。WSAID_CONNECTEX GUID 在 Mswsock.h 头文件
// 中定义。
//
// 注意，必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_EXTENSION_FUNCTION_POINTER
// 操作码来获取 DisconnectEx 函数的函数指针。传递给 WSAIoctl 函数的输入缓冲区必须包含
// WSAID_DISCONNECTEX，这是一个全局唯一标识符（GUID），其值标识 DisconnectEx 扩展函
// 数。成功时，WSAIoctl 函数返回的输出包含指向 DisconnectEx 函数的指针。WSAID_DISCONNECTEX
// GUID 在 Mswsock.h 头文件中定义。
//
// 注意，必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_EXTENSION_FUNCTION_POINTER
// 操作码来获取 WSASendMsg 函数的函数指针。传递给 WSAIoctl 函数的输入缓冲区必须包含
// WSAID_WSASENDMSG，这是一个全局唯一标识符（GUID），其值标识 WSASendMsg 扩展函数。
// 成功时，WSAIoctl 函数返回的输出包含指向 WSASendMsg 函数的指针。WSAID_WSASENDMSG
// GUID 在 Mswsock.h 头文件中定义。
//
// 一旦获取了扩展函数（如 TransmitFile）的函数指针，就可以直接调用它，而无需将应用程序
// 链接到 Mswsock.lib 库。这实际上减少了对 Mswsock.lib 的一个中间函数调用。
#include <mswsock.h>

static LPFN_ACCEPTEX PRH_IMPL_ACCEPTEX;
static LPFN_GETACCEPTEXSOCKADDRS PRH_IMPL_GETACCEPTEXSOCKADDRS;
static LPFN_CONNECTEX PRH_IMPL_CONNECTEX;
static LPFN_DISCONNECTEX PRH_IMPL_DISCONNECTEX;

void *prh_impl_wsaioctl_extension_func(prh_handle sock, GUID guid);
void prh_impl_wsaioctl_rio_extensions(prh_handle sock, void *table);

void prh_impl_mswsock_load_ext_funcs(prh_handle sock) {
    PRH_IMPL_ACCEPTEX = prh_impl_wsaioctl_extension_func(s, WSAID_ACCEPTEX);
    prh_wsa_abort_if(PRH_IMPL_ACCEPTEX == prh_null);

    PRH_IMPL_GETACCEPTEXSOCKADDRS = prh_impl_wsaioctl_extension_func(s, WSAID_GETACCEPTEXSOCKADDRS);
    prh_wsa_abort_if(PRH_IMPL_GETACCEPTEXSOCKADDRS == prh_null);

    PRH_IMPL_CONNECTEX = prh_impl_wsaioctl_extension_func(s, WSAID_CONNECTEX);
    prh_wsa_abort_if(PRH_IMPL_CONNECTEX == prh_null);

    // WSAID_TRANSMITFILE
    // WSAID_TRANSMITPACKETS
    // WSAID_DISCONNECTEX
    // WSAID_WSARECVMSG
    // WSAID_WSASENDMSG
    // WSAID_WSAPOLL
}

void prh_impl_mswsock_load_rio_funcs(prh_handle sock) {
    prh_impl_wsaioctl_rio_extensions(sock, &PRH_IMPL_RIO);
}

void prh_impl_wsasocket_init(void) {
    prh_impl_wsasocket_startup();
    prh_handle sock = prh_impl_tcp_socket(AF_INET);
    prh_impl_mswsock_load_ext_funcs(sock);
    prh_impl_mswsock_load_rio_funcs(sock);
    prh_impl_close_socket(sock);
}

// int WSAEnumProtocols(LPINT protocols, LPWSAPROTOCOL_INFO protocol_buffer LPDWORD buffer_length);
// int WSADuplicateSocket(SOCKET s, DWORD process_id, LPWSAPROTOCOL_INFO protocol_info);
//
// SOCKET socket(int af, int type, int protocol);
// SOCKET WSASocket(int af, int type, int protocol, LPWSAPROTOCOL_INFO protocol_info, GROUP group, DWORD flags);
//
// WSASocket 函数创建一个绑定到特定传输服务提供程序的套接字。如果没有错误发生，WSASocket
// 返回一个引用新套接字的描述符。否则返回 INVALID_SOCKET，可通过调用 WSAGetLastError
// 获取特定的错误代码。
//      WSANOTINITIALISED       在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN             网络子系统已失败。
//      WSAEAFNOSUPPORT         指定的地址族不受支持。
//      WSAEFAULT               lpProtocolInfo 参数不在进程地址空间的有效部分。
//      WSAEINPROGRESS          一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINVAL               如果满足以下任意条件，则此值为真。指定的 g 参数无效；lpProtocolInfo 指向的 WSAPROTOCOL_INFO
//                              结构不完整、内容无效或已在早期重复套接字操作中使用；套接字三元组 <af、type 和 protocol> 的成员
//                              指定的值分别受支持，但给定的组合不受支持。
//      WSAEINVALIDPROVIDER     服务提供程序返回的版本不是 2.2。
//      WSAEINVALIDPROCTABLE    服务提供程序返回的程序表无效或不完整。
//      WSAEMFILE               没有更多的套接字描述符可用。
//      WSAENOBUFS              没有可用的缓冲区空间。无法创建套接字。
//      WSAEPROTONOSUPPORT      指定的协议不受支持。
//      WSAEPROTOTYPE           指定的协议类型与套接字类型不匹配。
//      WSAEPROVIDERFAILEDINIT  服务提供程序初始化失败。如果分层服务提供程序 (LSP) 或命名空间提供程序安装不当，或者提供程序无法
//                              正常运行，则会返回此错误。
//      WSAESOCKTNOSUPPORT      指定的套接字类型在此地址族中不受支持。
//
// 参数 af 地址族规范。地址族的可能值在 Winsock2.h 头文件中定义。在为 Windows Vista
// 及更高版本发布的 Windows SDK 中，头文件的组织结构发生了变化，地址族的可能值在 Ws2def.h
// 头文件中定义。注意，Ws2def.h 头文件会自动包含在 Winsock2.h 中，不应直接使用。
//
// 目前支持的值是 AF_INET 和 AF_INET6，它们分别是 IPv4 和 IPv6 的 Internet 地址族格
// 式。如果安装了对应地址族的 Windows 套接字服务提供程序，其他地址族选项（例如用于 NetBIOS
// 的 AF_NETBIOS）也可能支持。注意，AF_ 地址族和 PF_ 协议族常量的值是相同的（例如，AF_INET
// 和 PF_INET），因此可以使用这两个常量中的任意一个。下表列出了地址族的一些常见值，尽管
// 还有许多其他可能的值。
//      AF_UNSPEC       0       地址族未指定。
//      AF_INET         2       Internet 协议版本 4 (IPv4) 地址族。
//      AF_IPX          6       IPX/SPX 地址族。仅当安装了 NWLink IPX/SPX NetBIOS 兼容传输协议时才支持
//                              此地址族。此地址族在 Windows Vista 及更高版本上不支持。
//      AF_APPLETALK    16      AppleTalk 地址族。仅当安装了 AppleTalk 协议时才支持此地址族。此地址族在
//                              Windows Vista 及更高版本上不支持。
//      AF_NETBIOS      17      NetBIOS 地址族。仅当安装了 NetBIOS 的 Windows 套接字提供程序时才支持此
//                              地址族。NetBIOS 的 Windows 套接字提供程序支持 32 位版本的 Windows，并且
//                              默认安装在 32 位版本的 Windows 上。NetBIOS 的 Windows 套接字提供程序不
//                              支持 64 位版本的 Windows，包括 Windows 7、Windows Server 2008、Windows
//                              Vista、Windows Server 2003 或 Windows XP。NetBIOS 的 Windows 套接字提
//                              供程序仅支持将类型参数设置为 SOCK_DGRAM 的套接字。NetBIOS 的 Windows 套
//                              接字提供程序与 NetBIOS 编程接口没有直接关系。Windows Vista、Windows Server
//                              2008 及更高版本不支持 NetBIOS 编程接口。
//      AF_INET6        23      Internet 协议版本 6 (IPv6) 地址族。
//      AF_IRDA         26      红外数据协会 (IrDA) 地址族。仅当计算机安装了红外端口和驱动程序时才支持此
//                              地址族。
//      AF_BTH          32      蓝牙地址族。如果计算机安装了蓝牙适配器和驱动程序，则在 Windows XP SP2 或
//                              更高版本上支持此地址族。
//
// 参数 type 新套接字的类型规范。套接字类型的可能值在 Winsock2.h 头文件中定义。下表列
// 出了 Windows 套接字版本 2 中支持的类型参数的可能值。
//      SOCK_STREAM     1       提供有序的、可靠的、双向的、基于连接的字节流，并带有带外数据传输机制的套接
//                              字类型。此套接字类型使用 Internet 地址族 (AF_INET 或 AF_INET6) 的传输控
//                              制协议 (TCP)。
//      SOCK_DGRAM      2       支持数据报的套接字类型，数据报是无连接的、不可靠的、固定（通常较小）最大长
//                              度的缓冲区。此套接字类型使用 Internet 地址族 (AF_INET 或 AF_INET6) 的用
//                              户数据报协议 (UDP)。
//      SOCK_RAW        3       提供原始套接字，允许应用程序操作下一层协议头。要操作 IPv4 头，必须在套接字
//                              上设置 IP_HDRINCL 套接字选项。要操作 IPv6 头，必须在套接字上设置 IPV6_HDRINCL
//                              套接字选项。
//      SOCK_RDM        4       提供可靠消息数据报的套接字类型。例如，Windows 中实用的通用多播 (Pragmatic
//                              General Multicast, PGM) 多播协议实现，通常称为可靠多播编程（Reliable Multicast
//                              Programming）。仅当安装了可靠多播协议时才支持此类型值。
//      SOCK_SEQPACKET  5       提供基于数据报的伪流套接字类型。
//
// 在 Windows 套接字版本 2 中，引入了新的套接字类型。应用程序可以通过 WSAEnumProtocols 函数动态发现每个可用
// 传输协议的属性。因此，应用程序可以确定地址族的可能套接字类型和协议选项，并在指定此参数时使用这些信息。随着
// 新的套接字类型、地址族和协议的定义，Winsock2.h 和 Ws2def.h 头文件中的套接字类型定义将定期更新。在 Windows
// 套接字版本 1.1 中，唯一可能的套接字类型是 SOCK_DGRAM 和 SOCK_STREAM。
//
// 参数 protocol 要使用的协议。协议参数的可能选项特定于指定的地址族和套接字类型。协议的
// 可能值在 Winsock2.h 和 Wsrm.h 头文件中定义。在为 Windows Vista 及更高版本发布的
// Windows SDK 中，头文件的组织结构发生了变化，此参数可以是 Ws2def.h 头文件中定义的
// IPPROTO 枚举类型的值之一。注意，Ws2def.h 头文件会自动包含在 Winsock2.h 中，不应直
// 接使用。
//
// 如果指定的值为 0，则调用方不想指定协议，服务提供程序将选择要使用的协议。当 af 参数为
// AF_INET 或 AF_INET6 且类型为 SOCK_RAW 时，协议指定的值将设置在 IPv6 或 IPv4 数据
// 包头的协议字段中。下表列出了协议的一些常见值，尽管还有许多其他可能的值。
//      IPPROTO_ICMP    1       Internet 控制消息协议 (ICMP)。当 af 参数为 AF_UNSPEC、AF_INET 或 AF_INET6
//                              且类型参数为 SOCK_RAW 或未指定时，这是一个可能的值。此协议值支持 Windows
//                              XP 及更高版本。
//      IPPROTO_IGMP    2       Internet 组管理协议 (IGMP)。当 af 参数为 AF_UNSPEC、AF_INET 或 AF_INET6
//                              且类型参数为 SOCK_RAW 或未指定时，这是一个可能的值。此协议值支持 Windows
//                              XP 及更高版本。
//      BTHPROTO_RFCOMM 3       蓝牙无线通信协议 (Bluetooth RFCOMM)。当 af 参数为 AF_BTH 且类型参数为
//                              SOCK_STREAM 时，这是一个可能的值。此协议值支持 Windows XP SP2 及更高版本。
//      IPPROTO_TCP     6       传输控制协议 (TCP)。当 af 参数为 AF_INET 或 AF_INET6 且类型参数为 SOCK_STREAM
//                              时，这是一个可能的值。
//      IPPROTO_UDP     17      用户数据报协议 (UDP)。当 af 参数为 AF_INET 或 AF_INET6 且类型参数为 SOCK_DGRAM
//                              时，这是一个可能的值。
//      IPPROTO_ICMPV6  58      Internet 控制消息协议版本 6 (ICMPv6)。当 af 参数为 AF_UNSPEC、AF_INET
//                              或 AF_INET6 且类型参数为 SOCK_RAW 或未指定时，这是一个可能的值。此协议值
//                              支持 Windows XP 及更高版本。
//      IPPROTO_RM      113     可靠多播的 PGM 协议。当 af 参数为 AF_INET 且类型参数为 SOCK_RDM 时，这是
//                              一个可能的值。在为 Windows Vista 及更高版本发布的 Windows SDK 中，此协议
//                              也称为 IPPROTO_PGM。仅当安装了可靠多播协议时才支持此协议值。
//
// 参数 lpProtocolInfo 指向 WSAPROTOCOL_INFO 结构，该结构定义了要创建的套接字的特性。如果此参数不为 NULL，
// 则套接字将绑定到与指示的 WSAPROTOCOL_INFO 结构关联的提供程序。
//
// 参数 g 现有的套接字组 ID 或在创建新套接字和新套接字组时要采取的适当操作。如果 g 是
// 现有的套接字组 ID，则在满足该组设置的所有要求的前提下，将新套接字加入此套接字组。如果
// g 不是现有的套接字组 ID，则可能的值如下。
//      0                               不执行组操作。
//      SG_UNCONSTRAINED_GROUP  0x01    创建一个无约束的套接字组，并使新套接字成为第一个成员。对于无约束组，
//                                      Winsock 不限制套接字组中的所有套接字必须使用相同的类型和协议参数
//                                      创建。
//      SG_CONSTRAINED_GROUP    0x02    创建一个有约束的套接字组，并使新套接字成为第一个成员。对于有约束的
//                                      套接字组，Winsock 限制套接字组中的所有套接字必须使用相同的类型和
//                                      协议参数创建。有约束的套接字组只能由面向连接的套接字组成，并且要求
//                                      所有组内套接字的连接都必须是同一主机上的同一地址。
//
// 注意 SG_UNCONSTRAINED_GROUP 和 SG_CONSTRAINED_GROUP 常量目前未在公共头文件中定义。
//
// 参数 dwFlags 用于指定附加套接字属性的一组标志。可以设置这些标志的组合如下，尽管某些
// 组合是不允许的。
//      WSA_FLAG_OVERLAPPED                 0x01    创建支持重叠 I/O 操作的套接字。大多数套接字都应该设置此标志创建。重叠套接字
//                                                  可以使用 WSASend、WSASendTo、WSARecv、WSARecvFrom 和 WSAIoctl 进行重叠
//                                                  I/O 操作，从而允许同时启动并进行多个操作。所有允许重叠操作的函数（WSASend、
//                                                  WSARecv、WSASendTo、WSARecvFrom、WSAIoctl）也支持在重叠套接字上使用非重
//                                                  叠模式，只要与重叠操作相关的参数值为 NULL 即可。
//      WSA_FLAG_MULTIPOINT_C_ROOT          0x02    创建一个多点会话中的 c_root 套接字。仅当创建套接字的传输提供程序的 WSAPROTOCOL_INFO
//                                                  结构支持多点或组播机制，并且多点会话的控制平面是根控的时，才允许此属性。这
//                                                  通过 WSAPROTOCOL_INFO 结构的 dwServiceFlags1 成员设置 XP1_SUPPORT_MULTIPOINT
//                                                  和 XP1_MULTIPOINT_CONTROL_PLANE 标志来指示。
//      WSA_FLAG_MULTIPOINT_C_LEAF          0x04    创建一个多点会话中的 c_leaf 套接字。仅当创建套接字的传输提供程序的 WSAPROTOCOL_INFO
//                                                  结构支持多点或组播机制，并且多点会话的控制平面是非根控的时，才允许此属性。
//                                                  这通过 WSAPROTOCOL_INFO 结构的 dwServiceFlags1 成员设置 XP1_SUPPORT_MULTIPOINT
//                                                  标志且未设置 XP1_MULTIPOINT_CONTROL_PLANE 标志来指示。
//      WSA_FLAG_MULTIPOINT_D_ROOT          0x08    创建一个多点会话中的 d_root 套接字。仅当创建套接字的传输提供程序的 WSAPROTOCOL_INFO
//                                                  结构支持多点或组播机制，并且多点会话的数据平面是根控的时，才允许此属性。这
//                                                  通过 WSAPROTOCOL_INFO 结构的 dwServiceFlags1 成员设置 XP1_SUPPORT_MULTIPOINT
//                                                  和 XP1_MULTIPOINT_DATA_PLANE 标志来指示。
//      WSA_FLAG_MULTIPOINT_D_LEAF          0x10    创建一个多点会话中的 d_leaf 套接字。仅当创建套接字的传输提供程序的 WSAPROTOCOL_INFO
//                                                  结构支持多点或组播机制，并且多点会话的数据平面是非根控的时，才允许此属性。这
//                                                  通过 WSAPROTOCOL_INFO 结构的 dwServiceFlags1 成员设置 XP1_SUPPORT_MULTIPOINT
//                                                  标志且未设置 XP1_MULTIPOINT_DATA_PLANE 标志来指示。
//      WSA_FLAG_ACCESS_SYSTEM_SECURITY     0x40    创建一个允许在套接字的安全描述符上设置包含系统访问控制列表 (SACL) 的安全描
//                                                  述符的套接字，而不仅仅是自由访问控制列表 (DACL)。SACL 用于在对对象进行访问
//                                                  检查时生成审核和警报。对于套接字，访问检查用于确定套接字是否允许绑定到 bind
//                                                  函数指定的特定地址。ACCESS_SYSTEM_SECURITY 访问权限控制获取或设置对象安全
//                                                  描述符中 SACL 的能力。系统仅在请求线程的访问令牌中启用了 SE_SECURITY_NAME
//                                                  特权时才授予此访问权限。
//      WSA_FLAG_NO_HANDLE_INHERIT          0x80    创建一个不可继承的套接字。由 WSASocket 或 socket 函数创建的套接字句柄默认
//                                                  是可继承的。设置此标志时，套接字句柄将不可继承。可以使用 GetHandleInformation
//                                                  函数确定套接字句柄是否是使用 WSA_FLAG_NO_HANDLE_INHERIT 标志创建的。GetHandleInformation
//                                                  函数将返回对应的 HANDLE_FLAG_INHERIT 标志值。此标志支持 Windows 7 SP1、
//                                                  Windows Server 2008 R2 SP1 及更高版本。
//
// 重要提示：对于多点会话套接字，只能指定 WSA_FLAG_MULTIPOINT_C_ROOT 或 WSA_FLAG_MULTIPOINT_C_LEAF
// 中的一个标志，以及 WSA_FLAG_MULTIPOINT_D_ROOT 或 WSA_FLAG_MULTIPOINT_D_LEAF 中
// 的一个标志。有关多点会话的更多信息，请参阅多点和组播语义。
//
// WSASocket 函数会导致套接字描述符及相关资源被分配并绑定到传输服务提供程序。大多数套接
// 字都应该在 dwFlags 参数中设置 WSA_FLAG_OVERLAPPED 属性创建。使用此属性创建的套接字
// 支持重叠 I/O 操作，从而提供更高的性能。默认情况下，使用 WSASocket 函数创建的套接字不
// 会设置此重叠属性。相比之下，socket 函数创建的套接字默认支持重叠 I/O 操作。
//
// 如果 lpProtocolInfo 参数为 NULL，Winsock 将使用第一个支持在 af、type 和 protocol
// 参数中指定的地址族、套接字类型和协议组合的可用传输服务提供程序。
//
// 如果 lpProtocolInfo 参数不为 NULL，则套接字将绑定到与指定的 WSAPROTOCOL_INFO 结构
// 关联的提供程序。在这种情况下，应用程序可以将 af、type 或 protocol 参数中的任意一个
// 的值指定为 FROM_PROTOCOL_INFO 表示常量。这表示应使用指定的 WSAPROTOCOL_INFO 结构
// 中的相应值（iAddressFamily、iSocketType、iProtocol）。在任何情况下，af、type 和
// protocol 的指定值都会未经修改地传递给传输服务提供程序。
//
// 当根据 af、type 和 protocol 选择协议及其支持的服务提供程序时，此过程只会选择一个基
// 础协议或一个协议链（a protocol chain），而不是一个单独的协议层自己（a protocol
// layer）。未链接的协议层（unchained protocol layers）也不会被视为部分匹配 type 或
// af。也就是说，如果找不到合适的协议，它们不会导致 WSAEAFNOSUPPORT 或 WSAEPROTONOSUPPORT
// 错误代码。注意，虽然在头文件中仍然定义了 AF_UNSPEC 表示常量，但强烈不建议使用它，因
// 为它可能导致协议参数值的解释产生歧义。
//
// 鼓励应用程序使用 AF_INET6 作为 af 参数，并创建一个可以用于 IPv4 和 IPv6 的双模套接
// 字。
//
// 如果使用 WSASocket 函数创建套接字，则 dwFlags 参数必须设置 WSA_FLAG_OVERLAPPED
// 属性，以便 SO_RCVTIMEO 或 SO_SNDTIMEO 套接字选项能够正常工作。否则，超时将永远不会
// 在套接字上生效。
//
// 面向连接的套接字（如 SOCK_STREAM）提供全双工连接，并且必须在能够通过它们发送或接收
// 任何数据之前处于已连接状态。通过调用 connect 或 WSAConnect 函数建立与指定套接字的
// 连接。连接后，可以使用 send/WSASend 和 recv/WSARecv 调用传输数据。完成会话后，应
// 调用 closesocket 函数释放与套接字关联的资源。对于面向连接的套接字，在调用 closesocket
// 函数之前，应调用 shutdown 函数停止套接字上的数据传输。
//
// 用于实现可靠、面向连接的套接字的通信协议确保数据不会丢失或重复。如果对等协议无法在合
// 理的时间内成功传输数据，则认为连接已断开，随后的调用将因超时而失败，错误代码设置为
// WSAETIMEDOUT。
//
// 无连接的、面向消息的套接字允许使用 sendto/WSASendTo 和 recvfrom/WSARecvFrom 向任
// 意对等方发送和接收数据报。如果此类套接字连接到特定对等方，则可以使用 send/WSASend
// 向该对等方发送数据报，并且可以使用 recv/WSARecv 从（仅）该对等方接收数据报。
//
// 不要求支持类型为 SOCK_RAW 的套接字，但鼓励服务提供程序尽可能支持原始套接字。
//
// 可以使用 WSASocket 函数创建一个用于服务的套接字，以便如果另一个套接字尝试绑定到服务
// 使用的同一端口，则会生成审核记录。要启用此选项，应用程序需要执行以下操作：
//  1.  调用 AdjustTokenPrivileges 函数以在进程的访问令牌中启用 SE_SECURITY_NAME 特
//      权。此特权是设置对象安全描述符上 ACCESS_SYSTEM_SECURITY 访问权限所必需的。
//  2.  调用 WSASocket 函数创建一个设置了 WSA_FLAG_ACCESS_SYSTEM_SECURITY 选项的套
//      接字。如果未先调用 AdjustTokenPrivileges 函数以启用此操作所需的 SE_SECURITY_NAME
//      特权，则 WSASocket 函数将失败。
//  3.  调用 SetSecurityInfo 函数在套接字上设置带有系统访问控制列表 (SACL) 的安全描述
//      符。由 WSASocket 函数返回的套接字句柄将作为 handle 参数传递。如果函数成功，则
//      会在套接字的安全描述符上设置 ACCESS_SYSTEM_SECURITY 访问权限。
//  4.  调用 bind 函数将套接字绑定到特定端口。如果 bind 函数成功，则当另一个套接字尝试
//      绑定到同一端口时，将生成审核记录。
//  5.  调用 AdjustTokenPrivileges 函数从进程的访问令牌中移除 SE_SECURITY_NAME 特权，
//      因为不再需要此特权。
//
// 有关 ACCESS_SYSTEM_SECURITY 的更多信息，请参阅授权文档中的 SACL 访问权限和审核生成。
//
// WinSock 2 引入了套接字组的概念，允许应用程序或一组协作应用程序，向底层服务提供程序
// 表明特定的一组套接字是相关的，并且由此形成的组具有某些属性。组属性包括组内各个套接字
// 的相对优先级以及组服务质量规范。需要通过网络交换多媒体流的应用程序是能够建立一组套接
// 字之间特定关系的典型示例。传输层如何处理套接字组由传输本身决定。
//
// 可以使用 WSASocket 和 WSAAccept 函数在创建新套接字时显式创建并加入套接字组。可以通
// 过使用 getsockopt 函数（将级别参数设置为 SOL_SOCKET，将 optname 参数设置为 SO_GROUP_ID）
// 检索套接字的套接字组 ID。套接字组及其关联的套接字组 ID 一直有效，直到属于该套接字组
// 的最后一个套接字关闭。套接字组 ID 对于给定服务提供程序的所有进程都是唯一的。套接字组
// ID 为零表示套接字不属于任何套接字组。
//
// 可以通过使用 getsockopt 函数（将级别参数设置为 SOL_SOCKET，将 optname 参数设置为
// SO_GROUP_PRIORITY）访问套接字组的相对组优先级。可以通过使用 setsockopt 函数（将级
// 别参数设置为 SOL_SOCKET，将 optname 参数设置为 SO_GROUP_PRIORITY）设置套接字组的
// 相对组优先级。
//
// 随 Windows 提供的 Winsock 提供程序允许创建套接字组，并强制执行 SG_CONSTRAINED_GROUP。
// 属于有约束套接字组的所有套接字必须使用相同的类型和协议参数创建。有约束套接字组只能由
// 面向连接的套接字组成，并且要求所有组内套接字的连接都必须是同一主机上的同一地址。这是
// 随 Windows 提供的 Winsock 提供程序对套接字组应用的唯一限制。套接字组优先级目前未被
// 随 Windows 提供的 Winsock 提供程序或 TCP/IP 栈使用。
//
// 注意 winsock2.h 头文件将 WSASocket 定义为一个别名，该别名会根据 UNICODE 预处理器
// 常量的定义自动选择 ANSI 或 Unicode 版本的函数。将编码中立的别名与非编码中立的代码
// 混合使用可能会导致不匹配，从而引发编译时或运行时错误。

void prh_sock_setnonblock(prh_handle sock, int nonblock);

prh_handle prh_impl_tcp_socket(int family) {
    SOCKET sock = WSASocket(family, SOCK_STREAM, IPPROTO_TCP, prh_null, 0, WSA_FLAG_OVERLAPPED | WSA_FLAG_RIO | WSA_FLAG_NO_HANDLE_INHERIT);
    prh_wsa_abort_if(sock == INVALID_SOCKET);
    prh_sock_setnonblock(sock, 1);
    return (prh_handle)sock;
}

// int shutdown(SOCKET s, int how);
//
// shutdown 函数用于禁用套接字上的发送或接收操作。
//      SD_RECEIVE  0   禁用接收操作
//      SD_SEND     1   禁用发送操作
//      SD_BOTH     2   禁用发送和接收操作
//
// 如果没有错误发生，shutdown 返回零。否则，返回值为 SOCKET_ERROR，可以通过调用 WSAGetLastError
// 获取特定的错误代码。
//      WSAECONNABORTED     虚拟电路因超时或其他故障而终止。应用程序应关闭套接字，因为它已不再可用。此错误
//                          仅适用于面向连接的套接字。
//      WSAECONNRESET       虚拟电路被远程方通过执行硬关闭或强制关闭而重置。应用程序应关闭套接字，因为它已
//                          不再可用。此错误仅适用于面向连接的套接字。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINVAL           how 参数无效，或者与套接字类型不一致。例如，使用 UNI_RECV 套接字类型时使用了
//                          SD_SEND。
//      WSAENETDOWN         网络子系统已失败。
//      WSAENOTCONN         套接字未连接。此错误仅适用于面向连接的套接字。
//      WSAENOTSOCK         注意：描述符不是套接字。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//
// shutdown 函数可用于所有类型的套接字，以禁用接收、发送或都禁止。如果 how 参数为 SD_RECEIVE，
// 后续对该套接字的 recv 函数调用将被禁止。这不会影响底层协议层。对于 TCP 套接字，如果
// 套接字上仍有排队等待接收的数据，或者后续有数据到达，连接将被重置，因为数据无法传递给   *** TCP 禁止接收后，如果仍有排队等待接收的数据或后续有数据到达，连接将被重置
// 用户。对于 UDP 套接字，传入的数据报将被接受并排队。在任何情况下，都不会生成 ICMP 错
// 误数据包。
//
// 如果 how 参数为 SD_SEND，后续对该套接字的 send 函数调用将被禁止。对于 TCP 套接字，   *** TCP 禁止发送后，在所有数据发送并被接收方确认后将发送 FIN
// 在所有数据发送并被接收方确认后，将发送 FIN。将 how 设置为 SD_BOTH 会禁用发送和接收，
// 如上所述。
//
// shutdown 函数不会关闭套接字。除非调用 closesocket，否则与套接字关联的任何资源都不会
// 被释放。为了确保在关闭连接之前，已连接的套接字上的所有数据都已发送和接收，应用程序应
// 在调用 closesocket 之前使用 shutdown 关闭连接。一种等待远程端发送所有数据并启动优雅
// 断开连接的方法是使用 WSAEventSelect 函数，如下所示：
//  1.  调用 WSAEventSelect 注册 FD_CLOSE 通知。
//  2.  调用 shutdown，将 how 设置为 SD_SEND。
//  3.  当收到 FD_CLOSE 时，调用 recv 或 WSARecv，直到函数成功完成并指示已接收零字节。
//      如果返回 SOCKET_ERROR，则无法实现优雅断开连接。
//  4.  调用 closesocket。
//
// 另一种等待远程端发送所有数据并启动优雅断开连接的方法是使用重叠接收调用，如下所示：
//  1.  调用 shutdown，将 how 设置为 SD_SEND。
//  2.  调用 recv 或 WSARecv，直到函数成功完成并指示已接收零字节。如果返回 SOCKET_ERROR，
//      则无法实现优雅断开连接。
//  3.  调用 closesocket。
//
// 注意 无论套接字上的 SO_LINGER 设置如何，shutdown 函数都不会阻塞。有关更多信息，请参
// 阅“优雅关闭、逗留选项和套接字关闭”部分：
// https://learn.microsoft.com/en-us/windows/desktop/WinSock/graceful-shutdown-linger-options-and-socket-closure-2
//
// 一旦调用 shutdown 函数禁用了发送、接收或两种都禁止，就无法重新启用现有套接字连接上的
// 发送或接收。应用程序不应依赖在关闭后重用套接字。特别是，Windows 套接字提供程序没强制
// 要求必须支持在已关闭（shut down）的套接字上使用 connect。
//
// 如果应用程序希望重用套接字，则应调用 DisconnectEx 函数，并将 dwFlags 参数设置为 TF_REUSE_SOCKET，
// 以关闭套接字上的连接并准备套接字句柄以供重用。当 DisconnectEx 请求完成时，可以将套接
// 字句柄传递给 AcceptEx 或 ConnectEx 函数。
//
// 如果应用程序希望重用套接字，可以调用 TransmitFile 或 TransmitPackets 函数，并将 dwFlags
// 参数设置为 TF_DISCONNECT 和 TF_REUSE_SOCKET，以在所有数据排队传输完成后断开连接并
// 准备套接字句柄以供重用。当 TransmitFile 请求完成时，可以将套接字句柄传递给之前用于
// 建立连接的函数调用，例如 AcceptEx 或 ConnectEx。当 TransmitPackets 函数完成时，可
// 以将套接字句柄传递给 AcceptEx 函数。
//
// 注意，套接字级断开连接受底层传输行为的影响。例如，TCP 套接字可能会受到 TCP TIME_WAIT
// 状态的影响，导致 DisconnectEx、TransmitFile 或 TransmitPackets 调用被延迟。
//
// 在发出阻塞的 Winsock 调用（如 shutdown）时，Winsock 可能需要等待网络事件才能完成调
// 用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排的异步过程调用
// （APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发出另一个阻塞
// Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。
//
// BOOL DisconnectEx(
//      SOCKET s,
//      LPOVERLAPPED lpOverlapped,
//      DWORD dwFlags,
//      DWORD dwReserved
// );
//
// DisconnectEx 函数关闭套接字上的连接，并允许重用套接字句柄。注意，该函数是 Microsoft
// 对 Windows 套接字规范的特定扩展。成功时，DisconnectEx 返回 TRUE。失败返回 FALSE。
// 使用 WSAGetLastError 函数获取扩展错误信息。如果 WSAGetLastError 函数返回 ERROR_IO_PENDING，
// 则表示操作已成功启动且正在进行。在这种情况下，调用可能在操作完成时仍然失败。
//      WSAEFAULT       系统在尝试使用指针参数时检测到无效的指针地址。如果在 lpOverlapped 参数中传递了无效的指针值，则返回此错误。
//      WSAEINVAL       传递了无效的参数。如果 dwFlags 参数指定了除 TF_REUSE_SOCKET 之外的零值，则返回此错误。
//      WSAENOTCONN     套接字未连接。如果套接字 s 参数不在连接状态，则返回此错误。如果套接字处于前一次请求导致的传输关闭（CLOSING）
//                      状态，并且 dwFlags 参数未设置 TF_REUSE_SOCKET 重用套接字，则也会返回此错误。
//
// 参数 s 已连接的、面向连接的套接字的句柄。参数 lpOverlapped 指向 OVERLAPPED 结构的
// 指针。如果套接字句柄以重叠方式打开，则指定此参数将导致重叠（异步）I/O 操作。参数
// dwReserved 保留，必须为零。如果非零，则返回 WSAEINVAL。
//
// 参数 dwFlags 一组标志，用于自定义函数调用的处理。当此参数设置为零时，不设置任何标志。
// dwFlags 参数可以具有以下值。
//      TF_REUSE_SOCKET     准备重用套接字句柄。当 DisconnectEx 请求完成时，可以将
//                          套接字句柄传递给 AcceptEx 或 ConnectEx 函数。
//
// 注意：套接字级别的断开连接受底层传输行为的影响。例如，TCP 套接字可能会受到 TIME_WAIT   *** 受 TIME_WAIT 状态影响 DisconnectEx 操作可能会延迟
// 状态的影响，导致 DisconnectEx 调用被延迟。
//
// DisconnectEx 函数不支持数据报套接字。因此，由 hSocket 指定的套接字必须是面向连接的，
// 例如 SOCK_STREAM、SOCK_SEQPACKET 或 SOCK_RDM 套接字。
//
// 当 lpOverlapped 不为 NULL 时，重叠 I/O 可能在 DisconnectEx 返回之前未完成，导致
// DisconnectEx 函数返回 FALSE，并且调用 WSAGetLastError 函数返回 ERROR_IO_PENDING
// 这种设计使调用者可以在断开连接操作完成时继续处理。请求完成后，Windows 将 OVERLAPPED
// 结构的 hEvent 成员指定的事件或由 hSocket 指定的套接字设置为已触发状态。
//
// 如果这个函数被一个重叠结构调用，且套接字上还有挂起的操作，则 DisconnectEx 会返回       *** DisconnectEx 会等待底层挂起的还未完成的操作先完成
// FALSE，错误为 WSA_IO_PENDING。一旦所有挂起的操作完成，且传输层断开操作已经发动，
// 操作就会结束。否则，如果以阻塞方式调用这个函数，则只有所有挂起的 I/O 都完成，且断开
// 操作已经发动（transport level disconnect has been issued）之后，函数才会返回。
//
// 注意，当给定线程退出时，该线程启动的所有 I/O 都将被取消。对于重叠套接字，如果在线程
// 关闭之前操作未完成，则挂起的异步操作可能会失败。有关更多信息，请参阅 ExitThread。
//
// TIME_WAIT 状态决定了 TCP 在释放已关闭连接并重用其资源之前必须经过的时间间隔。这个关
// 闭和释放之间的间隔称为 TIME_WAIT 状态或 2MSL 状态。在此期间，重新打开连接的成本远低
// 于建立新连接。TIME_WAIT 行为在 RFC 793 中指定，要求 TCP 在关闭连接后至少维持一个间
// 隔，该间隔等于网络最大报文段生命周期（MSL）的两倍。当连接被释放时，其套接字对和用于套
// 接字的内部资源可以用于支持另一个连接。
//
// Windows TCP 在关闭连接后进入 TIME_WAIT 状态。在 TIME_WAIT 状态下，套接字对不能被
// 重用。可以通过修改以下 DWORD 注册表设置来配置 TIME_WAIT 间隔，该设置表示 TIME_WAIT
// 间隔（以秒为单位）。HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\TCPIP\
// Parameters\TcpTimedWaitDelay。默认情况下，MSL 定义为 120 秒。TcpTimedWaitDelay
// 注册表设置默认为 240 秒的值，这表示 120 秒的最大报文段生命周期的两倍，即 4 分钟。然
// 而，可以使用此条目自定义间隔。降低此条目的值可以让 TCP 更快地释放已关闭的连接，从而
// 为新连接提供更多资源。然而，如果值过低，TCP 可能在连接完成之前释放连接资源，导致服务
// 器需要使用额外的资源重新建立连接。此注册值可设置的范围从 0 到 300 秒。
//
// int closesocket(SOCKET s);
//
// closesocket 函数用于关闭现有的套接字。如果未发生错误，closesocket 返回零。否则，返
// 回值为 SOCKET_ERROR，可以通过调用 WSAGetLastError 获取特定的错误代码。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAENOTSOCK         描述符不是套接字。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINTR            阻塞的 Windows 套接字 1.1 调用通过 WSACancelBlockingCall 被取消。
//      WSAEWOULDBLOCK      套接字被标记为非阻塞，但 linger 结构的 l_onoff 成员设置为非零值，且 linger 结
//                          构的 l_linger 成员设置为非零超时值。
//
// closesocket 函数用于关闭套接字。使用它来释放通过 s 参数传递的套接字描述符。请注意，
// 一旦发出 closesocket 函数调用，传递给 s 参数的套接字描述符可能会立即被系统重用。因    *** 关闭的套接字可能被立即重用，因此不要多个线程关闭同一个套接字
// 此，期望对传递给 s 参数的套接字描述符的进一步引用会因 WSAENOTSOCK 错误而失败。Winsock
// 客户端绝不应在另一个 Winsock 函数调用的同时并发地对 s 发起 closesocket。
//
// 该进程中的任何线程发出的任何挂起的重叠发送和接收操作（使用重叠套接字的 WSASend/WSASendTo/
// WSARecv/WSARecvFrom）也会被取消。为这些重叠操作指定的任何事件、完成例程或完成端口操
// 作都将执行。挂起的重叠操作将以 WSA_OPERATION_ABORTED 错误状态失败。
//
// 应用程序不应假设当 closesocket 返回时，套接字上所有未完成的 I/O 操作都将保证完成。
// closesocket 函数将启动对未完成 I/O 操作的取消，但这并不意味着当 closesocket 函数
// 返回时，应用程序将收到这些 I/O 操作的 I/O 完成。因此，应用程序应在 I/O 请求确实完成
// 之前，不要清理任何被未完成 I/O 请求引用的资源（例如 WSAOVERLAPPED 结构）。
//
// 应用程序应该对每个成功的 socket 调用都有一个匹配的 closesocket 调用，以将任何套接字
// 资源返回给系统。
//
// linger 结构维护有关特定套接字的信息，指定当数据排队等待发送且对套接字调用 closesocket
// 函数时，该套接字的行为。linger 结构的 l_onoff 成员确定在对套接字调用 closesocket
// 函数后，套接字是否应在指定的时间内保持打开状态以发送排队的数据。可以通过两种方式修改
// 此成员：
//  1.  调用 setsockopt 函数，并将 optname 参数设置为 SO_DONTLINGER。optval 参数决
//      定如何修改 l_onoff 成员。
//  2.  调用 setsockopt 函数，并将 optname 参数设置为 SO_LINGER。optval 参数指定如
//      何修改 l_onoff 和 l_linger 两个成员。
//
// linger 结构的 l_linger 成员确定套接字应保持打开状态的时间（以秒为单位）。只有当 linger
// 结构的 l_onoff 成员非零时，此成员才适用。套接字的默认参数是 linger 结构的 l_onoff
// 成员为零，表示套接字不应保持打开状态。linger 结构的 l_linger 成员的默认值为零，但当
// l_onoff 成员设置为零时，此值将被忽略。
//
// 要使套接字保持打开状态，应用程序应将 l_onoff 成员设置为非零值，并将 l_linger 成员设
// 置为所需的超时时间（以秒为单位）。要禁用套接字保持打开状态，应用程序只需将 linger 结
// 构的 l_onoff 成员设置为零。
//
// 如果应用程序调用 setsockopt 函数，并将 optname 参数设置为 SO_DONTLINGER 以将 l_onoff
// 成员设置为非零值，则未指定 l_linger 成员的值。在这种情况下，使用的超时时间取决于实现。
// 如果之前为套接字建立了超时时间（通过调用 setsockopt 函数并将 optname 参数设置为
// SO_LINGER），服务提供程序应重新使用此超时值。
//
// linger 结构成员的设置影响 closesocket 函数的行为。
//      l_onoff     l_linger    关闭类型                                  是否等待关闭完成
//      0           任意        优雅关闭                                         否
//      非零        0           强制关闭                                         否
//      非零        非零        如果在 l_linger 指定的超时时间内发送所有数据，      是
//                             则为优雅关闭；否则为强制关闭
//
// 如果流式套接字的 LINGER 结构的 l_onoff 成员为零，则 closesocket 调用将立即返回，
// 并且无论套接字是阻塞还是非阻塞，都不会收到 WSAEWOULDBLOCK 错误。然而，如果可能，将
// 在关闭底层套接字之前发送排队等待传输的数据。这称为优雅断开连接或关闭。在这种情况下，
// Windows 套接字提供程序无法在任意的时限内释放套接字和其他资源，从而影响期望使用所有可
// 用套接字的应用程序。这是套接字的默认行为。
//
// 如果 linger 结构的 l_onoff 成员非零且 l_linger 成员为零，则即使排队的数据尚未发送
// 或确认，closesocket 也不会阻塞。这称为强制关闭或强制关闭，因为套接字的虚拟电路将立
// 即重置，任何未发送的数据都将丢失。在 Windows 上，电路远程端的任何 recv 调用都将因
// WSAECONNRESET 错误而失败。
//
// 如果在阻塞套接字上将 linger 结构的 l_onoff 成员设置为非零，并且 l_linger 成员设置
// 为非零超时时间，则 closesocket 调用将阻塞，直到所有数据发送完毕或超时到期。如果在
// l_linger 成员指定的超时时间内发送了所有数据，则称为优雅关闭；如果超时到期前未发送所
// 有数据，则 Windows 套接字实现将在 closesocket 返回之前终止连接，这称为强制关闭。
//
// 不建议在非阻塞套接字上将 linger 结构的 l_onoff 成员设置为非零，并将 l_linger 成员
// 设置为非零超时时间。在这种情况下，如果无法立即完成关闭操作，则 closesocket 调用将因
// WSAEWOULDBLOCK 错误而失败。如果 closesocket 因 WSAEWOULDBLOCK 错误失败，则套接字
// 句柄仍然有效，并且不会启动断开连接。应用程序必须再次调用 closesocket 来关闭套接字。
//
// 如果在阻塞套接字上将 linger 结构的 l_onoff 成员设置为非零，并且 l_linger 成员设置
// 为非零超时时间，则无法使用 closesocket 函数的结果来确定是否已将所有数据发送到对等方。
// 如果在 l_linger 成员指定的超时时间内发送了数据，或者连接被中止，则 closesocket 函数
// 不会返回错误代码（closesocket 函数的返回值为零）。
//
// closesocket 调用将会阻塞，直到所有数据已传递给对等方或超时到期。如果因超时到期而重置
// 连接，则套接字不会进入 TIME_WAIT 状态。如果在超时时间内发送了所有数据，则套接字可能
// 会进入 TIME_WAIT 状态。
//
// 如果在阻塞套接字上将 linger 结构的 l_onoff 成员设置为非零，并且 l_linger 成员设置
// 为零超时时间，则 closesocket 调用将重置连接。套接字不会进入 TIME_WAIT 状态。
//
// 可以通过调用 getsockopt 函数，并将 optname 参数设置为 SO_LINGER，来检索与套接字关
// 联的 linger 结构的当前值。注意，为确保在连接上发送和接收所有数据，应用程序应在调用
// closesocket 之前调用 shutdown（有关更多信息，请参阅优雅关闭、逗留选项和套接字关闭）。
// 请注意，在调用 closesocket 之后，不会发布 FD_CLOSE 网络事件。
//
// 以下是 closesocket 行为的总结：
//  1.  如果 LINGER 结构的 l_onoff 成员为零（套接字的默认值），则 closesocket 立即
//      返回，连接将在后台优雅关闭。Windows 套接字提供程序可能无法在预期时限内释放套接
//      字和其他资源，从而影响期望使用所有可用套接字的应用程序。这是套接字的默认行为。
//  2.  如果将 linger 结构的 l_onoff 成员设置为非零值，并且 l_linger 成员设置为零
//      （无超时），则 closesocket 立即返回，连接将被重置或终止。
//  3.  如果将 linger 结构的 l_onoff 成员设置为非零值，并且 l_linger 成员设置为非零
//      超时时间：对于阻塞套接字，closesocket 将阻塞直到所有数据发送完毕或超时到期；
//      对于非阻塞套接字，closesocket 立即返回 WSAEWOULDBLOCK，表示失败。
//
// 有关更多信息，请参阅优雅关闭、逗留选项和套接字关闭。
// https://learn.microsoft.com/en-us/windows/desktop/WinSock/graceful-shutdown-linger-options-and-socket-closure-2
//
// 注意 在发出阻塞的 Winsock 调用（如 closesocket）时，Winsock 可能需要等待网络事件
// 才能完成调用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排的异步
// 过程调用（APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发出另一
// 个阻塞 Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。

prh_u32 prh_sock_shut_send(prh_handle sock) {
    int n = shutdown((SOCKET)sock, SD_SEND);
    prh_u32 error_code = 0;
    if (n != 0) {
        error_code = WSAGetLastError();
        prh_prerr(error_code);
    }
    return error_code;
}

prh_u32 prh_sock_shut_recv(prh_handle sock) {
    int n = shutdown((SOCKET)sock, SD_RECEIVE);
    prh_u32 error_code = 0;
    if (n != 0) {
        error_code = WSAGetLastError();
        prh_prerr(error_code);
    }
    return error_code;
}

prh_u32 prh_sock_shut_both(prh_handle sock) {
    int n = shutdown((SOCKET)sock, SD_BOTH);
    prh_u32 error_code = 0;
    if (n != 0) {
        error_code = WSAGetLastError();
        prh_prerr(error_code);
    }
    return error_code;
}

prh_inline void prh_impl_close_socket(prh_handle sock) {
    prh_wsa_prerr_if(closesocket((SOCKET)sock));
}

// LINGER 结构用于维护特定套接字的信息，指定在套接字上有排队的数据待发送且调用 closesocket
// 函数时，该套接字的行为。套接字的默认参数是 linger 结构的 l_onoff 成员为零，表示套接
// 字不应保持在打开状态。
//      typedef struct linger { // linger 逗留；苟延残喘；磨蹭；继续存留；缓慢消失
//          u_short l_onoff;
//          u_short l_linger;
//      } LINGER, *PLINGER, *LPLINGER;
//
// 成员 l_onoff 指定在调用 closesocket 函数后，套接字是否应保持打开状态以发送排队的数
// 据。此成员可以有以下值：
//      0       套接字不会保持打开状态。如果使用 setsockopt 函数且 optname 参数设置为 SO_DONTLINGER，optval 参数为零，则设置此
//              值。如果使用 setsockopt 函数且 optname 参数设置为 SO_LINGER，传递到 optval 参数的 linger 结构的 l_onoff 成员
//              设置为 0，则也会设置此值。
//      非零    套接字将保持打开状态一段时间。如果使用 setsockopt 函数且 optname 参数设置为 SO_DONTLINGER，optval 参数为非零值，
//              则设置此值。如果使用 setsockopt 函数且 optname 参数设置为 SO_LINGER，传递到 optval 参数的 linger 结构的 l_onoff
//              成员设置为非零值，则也会设置此值。
//
// 成员 l_linger 指定在调用 closesocket 函数后，套接字保持打开状态的时间（以秒为单位）。
// 此成员仅在 linger 结构的 l_onoff 成员设置为非零值时才适用。如果使用 setsockopt 函
// 数且 optname 参数设置为 SO_LINGER，则会设置此值。传递给 setsockopt 函数的 optval
// 参数必须包含一个 linger 结构，该结构将被复制到为套接字维护的内部 linger 结构中。
//
// linger 结构的 l_onoff 成员决定了在调用 closesocket 函数后，套接字是否应保持打开状
// 态以发送排队的数据。有些令人困惑的是，此成员可以通过两种方式修改：
//  *   调用 setsockopt 函数，将 optname 参数设置为 SO_DONTLINGER。optval 参数决定了如何修改 l_onoff 成员。
//  *   调用 setsockopt 函数，将 optname 参数设置为 SO_LINGER。optval 参数指定了如何修改 l_onoff 和 l_linger 成员。
//
// linger 结构的 l_linger 成员决定了套接字应保持打开状态的时间（以秒为单位）。此成员仅
// 在 linger 结构的 l_onoff 成员非零时才适用。为了使套接字保持打开状态，应用程序应将
// l_onoff 成员设置为非零值，并将 l_linger 成员设置为所需的超时时间（以秒为单位）。为了
// 禁用套接字保持打开状态，应用程序只需将 linger 结构的 l_onoff 成员设置为零。
//
// 如果应用程序调用 setsockopt 函数，将 optname 参数设置为 SO_DONTLINGER 以将 l_onoff
// 成员设置为非零值，则未指定 l_linger 成员的值。在这种情况下，使用的超时时间取决于实现。
// 如果之前为套接字设置了超时时间（通过启用 SO_LINGER），服务提供程序应恢复此超时值。
//
// 可以调用 getsockopt 函数，将 optname 参数设置为 SO_LINGER，以检索与套接字关联的当
// 前 linger 结构的值。
//
// SO_DONTLINGER 类型 DWORD（布尔值）- 指示与套接字关联的 linger 结构的 l_onoff 成员
// 的状态。如果此成员为非零值，则在调用 closesocket 函数后，套接字将保持打开状态一段时
// 间，以便发送排队的数据。此选项仅适用于可靠的、面向连接的协议。
//
// SO_LINGER 类型 struct linger - 指示与套接字关联的 linger 结构的状态。如果 linger
// 结构的 l_onoff 成员为非零值，则在调用 closesocket 函数后，套接字将保持打开状态一段
// 时间，以便发送排队的数据。保持打开状态的时间（以秒为单位）由 linger 结构的 l_linger
// 成员指定。此选项仅适用于可靠的、面向连接的协议。
//
// linger 结构成员的设置影响 closesocket 函数的行为：
//      l_onoff     l_linger    关闭类型                        是否等待关闭完成
//      0           任意        优雅关闭                              否，调用立即返回。如果可能，排队等待传输的数据将在关闭底层套接字之前发送，但连接可能还需要在返回之后在后台优雅关闭。
//      非零        0           强制关闭                              否，调用立即返回。强制关闭，套接字连接将被立即重置，任何未发送的数据都将丢失，套接字不会进入 TIME_WAIT 状态。
//      非零        非零        如果在 l_linger 指定的超时时间内发送    是，阻塞模式将阻塞到未发送的数据发送完毕或超时。
//                             所有数据，则为优雅关闭；否则为强制关闭       非阻塞模式，如果不能立即完成关闭，将返回 WSAEWOULDBLOCK，后续需要继续调用 closesocket 直到成功返回。
//
// 请注意，不建议在非阻塞套接字上启用非零超时时间。因为如果无法立即完成关闭操作，closesocket
// 调用将返回 WSAEWOULDBLOCK。此时，套接字句柄仍然有效，并且不会启动断开连接，应用程序
// 必须再次调用 closesocket 来关闭套接字。
//
// 对于阻塞套接字，closesocket 调用将会阻塞，直到所有数据已传递给对方或时间超时。如果因
// 超时到期而重置连接，则套接字不会进入 TIME_WAIT 状态。如果在超时时间内发送了所有数据，
// 则套接字可能会进入 TIME_WAIT 状态。对于 closesocket 阻塞调用，不能通过 closesocket
// 的返回结果确定所有的数据都已经发送给了对方，因为在超时时间内发送了数据已经连接被中止
// （connection aborted），closesocket 都不会返回错误。
//
// 请注意，在调用 closesocket 之后，不会发布 FD_CLOSE 网络事件。
//
// 以下是 closesocket 行为的总结：
//  1.  如果 LINGER 结构的 l_onoff 成员为零（套接字的默认值），则 closesocket 立即
//      返回，连接将在后台优雅关闭。Windows 套接字提供程序可能无法在预期时限内释放套接
//      字和其他资源，从而影响期望使用所有可用套接字的应用程序。这是套接字的默认行为。
//  2.  如果将 linger 结构的 l_onoff 成员设置为非零值，并且 l_linger 成员设置为零
//      （无超时），则 closesocket 立即返回，连接将被重置或终止。
//  3.  如果将 linger 结构的 l_onoff 成员设置为非零值，并且 l_linger 成员设置为非零
//      超时时间：对于阻塞套接字，closesocket 将阻塞直到所有数据发送完毕或超时到期；
//      对于非阻塞套接字，closesocket 立即返回 WSAEWOULDBLOCK，表示失败。
//
// 平稳关闭、留置选项和套接字关闭
// https://learn.microsoft.com/en-us/windows/desktop/WinSock/graceful-shutdown-linger-options-and-socket-closure-2
//
// 以下内容旨在澄清关闭套接字连接和关闭套接字之间的区别。这两个概念非常重要。关闭套接字
// 连接涉及两个端点之间协议消息的交换，被称为关闭序列。关闭序列分为两类：平稳关闭和强制
// 关闭（也称为硬关闭）。在平稳关闭序列中，可以在关闭连接之前发送所有已排队但尚未传输的
// 数据。在强制关闭中，任何未发送的数据都会丢失。无论哪种关闭序列发生（平稳或强制），都
// 可以向相关应用程序提供 FD_CLOSE 指示，表明关闭正在进行。
//
// 关闭套接字则会导致套接字句柄被释放，从而使应用程序无法再以任何方式引用或使用该套接字。
// 在 Windows Sockets 中，shutdown 函数和 WSASendDisconnect 函数都可以用来启动关闭
// 序列，而 closesocket 函数则用于释放套接字句柄并释放任何相关资源。然而，closesocket
// 函数会隐式地触发一个关闭序列，如果尚未发生的话。实际上，许多程序员依赖这一特性，使用
// closesocket 来同时启动关闭序列和释放套接字句柄。
//
// 为了方便这种用法，套接字接口通过套接字选项机制提供了控制功能，允许程序员指定隐式关闭
// 序列应该是平稳的还是强制的，以及 closesocket 函数是否应该留置（即不立即完成）以允许
// 平稳关闭序列完成。这种用法的重要性以及由此产生的影响仍然没有被广泛理解。
//
// 通过为 SO_LINGER 和 SO_DONTLINGER 套接字选项设置适当的值，可以在调用 closesocket
// 时实现以下行为：
//  *   强制关闭序列，closesocket 立即返回。
//  *   平稳关闭，延迟返回，直到关闭序列完成或指定的时间间隔到期。如果在平稳关闭序列完成
//      之前时间间隔到期，则会发生强制关闭序列，closesocket 返回。
//  *   平稳关闭，closesocket 立即返回——允许关闭序列在后台完成。虽然这是默认行为，但应
//      用程序无法知道（或是否）平稳关闭序列实际完成的时间。
//
// 为了最小化连接拆除期间出现问题的可能性，应避免依赖 closesocket 隐式启动关闭。相反，
// 使用 shutdown 或 WSASendDisconnect 中的两个显式关闭函数。这会导致对等应用程序接收
// 到 FD_CLOSE 指示，表明所有待处理数据已接收。以下表格显示了应用程序的客户端和服务器组
// 件将调用的函数，其中客户端负责启动平稳关闭。
//
//  客户端                                        服务器端
//  (1) 调用 shutdown(s, SD_SEND) 以指示会话结束，
//      客户端没有更多数据要发送。                  (2) 接收 FD_CLOSE，表明平稳关闭正在进行，所有数据已接收。
//                                                (3) 发送任何剩余的响应数据。
//  (local timing significance only) 调用 recv    (4) 调用 shutdown(s, SD_SEND) 以指示服务器没有更多数据
//      获取服务器发送的任何响应数据。                  要发送。
//  (5) 接收 FD_CLOSE 指示。                       (local timing significance only) 调用 closesocket。
//  (6) 调用 closesocket。
//
// 连接建立与拆除。WSAAccept 函数允许应用程序在决定是否接受传入连接请求之前，通过回调应
// 用程序提供的条件函数，获取呼叫者信息，如呼叫者身份标识和服务质量。只要服务提供程序支
// 持此功能，WSAConnect 函数的参数和 WSAAccept 的条件函数指定的用户到用户数据，可以在
// 建立连接时传输到对等方。
//
// 对于支持此功能的协议，也可以在连接拆除时在端点之间交换用户数据。发起拆除的一端可以调用
// WSASendDisconnect 函数，表明不再发送数据并启动连接拆除序列。对于某些协议，拆除的一部
// 分是从拆除发起者处传递断开连接数据。在收到远端已发起拆除的通知后（通常通过 FD_CLOSE
// 指示），可以调用 WSARecvDisconnect 函数来接收断开连接数据（如果有的话）。
//
// 为了说明如何使用断开连接数据，考虑以下场景。客户端负责终止客户端/服务器应用程序中的套
// 接字连接。在终止的同时，它提供了（使用断开连接数据）与服务器处理的事务总数。服务器反
// 过来响应所有客户端处理的事务总数。调用和指示的顺序可能如下：
//
//  客户端                                          服务器端
//  (1) 调用 WSASendDisconnect 以结束会话并提供事务
//      总数。                                      (2) 收到 FD_CLOSE，recv 返回值为零，或 WSARecv 返回
//                                                     的 WSAEDISCON 错误，表明正在执行平稳关闭。
//                                                 (3) 调用 WSARecvDisconnect 以获取客户端的事务总数。
//                                                 (4) 计算所有事务的累计总数。
//                                                 (5) 调用 WSASendDisconnect 以发送总数。
//  (6) 收到 FD_CLOSE 指示。                        (5a) 调用 closesocket。
//  (7) 调用 WSARecvDisconnect 以接收并存储事务总数。
//  (8) 调用 closesocket。
//  注意，步骤 (5a) 必须在步骤 (5) 之后执行，但与步骤 (6)、(7) 或 (8) 没有时间关系。

void prh_setsockopt_linger_disable(prh_handle socket) {
    LINGER linger = {.l_onoff = 0, .l_linger = 0};
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_LINGER, (char *)&linger, (int)sizeof(linger));
    prh_wsa_prerr_if(n != 0);
}

void prh_setsockopt_linger_enable(prh_handle socket, prh_u16 keep_open_time_secs) {
    LINGER linger = {.l_onoff = 1, .l_linger = keep_open_time_secs};
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_LINGER, (char *)&linger, (int)sizeof(linger));
    prh_wsa_prerr_if(n != 0);
}

void prh_setsockopt_linger_enable_with_default_keep_open_time(prh_handle socket) {
    DWORD enable = 0; // 在套接字连接上启动发送保活数据包
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_DONTLINGER, (char *)&enable, (int)sizeof(enable));
    prh_wsa_prerr_if(n != 0);
}

bool prh_getsockopt_linger(prh_handle socket, prh_u16 *keep_open_time_secs) {
    LINGER linger = {0};
    int optlen = (int)sizeof(linger);
    int n = getsockopt((SOCKET)socket, SOL_SOCKET, SO_LINGER, (char *)&linger, &optlen);
    prh_wsa_prerr_if(n != 0);
    *keep_open_time_secs = linger.l_linger;
    return linger.l_onoff != 0;
}

#if PRH_DEBUG
void prh_impl_test_print_linger(prh_handle socket) {
    prh_u16 keep_open_time_secs = 0;
    bool enable = prh_getsockopt_linger(socket, &keep_open_time_secs);
    printf("TEST: linger %d keep_open_time_secs %d\n", enable, keep_open_time_secs);
}
#endif

// shutdown 函数可以用来禁用发送和接收，TCP 禁止接收后，如果仍有排队等待接收的数据或后
// 续有数据到达，连接将被重置。TCP 禁止发送后，在所有数据发送并被接收方确认后将发送 FIN
// 数据包。
//
// 应用程序不应依赖 shutdown 套接字后重用套接字，特别是 Windows 套接字提供程序并不要求
// 必须强制支持在已 shutdown 的套接字上使用 connect。如果应用程序希望重用套接字，应该
// 调用 DisconnectEx 并设置 TF_REUSE_SOCKET，当 DisconnectEx 请求完成时，可以将套接
// 字句柄传递给 AcceptEx 或 ConnectEx 函数。TransmitFile 或 TransmitPackets 函数也
// 有同样的行为，TF_DISCONNECT 和 TF_REUSE_SOCKET。但是要注意，套接字级别的连接断开
// 受底层传输行为的影响，例如 TCP 套接字 TIME_WAIT 状态的影响，导致 DisconnectEx、
// TransmitFile 或 TransmitPackets 调用被延迟。
//
// 当 TCP 处于 TIME_WAIT 状态时，套接字对不能被重用。(The TIME_WAIT state determines
// the time that must elapse before TCP can release a closed connection and reuse
// its resources. While in the TIME_WAIT state, a socket pair cannot be re-used.)
//
// 处于 TIME_WAIT 状态的是主动关闭连接的那一端，该间隔等于网络最大报文段生命周期（MSL，
// Maximum Segment Lifetime）的两倍，其目的是：
//  1.  保证最后发出的 ACK 能被对方收到
//  2.  防止在本次连接中 “迷途” 的报文段被误认为是下一次使用相同四元组的新连接中的合法
//      数据，相当于保证清空旧连接在网络上的数据污染
//
// 因此，只要本地仍然占据着这条连接记录，任何一方都无法用完全相同的四元组再次握手成功。
// 对方如果尝试发 SYN，本地会回 RST，连接无法建立。只有当 TIME_WAIT 定时器到期、本地内
// 核把表项删除后，同一台机器才能再次使用相同的四元组。
//
// 或者改用新的本地端口，或启用了 SO_REUSEADDR / SO_LINGER / net.ipv4.tcp_tw_reuse
// 等选项（需双方内核支持且时间戳检查通过），新的连接才能顺利建立。
//
// closesocket 函数用于关闭套接字。关闭的套接字可能被立即重用，因此不要多个线程关闭同一
// 个套接字，这可能导致新创建的套接字也被关闭。关闭套接字时，如果存在还未完成的操作，这
// 些操作将以 WSA_OPERATION_ABORTED 错误而失败。

void prh_impl_iocp_force_close(struct tcp_socket *tcp) {
    prh_handle socket = tcp->socket;
    prh_setsockopt_linger_enable(socket, 0); // 套接字连接将被立即重置，任何未发送的数据都将丢失，套接字不会进入 TIME_WAIT 状态
    prh_impl_close_socket(socket);
}

// 使用 SO_REUSEADDR 和 SO_EXCLUSIVEADDRUSE
// https://learn.microsoft.com/en-us/windows/win32/winsock/using-so-reuseaddr-and-so-exclusiveaddruse
//
// 开发安全的高级网络基础设施是大多数网络应用程序开发人员的首要任务。然而，套接字安全常常
// 被忽视，尽管在考虑完整的安全解决方案时，它非常关键。套接字安全特别涉及绑定到同一端口的
// 进程，这些端口之前已被其他应用程序进程绑定。在过去，网络应用程序可能会 “劫持” 另一个
// 应用程序的端口，这很容易导致 “拒绝服务” 攻击或数据窃取（denial of service attack or
// data theft）。
//
// 一般来说，套接字安全适用于服务器端进程。更具体地说，套接字安全适用于任何接受连接并接收
// IP 数据报流量的网络应用程序。这些应用程序通常绑定到一个众所周知的端口，并且是恶意网络
//代码的常见攻击目标。
//
// 客户端应用程序不太可能是此类攻击的目标——不是因为它们更不容易受到攻击，而是因为大多数客
// 户端绑定到 “临时” 本地端口，而不是静态的 “服务” 端口。客户端网络应用程序应始终绑定到
// 临时端口（通过在调用 bind 函数时，将指向 SOCKADDR 结构的 name 参数指定为端口 0），除
// 非有令人信服的架构原因不这么做。临时本地端口是大于 49151 的端口，大多数专用服务的服务
// 器应用程序绑定到小于或等于 49151 的知名保留端口。因此，对于大多数应用程序来说，客户端
// 和服务器应用程序之间的绑定请求通常不会发生冲突。
//
// 对于 TCP/IP，如果端口指定为零，则服务提供程序将从动态客户端端口范围中为应用程序分配
// 一个唯一的端口。在 Windows Vista 及更高版本中，动态客户端端口范围是 [49152, 65535]。
// Windows Server 2003 及更早版本的动态客户端端口范围是 [1025, 5000] 之间的值。
//
// 本节描述了各种 Microsoft Windows 平台上的默认安全级别，以及特定的套接字选项 SO_REUSEADDR
// 和 SO_EXCLUSIVEADDRUSE 如何影响网络应用程序的安全性。在 Windows Server 2003 及更高
// 版本中，提供了一种称为增强套接字安全的附加功能。这些套接字选项和增强套接字安全的可用性
// 在 Microsoft 操作系统的不同版本中有所不同，如下表所示。
//
//      平台                    SO_REUSEADDR    SO_EXCLUSIVEADDRUSE     增强套接字安全（Enhanced Socket Security）
//      Windows 95              可用            不可用                      不可用
//      Windows 98              可用            不可用                      不可用
//      Windows Me              可用            不可用                      不可用
//      Windows NT 4.0          可用            从 Service Pack 4 开始可用  不可用
//      Windows 2000            可用            可用                        不可用
//      Windows XP              可用            可用                        不可用
//      Windows Server 2003     可用            可用                        可用
//      Windows Vista           可用            可用                        可用
//      Windows Server 2008     可用            可用                        可用
//      Windows 7 及更高版本     可用            可用                        可用
//
// 使用 SO_REUSEADDR
//
// SO_REUSEADDR 套接字选项允许一个套接字强制绑定到已被另一个套接字使用的端口。第二个套
// 接字在绑定到与原始套接字相同的端口之前，通过调用 setsockopt 并将 optname 参数设置为
// SO_REUSEADDR，optval 参数设置为布尔值 TRUE。一旦第二个套接字成功绑定，所有绑定到该
// 端口的套接字的行为将变得不确定。例如，如果所有绑定到同一端口的套接字都提供 TCP 服务，
// 那么无法保证任何传入的 TCP 连接请求都将由正确的套接字处理——行为是非确定性的。恶意程序
// 可以使用 SO_REUSEADDR 强制绑定已被标准网络协议服务使用的套接字，以拒绝对该服务的访问。
// 使用此选项不需要特殊权限。
//
// 如果客户端应用程序在服务器应用程序能够绑定到同一端口之前绑定到端口，则可能会出现问题。
// 如果服务器应用程序使用 SO_REUSEADDR 套接字选项强制绑定到同一端口，则所有绑定到该端口
// 的套接字的行为将变得不确定。
//
// 这种非确定性行为的例外是多播套接字。如果两个套接字绑定到同一接口和端口，并且是同一多播
// 组的成员，则数据将被传递到两个套接字，而不是任意选择一个。
//
// https://learn.microsoft.com/en-us/windows/win32/api/winsock2/nf-winsock2-getsockopt
//
// 默认情况下，套接字无法绑定到已经处于使用中的本地地址（参见 bind）。然而，在某些情况下，
// 可能需要以这种方式重用地址。由于每个连接都是通过本地和远程地址的组合唯一标识的，因此只
// 要远程地址不同，两个套接字绑定到同一个本地地址是没有问题的。为了告知 Windows Sockets
// 提供程序，绑定到一个套接字的地址不应因为该地址已被另一个套接字使用而被禁止，应用程序应
// 在发出 bind 之前为该套接字设置 SO_REUSEADDR 套接字选项。请注意，该选项仅在绑定时被解
// 释：因此，在不绑定到现有地址的套接字上设置该选项是不必要的（但无害的），并且在绑定之后
// 设置或重置该选项对该套接字或其他任何套接字都没有影响。SO_REUSEADDR 不适用于 ATM 套接
// 字，尽管重用地址的请求不会导致错误，但它们对 ATM 套接字的使用没有影响。
//
// 对于客户端程序，一般都绑定到动态本地端口，因此不需要使用该套接字选项。对于服务端程序，
// 监听套接字才可能需要绑定到特定的服务端口，但为了安全性，当相同的服务已经在运行时，不
// 应该启动另一个相同的服务，因此通常也不需要设置这个套接字选项。唯一的例外是，服务器主动
// 关闭了一个客户连接，并且同一个客户使用相同的地址和端口来重来，这个客户在 TIME_WAIT
// 时间内重连不上。但是只要客户使用动态端口，这种情况不会发生。另外，服务端可以不主动关闭
// 连接，即使需要主动关闭的情况下，可以使用强制主动重置连接，此时 TCP 不会进入 TIME_WAIT
// 状态。
//
// 使用 SO_EXCLUSIVEADDRUSE
//
// 在引入 SO_EXCLUSIVEADDRUSE 套接字选项之前，网络应用程序开发人员几乎无法阻止恶意程序
// 绑定到网络应用程序已绑定套接字的端口。为了应对这一安全问题，Windows Sockets 引入了
// SO_EXCLUSIVEADDRUSE 套接字选项，该选项从 Windows NT 4.0 的 Service Pack 4 (SP4)
// 开始可用。
//
// 通过在套接字绑定之前调用 setsockopt 函数，并将 optname 参数设置为 SO_EXCLUSIVEADDRUSE，
// optval 参数设置为布尔值 TRUE 来设置 SO_EXCLUSIVEADDRUSE 选项。设置该选项后，后续绑
// 定调用的行为将根据每个绑定调用中指定的网络地址而有所不同。
//
// SO_EXCLUSIVEADDRUSE 套接字选项只能由 Windows XP 及更早版本中的管理员安全组成员使用。
// 在 Windows Server 2003 及更高版本中，这一要求发生了变化。下表描述了在 Windows XP
// 及更早版本中，当第二个套接字尝试绑定到已被第一个套接字绑定的地址时发生的行为。注意下表
// 中，“通配符” 表示给定协议的通配符地址（IPv4 的 “0.0.0.0” 和 IPv6 的 “::”）。“特定”
// 表示分配给接口的特定 IP 地址。表中的单元格指示绑定是否成功（“成功”）或返回错误（“INUSE”
// 表示 WSAEADDRINUSE 错误；“ACCESS”表示 WSAEACCES 错误）。
//
//      第一次绑定调用            第二次绑定调用
//                                  默认            SO_REUSEADDR    SO_EXCLUSIVEADDRUSE
//                                  通配符  特定    通配符  特定    通配符  特定
//      默认                通配符  INUSE   INUSE   成功    成功    INUSE   INUSE
//                          特定    INUSE   INUSE   成功    成功    INUSE   INUSE
//      SO_REUSEADDR        通配符  INUSE   INUSE   成功    成功    INUSE   INUSE
//                          特定    INUSE   INUSE   成功    成功    INUSE   INUSE
//      SO_EXCLUSIVEADDRUSE 通配符  INUSE   INUSE   ACCESS  ACCESS  INUSE   INUSE
//                          特定    INUSE   INUSE   ACCESS  ACCESS  INUSE   INUSE
//
// 当两个套接字绑定到同一端口号但位于不同的显式接口上时，不会发生冲突。例如，在计算机有两
// 个 IP 接口（10.0.0.1 和 10.99.99.99）的情况下，如果第一次绑定调用是在 10.0.0.1 上，
// 端口设置为 5150，并且指定了 SO_EXCLUSIVEADDRUSE，则第二次在 10.99.99.99 上绑定，端
// 口也设置为 5150，且未指定任何选项的调用将成功。然而，如果第一个套接字绑定到通配符地址
// 和端口 5150，则任何后续绑定到端口 5150 并设置了 SO_EXCLUSIVEADDRUSE 的调用都将失败，
// 绑定操作将返回 WSAEADDRINUSE 或 WSAEACCES。
//
// 如果第一次绑定调用设置了 SO_REUSEADDR 或未设置任何套接字选项，则第二次绑定调用将 “劫持”
// 端口，应用程序将无法确定两个套接字中哪一个接收了发送到 “共享” 端口的特定数据包。典型调
// 用 bind 函数的应用程序不会为绑定的套接字分配独占使用，除非在调用 bind 函数之前在套接
// 字上设置了 SO_EXCLUSIVEADDRUSE 套接字选项。如果客户端应用程序在服务器应用程序绑定到
// 同一端口之前绑定到临时端口或特定端口，则可能会出现问题。服务器应用程序可以通过在调用
// bind 函数之前在套接字上使用 SO_REUSEADDR 套接字选项强制绑定到同一端口，但此时所有绑
// 定到该端口的套接字的行为将变得不确定。如果服务器应用程序尝试使用 SO_EXCLUSIVEADDRUSE
// 套接字选项以独占方式使用端口，则请求将失败。
//
// 相反，设置了 SO_EXCLUSIVEADDRUSE 的套接字在套接字关闭后不一定能够立即被重用。例如，
// 如果设置了 SO_EXCLUSIVEADDRUSE 的监听套接字接受了一个连接，然后随后被关闭，另一个套
// 接字（也设置了 SO_EXCLUSIVEADDRUSE）将无法绑定到与第一个套接字相同的端口，直到原始
// 连接变为非活动状态。
//
// 这个问题可能会变得复杂，因为底层传输协议可能不会在套接字关闭后终止连接。即使应用程序已
// 经关闭了套接字，系统仍必须传输任何缓冲的数据，向对等方发送优雅的断开连接消息，并等待对
// 等方的相应优雅断开连接消息。有可能底层传输协议永远不会释放连接；例如，参与原始连接的对
// 等方可能会发布零大小的窗口，或者某种其他形式的 “攻击” 配置。在这种情况下，尽管请求关闭
// 连接，但客户端连接仍然处于活动状态，因为未确认的数据仍然保留在缓冲区中。
//
// 为了避免这种情况，网络应用程序应通过调用 shutdown 并设置 SD_SEND 标志，然后在 recv
// 循环中等待，直到连接上返回零字节，从而确保优雅关闭。这可以保证所有数据都被对等方接收，
// 并且同样确认已接收对等方传输的所有数据，同时避免上述端口重用问题。
//
// 可以在套接字上设置 SO_LINGER 套接字选项，以防止端口进入 “活动” 等待状态；然而，这是
// 不推荐的，因为它可能导致不期望的效果，例如重置连接。例如，如果对等方接收到了数据但仍未
// 确认，而本地计算机关闭了设置了 SO_LINGER 的套接字，则两台计算机之间的连接将被重置，对
// 等方将丢弃未确认的数据。选择合适的停留时间是困难的，因为较短的超时值通常会导致连接突然
// 中断，而较大的超时时间可能会使系统容易受到拒绝服务攻击（通过建立许多连接，从而阻塞大量
// 应用程序线程）。关闭具有非零停留超时值的套接字也可能导致 closesocket 调用阻塞。
//
// 注意，使用 SO_EXCLUSIVEADDRUSE 选项的套接字必须在关闭之前正确断连。未能做到这一点可
// 能会导致拒绝服务攻击，如果相关服务需要重新启动的话。
//
// 增强套接字安全
//
// 增强套接字安全是在 Windows Server 2003 发布时添加的。在以前的 Microsoft 服务器操作
// 系统版本中，套接字安全很容易让进程从毫无戒备的应用程序中劫持端口。在 Windows Server
// 2003 中，默认情况下套接字不是处于可共享状态。因此，如果应用程序希望允许其他进程重用已
// 绑定套接字的端口，则必须明确启用它。如果出现这种情况，则首次对该端口调用 bind 的套接
// 字必须在套接字上设置 SO_REUSEADDR。唯一的例外是，当第二次 bind 调用是由最初调用 bind
// 的同一用户帐户执行的。此例外仅用于提供向后兼容性。
//
// 下表描述了在 Windows Server 2003 及更高版本操作系统中，当第二个套接字尝试绑定到已被
// 第一个套接字绑定的地址时发生的行为。还请注意，此表中的两次绑定调用都是在同一个用户帐户
// 下进行的。
//
//      第一次绑定调用              第二次绑定调用
//                                  默认            SO_REUSEADDR  SO_EXCLUSIVEADDRUSE
//                                  通配符  特定    通配符  特定    通配符  特定
//      默认                通配符  INUSE   成功    ACCESS  成功    INUSE   成功
//                          特定    成功    INUSE   成功    ACCESS  INUSE   INUSE
//      SO_REUSEADDR        通配符  INUSE   成功    成功    成功    INUSE   成功
//                          特定    成功    INUSE   成功    成功    INUSE   INUSE
//      SO_EXCLUSIVEADDRUSE 通配符  INUSE   ACCESS  ACCESS  ACCESS  INUSE   ACCESS
//                          特定    成功    INUSE   成功    ACCESS  INUSE   INUSE
//
// 上表中的一些条目需要解释。例如，如果第一个调用者在特定地址上设置了 SO_EXCLUSIVEADDRUSE，
// 而第二个调用者尝试在相同端口上使用通配符地址调用 bind，则第二次绑定调用将成功。在这种
// 特定情况下，第二个调用者绑定到除第一个调用者绑定的特定地址之外的所有接口。请注意，这种
// 情况的相反情况并不成立：如果第一个调用者设置了 SO_EXCLUSIVEADDRUSE 并使用通配符标志
// 调用 bind，第二个调用者将无法使用相同的端口调用 bind。
//
// 当使用不同用户帐户进行套接字绑定调用时，套接字绑定行为会发生变化。下表指定了在 Windows
// Server 2003 及更高版本操作系统中，当第二个套接字尝试绑定到已被第一个套接字绑定的地址
// 时发生的行为，并且使用了不同的用户帐户。
//
//      第一次绑定调用              第二次绑定调用
//                                  默认            SO_REUSEADDR  SO_EXCLUSIVEADDRUSE
//                                  通配符  特定    通配符  特定    通配符  特定
//      默认                通配符  INUSE   ACCESS  ACCESS  ACCESS  INUSE   ACCESS
//                          特定    成功    INUSE   成功    ACCESS  INUSE   INUSE
//      SO_REUSEADDR        通配符  INUSE   ACCESS  成功    成功    INUSE   ACCESS
//                          特定    成功    INUSE   成功    成功    INUSE   INUSE
//      SO_EXCLUSIVEADDRUSE 通配符  INUSE   ACCESS  ACCESS  ACCESS  INUSE   ACCESS
//                          特定    成功    INUSE   成功    ACCESS  INUSE   INUSE
//
// 请注意，当绑定调用是在不同用户帐户下进行时，默认行为是不同的。如果第一个调用者未在套接
// 字上设置任何选项并绑定到通配符地址，则第二个调用者无法设置 SO_REUSEADDR 选项并成功绑
// 定到同一端口。没有设置任何选项的默认行为，也将返回错误。
//
// 在 Windows Vista 及更高版本中，可以创建一个双栈套接字，该套接字在 IPv6 和 IPv4 上运
// 行。当双栈套接字绑定到通配符地址时，给定端口将同时在 IPv4 和 IPv6 网络栈上保留，并且
// 如果设置了 SO_REUSEADDR 和 SO_EXCLUSIVEADDRUSE（如果设置），将进行相关检查。这些检
// 查必须在两个网络堆栈上都成功。例如，如果双栈 TCP 套接字设置了 SO_EXCLUSIVEADDRUSE，
// 然后尝试绑定到端口 5000，则不能有其他 TCP 套接字先前绑定到端口 5000（无论是通配符还是
// 特定）。在这种情况下，如果一个 IPv4 TCP 套接字先前绑定了端口 5000 上的回环地址，则双
// 栈套接字的绑定调用将因 WSAEACCES 而失败。
//
// 在 Windows Vista 及以上版本上，创建 “双栈套接字” 只需 3 步：
//  1.  创建一个 IPv6 地址族的套接字
//  2.  在绑定之前把套接字选项 IPV6_V6ONLY 设成 0（允许 IPv4 映射地址）
//  3.  绑定到通配地址 in6addr_any 或指定端口即可
//
// 此后，这一个套接字就能同时接收 IPv4 与 IPv6 的入站连接，也能向两种地址族发起出站连接。
// 仅在 Windows Vista 及以后支持；XP/2003 需分别建 IPv4、IPv6 两个套接字。必须在 bind
// 前关闭 IPV6_V6ONLY，否则默认仅允许 IPv6 。客户端 connect 时，把 IPv4 地址写成映射形
// 式 ::ffff:a.b.c.d 即可，系统会自动走 IPv4 路径。
//
// 应用程序策略
//
// 在开发套接字层运行的网络应用程序时，重要的是要考虑所需的套接字安全类型。客户端应用程序，
// 连接或向服务发送数据的应用程序，很少需要任何额外的步骤，因为它们绑定到随机的本地（临时）
// 端口。如果客户端确实需要特定的本地端口绑定才能正常工作，则必须考虑套接字安全。
//
// 除了多播套接字（数据被传递到绑定在同一端口上的所有套接字）之外，SO_REUSEADDR 选项在正
// 常应用程序中的用途很少。否则，任何设置了此套接字选项的应用程序都应该重新设计以去除依赖，
// 因为它极易受到 “套接字劫持” 的攻击。只要 SO_REUSEADDR 套接字选项可以用于在服务器应用
// 程序中潜在地劫持端口，该应用程序就必须被视为不安全的。
//
// 所有服务器应用程序都必须设置 SO_EXCLUSIVEADDRUSE，以实现高级别的套接字安全。它不仅防
// 止恶意软件劫持端口，还可以指示是否有其他应用程序绑定到请求的端口。例如，如果一个具有
// SO_EXCLUSIVEADDRUSE 套接字选项的进程在通配符地址上绑定，而另一个进程当前在特定接口上
// 绑定到同一端口，则该绑定调用将失败。
//
// 最后，尽管 Windows Server 2003 中的套接字安全有所改进，但应用程序始终应该设置 SO_EXCLUSIVEADDRUSE
// 套接字选项，以确保它绑定到进程请求的所有特定接口。Windows Server 2003 中的套接字安全
// 为遗留应用程序增加了安全级别，但应用程序开发人员仍然必须在设计产品时全面考虑所有安全
// 因素。

void prh_setsockopt_reuseaddr(prh_handle socket, bool enable) {
    DWORD reuseaddr = enable;
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_REUSEADDR, (char *)&reuseaddr, (int)sizeof(DWORD));
    prh_wsa_prerr_if(n != 0);
}

bool prh_getsockopt_reuseaddr(prh_handle socket) {
    DWORD reuseaddr = 0;
    int n = getsockopt((SOCKET)socket, SOL_SOCKET, SO_REUSEADDR, (char *)&reuseaddr, (int)sizeof(DWORD));
    prh_wsa_prerr_if(n != 0);
    return reuseaddr != 0;
}

void prh_setsockopt_exclusiveaddruse(prh_handle socket, bool enable) {
    DWORD exclusiveaddruse = enable;
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_EXCLUSIVEADDRUSE, (char *)&exclusiveaddruse, (int)sizeof(DWORD));
    prh_wsa_prerr_if(n != 0);
}

void prh_getsockopt_exclusiveaddruse(prh_handle socket) {
    DWORD exclusiveaddruse = 0;
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_EXCLUSIVEADDRUSE, (char *)&exclusiveaddruse, (int)sizeof(DWORD));
    prh_wsa_prerr_if(n != 0);
    return exclusiveaddruse != 0;
}

// SO_PORT_SCALABILITY 套接字选项通过允许在本地计算机上为不同的本地地址和端口对多次分配
// 通配符端口，从而最大化端口分配，实现本地端口的可扩展性。
//
// 注意，在同时支持 SO_PORT_SCALABILITY 和 SO_REUSE_UNICASTPORT 的平台上，建议优先使
// 用 SO_REUSE_UNICASTPORT。
//
// 代理服务器环境由于本地端口可用性有限而存在可扩展性问题。一种解决方法是为机器添加更多的
// IP 地址。然而，默认情况下，使用 bind 函数的通配符端口仅限于本地计算机的动态端口范围大
// 小（最多 64K 端口，但通常更少），无论本地计算机上有多少 IP 地址。解决此问题需要应用程
// 序维护自己的端口池，可以使用端口预留或启发式方法。
//
// 为了避免每个需要可扩展性的应用程序都管理自己的端口池，并在保持应用程序兼容性的同时实现
// 更大的可扩展性，Windows Server 2008 引入了 SO_PORT_SCALABILITY 套接字选项，以帮助
// 最大化通配符端口分配。通过允许应用程序为每个唯一的本地地址和端口对分配通配符端口，从而
// 最大化端口分配。因此，如果本地计算机有四个 IP 地址，则可以通过通配符绑定函数请求分配多
// 达 256K 的通配符端口（64K 端口 × 4 个 IP 地址）。
//
// 当在套接字上设置了 SO_PORT_SCALABILITY 套接字选项，并对指定地址和通配符端口（name
// 参数设置为特定地址和端口 0）调用 bind 函数时，Winsock 将为指定地址分配一个端口。此分
// 配将基于本地计算机上所有可能的 IP 地址和每个地址上的端口。如果使用 SO_PORT_SCALABILITY
// 选项获取了通配符端口，则没有设置 SO_PORT_SCALABILITY 选项的另一个套接字无法分配该端
// 口。此限制是为了避免与假设通配符本地端口不能重用的应用程序出现向后兼容性问题。请注意，
// 这意味着使用 SO_PORT_SCALABILITY 获取大量端口的应用程序可能会使传统应用程序缺乏端口。
// 如果至少为一个地址使用 SO_PORT_SCALABILITY 获取了所有可用的临时端口，则在没有套接字
// 选项的情况下，不再可能进行通配符端口分配。
//
// 简而言之，SO_PORT_SCALABILITY 可以 bind(ip_1, 0) 动态绑定到端口 a 之后，可以继续
// 调用 bind(ip_2, 0) 动态绑定到相同的端口 a，即使得每个 IP 地址有一个独立的端口分配
// 空间。
//
// 为了产生任何效果，必须在调用 bind 函数之前设置 SO_PORT_SCALABILITY 选项。以下概述了
// 如何在具有两个地址的计算机上使用此选项的示例：
//  1.  进程调用 socket 函数创建一个套接字。
//  2.  调用 setsockopt 函数在新创建的套接字上启用 SO_PORT_SCALABILITY 套接字选项。
//  3.  调用 bind 函数将套接字绑定到本地计算机的一个 IP 地址和端口 0。
//  4.  调用 connect 函数连接到远程 IP 地址。应用程序需使用该套接字。
//  5.  同一进程（可能是不同的线程）调用 socket 函数创建第二个套接字。
//  6.  调用 setsockopt 函数在新创建的第二个套接字上启用 SO_PORT_SCALABILITY 选项。
//  7.  调用 bind 函数，将套接字绑定到本地计算机的第二个 IP 地址和端口 0。即使所有端口
//      都已预先分配，此调用也会成功，因为本地计算机上有多个 IP 地址，并且在同一个进程的
//      两个套接字上都设置了 SO_PORT_SCALABILITY 套接字选项。
//  8.  调用 connect 函数连接到远程 IP 地址。应用程序需使用第二个套接字。
//
// SO_REUSE_UNICASTPORT DWORD（布尔值）- 设置后，允许需要显式绑定的 Winsock API 连接
// 函数（例如 ConnectEx）重用临时端口。请注意，具有隐式绑定的连接函数（例如没有显式绑定
// 的 connect）默认已设置此选项。如果平台同时支持这两种选项，请使用此选项而不是 SO_PORT_SCALABILITY。

void prh_setsockopt_reuse_unicastport(prh_handle socket, bool enable) {
    DWORD reuseport = enable;
#ifdef SO_REUSE_UNICASTPORT
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_REUSE_UNICASTPORT, (char *)&reuseport, (int)sizeof(DWORD));
#else
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_PORT_SCALABILITY, (char *)&reuseport, (int)sizeof(DWORD));
#endif
    prh_wsa_prerr_if(n != 0);
}

bool prh_getsockopt_reuse_unicastport(prh_handle socket) {
    DWORD reuseport = 0;
#ifdef SO_REUSE_UNICASTPORT
    int n = getsockopt((SOCKET)socket, SOL_SOCKET, SO_REUSE_UNICASTPORT, (char *)&reuseport, (int)sizeof(DWORD));
#else
    int n = getsockopt((SOCKET)socket, SOL_SOCKET, SO_PORT_SCALABILITY, (char *)&reuseport, (int)sizeof(DWORD));
#endif
    prh_wsa_prerr_if(n != 0);
    return reuseport != 0;
}

// int setsockopt(SOCKET s, int level, int optname, const char *optval, int optlen);
// int getsockopt(SOCKET s, int level, int optname, char *optval, [in, out] int *optlen);
//
// setsockopt 函数设置套接字选项。如果没有错误发生，setsockopt 返回零。否则返回 SOCKET_ERROR，
// 可以通过调用 WSAGetLastError 获取特定的错误代码。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEFAULT           optval 参数所指向的缓冲区不在进程地址空间的有效部分，或者
//                          optlen 参数太小。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提
//                          供程序仍在处理回调函数。
//      WSAEINVAL           level 参数无效，或者 optval 参数所指向缓冲区中的信息无效。
//      WSAENETRESET        当设置 SO_KEEPALIVE 时，连接已超时。
//      WSAENOPROTOOPT      选项对于指定的提供程序或套接字是未知的或不支持的（请参阅
//                          SO_GROUP_PRIORITY 的限制）。
//      WSAENOTCONN         当设置 SO_KEEPALIVE 时，连接已被重置。
//      WSAENOTSOCK         描述符不是套接字。
//
// 参数 s 标识套接字的描述符。参数 level 定义选项的级别（例如 SOL_SOCKET）。参数
// optname 要设置的套接字选项（例如 SO_BROADCAST）。optname 参数必须是指定级别中定义
// 的套接字选项，否则行为是未定义的。参数 optval 指向指定请求选项值的缓冲区指针。参数
// optlen，optval 参数所指向缓冲区的大小，以字节为单位。
//
// setsockopt 函数设置与任何类型、任何状态套接字关联的套接字选项的当前值。尽管选项可存
// 在于多个协议级别，但它们始终存在于套接字级别的最上层。选项影响套接字操作，例如是否在
// 正常数据流中接收紧急数据（例如 OOB 数据），以及是否可以在套接字上发送广播消息。
//
// 注意，如果在调用 bind 函数之前调用 setsockopt 函数，TCP/IP 选项将不会通过 TCP/IP
// 进行检查，直到 bind 发生。在这种情况下，setsockopt 函数调用将始终成功，但 bind 函
// 数调用可能会因早期 setsockopt 调用失败而失败。如果打开套接字，调用 setsockopt，然
// 后调用 sendto，则 Windows 套接字将执行隐式 bind 函数调用。
//
// 套接字选项有两种类型：启用或禁用功能或行为的布尔选项，以及需要整数值或结构的选项。要
// 启用布尔选项，optval 参数指向一个非零整数。要禁用选项，optval 指向一个等于零的整数。
// 对于布尔选项，optlen 参数应等于 sizeof(int)。对于其他选项，optval 指向一个包含选项
// 所需值的整数或结构，optlen 是整数或结构的长度。以下表格列出了一些由 setsockopt 函数
// 支持的常见选项。类型列标识 optval 参数所指向的数据类型。描述列提供有关套接字选项的一
// 些基本信息。有关套接字选项的更完整列表和更详细的信息（例如默认值），请参阅套接字选项
// 下的详细信息。https://learn.microsoft.com/en-us/windows/win32/winsock/socket-options
//
// level = SOL_SOCKET 更完整的信息参考 SOL_SOCKET 套接字选项。
// https://learn.microsoft.com/en-us/windows/win32/winsock/sol-socket-socket-options
//      SO_BROADCAST                BOOL    配置套接字以发送广播数据。
//      SO_CONDITIONAL_ACCEPT       BOOL    启用传入连接由应用程序接受或拒绝，而不是由协议栈接受。
//      SO_DEBUG                    BOOL    启用调试输出。Microsoft 提供程序目前不输出任何调试信息。
//      SO_DONTLINGER               BOOL    关闭时不阻塞等待未发送数据被发送。设置此选项等同于将 SO_LINGER
//                                          的 l_onoff 设置为零。
//      SO_DONTROUTE                BOOL    设置是否应将传出数据发送到套接字绑定的接口，而不是在其他接口上
//                                          路由。此选项不支持 ATM 套接字（会导致错误）。
//      SO_GROUP_PRIORITY           int     保留。
//      SO_KEEPALIVE                BOOL    启用套接字连接发送保持活动数据包。不支持 ATM 套接字（会导致错误）。
//      SO_LINGER                   LINGER  如果存在未发送数据，则关闭时停留。
//      SO_OOBINLINE                BOOL    指示应将带外数据与常规数据一起返回。此选项仅适用于支持带外数据
//                                          的面向连接的协议。有关此主题的讨论，请参阅协议无关的带外数据。
//      SO_RCVBUF                   int     指定为接收保留的每个套接字缓冲区空间的总量。
//      SO_REUSEADDR                BOOL    允许套接字绑定到已被使用的地址。有关更多信息，请参阅 bind。不
//                                          适用于 ATM 套接字。
//      SO_EXCLUSIVEADDRUSE         BOOL    启用套接字以独占方式绑定。不需要管理员权限。
//      SO_RCVTIMEO                 DWORD   设置阻塞接收调用的超时时间，以毫秒为单位。
//      SO_SNDBUF                   int     指定为发送保留的每个套接字缓冲区空间的总量。
//      SO_SNDTIMEO                 DWORD   设置阻塞发送调用的超时时间，以毫秒为单位。
//      SO_UPDATE_ACCEPT_CONTEXT    UINT_PTR        使用监听套接字的上下文更新接受套接字。
//      PVD_CONFIG                  服务提供程序依赖  此对象存储与套接字 s 关联的服务提供程序的配置信息。
//                                          此数据结构的确切格式是服务提供程序特定的。
//
// level = IPPROTO_TCP
//      请参阅 IPPROTO_TCP 套接字选项中的 TCP_NODELAY。有关 level = IPPROTO_TCP 的
//      套接字选项的更完整和详细信息，请参阅该对象选项详情。
//
// level = NSPROTO_IPX，更完整和详细信息参考 NSPROTO_IPX 套接字选项。
//      IPX_PTYPE                   int     设置 IPX 数据包类型。
//      IPX_FILTERPTYPE             int     设置接收过滤数据包类型。
//      IPX_STOPFILTERPTYPE         int     停止过滤使用 IPX_FILTERTYPE 设置的过滤类型。
//      IPX_DSTYPE                  int     设置每个发送的数据包的 SPX 头中的数据流字段的值。
//      IPX_EXTENDED_ADDRESS        BOOL    设置是否启用扩展寻址。
//      IPX_RECVHDR                 BOOL    设置是否在所有接收头中发送协议头。
//      IPX_RECEIVE_BROADCAST       BOOL    指示套接字上可能有广播数据包。默认设置为 TRUE。不使用广播的应
//                                          用程序应将其设置为 FALSE，以提高系统性能。
//      IPX_IMMEDIATESPXACK         BOOL    指示 SPX 连接在发送 ACK 时不延迟。没有往返流量的应用程序应将
//                                          其设置为 TRUE，以提高性能。
//
// 不支持的 BSD 选项，以下列出了不支持 setsockopt 的 BSD 选项。
//      SO_ACCEPTCONN               BOOL    返回套接字是否处于监听模式。此选项仅适用于面向连接的协议。此套
//                                          接字选项不支持设置。
//      SO_RCVLOWAT                 int     从 BSD UNIX 包含的套接字选项，用于向后兼容。此选项设置套接字
//                                          输入操作要处理的最小字节数。
//      SO_SNDLOWAT                 int     从 BSD UNIX 包含的套接字选项，用于向后兼容。此选项设置套接字
//                                          输出操作要处理的最小字节数。
//      SO_TYPE                     int     返回给定套接字的套接字类型（例如 SOCK_STREAM 或 SOCK_DGRAM）。
//                                          此套接字选项不支持设置套接字类型。
//
// 注意，在发出阻塞的 Winsock 调用（如 setsockopt）时，Winsock 可能需要等待网络事件才
// 能完成调用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排的异步过
// 程调用（APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发出另一个
// 阻塞 Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。

void prh_setsockopt_ipv6_accept_v4_mapped_address(prh_handle socket, int enable) {
    int ipv6_v6_only = !enable; // IPv6 监听，必须加 IPV6_V6ONLY=0 才能同时接收 v4-mapped 地址
    int n = setsockopt((SOCKET)socket, IPPROTO_IPV6, IPV6_V6ONLY, (char *)&ipv6_v6_only, (int)sizeof(int));
    prh_wsa_prerr_if(n != 0);
}

void prh_setsockopt_update_connect_context(prh_handle socket) {
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_UPDATE_CONNECT_CONTEXT, prh_null, 0);
    prh_wsa_prerr_if(n != 0);
}

void prh_setsockopt_updata_accept_context(prh_handle accept_socket, prh_handle from_listen_socket) {
    int n = setsockopt((SOCKET)accept_socket, SOL_SOCKET, SO_UPDATE_ACCEPT_CONTEXT, (char *)&from_listen_socket, (int)sizeof(SOCKET));
    prh_wsa_prerr_if(n != 0);
}

prh_u32 prh_getsockopt_connect_time(prh_handle socket) {
    // SO_CONNECT_TIME 此选项返回套接字已连接的秒数，此选项仅适用于面向连接的协议。此选
    // 项可以与 getsockopt 函数一起使用，以检查连接是否已建立。在 ConnectEx 函数调用正
    // 在进行的过程中，也可以使用此选项。如果连接已建立，SO_CONNECT_TIME 选项可以确定连
    // 接已建立的时长。如果套接字未连接，getsockopt 将返回 SOCKET_ERROR。以这种方式检查
    // 连接是必要的，以便查看已建立一段时间但未发送任何数据的连接，建议应用程序终止这些连
    // 接。
    DWORD connect_time_secs = 0;
    int n = getsockopt((SOCKET)socket, SOL_SOCKET, SO_CONNECT_TIME, (char *)&connect_time_secs, (int)sizeof(DWORD));
    prh_wsa_prerr_if(n != 0);
    // If the socket is not currently connected, the value returned is 0xFFFFFFFF.
    return connect_time_secs;
}

// 调用带有 SO_KEEPALIVE 套接字选项的 getsockopt 函数允许应用程序检索保活选项的当前状
// 态，尽管此功能通常不被使用。如果应用程序需要在套接字上启用保活数据包，它只需调用 setsockopt
// 函数来启用该选项。调用带有 SO_KEEPALIVE 套接字选项的 setsockopt 函数允许应用程序为
// 套接字连接启用保活数据包。套接字的 SO_KEEPALIVE 选项默认是禁用的（设置为 FALSE）。
//
// 启用此套接字选项后，当连接在一定间隔内未收到任何数据或确认数据包时，TCP 栈会发送保活
// 数据包。有关保活选项的更多信息，请参阅 RFC 1122 中的第 4.2.3.6 节 “Internet 主机要
// 求——通信层”，可在 IETF 网站上找到。
//
// SO_KEEPALIVE 套接字选项仅适用于支持保活概念的协议（面向连接的协议）。对于 TCP，默认
// 的保活超时时间为 2 小时，保活间隔为 1 秒。默认的保活探测次数根据 Windows 的版本而有
// 所不同。
//
// 可以使用 SIO_KEEPALIVE_VALS 控制代码为单个连接启用或禁用保活功能，并调整超时时间和间
// 隔。如果使用 SO_KEEPALIVE 启用了保活功能，则除非使用 SIO_KEEPALIVE_VALS 更改了这些
// 值，否则将使用默认的 TCP 设置作为保活超时时间和间隔。
//
// 默认的系统范围的保活超时时间可以通过 KeepAliveTime 注册表设置进行控制，该设置的值以
// 毫秒为单位。默认的系统范围的保活间隔可以通过 KeepAliveInterval 注册表设置进行控制，
// 该设置的值以毫秒为单位。
//
// 在 Windows Vista 及更高版本中，保活探测次数（数据重传次数）被设置为 10，并且无法更改。
// 在 Windows Server 2003、Windows XP 和 Windows 2000 上，默认的保活探测次数设置为 5。
// 保活探测次数可以通过 TcpMaxDataRetransmissions 和 PPTPTcpMaxDataRetransmissions
// 注册表设置进行控制。保活探测次数被设置为这两个注册表项值中较大的一个。如果此数字为 0，
// 则不会发送保活探测。如果此数字高于 255，则会被调整为 255。
//
// 在 Windows Vista 及更高版本中，只有在套接字处于已知状态（而非过渡状态）时，才能使用
// setsockopt 函数设置 SO_KEEPALIVE 套接字选项。对于 TCP，应在调用连接函数（connect、
// ConnectEx、WSAConnect、WSAConnectByList 或 WSAConnectByName）之前，或在连接请求
// 实际完成之后设置 SO_KEEPALIVE 套接字选项。如果连接函数是异步调用的，则需要等待连接完
// 成，然后才能尝试设置 SO_KEEPALIVE 套接字选项。如果应用程序在连接请求仍在进行时尝试设
// 置 SO_KEEPALIVE 套接字选项，setsockopt 函数将失败并返回 WSAEINVAL。
//
// 在 Windows Server 2003、Windows XP 和 Windows 2000 上，可以在套接字处于过渡状态
// （连接请求仍在进行中）以及已知状态时，使用 setsockopt 函数设置 SO_KEEPALIVE 套接字
// 选项。请注意，Ws2def.h 头文件会自动包含在 Winsock2.h 中，不应直接使用。

void prh_setsockopt_keepalive(prh_handle socket, bool enable) {
    DWORD keepalive = enable; // 在套接字连接上启动发送保活数据包
    int n = setsockopt((SOCKET)socket, SOL_SOCKET, SO_KEEPALIVE, (char *)&keepalive, (int)sizeof(keepalive));
    prh_wsa_prerr_if(n != 0);
}

bool prh_getsockopt_keepalive(prh_handle socket) {
    DWORD keepalive = 0;
    int n = getsockopt((SOCKET)socket, SOL_SOCKET, SO_KEEPALIVE, (char *)&keepalive, (int)sizeof(keepalive));
    prh_wsa_prerr_if(n != 0);
    return keepalive != 0;
}

// int WSAAPI ioctlsocket(SOCKET s, long cmd, [in, out] u_long *argp);
//
// ioctlsocket 函数用于控制套接字的 I/O 模式。参数 cmd 要在套接字 s 上执行的命令。参数
// argp 指向 cmd 的参数的指针。成功完成时，ioctlsocket 返回零。否则返回 SOCKET_ERROR，
// 可以通过调用 WSAGetLastError 获取特定的错误代码。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提
//                          供程序仍在处理回调函数。
//      WSAENOTSOCK         描述符 s 不是套接字。
//      WSAEFAULT           argp 参数不是用户地址空间的有效部分。
//
// ioctlsocket 函数可用于任何状态的任何套接字。它用于设置或检索与套接字相关的一些操作
// 参数，这些参数与协议和通信子系统无关。以下是在 cmd 参数中使用的支持命令及其语义：
//      FIONREAD    获取套接字接收缓冲区中可读取的数据量。argp 参数应指向一个整数，该
//                  整数将被设置为可读取的数据量。
//      FIONBIO     设置或检索套接字的阻塞模式。argp 参数应指向一个整数，非零值表示非
//                  阻塞模式，零值表示阻塞模式。
//      SIOCATMARK  检查套接字带外数据标记是否已到达。argp 参数应指向一个整数，该整数
//                  将被设置为非零值（表示已到达标记）或零（表示未到达标记）。
//
// WSAIoctl 函数用于设置或检索与套接字、传输协议或通信子系统相关联的操作参数。WSAIoctl
// 函数比 ioctlsocket 函数更强大，并支持大量可能的操作参数值。
//
// 兼容性，与 Berkeley 套接字中的 ioctl 函数相比，ioctlsocket 函数仅在套接字上执行一
// 部分功能。ioctlsocket 函数没有与 ioctl 的 FIOASYNC 等效的命令参数，SIOCATMARK 是
// ioctlsocket 唯一支持的套接字级别命令。

void prh_sock_setnonblock(prh_handle sock, int nonblock) {
    u_long set_nonblock = nonblock; // 0 blcok mode, 1 nonblock mode
    int n = ioctlsocket((SOCKET)sock, FIONBIO, &set_nonblock);
    prh_wsa_prerr_if(n != 0);
}

// int WSAAPI WSAIoctl(
//      [in]  SOCKET                             s,
//      [in]  DWORD                              dwIoControlCode,
//      [in]  LPVOID                             lpvInBuffer,
//      [in]  DWORD                              cbInBuffer,
//      [out] LPVOID                             lpvOutBuffer,
//      [in]  DWORD                              cbOutBuffer,
//      [out] LPDWORD                            lpcbBytesReturned,
//      [in]  LPWSAOVERLAPPED                    lpOverlapped,
//      [in]  LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionRoutine
// );
//
// WSAIoctl 函数用于控制套接字的模式。成功完成时，WSAIoctl 返回零。否则返回 SOCKET_ERROR，
// 可以通过调用 WSAGetLastError 获取特定的错误代码。
//      WSA_IO_PENDING      重叠操作已成功启动，操作将在稍后时间完成。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEFAULT           lpvInBuffer、lpvOutBuffer、lpcbBytesReturned、lpOverlapped 或 lpCompletionRoutine 参数未完全包
//                          含在有效的用户地址空间中，或者 cbInBuffer 或 cbOutBuffer 参数太小。
//      WSAEINVAL           dwIoControlCode 参数不是有效命令，或者指定的输入参数不可接受，或者该命令不适用于指定类型的套接字。
//      WSAEINPROGRESS      在回调正在进行时调用了该函数。
//      WSAENOTSOCK         描述符 s 不是套接字。
//      WSAEOPNOTSUPP       指定的 IOCTL 命令无法实现。例如 SIO_SET_QOS 或 SIO_SET_GROUP_QOS 中指定的 FLOWSPEC 结构无法满足。
//      WSAEWOULDBLOCK      套接字被标记为非阻塞，且请求的操作将阻塞。
//      WSAENOPROTOOPT      指定的协议上不支持套接字选项。例如，在 IPv6 套接字上尝试使用 SIO_GET_BROADCAST_ADDRESS IOCTL，或者
//                          在数据报套接字上尝试使用 TCP SIO_KEEPALIVE_VALS IOCTL。
//
// 参数 s 标识套接字的描述符。参数 dwIoControlCode 要执行的操作的控制代码。请参阅
// Winsock IOCTLs。
//
// 参数 lpvInBuffer 指向输入缓冲区的指针。参数 cbInBuffer 输入缓冲区的大小，以字节为
// 单位。参数 lpvOutBuffer 指向输出缓冲区的指针。参数 cbOutBuffer 输出缓冲区的大小，
// 以字节为单位。参数 lpcbBytesReturned 指向实际输出字节数的指针。
//
// 参数 lpOverlapped 指向 WSAOVERLAPPED 结构的指针（对于非重叠套接字将被忽略）。
// 参数 lpCompletionRoutine 指向完成例程的指针，当操作完成时调用（对于非重叠套接字将
// 被忽略）。
//
// WSAIoctl 函数用于设置或检索与套接字、传输协议或通信子系统相关联的操作参数。如果 lpOverlapped
// 和 lpCompletionRoutine 均为 NULL，则此函数中的套接字将被视为非重叠套接字。对于非重
// 叠套接字，lpOverlapped 和 lpCompletionRoutine 参数将被忽略，这使得该函数的行为类
// 似于标准的 ioctlsocket 函数，只是如果套接字 s 处于阻塞模式，该函数可能会阻塞。如果
// 套接字 s 处于非阻塞模式，当指定的操作无法立即完成时，此函数可能会返回 WSAEWOULDBLOCK。
// 在这种情况下，应用程序可以将套接字更改为阻塞模式并重新发出请求，或者使用基于 Windows
// 消息（使用 WSAAsyncSelect）或基于事件（使用 WSAEventSelect）的通知机制等待相应的网
// 络事件（例如在 SIO_ROUTING_INTERFACE_CHANGE 或 SIO_ADDRESS_LIST_CHANGE 的情况
// 下，FD_ROUTING_INTERFACE_CHANGE 或 FD_ADDRESS_LIST_CHANGE 网络事件）。
//
// 对于重叠套接字，无法立即完成的操作将被启动，完成将在稍后时间指示。返回的 lpcbBytesReturned
// 参数指向的 DWORD 值可以被忽略。当操作完成时，最终完成状态和返回的字节数可以通过适当
// 的完成方法触发时获取。
//
// 任何 IOCTL 都可能会无限期阻塞，具体取决于服务提供程序的实现。如果应用程序无法容忍
// WSAIoctl 调用中的阻塞，则建议对特别可能阻塞的 IOCTL 使用重叠 I/O，包括：
//      SIO_ADDRESS_LIST_CHANGE
//      SIO_FINDROUTE
//      SIO_FLUSH
//      SIO_GET_QOS
//      SIO_GET_GROUP_QOS
//      SIO_ROUTING_INTERFACE_CHANGE
//      SIO_SET_QOS
//      SIO_SET_GROUP_QOS
//
// 某些特定于协议的 IOCTL 也可能特别容易阻塞。请查阅相关的特定于协议的附录，了解任何可
// 用信息。
//
// dwIoControlCode 参数现在是一个 32 位实体，允许在保留与 Windows 套接字 1.1 和 Unix
// 控制代码向后兼容性的同时，为新控制代码添加协议和供应商独立性。dwIoControlCode 参数的
// 格式如下：
//      I   O   V   T       Vendor/address family               Code
//      31  30  29  28 27   26 25 24 23 22 21 20 19 18 17 16    15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0
//
// 注意 dwIoControlCode 参数中的位应从上到下按列垂直读取。因此，最左边的位是第 31 位，
// 下一个位是第 30 位，最右边的位是第 0 位。
//
// I：如果输入缓冲区对操作码有效，则设置，如 IOC_IN。
// O：如果输出缓冲区对操作码有效，则设置，如 IOC_OUT。使用输入和输出缓冲区的操作码同时设置 I 和 O。
// V：如果操作码没有参数，则设置，如 IOC_VOID。
// T：一个 2 位的量，定义 IOCTL 的类型。定义了以下值：
//      0   该 IOCTL 是标准的 Unix IOCTL 操作码，如 FIONREAD 和 FIONBIO。
//      1   该 IOCTL 是通用的 Windows 套接字版本 2 的 IOCTL 操作码。为 Windows 套接字版本 2 定义的新 IOCTL 操作码将有 T == 1。
//      2   该 IOCTL 仅适用于特定的地址族。
//      3   该 IOCTL 仅适用于特定供应商的提供程序，如 IOC_VENDOR。此类型允许公司被分配一个在供应商/地址族参数中出现的供应商编号。
//          然后，供应商可以定义特定于该供应商的新 IOCTL，而无需向注册机构注册 IOCTL，从而提供供应商灵活性和隐私。
// Vendor/Address family：一个 11 位的量，定义拥有操作码的供应商（如果 T == 3）或包含
// 操作码适用的地址族（如果 T == 2）。如果这是 Unix IOCTL 操作码（T == 0），则此参数在
// Unix 上具有与操作码相同的值。如果这是通用的 Windows 套接字版本 2 IOCTL（T == 1），
// 则此参数可以用作操作码参数的扩展，以提供额外的操作码值。
// Code：一个 16 位的量，包含特定于操作的 IOCTL 操作码。
//
// 如果重叠操作立即完成，WSAIoctl 返回零值，并且 lpcbBytesReturned 参数将被更新为输出
// 缓冲区中的字节数。如果重叠操作已成功启动且稍后完成，此函数返回 SOCKET_ERROR 并指示
// 错误代码 WSA_IO_PENDING。在这种情况下，lpcbBytesReturned 不会被更新。当重叠操作完
// 成时，输出缓冲区中的数据量通过完成例程中的 cbTransferred 参数（如果已指定）或 WSAGetOverlappedResult
// 中的 lpcbTransfer 参数指示。
//
// 当使用重叠套接字调用时，lpOverlapped 参数必须在整个重叠操作期间有效。lpOverlapped
// 参数包含 WSAOVERLAPPED 结构的地址。如果 lpCompletionRoutine 参数为 NULL，则当重
// 叠操作完成且 lpOverlapped 中包含有效的事件对象句柄时，lpOverlapped 的 hEvent 参数
// 将被触发。应用程序可以使用 WSAWaitForMultipleEvents 或 WSAGetOverlappedResult 在
// 事件对象上等待或轮询。
//
// 注意，当给定线程退出时，该线程启动的所有 I/O 都将被取消。对于重叠套接字，如果在线程
// 关闭之前操作未完成，则挂起的异步操作可能会失败。有关更多信息，请参阅 ExitThread。
//
// 如果 lpCompletionRoutine 不为 NULL，则忽略 hEvent 参数，应用程序可以使用它将上下
// 文信息传递给完成例程。传递非 NULL lpCompletionRoutine 的调用者稍后为相同的重叠 I/O
// 请求调用 WSAGetOverlappedResult 时，不得将该调用的 fWait 参数设置为 TRUE。在这种
// 情况下，hEvent 参数的使用是未定义的，尝试等待 hEvent 参数将产生不可预测的结果。
//
// 完成例程的原型如下：
//      void CALLBACK CompletionRoutine(
//          IN DWORD dwError,
//          IN DWORD cbTransferred,
//          IN LPWSAOVERLAPPED lpOverlapped,
//          IN DWORD dwFlags
//      );
//
// 此 CompletionRoutine 是应用程序定义或库定义的函数的占位符。仅当线程处于可警报状态时，
// 才会调用完成例程。要使线程进入可警报状态，请使用 WSAWaitForMultipleEvents、WaitForSingleObjectEx
// 或 WaitForMultipleObjectsEx 函数，并将 fAlertable 或 bAlertable 参数设置为 TRUE。
//
// CompletionRoutine 的 dwError 参数指定由 lpOverlapped 参数指示的重叠操作的完成状态。
// cbTransferred 参数指定返回的字节数。目前没有定义 dwFlags 标志值，其值为零。CompletionRoutine
// 函数不返回值。
//
// 从这个函数返回允许为该套接字调用另一个挂起的完成例程。完成例程可以以任何顺序被调用，
// 不一定是重叠操作完成的相同顺序。
//
// 兼容性，T == 0 的 IOCTL 操作码是 Berkeley 套接字中使用的 IOCTL 操作码的一个子集。
// 特别是，没有与 FIOASYNC 等效的命令。注意，某些 IOCTL 操作码需要额外的头文件。例如，
// 使用 SIO_RCVALL IOCTL 需要 Mstcpip.h 头文件。
//
// https://learn.microsoft.com/en-us/windows/win32/winsock/winsock-ioctls
//
// Winsock IOCTLs，可以使用 WSAIoctl 或 WSPIoctl 函数发出 Winsock IOCTL，以控制套
// 接字、传输协议或通信子系统的模式。dwIoControlCode 参数的设计允许在添加新的控制码时
// 实现协议和供应商的独立性，同时保留与 Windows 套接字 1.1 和 Unix 控制码的向后兼容性。
//
// Unix IOCTL 操作码，以下是受支持的 Unix IOCTL 操作码（命令）。
//      FIONBIO     在套接字 s 上启用或禁用非阻塞模式。lpvInBuffer 参数指向一个非零
//                  值的无符号长整型（QoS），以启用非阻塞模式，零值则禁用非阻塞模式。
//                  创建套接字时，默认为阻塞模式（即非阻塞模式被禁用）。这与 BSD 套接
//                  字一致。
//                  WSAAsyncSelect 或 WSAEventSelect 会自动将套接字设置为非阻塞模
//                  式。如果已对套接字调用了 WSAAsyncSelect 或 WSAEventSelect，则
//                  尝试使用 WSAIoctl 将套接字重新设置为阻塞模式将因 WSAEINVAL 错误
//                  而失败。要将套接字重新设置为阻塞模式，应用程序必须首先通过调用
//                  WSAAsyncSelect（将 lEvent 参数设置为零）或 WSAEventSelect（将
//                  lNetworkEvents 参数设置为零）来禁用 WSAAsyncSelect 或 WSAEventSelect。
//      FIONREAD    确定可以从套接字 s 原子地读取的数据量。lpvOutBuffer 参数指向一个
//                  无符号长整型，WSAIoctl 在其中存储结果。
//                  如果 s 参数中的套接字是面向流的（例如，类型为 SOCK_STREAM），FIONREAD
//                  返回单次接收操作可以读取的总数据量；这通常与套接字上排队的总数据量
//                  相同（由于数据流是字节导向的，因此不能保证）。
//                  如果 s 参数中的套接字是面向消息的（例如，类型为 SOCK_DGRAM），FIONREAD
//                  返回可用的总字节数，而不是套接字上排队的第一个数据报（消息）的大小。
//      SIOCATMARK  确定是否已读取所有带外数据。这仅适用于已配置为内联接收任何带外数据
//                  （SO_OOBINLINE）的流式套接字（例如，类型为 SOCK_STREAM）。如果没
//                  有带外数据等待读取，则该操作返回 TRUE。否则，返回 FALSE，且套接字
//                  上执行的下一个接收操作将检索标记之前的一些或全部数据；应用程序应使
//                  用 SIOCATMARK 操作来确定是否仍有剩余数据。如果有任何普通数据在紧
//                  急（带外）数据之前，则将以顺序接收。（注意，recv 操作永远不会在同
//                  一个调用中混杂带外数据和普通数据。）lpvOutBuffer 指向一个布尔值，
//                  WSAIoctl 在其中存储结果。
//
// Windows 套接字版本 2 支持的操作码：
//
// SIO_ACQUIRE_PORT_RESERVATION (opcode setting: I, T==3)
// SIO_ADDRESS_LIST_CHANGE (opcode setting: V, T==1)
// SIO_ADDRESS_LIST_QUERY (opcode setting: O, T==1)
// SIO_APPLY_TRANSPORT_SETTING (opcode setting: I, T==3)
// SIO_ASSOCIATE_HANDLE (opcode setting: I, T==1)
// SIO_ASSOCIATE_PORT_RESERVATION (opcode setting: I, T==3)
// SIO_BASE_HANDLE (opcode setting: O, T==1)
// SIO_BSP_HANDLE (opcode setting: O, T==1)
// SIO_BSP_HANDLE_SELECT (opcode setting: O, T==1)
// SIO_BSP_HANDLE_POLL (opcode setting: O, T==1)
// SIO_CHK_QOS (opcode setting: I, O, T==3)
// SIO_CPU_AFFINITY (opcode setting: I, T==3)
// SIO_ENABLE_CIRCULAR_QUEUEING (opcode setting: V, T==1)
// SIO_FIND_ROUTE (opcode setting: O, T==1)
// SIO_FLUSH (opcode setting: V, T==1)
// SIO_GET_BROADCAST_ADDRESS (opcode setting: O, T==1)
// SIO_GET_GROUP_QOS (opcode setting: O, I, T==1)
// SIO_GET_INTERFACE_LIST (opcode setting: O, T==0)
// SIO_GET_INTERFACE_LIST_EX (opcode setting: O, T==0)
// SIO_GET_QOS (opcode setting: O, T==1)
// SIO_GET_TX_TIMESTAMP
// SIO_IDEAL_SEND_BACKLOG_CHANGE (opcode setting: V, T==0)
// SIO_IDEAL_SEND_BACKLOG_QUERY (opcode setting: O, T==0)
// SIO_KEEPALIVE_VALS (opcode setting: I, T==3)
// SIO_LOOPBACK_FAST_PATH (opcode setting: I, T==3)
// SIO_MULTIPOINT_LOOPBACK (opcode setting: V, T==1)
// SIO_MULTICAST_SCOPE (opcode setting: I, T==1)
// SIO_QUERY_RSS_PROCESSOR_INFO (opcode setting: O, T==1)
// SIO_QUERY_RSS_SCALABILITY_INFO (opcode setting: O, T==3)
// SIO_QUERY_TRANSPORT_SETTING (opcode setting: I, T==3)
// SIO_QUERY_WFP_ALE_ENDPOINT_HANDLE (opcode setting: O, T==3)
// SIO_QUERY_WFP_CONNECTION_REDIRECT_CONTEXT (opcode setting: I, T==3)
// SIO_QUERY_WFP_CONNECTION_REDIRECT_RECORDS (opcode setting: I, T==3)
// SIO_RCVALL (opcode setting: I, T==3)
// SIO_RCVALL_IGMPMCAST (opcode setting: I, T==3)
// SIO_RCVALL_MCAST (opcode setting: I, T==3)
// SIO_RELEASE_PORT_RESERVATION (opcode setting: I, T==3)
// SIO_ROUTING_INTERFACE_CHANGE (opcode setting: I, T==1)
// SIO_ROUTING_INTERFACE_QUERY (opcode setting: I, O, T==1)
// SIO_SET_COMPATIBILITY_MODE (opcode setting: I, T==3)
// SIO_SET_GROUP_QOS (opcode setting: I, T==1)
// SIO_SET_PRIORITY_HINT (opcode setting: I, T==3)
// SIO_SET_QOS (opcode setting: I, T==1)
// SIO_TCP_INITIAL_RTO (opcode setting: I, T==3)
// SIO_TIMESTAMPING
// SIO_TRANSLATE_HANDLE (opcode setting: I, O, T==1)
// SIO_UDP_CONNRESET (opcode setting: I, T==3)
// SIO_UDP_NETRESET
// SIO_SET_WFP_CONNECTION_REDIRECT_RECORDS (opcode setting: I, T==3)
// SIO_TCP_INFO (opcode setting: I, O, T==3)
//
// SIO_GET_EXTENSION_FUNCTION_POINTER (操作码设置：O, I, T==1)
//
// 检索与服务提供程序关联的指定扩展函数的指针。输入缓冲区包含一个全局唯一标识符（GUID），
// 其值标识要检索的扩展函数。输出缓冲区返回指向所需函数的指针。扩展函数标识符由服务提供
// 程序供应商建立，并应包含在描述扩展函数功能和语义的供应商文档中。

void *prh_impl_wsaioctl_extension_func(prh_handle s, GUID guid) {
    void *extension_func;
    DWORD bytes_returned = 0;
    if (WSAIoctl((SOCKET)s, SIO_GET_EXTENSION_FUNCTION_POINTER, &guid, sizeof(GUID), &extension_func, sizeof(void *), &bytes_returned, prh_null, prh_null) != 0) {
        prh_wsa_prerr();
        return prh_null;
    }
    return extension_func;
}

// 注意，必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_MULTIPLE_EXTENSION_FUNCTION_POINTER
// 操作码来获取 RIOCreateCompletionQueue 函数的函数指针。传递给 WSAIoctl 函数的输入
// 缓冲区必须包含 WSAID_MULTIPLE_RIO，这是一个全局唯一标识符（GUID），其值标识 Winsock
// RIO 扩展函数。成功时，WSAIoctl 函数返回的输出包含指向 RIO_EXTENSION_FUNCTION_TABLE
// 结构的指针，该结构包含指向 Winsock RIO 扩展函数的指针。SIO_GET_MULTIPLE_EXTENSION_FUNCTION_POINTER
// IOCTL 在 Ws2def.h 头文件中定义。WSAID_MULTIPLE_RIO GUID 在 Mswsock.h 头文件中定
// 义。
//
// typedef struct _RIO_EXTENSION_FUNCTION_TABLE {
//      DWORD                         cbSize;
//      LPFN_RIORECEIVE               RIOReceive;
//      LPFN_RIORECEIVEEX             RIOReceiveEx;
//      LPFN_RIOSEND                  RIOSend;
//      LPFN_RIOSENDEX                RIOSendEx;
//      LPFN_RIOCLOSECOMPLETIONQUEUE  RIOCloseCompletionQueue;
//      LPFN_RIOCREATECOMPLETIONQUEUE RIOCreateCompletionQueue;
//      LPFN_RIOCREATEREQUESTQUEUE    RIOCreateRequestQueue;
//      LPFN_RIODEQUEUECOMPLETION     RIODequeueCompletion;
//      LPFN_RIODEREGISTERBUFFER      RIODeregisterBuffer;
//      LPFN_RIONOTIFY                RIONotify;
//      LPFN_RIOREGISTERBUFFER        RIORegisterBuffer;
//      LPFN_RIORESIZECOMPLETIONQUEUE RIOResizeCompletionQueue;
//      LPFN_RIORESIZEREQUESTQUEUE    RIOResizeRequestQueue;
// } RIO_EXTENSION_FUNCTION_TABLE, *PRIO_EXTENSION_FUNCTION_TABLE;
#include <ws2def.h>

void prh_impl_wsaioctl_rio_extensions(prh_handle sock, void *table) {
    DWORD ioctl = SIO_GET_MULTIPLE_EXTENSION_FUNCTION_POINTER;
    GUID rios = WSAID_MULTIPLE_RIO;
    DWORD bytes_returned = 0;
    int n = WSAIoctl((SOCKET)sock, ioctl, &rios, sizeof(GUID), table, sizeof(RIO_EXTENSION_FUNCTION_TABLE), &bytes_returned, prh_null, prh_null);
    prh_wsa_abort_if(n != 0);
}

// u_long htonl(u_long hostlong);
// u_short htons(u_short hostshort);
// int WSAHtonl(SOCKET s, u_long hostlong, u_long *netlong);
// int WSAHtons(SOCKET s, u_short hostshort, u_short *netshort);
// u_long ntohl(u_long netlong);
// u_short ntohs(u_short netshort);
// int WSANtohl(SOCKET s, u_long netlong, u_long *hostlong);
// int WSANtohs(SOCKET s, u_short netshort, u_short *hostshort);
// unsigned long inet_addr(const char *ip);
// char *inet_ntoa(struct in_addr in);
// getaddrinfo
// getnameinfo
// gethostbyaddr
// gethostbyname
// gethostname
// getprotobyname
// getprotobynumber
// getservbyname
// getservbyport
// WSAAddressToString
// WSAStringToAddress
// WSAAsyncGetHostByAddr
// WSAAsyncGetHostByName
// WSAAsyncGetProtoByName
// WSAAsyncGetProtoByNumber
// WSAAsyncGetServByName
// WSAAsyncGetServByPort
// int WSACancelAsyncRequest(HANDLE async_task_handle);
//
// int getsockname(
//      [in]      SOCKET   s, // 已绑定或已连接套接字
//      [out]     sockaddr *name,
//      [in, out] int      *namelen
// );
//
// getsockname 函数用于检索套接字的本地名称。如果没有错误发生，getsockname 返回零。
// 否则返回 SOCKET_ERROR，可以通过调用 WSAGetLastError 获取具体的错误代码。
//      WSANOTINITIALISED   在使用此 API 之前，必须成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEFAULT           name 或 namelen 参数不是用户地址空间的有效部分，或者 namelen 参数太小。
//      WSAEINPROGRESS      正在执行一个阻塞的 Windows 套接字 1.1 调用，或者服务提供程序仍在处理回调函数。
//      WSAENOTSOCK         描述符不是套接字。
//      WSAEINVAL           套接字尚未使用 bind 绑定到地址，或者在 bind 中指定了 ADDR_ANY，但尚未建立连接。
//
// 参数 s 标识套接字的描述符。参数 name 指向 SOCKADDR 结构，该结构接收套接字的地址。
// 参数 namelen 指定 name 缓冲区的大小，以字节为单位。
//
// getsockname 函数检索指定套接字描述符的当前名称，并存储在 name 中。参数 s 指定已绑定
// 或已连接的套接字。当没有先 bind 的情况下调用 connect 时此调用特别有用，getsockname
// 函数是确定系统设置的本地关联的唯一方法。
//
// 在调用时，namelen 参数包含 name 缓冲区的大小，以字节为单位。返回时，namelen 参数包
// 含 name 参数的实际大小，以字节为单位。
//
// 当套接字绑定到未指定地址时（例如使用 ADDR_ANY），getsockname 函数并不总是返回主机
// 地址信息，除非套接字已通过 connect 或 accept 连接。Windows 套接字应用程序不应假设
// 地址已指定，除非套接字已连接。在多宿主主机中使用时，除非套接字已连接，否则不知道将用
// 于套接字的地址。如果套接字使用无连接协议，则在套接字上发生 I/O 之前，地址可能不可用。

void prh_sock_local_addr(prh_handle sock, struct sockaddr *addr) {
    int namelen = (addr->sa_family == AF_INET) ? (int)sizeof(struct sockaddr_in) : (int)sizeof(struct sockaddr_in6);
    if (getsockname((SOCKET)sock, addr, &namelen)) prh_wsa_abort_error(); // 以上错误正常不可能发生
    assert(namelen == sizeof(struct sockaddr_in) || namelen == sizeof(struct sockaddr_in6));
}

// int getpeername(
//      [in]      SOCKET   s, // 已连接套接字
//      [out]     sockaddr *name,
//      [in, out] int      *namelen
// );
//
// getpeername 函数用于检索已连接套接字的对端地址。如果没有错误发生，getpeername 返回
// 零。否则返回 SOCKET_ERROR，可以通过调用 WSAGetLastError 获取具体的错误代码。
//      WSANOTINITIALISED   在使用此函数之前，必须成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEFAULT           name 或 namelen 参数不在用户地址空间的有效部分中，或者 namelen 参数太小。
//      WSAEINPROGRESS      正在执行一个阻塞的 Windows 套接字 1.1 调用，或者服务提供程序仍在处理回调函数。
//      WSAENOTCONN         套接字未连接。
//      WSAENOTSOCK         描述符不是套接字。
//
// 参数 s 标识已连接套接字的描述符。参数 name 接收对端地址的 SOCKADDR 结构。参数 namelen
// 指向 name 参数大小（以字节为单位）。
//
// getpeername 函数检索与套接字 s 连接的对端地址，并将其存储在由 name 参数标识的 SOCKADDR
// 结构中。此函数适用于任何地址族，仅返回套接字连接到的地址。getpeername 函数只能用于已
// 连接的套接字。
//
// 对于数据报套接字，仅返回在先前的 connect 调用中指定的对端地址。先前的 sendto 调用中
// 指定的地址不会被 getpeername 返回。
//
// 在调用时，namelen 参数包含 name 缓冲区的大小（以字节为单位）。返回时，namelen 参数
// 包含返回的 name 参数的实际大小（以字节为单位）。

prh_u32 prh_sock_peer_addr(prh_handle sock, struct sockaddr *addr) {
    int namelen = (addr->sa_family == AF_INET) ? (int)sizeof(struct sockaddr_in) : (int)sizeof(struct sockaddr_in6);
    if (getpeername((SOCKET)sock, addr, &namelen)) {
        DWORD error_code = WSAGetLastError();
        prh_prerr(error_code);
        return error_code;
    }
    assert(namelen == sizeof(struct sockaddr_in) || namelen == sizeof(struct sockaddr_in6));
    return 0;
}

// int bind(SOCKET s, const sockaddr *name, int namelen);
//
// bind 函数将本地地址与套接字关联。如果没有错误发生，bind 返回零。否则返回 SOCKET_ERROR，
// 可以通过调用 WSAGetLastError 获取特定的错误代码。
//      WSANOTINITIALISED   注意：在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEACCES           尝试以被其访问权限禁止的方式访问套接字。如果因为未启用 setsockopt 选项 SO_BROADCAST，
//                          而将数据报套接字绑定到广播地址失败，则会返回此错误。
//      WSAEADDRINUSE       通常只允许每个套接字地址（协议/网络地址/端口）使用一次。如果计算机上的进程已经
//                          绑定到相同的完全限定地址，并且套接字未使用 SO_REUSEADDR 标记为允许地址重用，则
//                          会返回此错误。例如，name 参数中指定的 IP 地址和端口已被另一个应用程序使用的另
//                          一个套接字绑定。有关更多信息，请参阅 SOL_SOCKET 套接字选项中的 SO_REUSEADDR
//                          套接字选项、使用 SO_REUSEADDR 和 SO_EXCLUSIVEADDRUSE 以及 SO_EXCLUSIVEADDRUSE。
//      WSAEADDRNOTAVAIL    请求的地址在其上下文中无效。如果 name 参数指向的指定地址不是此计算机上的有效本
//                          地 IP 地址，则会返回此错误。
//      WSAEFAULT           系统在尝试使用指针参数进行调用时检测到无效的指针地址。如果 name 参数为 NULL，
//                          name 或 namelen 参数不是用户地址空间的有效部分，namelen 参数太小，name 参数
//                          包含与关联地址族不匹配的地址格式，或者由 name 指定的内存块的前两个字节与套接字
//                          描述符 s 关联的地址族不匹配，则会返回此错误。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINVAL           提供了无效的参数。如果套接字 s 已经绑定到地址，则会返回此错误。
//      WSAENOBUFS          由于系统缺乏足够的缓冲区空间或队列已满，无法对套接字执行操作。如果没有足够的缓
//                          冲区可用或连接过多，则会返回此错误。
//      WSAENOTSOCK         在不是套接字的对象上尝试执行操作。如果 s 参数中的描述符不是套接字，则会返回此错误。
//
// 参数 s 标识未绑定套接字的描述符。参数 name 指向本地地址的 sockaddr 结构，该地址将
// 被分配给绑定的套接字。参数 namelen 表示 name 参数所指向值的长度，以字节为单位。
//
// 在调用 listen 函数之前，未连接的套接字需要调用 bind 函数。它通常用于绑定到面向连接
// （流式）或无连接（数据报）套接字。bind 函数也可以用于绑定到原始套接字（通过调用 socket
// 函数并设置类型参数为 SOCK_RAW 创建套接字）。bind 函数也可以在调用 connect、ConnectEx、
// WSAConnect、WSAConnectByList 或 WSAConnectByName 函数之前，用于绑定到未连接的套
// 接字，以便在发送操作之前使用。
//
// 当通过调用 socket 函数创建套接字时，它存在于一个命名空间（地址族）中，但未分配任何名
// 称。使用 bind 函数通过为无名套接字分配本地名称来建立套接字的本地关联。
//
// 使用 Internet 地址族时，名称由三部分组成：地址族，主机地址，用于标识应用程序的端口号。
//
// 在 Windows 套接字版本 2 中，name 参数并不严格解释为指向 sockaddr 结构的指针。为了
// 与 Windows 套接字版本 1.1 兼容，它被强制转换为这种类型。服务提供程序可以将其视为指
// 向大小为 namelen 的内存块的指针。此内存块的前两个字节（对应于 sockaddr 结构的 sa_family
// 成员、sockaddr_in 结构的 sin_family 成员或 sockaddr_in6 结构的 sin6_family 成员）
// 必须包含用于创建套接字的地址族。否则，将发生 WSAEFAULT 错误。
//
// 如果应用程序不关心分配特定的本地地址，可以在 name 参数的 sa_data 成员中指定 IPv4 本
// 地地址的常量值 INADDR_ANY 或 IPv6 本地地址的常量值 in6addr_any。这允许底层服务提供
// 程序使用任何适当的网络地址，可能简化了在多宿主主机（即具有多个网络接口和地址的主机）
// 上进行应用程序编程。
//
// 对于 TCP/IP，如果端口指定为零，则服务提供程序将从动态客户端端口范围中为应用程序分配
// 一个唯一的端口。在 Windows Vista 及更高版本中，动态客户端端口范围是 49152 到 65535
// 之间的值。这与 Windows Server 2003 及更早版本不同，后者的动态客户端端口范围是 1025
// 到 5000 之间的值。可以通过在以下注册表项下设置值来更改客户端动态端口范围的最大值：
//      HKLM\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters
//
// MaxUserPort 注册表值设置动态客户端端口范围的最大值。必须重新启动计算机才能使此设置
// 生效。在 Windows Vista 及更高版本中，可以使用 netsh 命令查看和更改动态客户端端口范
// 围。可以分别为 UDP 和 TCP 以及 IPv4 和 IPv6 设置不同的动态客户端端口范围。有关更多
// 信息，请参阅 KB 929851。https://support.microsoft.com/kb/929851
//
// 应用程序可以在调用 bind 后使用 getsockname 了解已分配给套接字的地址和端口。如果 Internet
// 地址等于 INADDR_ANY 或 in6addr_any，则在套接字连接之前，getsockname 无法提供地址，
// 因为如果主机是多宿主的，则多个地址可能是有效的。不建议客户端应用程序绑定到除端口 0 之
// 外的特定端口号，因为存在与本地计算机上已使用该端口号的另一个套接字冲突的危险。
//
// 注意，当使用 bind 与 SO_EXCLUSIVEADDRUSE 或 SO_REUSEADDR 套接字选项时，必须在执行
// bind 之前设置套接字选项，才能产生任何影响。有关更多信息，请参阅 SO_EXCLUSIVEADDRUSE
// 和使用 SO_REUSEADDR 和 SO_EXCLUSIVEADDRUSE。
//
// 对于多播操作，推荐的方法是调用 bind 函数将套接字与本地 IP 地址关联，然后加入多播组。
// 尽管这种操作顺序不是强制性的，但强烈推荐。因此，多播应用程序将首先选择本地计算机上的
// IPv4 或 IPv6 地址、IPv4 通配符地址（INADDR_ANY）或 IPv6 通配符地址（in6addr_any）。
// 然后，多播应用程序将调用 bind 函数，并在 name 参数的 sa_data 成员中使用此地址，将本
// 地 IP 地址与套接字关联。如果指定了通配符地址，则 Windows 将选择要使用的本地 IP 地址。
// 在 bind 函数完成后，应用程序将加入感兴趣的多播组。有关如何加入多播组的更多信息，请参
// 阅多播编程部分。然后可以使用 recv、recvfrom、WSARecv、WSARecvEx、WSARecvFrom 或
// LPFN_WSARECVMSG (WSARecvMsg) 函数通过此套接字从多播组接收多播数据包。
//
// 对于向多播组发送操作，通常不需要 bind 函数。sendto、WSASendMsg 和 WSASendTo 函数
// 如果套接字尚未绑定，则会隐式地将套接字绑定到通配符地址。bind 函数在使用 send 或 WSASend
// 函数之前是必需的，这些函数不会执行隐式绑定，并且仅允许在已连接的套接字上使用，这意味
// 着套接字必须已经绑定才能连接。如果应用程序希望在具有多个网络接口和本地 IP 地址的本地
// 计算机上选择特定的本地 IP 地址，则可以在使用 sendto、WSASendMsg 或 WSASendTo 函数
// 进行发送操作之前使用 bind 函数。否则，使用 sendto、WSASendMsg 或 WSASendTo 函数进
// 行的隐式绑定可能会导致使用不同的本地 IP 地址进行发送操作。
//
// 注意，在发出阻塞的 Winsock 调用（如 bind）时，Winsock 可能需要等待网络事件才能完成
// 调用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排的异步过程调用
// （APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发出另一个阻塞
// Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。

prh_u32 prh_impl_sock_bind(prh_handle socket, struct sockaddr *local, int addrlen) {
    // bind 返回的一个常见错误时 EADDRINUSE，这涉及 SO_REUSEADDR 和 SO_REUSEPORT
    // 这两个套接字选项。SO_REUSEADDR 有一个潜在的安全问题，假设存在一个绑定到通配地
    // 址和端口5555的套接字，如果指定SO_REUSEADDR，我们就可以把相同的端口绑定到不同
    // 的IP地址上，譬如说是所在主机的主IP地址。此后目的地为端口5555及新绑定IP地址的数
    // 据报将被递送到新的套接字，而不是递送到绑定了通配地址的已有套接字。这些数据报可
    // 以是TCP的SYN报文、SCTP的INIT块或UDP数据报。
    // 为了安全起见，有些操作系统不允许对已经绑定了通配地址的端口再绑定任何更为明确的
    // 地址，也就是说不论是否预先设置 SO_REUSEADDR，对应的bind调用都会失败。在这样的
    // 系统上，执行通配地址捆绑的服务器进程必须最后一个启动。这么做是为了防止把恶意的服
    // 务器绑定到某个系统服务正在使用的IP地址和端口上，造成合法请求被截取。
    int n = bind((SOCKET)socket, local, addrlen);
    prh_u32 error_code = 0;
    if (n != 0) {
        error_code = WSAGetLastError();
        prh_prerr(error_code);
    }
    return error_code;
}

// int listen(SOCKET s, int backlog);
//
// listen 函数将套接字置于监听传入连接的状态。如果没有错误发生，listen 返回零。否则返回
// SOCKET_ERROR，可以通过调用 WSAGetLastError 获取特定的错误代码。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN	        网络子系统已失败。
//      WSAEADDRINUSE       套接字的本地地址已被使用，且套接字未使用 SO_REUSEADDR 标记为允许地址重用。此错
//                          误通常在执行 bind 函数时发生，但如果 bind 是对通配符地址（涉及 ADDR_ANY）进行
//                          的，并且需要在该函数执行时提交特定地址，则可能会延迟到此函数。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINVAL           套接字未使用 bind 绑定。
//      WSAEISCONN          套接字已连接。
//      WSAEMFILE           没有更多的套接字描述符可用。
//      WSAENOBUFS          没有可用的缓冲区空间。
//      WSAENOTSOCK         描述符不是套接字。
//      WSAEOPNOTSUPP       引用的套接字不是支持 listen 操作的类型。
//
// 参数 s 标识已绑定但未连接的套接字的描述符。参数 backlog 挂起连接队列的最大长度。如果
// 设置为 SOMAXCONN，负责套接字 s 的底层服务提供程序将把队列长度设置为一个合理的最大值。
// 如果设置为 SOMAXCONN_HINT(N)（其中 N 是一个数字），队列长度将被调整为 N，并确保在范
// 围 (200, 65535) 内。注意，SOMAXCONN_HINT 可以用来设置比 SOMAXCONN 更大的队列长度。
// 注意 SOMAXCONN_HINT 仅由 Microsoft TCP/IP 服务提供程序支持。没有标准方法可以获取实
// 际的队列长度。底层服务提供程序会将 backlog 参数静默地（silently）限制在一个合理的范
// 围内。非法值将被替换为最接近的合法值。没有标准方法可以获取实际的队列长度。
//
// 要接受连接，首先使用 socket 函数创建套接字，并使用 bind 函数将其绑定到本地地址。使用
// listen 指定传入连接的队列长度，然后使用 accept 函数接受连接。面向连接的套接字，例如
// SOCK_STREAM 类型的套接字，可以调用 listen。套接字 s 将被置于被动模式，其中传入的连
// 接请求被确认并排队，等待进程接受。
//
// SOMAXCONN 是一个特殊常量，指示负责套接字 s 的底层服务提供程序将挂起连接队列的长度设
// 置为一个合理的最大值。在 Windows 套接字版本 2 中，此最大值默认为一个较大的值（通常是
// 几百或更多）。
//
// 在蓝牙应用程序中调用 listen 函数时，强烈建议使用较低的值作为 backlog 参数（通常为 2
// 到 4），因为只接受少量客户端连接。这减少了为监听套接字分配的系统资源。此建议也适用于
// 其他仅期望少量客户端连接的网络应用程序。
//
// listen 函数通常用于可以同时处理多个连接请求的服务器。如果连接请求到达且队列已满，客
// 户端将收到一个错误，指示 WSAECONNREFUSED。
//
// 如果没有可用的套接字描述符，listen 尝试继续运行。如果描述符变得可用，后续对 listen
// 或 accept 的调用将尽可能将队列重新填充到当前或最近指定的 backlog 参数值，并恢复监听
// 连入连接（incoming connections）。
//
// 如果在已经处于监听状态的套接字上调用 listen 函数，它将成功返回而不改变 backlog 参数
// 的值。在后续对监听套接字的 listen 调用中，将 backlog 参数设置为 0 不被视为适当的重
// 置，特别是如果套接字上有连接时。
//
// 注意 在发出阻塞的 Winsock 调用（如 listen）时，Winsock 可能需要等待网络事件才能完
// 成调用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排的异步过程
// 调用（APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发出另一个
// 阻塞 Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。

prh_u32 prh_impl_sock_listen(prh_handle socket, int backlog) {
    int n = listen((SOCKET)socket, backlog);
    prh_u32 error_code = 0;
    if (n != 0) {
        error_code = WSAGetLastError();
        prh_prerr(error_code);
    }
    return error_code;
}

void prh_impl_parse_address(const char *host, int flags_port, prh_byte *family, prh_u16 *port, prh_u32 *addr) {
    *port = (prh_u16)(flags_port & 0xffff);
    if (flags_port & PRH_IPV4_BYTE_ARRAY) {
        *family = PRH_AF_IPV4;
        memcpy(addr, host, 4);
    } else if (flags_port & PRH_IPV6_BYTE_ARRAY) {
        *family = PRH_AF_IPV6;
        memcpy(addr, host, 16);
    } else if (host == prh_loopback) {
        *family = PRH_AF_IPV4;
        *addr = htonl(INADDR_LOOPBACK);
    } else if (host == prh_ipv6_loopback) {
        *family = PRH_AF_IPV6;
        *(struct in6_addr *)addr = in6addr_loopback;
    } else if (host == prh_addr_any) {
        *family = PRH_AF_IPV4;
        *addr = htonl(INADDR_ANY);
    } else if (host == prh_ipv6_addr_any) {
        *family = PRH_AF_IPV6;
        *(struct in6_addr *)addr = in6addr_any;
    } else if (prh_impl_is_ipv4_str(host)) {
        *family = PRH_AF_IPV4;
        *addr = prh_sock_ipv4_address(host);
    } else if (prh_impl_is_ipv6_str(host)) {
        *family = PRH_AF_IPV6;
        prh_sock_ipv6_address(host, (prh_byte *)addr);
    } else {
        prh_impl_abort(__LINE__); // TODO 添加域名解析
    }
}

void prh_impl_recv_sockaddr(struct sockaddr_in6 *in6, prh_u16 *port, prh_u32 *addr) {
    if (in6->sin6_family == AF_INET6) {
        *port = ntohs(in6->sin6_port);
        *(struct in6_addr *)addr = in6->sin6_addr;
    } else {
        struct sockaddr_in *in = (struct sockaddr_in *)in6;
        *port = ntohs(in->sin_port);
        *addr = in->sin_addr.s_addr;
    }
}

int prh_impl_init_sockaddr(int family, prh_u16 port, prh_u32 *addr, struct sockaddr_in6 *in6) {
    // struct sockaddr {
    //   sa_family_t sa_family;
    //   char sa_data[14];
    // };
    // struct sockaddr_in {          // 'in' is for internet
    //   sa_family_t    sin_family;  // address family: AF_INET
    //   in_port_t      sin_port;    // port in network byte-order 端口和地址必须是网络字节序
    //   struct in_addr sin_addr;    // internet address in network byte-order: struct in_addr { uint32_t s_addr; } INADDR_ANY INADDR_LOOPBACK
    //   unsigned char __pad[8];     // pad to size of sockaddr (16-byte)
    // };
    // struct sockaddr_in6 {
    //   sa_family_t     sin6_family;   // AF_INET6
    //   in_port_t       sin6_port;     // port number
    //   uint32_t        sin6_flowinfo; // IPv6 flow information
    //   struct in6_addr sin6_addr;     // IPv6 address: struct in6_addr { unsigned char s6_addr[16]; } IN6ADDR_ANY_INIT
    //   uint32_t        sin6_scope_id; // Scope ID (new in kernel 2.4)
    // };
    int namelen;
    if (family == AF_INET6) {
        in6->sin6_family = AF_INET6;
        in6->sin6_port = htons(port);
        in6->sin6_addr = *(struct in6_addr *)addr;
        namelen = (int)sizeof(struct sockaddr_in6);
    } else {
        struct sockaddr_in *in = (struct sockaddr_in *)in6;
        in->sin_family = AF_INET;
        in->sin_port = htons(port);
        in->sin_addr.s_addr = *addr;
        namelen = (int)sizeof(struct sockaddr_in);
    }
    return namelen;
}

void prh_impl_iocp_create_socket(struct tcp_socket *tcp, int family) {
    prh_handle socket = prh_impl_tcp_socket(family);
    prh_impl_iocp_attach_handle(socket);
    tcp->socket = socket;
}

// #include <winsock2.h> // ws2_32.lib ws2_32.dll
// SOCKET accept(SOCKET s, struct sockaddr *addr, int *addrlen);
// SOCKET WSAAPI WSAAccept(
//      [in]      SOCKET          s,
//      [out]     sockaddr        *addr,
//      [in, out] LPINT           addrlen,
//      [in]      LPCONDITIONPROC lpfnCondition,
//      [in]      DWORD_PTR       dwCallbackData
// );
//
// #include <mswsock.h> // mswsock.lib mswsock.dll
// BOOL AcceptEx(
//      [in]  SOCKET       sListenSocket,
//      [in]  SOCKET       sAcceptSocket, // 必须是未绑定未连接的
//      [in]  PVOID        lpOutputBuffer,
//      [in]  DWORD        dwReceiveDataLength,
//      [in]  DWORD        dwLocalAddressLength,
//      [in]  DWORD        dwRemoteAddressLength,
//      [out] LPDWORD      lpdwBytesReceived,
//      [in]  LPOVERLAPPED lpOverlapped
// );
//
// AcceptEx 函数接受新的连接，返回本地和远程地址，并接收客户端应用程序发送的第一个数据
// 块。注意，该函数是 Microsoft 对 Windows 套接字规范的特定扩展。如果没有错误发生，
// AcceptEx 函数成功完成并返回 TRUE 值。如果函数失败，AcceptEx 返回 FALSE。然后可以
// 调用 WSAGetLastError 函数以返回扩展错误信息。如果 WSAGetLastError 返回 ERROR_IO_PENDING，
// 则表示操作已成功启动且仍在进行中。如果错误是 WSAECONNRESET，则表示有传入连接，但随后
// 在接受调用之前被远程对等方终止。
//
// 参数 sListenSocket 标识已调用 listen 函数的套接字的描述符。服务器应用程序在此套接
// 字上等待连接。
//
// 参数 sAcceptSocket 标识用于接受传入连接的套接字的描述符。此套接字必须未绑定且未连接。
// 因为套接字创建开销较大，如果一个服务器希望尽可能快地处理客户连接，它就需要一个已创建
// 的套接字库，以便尽快接收新的连接。
//
// 参数 lpOutputBuffer 指向缓冲区的指针，该缓冲区接收新连接上发送的第一个数据块、服务
// 器的本地地址和客户端的远程地址。接收数据写入缓冲区的起始部分（从偏移量零开始），而地
// 址写入缓冲区的后半部分。必须指定此参数。
//
// 参数 dwReceiveDataLength 表示 lpOutputBuffer 中用于实际接收数据的字节数，位于缓冲
// 区的起始位置。此大小不应包括服务器的本地地址大小，也不应包括客户端的远程地址大小。如
// 果 dwReceiveDataLength 为零，则接受连接不会导致接收操作。相反，AcceptEx 在连接到达
// 时立即完成，而不等待任何数据。如果 dwReceiveDataLength 大于零，则重叠操作只有在连接
// 之后至少收到一个字节数据后才能完成。因此恶意的客户端可能投递许多连接，但决不发送任何
// 数据，可以使用 SO_CONNECT_TIME 套接字选项避免这种情况。
//
// 参数 dwLocalAddressLength 为本地地址信息保留的字节数。此值必须至少比使用的传输协
// 议的最大地址长度多 16 字节。
//
// 参数 dwRemoteAddressLength 为远程地址信息保留的字节数。此值必须至少比使用的传输协
// 议的最大地址长度多 16 字节。不能为零。
//
// 参数 lpdwBytesReceived 指向 DWORD 的指针，用于接收实际收到的数据字节数。仅当操作同
// 步完成时，才设置此参数。如果返回 ERROR_IO_PENDING 并稍后完成，则此 DWORD 永远不会被
// 设置，必须从完成通知机制中获取读取的字节数。
//
// 参数 lpOverlapped 用于处理请求的 OVERLAPPED 结构。必须指定此参数；它不能为 NULL。
//
// AcceptEx 函数将多个套接字函数合并为一个 API 或内核切换。当成功时，AcceptEx 函数执行
// 三个任务：
//  1.  接受新的连接。
//  2.  返回连接的本地和远程地址。
//  3.  接收远程发送的第一个数据块。
//
// 使用 AcceptEx 而不是 accept 函数，可以更快地建立与套接字的连接。单个输出缓冲区接收
// 数据、本地套接字地址（服务器）和远程套接字地址（客户端）。使用单个缓冲区可以提高性能。
// 当使用 AcceptEx 时，必须调用 GetAcceptExSockaddrs 函数将缓冲区解析为其三个不同的
// 部分（数据、本地套接字地址和远程套接字地址）。在 Windows XP 及更高版本中，一旦 AcceptEx
// 函数完成并且在已接受的套接字上设置了 SO_UPDATE_ACCEPT_CONTEXT 选项，就可以使用
// getsockname 函数检索与已接受套接字关联的本地地址。同样，可以使用 getpeername 函数
// 检索与已接受套接字关联的远程地址。
//
// 本地和远程地址的缓冲区大小必须比使用的传输协议的 sockaddr 结构大小多 16 字节，因为
// 地址以内部格式写入。例如，sockaddr_in（TCP/IP 的地址结构）的大小为 16 字节。因此，
// 必须为本地和远程地址指定至少 32 字节的缓冲区大小。
//
// 与 accept 函数不同，AcceptEx 函数使用重叠 I/O。如果您的应用程序使用 AcceptEx，它
// 可以使用相对较少的线程来服务大量客户端。与所有重叠的 Windows 函数一样，可以使用 Windows
// 事件或完成端口作为完成通知机制。AcceptEx 函数与 accept 函数的另一个关键区别是，AcceptEx
// 要求调用者已经拥有两个套接字：
//  1.  一个指定用于监听的套接字。
//  2.  一个指定用于接受连接的套接字。
//
// sAcceptSocket 参数必须是一个未绑定且未连接的打开套接字。GetQueuedCompletionStatus
// 函数或 GetOverlappedResult 函数的 lpNumberOfBytesTransferred 参数指示请求中接收
// 的字节数。当此操作成功完成时，可以传递 sAcceptSocket，但只能传递给以下函数：
//  - ReadFile
//  - WriteFile
//  - send
//  - WSASend
//  - recv
//  - WSARecv
//  - TransmitFile
//  - closesocket
//  - setsockopt（仅用于 SO_UPDATE_ACCEPT_CONTEXT）
//
// 注意，如果使用 TF_DISCONNECT 和 TF_REUSE_SOCKET 标志调用 TransmitFile 函数，则指
// 定的套接字已返回到既未绑定也未连接的状态。然后可以将套接字句柄传递给 AcceptEx 函数的
// sAcceptSocket 参数，但不能将套接字传递给 ConnectEx 函数。
//
// 当 AcceptEx 函数返回时，套接字 sAcceptSocket 处于已连接套接字的默认状态。直到在套
// 接字上设置 SO_UPDATE_ACCEPT_CONTEXT 选项后，套接字 sAcceptSocket 才继承与 sListenSocket
// 参数关联的套接字的属性。使用 setsockopt 函数设置 SO_UPDATE_ACCEPT_CONTEXT 选项，
// 指定 sAcceptSocket 作为套接字句柄，sListenSocket 作为选项值。
//      // Need to #include <mswsock.h> for SO_UPDATE_ACCEPT_CONTEXT
//      int iResult = 0;
//      iResult = setsockopt(sAcceptSocket, SOL_SOCKET, SO_UPDATE_ACCEPT_CONTEXT,
//          (char *)&sListenSocket, sizeof(sListenSocket));
//
// 如果提供了接收缓冲区，则重叠操作不会完成，直到接受连接并读取数据。使用 getsockopt
// 函数和 SO_CONNECT_TIME 选项检查是否已接受连接。如果已接受连接，您可以确定连接已建立
// 多长时间。返回值是套接字已连接的秒数。如果套接字未连接，则 getsockopt 返回 0xFFFFFFFF。
// 结合 SO_CONNECT_TIME 选项检查重叠操作是否完成的应用程序可以确定连接已接受但未接收数
// 据。以这种方式检查连接使应用程序能够确定已建立一段时间但未接收数据的连接。建议通过关闭
// 已接受的套接字来终止此类连接，这将强制 AcceptEx 函数调用以错误完成。
//      INT seconds;
//      INT bytes = sizeof(seconds);
//      int iResult = 0;
//      iResult = getsockopt(sAcceptSocket, SOL_SOCKET, SO_CONNECT_TIME, (char *)&seconds, (PINT)&bytes);
//      if (iResult != NO_ERROR) {
//          printf("getsockopt(SO_CONNECT_TIME) failed: %u\n", WSAGetLastError());
//          exit(1);
//      }
//
// 注意，当给定线程退出时，该线程启动的所有 I/O 都将被取消。对于重叠套接字，如果在线程
// 关闭之前操作未完成，则挂起的异步操作可能会失败。有关更多信息，请参阅 ExitThread。
//
// 关于 QoS 的注意事项，TransmitFile 函数允许设置两个标志，TF_DISCONNECT 或 TF_REUSE_SOCKET，
// 在文件传输完成后将套接字返回到“未连接，可重用”状态。不应在请求了服务质量的套接字上使
// 用这些标志，因为服务提供程序可能会在文件传输完成之前立即删除与套接字关联的任何服务质
// 量。对于启用了 QoS 的套接字，最好的方法是在文件传输完成后简单地调用 closesocket 函
// 数，而不是依赖这些标志。
//
// VOID GetAcceptExSockaddrs(
//      [in]  PVOID    lpOutputBuffer,
//      [in]  DWORD    dwReceiveDataLength,
//      [in]  DWORD    dwLocalAddressLength,
//      [in]  DWORD    dwRemoteAddressLength,
//      [out] sockaddr **LocalSockaddr,
//      [out] LPINT    LocalSockaddrLength,
//      [out] sockaddr **RemoteSockaddr,
//      [out] LPINT    RemoteSockaddrLength
// );
//
// GetAcceptExSockaddrs 函数解析从 AcceptEx 函数调用中获得的数据，并将本地和远程地址
// 传递给 sockaddr 结构。注意该函数是 Microsoft 对 Windows 套接字规范的特定扩展。
//
// 参数 lpOutputBuffer 指向从 AcceptEx 调用返回的连接上发送的第一个数据块的缓冲区的
// 指针。必须与传递给 AcceptEx 函数的 lpOutputBuffer 参数相同。
//
// 参数 dwReceiveDataLength 用于接收第一个数据的缓冲区中的字节数。此值必须等于传递给
// AcceptEx 函数的 dwReceiveDataLength 参数。
//
// 参数 dwLocalAddressLength 为本地地址信息保留的字节数。此值必须等于传递给 AcceptEx
// 函数的 dwLocalAddressLength 参数。
//
// 参数 dwRemoteAddressLength 为远程地址信息保留的字节数。此值必须等于传递给 AcceptEx
// 函数的 dwRemoteAddressLength 参数。
//
// 参数 LocalSockaddr 指向 sockaddr 结构的指针，该结构接收连接的本地地址（与 getsockname
// 函数返回的信息相同）。必须指定此参数。
//
// 参数 LocalSockaddrLength 本地地址的大小，以字节为单位。必须指定此参数。
//
// 参数 RemoteSockaddr 指向 sockaddr 结构的指针，该结构接收连接的远程地址（与 getpeername
// 函数返回的信息相同）。必须指定此参数。
//
// 参数 RemoteSockaddrLength 远程地址的大小，以字节为单位。必须指定此参数。
//
// GetAcceptExSockaddrs 函数专门与 AcceptEx 函数一起使用，用于将套接字接收到的第一个
// 数据解析为本地和远程地址。AcceptEx 函数以内部格式返回本地和远程地址信息。如果需要包
// 含本地或远程地址的 sockaddr 结构，应用程序开发人员需要使用 GetAcceptExSockaddrs
// 函数。
//
// 一个服务器最常见的动作是接收客户连接，微软扩展函数 AcceptEx 是唯一一个通过重叠 I/O
// 方式接收客户连接的 Winsock 函数。前面已经提到，AcceptEx 函数需要预先创建一个客户套
// 接字用于接收客户连接，这个套接字必须是未绑定且未连接，当然也可以重用调用 TransmitFile、
// TransmitPackets、DisconnectEx 等函数后的套接字。
//
// 可响应的服务器必须总是有足够多的 AcceptEx 调用，用来立即接收到来的客户请求。TCP/IP
// 协议栈亏自动代表监听应用程序接收连接，直到 backlog 设置的限制数量。对于 Windows NT
// 服务器，这个值最大可以是 200。如果服务器投递 15 个 AcceptEx 调用，然后瞬间有 50 个
// 连接同时到来，那么有 15 个连接将立即被 AcceptEx 处理，然后 35 个被内核协议栈自动接
// 收，不会有连接请求被拒绝。然后服务器可以继续投递额外的 AcceptEx 调用，这些调用会立即
// 成功返回，因为已经有排队的待处理的连接在队列中等待。
//
// 决定要发布多少个 AcceptEx 操作对服务器的行为起着重要作用。例如，预计要处理来自大量
// 客户端的许多短生命周期连接的服务器，可能希望发布比处理较少但生命周期更长的连接的服务
// 器更多的并发 AcceptEx 操作。一个良好的策略是允许 AcceptEx 调用的数量在低水位和高水
// 位之间变化。应用程序可以跟踪挂起的 AcceptEx 操作的数量。然后，当这些操作中的一个或
// 多个完成且挂起的数量低于设定的水位时，可以发布更多的 AcceptEx 调用。当然，如果在某
// 个时刻一个 AcceptEx 完成且挂起的接受数量大于或等于高水位，则在处理当前 AcceptEx 时
// 不应发布额外的调用。初始时可以创建低水位的 AcceptEx（accept_min_burst_requests），
// 每当一个 AcceptEx 完成时接收的客户请求继续处理，同时创建一个新的 AcceptEx 维持接收
// 客户请求的数量不小于低水位，但有一个同时处理客户请求的最大数量限制（concurrent_process_requests），
// 同时处理的请求超出这个数量，不再创建新的 AcceptEx。当客户请求处理完毕，会将这个现有
// 的客户套接字重用来创建 AcceptEx，直到达到 accept_min_burst_requests，多余的套接字
// 关闭。如果在单位时间内接收的请求数量激增，可以将 AcceptEx 维持的水位从低水位提高到
// 高水位（accept_max_burst_requests），当请求数量下降时再切回到低水位。
//
// 尽管在处理来自完成端口通知的工作线程中发布 AcceptEx 请求似乎更合乎逻辑且更简单，但
// 应避免这样做，因为套接字创建过程是昂贵的。此外，应避免在工作线程中进行任何复杂的计算，
// 以便服务器能够尽可能快速地处理完成通知。套接字创建昂贵的一个原因是 Winsock 2.0 的分
// 层架构。当服务器创建一个套接字时，它可能会通过多个提供程序，每个提供程序都会执行自己
// 的任务，然后才会创建并返回套接字给应用程序。相反，服务器应该从一个单独的线程中创建客
// 户端套接字并发布 AcceptEx 操作。当工作线程中的重叠 AcceptEx 完成时，可以使用事件来
// 通知接受 AcceptEx 发布线程。
//
// 同一个线程可以多次调用 AcceptEx 投递多个重叠 I/O 操作，只要每次使用独立的 OVERLAPPED、
// 缓冲区和客户套接字即可。在监听套接字上，可以一次性投递多个 AcceptEx 请求，以应对突发
// 连接高峰。这些请求会以 “先入先出” 的方式被完成端口处理，无需等待前一个完成再投递下一
// 个。
//
// AcceptEx 的完成通知会通过 IOCP 返回，你可以安全地并发处理多个连接请求。投递的 AcceptEx
// 操作完成时会通过 GetQueuedCompletionStatus 返回，你可以通过 lpCompletionKey 和
// lpOverlapped 区分是哪个 AcceptEx 完成。

#define PRH_IMPL_ACCEPT_V4_ADDRSIZE (int)(sizeof(struct sockaddr_in) + 16)
#define PRH_IMPL_ACCEPT_V6_ADDRSIZE (int)(sizeof(struct sockaddr_in6) + 16)
void prh_impl_iocp_accept_req(struct prh_impl_accept_v6_req *req);
prh_static_assert(WSA_IO_PENDING == ERROR_IO_PENDING);

struct tcp_socket *prh_impl_iocp_alloc_tcp_socket(prh_alloc_free alloc) {
    struct tcp_socket *tcp = prh_memory_alloc(alloc, PRH_TCP_SOCKET_STRUCT_SIZE);
    memset(tcp, 0, sizeof(struct tcp_socket));
    return tcp;
}

void prh_impl_iocp_prepare_accept_socket(struct tcp_listen *listen, struct prh_impl_accept_v6_req *accept_req, struct tcp_socket *socket) {
    accept_req->accept = socket;
    memset(&socket->flags, 0, sizeof(socket->flags));
    socket->flags.server_accept = true;
    socket->family = listen->family;
    socket->callback = listen->callback;
    socket->context = listen;
}

void prh_impl_iocp_listen_resue_socket(struct tcp_listen *listen, struct tcp_socket *socket) {
    bool empty_idle_accept_found = false;
    struct prh_impl_accept_v6_req *idle_accept = prh_null;
    prh_snode *idle_node = &listen->accept_idle_chain;
    assert(socket->flags.server_accept);
    assert(socket->flags.closed);
    if (listen->connection_count > 0) { // 只有连接成功的 tcp_socket 才会传递给上层
        listen->connection_count -= 1;
    }

    for (; idle_node->next; idle_node = idle_node->next) {
        idle_accept = (struct prh_impl_accept_v6_req *)idle_node->next;
        if (idle_accept->accept == prh_null) {
            prh_impl_iocp_prepare_accept_socket(listen, idle_accept, socket);
            empty_idle_accept_found = true;
            break;
        }
    }
    if (!empty_idle_accept_found) {
        prh_memory_free(listen->alloc, socket);
    }

    int num_accept_can_request = listen->same_time_connections - listen->connection_count;
    if (idle_accept && listen->curr_outgoing_reqs < num_accept_can_request) {
        listen->curr_outgoing_reqs += 1;
        idle_node->next = ((prh_snode *)idle_accept)->next; // 移除该空闲节点
        prh_impl_iocp_accept_req(idle_accept); // 此时 idle_accept->accept 一定不为空
    }
}

bool prh_impl_sched_synced_listen_reuse_socket(prh_iocp_thrd_req *thrd_req) {
    struct tcp_socket *socket = (void *)thrd_req->post_req;
    struct tcp_listen *listen = socket->context;
    prh_impl_iocp_listen_resue_socket(listen, socket);
    return false;
}

void prh_iocp_listen_reuse_socket(struct tcp_listen *listen, struct tcp_socket *socket) {
    socket->context = listen;
    prh_sched_thrd_synced_post(socket, prh_impl_sched_synced_listen_reuse_socket);
}

bool prh_impl_sched_synced_idle_accept_req(prh_iocp_thrd_req *thrd_req) {
    struct prh_impl_accept_v6_req *accept_req = (void *)thrd_req->post_req;
    struct tcp_listen *listen = (void *)accept_req->overlapped.hEvent;
    int num_accept_can_request = listen->same_time_connections - listen->connection_count;
    if (listen->curr_outgoing_reqs < num_accept_can_request) {
        listen->curr_outgoing_reqs += 1;
        if (accept_req->accept == prh_null) {
            prh_impl_iocp_prepare_accept_socket(listen, accept_req, prh_impl_iocp_alloc_tcp_socket(listen->alloc));
        }
        prh_impl_iocp_accept_req(accept_req);
    } else { // 将 accept_req 插入空闲列表
        prh_snode *idle_node = (prh_snode *)accept_req;
        idle_node->next = listen->accept_idle_chain.next;
        listen->accept_idle_chain.next = idle_node;
    }
    return false;
}

void prh_impl_iocp_accept_continue(void *overlapped) {
    struct prh_impl_accept_v6_req *req = (struct prh_impl_accept_v6_req *)overlapped;
    struct tcp_socket *tcp = req->accept;
    struct tcp_listen *listen = tcp->context;
    prh_u32 error_code = (prh_u32)((OVERLAPPED *)overlapped)->Internal;
    if (error_code) {
        // PRH_ECONN_FAILURE 操作无法执行，套接字模块没有启动，内存不足，网卡崩溃，指定的套接字操作正在执行或者已经连接
        //      WSANOTINITIALISED   在使用此函数之前，必须成功调用 WSAStartup。
        //      WSAEINTR            通过 WSACancelBlockingCall 取消了一个阻塞的 Windows Sockets 1.1 调用。
        //      WSAEINPROGRESS      一个阻塞的 Windows Sockets 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
        //      WSAEMFILE           在进入 accept 时队列非空，但没有可用的描述符。
        //      WSAENETDOWN         网络子系统已失败。
        //      WSAENOBUFS          没有可用的缓冲区空间。
        //      WSAEWOULDBLOCK      套接字被标记为非阻塞，且没有连接可供接受。
        // PRH_ECONN_INVALID 无效参数，无效内存，无效地址长度，accept前未调用listen
        //      WSAEFAULT           addrlen 参数太小，或者 addr 不是用户地址空间的有效部分。
        //      WSAEINVAL           在调用 accept 之前，未调用 listen 函数。
        //      WSAENOTSOCK         描述符不是套接字。
        //      WSAEOPNOTSUPP       引用的套接字不是支持面向连接服务的类型。
        // PRH_ECONN_RESETED 连接被对方重置而终止
        //      WSAECONNRESET       已指示一个传入连接，但在接受调用之前，该连接已被远程对等方终止。
        if (error_code == WSAECONNRESET) { // 如果错误是 WSAECONNRESET，则表示有传入连接，但随后在接受调用之前被远程对等方终止
            error_code = PRH_ECONN_RESETED;
        } else if (error_code == WSAEFAULT || error_code == WSAEINVAL || error_code == WSAENOTSOCK || error_code == WSAEOPNOTSUPP) {
            error_code = PRH_ECONN_INVALID;
        } else {
            prh_abort_error(error_code);
        }
        req->overlapped.hEvent = (HANDLE)listen;
        prh_sched_thrd_synced_post(req, prh_impl_sched_synced_idle_accept_req);
        listen->callback->conn_rsp(listen->context, error_code, prh_null);
    } else {
        struct sockaddr_in6 l_addr, p_addr;
        INT l_addrlen = 0, p_addrlen = 0;
        DWORD addrbuf_length;
        prh_debug(INT addrlen; int family);
        if (listen->family == PRH_AF_IPV6) {
            prh_debug(family = AF_INET6; addrlen = sizeof(struct sockaddr_in6));
            addrbuf_length = PRH_IMPL_ACCEPT_V6_ADDRSIZE;
        } else {
            prh_debug(family = AF_INET; addrlen = sizeof(struct sockaddr_in));
            addrbuf_length = PRH_IMPL_ACCEPT_V4_ADDRSIZE;
        }
        PRH_IMPL_GETACCEPTEXSOCKADDRS(
            /* [in]  PVOID    lpOutputBuffer        */ &req->addr,
            /* [in]  DWORD    dwReceiveDataLength   */ 0,
            /* [in]  DWORD    dwLocalAddressLength  */ addrbuf_length,
            /* [in]  DWORD    dwRemoteAddressLength */ addrbuf_length,
            /* [out] sockaddr **LocalSockaddr       */ (sockaddr *)&l_addr,
            /* [out] LPINT    LocalSockaddrLength   */ &l_addrlen,
            /* [out] sockaddr **RemoteSockaddr      */ (sockaddr *)&p_addr,
            /* [out] LPINT    RemoteSockaddrLength  */ &p_addrlen
            );
        assert(l_addrlen == addrlen);
        assert(p_addrlen == addrlen);
        assert(l_addr.sin6_family == family);
        assert(p_addr.sin6_family == family);
        prh_impl_recv_sockaddr(&l_addr, &tcp->l_port, &tcp->l_addr);
        prh_impl_recv_sockaddr(&p_addr, &tcp->p_port, &tcp->p_addr);
        req->accept = prh_null;
        req->overlapped.hEvent = (HANDLE)listen;
        prh_sched_thrd_synced_post(req, prh_impl_sched_synced_idle_accept_req);
        tcp->context = listen->context;
        tcp->flags.opened = true;
        tcp->callback->conn_rsp(tcp->context, 0, tcp);
    }
}

void prh_impl_iocp_accept_immediately_complete(struct prh_impl_accept_v6_req *req, prh_u32 error_code) {
    assert(error_code != 0);
    req->overlapped.Internal = error_code;
    prh_iocp_thrd_post(&req->overlapped, prh_impl_iocp_accept_continue);
}

void prh_impl_iocp_accept_completed_from_port(void *overlapped) {
    struct prh_impl_accept_v6_req *req = (struct prh_impl_accept_v6_req *)overlapped;
    struct tcp_listen *listen = req->accept->context;
    if (req->overlapped.Internal == 0 && listen->connection_count < listen->same_time_connections) {
        listen->connection_count += 1; // 成功接收连接
    }
    listen->curr_outgoing_reqs -= 1;
    prh_impl_iocp_sched_thrd_post(overlapped, prh_impl_iocp_accept_continue);
}

void prh_impl_iocp_accept_req(struct prh_impl_accept_v6_req *req) {
    struct tcp_socket *tcp = req->accept; assert(tcp != prh_null);
    struct tcp_listen *listen = tcp->context; assert(listen != prh_null);
    int family; DWORD addrbuf_length;
    if (listen->family == PRH_AF_IPV6) {
        family = AF_INET6;
        addrbuf_length = PRH_IMPL_ACCEPT_V6_ADDRSIZE;
    } else {
        family = AF_INET;
        addrbuf_length = PRH_IMPL_ACCEPT_V4_ADDRSIZE;
    }
    if (tcp->socket == PRH_INVASOCK) {
        prh_impl_iocp_create_socket(tcp, family);
    }
    assert(listen->socket != PRH_INVASOCK);
    req->overlapped.hEvent = prh_null; // 确保完成操作被投递到完成端口
    BOOL b = PRH_IMPL_ACCEPTEX(
        /* [in]  SOCKET       sListenSocket         */  (SOCKET)listen->socket,
        /* [in]  SOCKET       sAcceptSocket         */  (SOCKET)tcp->socket, // 必须是未绑定未连接的套接字句柄
        /* [in]  PVOID        lpOutputBuffer        */  &req->addr,
        /* [in]  DWORD        dwReceiveDataLength,  */  0,
        /* [in]  DWORD        dwLocalAddressLength, */  addrbuf_length,
        /* [in]  DWORD        dwRemoteAddressLength,*/  addrbuf_length,
        /* [out] LPDWORD      lpdwBytesReceived,    */  prh_null, // 仅操作同步完成时才设置此参数，如果 ERROR_IO_PENDING 永远不会被设置，必须从完成机制中获取读取的字节数
        /* [in]  LPOVERLAPPED lpOverlapped          */  &req->overlapped
        );
    // 如果一个句柄与完成端口关联，即使异步请求以同步方式完成，其结果仍然会被添加到完成端口队列中
    // 不管当前完成端口上有没有排队的新连接，都走 “发起→挂起→完成” 流程，代码统一使用重叠模型编写，无需关注操作同步完成的分支
    DWORD error_code;
    if (b || (error_code = WSAGetLastError()) == WSA_IO_PENDING) { // 请求立即完成或已经成功投递
        prh_impl_iocp_set_continue_routine(&req->overlapped, prh_impl_iocp_accept_completed_from_port);
    } else {
        listen->curr_outgoing_reqs -= 1;
        prh_prerr(error_code);
        if (error_code == 0) error_code = WSAEINVAL;
        prh_impl_iocp_accept_immediately_complete(req, error_code);
    }
}

struct tcp_listen *prh_iocp_tcp_server(prh_alloc_free alloc, struct tcp_callback *callback, void *context, int outgoing_accept_reqs, int same_time_connections, int accept_rate_per_second) {
    if (alloc == prh_null) alloc = prh_impl_default_alloc_free;
    if (same_time_connections <= 0) same_time_connections = 1; // 至少可以服务一个客户
    if (outgoing_accept_reqs > same_time_connections) {
        outgoing_accept_reqs = same_time_connections; // 同时发出接收连接请求的数量，大于最大连接数是一种浪费
    }
    prh_unt alloc_size = PRH_TCP_LISTEN_STRUCT_SIZE + outgoing_accept_reqs * PRH_TCP_ACCEPT_STRUCT_SIZE;
    struct tcp_listen *listen = prh_memory_alloc(alloc, alloc_size);
    memset(listen, 0, alloc_size);
    listen->socket = PRH_INVASOCK;
    listen->callback = callback;
    listen->context = context;
    listen->alloc = alloc;
    listen->outgoing_accept_reqs = outgoing_accept_reqs;
    listen->same_time_connections = same_time_connections;
    listen->accept_rate_per_second = accept_rate_per_second;
    struct prh_impl_accept_req *accept_req = (struct prh_impl_accept_req *)((prh_byte *)listen + PRH_TCP_LISTEN_STRUCT_SIZE);
    struct prh_impl_accept_req *accept_end = accept_req + outgoing_accept_reqs;
    for (; accept_req < accept_end; accept_req += 1) {
        prh_impl_iocp_prepare_accept_socket(listen, (struct prh_impl_accept_v6_req *)accept_req, prh_impl_iocp_alloc_tcp_socket(alloc));
    }
    return listen;
}

bool prh_impl_sched_synced_listen_start_accept_req(prh_iocp_thrd_req *thrd_req) {
    struct tcp_listen *listen = (void *)thrd_req->post_req;
    struct prh_impl_accept_req *accept_req = (struct prh_impl_accept_req *)((prh_byte *)listen + PRH_TCP_LISTEN_STRUCT_SIZE);
    struct prh_impl_accept_req *accept_end = accept_req + listen->outgoing_accept_reqs;
    prh_handle listen_socket = listen->socket;
    prh_impl_iocp_attach_handle(listen_socket);
    listen->curr_outgoing_reqs = listen->outgoing_accept_reqs;
    for (; accept_req < accept_end; accept_req += 1) {
        struct tcp_socket *tcp = ((struct prh_impl_accept_v6_req *)accept_req)->accept;
        tcp->family = listen->family;
        prh_impl_iocp_create_socket(tcp, family);
        prh_impl_iocp_accept_req((struct prh_impl_accept_v6_req *)accept_req);
    }
    return false;
}

int prh_iocp_tcp_listen(struct tcp_listen *listen, const char *host, int flags_port, int backlog) {
    if (listen->socket != PRH_INVASOCK) { prh_prerr(__LINE__); return; }
    prh_u16 l_port; prh_u32 l_addr[4];
    prh_impl_parse_address(host, flags_port, &listen->family, &l_port, l_addr);
    int family = (listen->family == PRH_AF_IPV6) ? AF_INET6 : AF_INET;
    prh_handle listen_socket = prh_impl_tcp_socket(family);
    listen->socket = listen_socket;
    // 所有服务器应用程序都必须设置 SO_EXCLUSIVEADDRUSE，以实现高级别的套接字安全。它
    // 不仅防止恶意软件劫持端口，还可以指示是否有其他应用程序绑定到请求的端口。
    prh_setsockopt_exclusiveaddruse(listen_socket, true);
    // bind 函数将本地地址与套接字关联。如果没有错误发生，bind 返回零。否则返回 SOCKET_ERROR，可以通过调用
    // WSAGetLastError 获取特定的错误代码。
    // WSANOTINITIALISED   注意：在调用此函数之前，必须先成功调用 WSAStartup。
    // WSAENETDOWN         网络子系统已失败。
    // WSAEACCES           尝试以被其访问权限禁止的方式访问套接字。如果因为未启用 setsockopt 选项 SO_BROADCAST，
    //                     而将数据报套接字绑定到广播地址失败，则会返回此错误。
    // WSAEADDRINUSE       通常只允许每个套接字地址（协议/网络地址/端口）使用一次。如果计算机上的进程已经
    //                     绑定到相同的完全限定地址，并且套接字未使用 SO_REUSEADDR 标记为允许地址重用，则
    //                     会返回此错误。例如，name 参数中指定的 IP 地址和端口已被另一个应用程序使用的另
    //                     一个套接字绑定。有关更多信息，请参阅 SOL_SOCKET 套接字选项中的 SO_REUSEADDR
    //                     套接字选项、使用 SO_REUSEADDR 和 SO_EXCLUSIVEADDRUSE 以及 SO_EXCLUSIVEADDRUSE。
    // WSAEADDRNOTAVAIL    请求的地址在其上下文中无效。如果 name 参数指向的指定地址不是此计算机上的有效本
    //                     地 IP 地址，则会返回此错误。
    // WSAEFAULT           系统在尝试使用指针参数进行调用时检测到无效的指针地址。如果 name 参数为 NULL，
    //                     name 或 namelen 参数不是用户地址空间的有效部分，namelen 参数太小，name 参数
    //                     包含与关联地址族不匹配的地址格式，或者由 name 指定的内存块的前两个字节与套接字
    //                     描述符 s 关联的地址族不匹配，则会返回此错误。
    // WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
    // WSAEINVAL           提供了无效的参数。如果套接字 s 已经绑定到地址，则会返回此错误。
    // WSAENOBUFS          由于系统缺乏足够的缓冲区空间或队列已满，无法对套接字执行操作。如果没有足够的缓
    //                     冲区可用或连接过多，则会返回此错误。
    // WSAENOTSOCK         在不是套接字的对象上尝试执行操作。如果 s 参数中的描述符不是套接字，则会返回此错误。
    struct sockaddr_in6 in6_local = {0};
    int addrlen = prh_impl_init_sockaddr(family, l_port, l_addr, &in6_local);
    prh_u32 error_code = prh_impl_sock_bind(listen_socket, (struct sockaddr *)&in6_local, addrlen);
    if (error_code) goto label_error_handle;
    // listen 函数将套接字置于监听传入连接的状态。如果没有错误发生，listen 返回零。否则返回 SOCKET_ERROR，
    // 可以通过调用 WSAGetLastError 获取特定的错误代码。
    // WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
    // WSAENETDOWN         网络子系统已失败。
    // WSAEADDRINUSE       套接字的本地地址已被使用，且套接字未使用 SO_REUSEADDR 标记为允许地址重用。此错
    //                     误通常在执行 bind 函数时发生，但如果 bind 是对通配符地址（涉及 ADDR_ANY）进行
    //                     的，并且需要在该函数执行时提交特定地址，则可能会延迟到此函数。
    // WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
    // WSAEINVAL           套接字未使用 bind 绑定。
    // WSAEISCONN          套接字已连接。
    // WSAEMFILE           没有更多的套接字描述符可用。
    // WSAENOBUFS          没有可用的缓冲区空间。
    // WSAENOTSOCK         描述符不是套接字。
    // WSAEOPNOTSUPP       引用的套接字不是支持 listen 操作的类型。
    error_code = prh_impl_sock_listen(listen_socket, backlog);
    if (error_code) goto label_error_handle;
    prh_sched_thrd_synced_post(listen, prh_impl_sched_synced_listen_start_accept_req);
    return 0;
label_error_handle:
    prh_prerr(error_code);
    if (error_code == WSAEADDRINUSE || error_code == WSAEACCES) {
        return PRH_EBIND_ADDRINUSE;
    }
    return PRH_FAILURE;
}

// int connect(SOCKET s, const struct sockaddr *name, int namelen);
// int WSAAPI WSAConnect(
//      [in]  SOCKET         s,
//      [in]  const sockaddr *name,
//      [in]  int            namelen,
//      [in]  LPWSABUF       lpCallerData,
//      [out] LPWSABUF       lpCalleeData,
//      [in]  LPQOS          lpSQOS,
//      [in]  LPQOS          lpGQOS
// );
//
// typedef struct _flowspec {
//      ULONG       TokenRate;
//      ULONG       TokenBucketSize;
//      ULONG       PeakBandwidth;
//      ULONG       Latency;
//      ULONG       DelayVariation;
//      SERVICETYPE ServiceType;
//      ULONG       MaxSduSize;
//      ULONG       MinimumPolicedSize;
// } FLOWSPEC, *PFLOWSPEC, *LPFLOWSPEC;
//
// WSAConnect 函数用于建立与另一个套接字应用程序的连接，交换连接数据，并根据指定的 FLOWSPEC
// 配置所需的 QoS（服务质量）。如果没有错误发生，WSAConnect 返回零。否则，返回值为
// SOCKET_ERROR，可以通过调用 WSAGetLastError 获取特定的错误代码。对于阻塞套接字，返
// 回值指示连接尝试是否成功。对于非阻塞套接字，连接尝试无法立即完成。在这种情况下，WSAConnect
// 将返回 SOCKET_ERROR，WSAGetLastError 将返回 WSAEWOULDBLOCK；应用程序可以：
//  1.  使用 select 通过检查套接字是否可写来确定连接请求的完成。
//  2.  如果应用程序使用 WSAAsyncSelect 表示对连接事件感兴趣，则在连接操作完成时（成功与否），应用程序将收到 FD_CONNECT 通知。
//  3.  如果应用程序使用 WSAEventSelect 表示对连接事件感兴趣，则在连接操作完成时（成功与否），关联的事件对象将被触发。
//
// 对于非阻塞套接字，在连接尝试完成之前，对该套接字的所有后续 WSAConnect 调用都将因
// WSAEALREADY 错误代码而失败。如果返回的错误代码表明连接尝试失败（即 WSAECONNREFUSED、
// WSAENETUNREACH、WSAETIMEDOUT），应用程序可以为同一个套接字再次调用 WSAConnect。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEADDRINUSE       套接字的本地地址已在使用中，且套接字未使用 SO_REUSEADDR 标记为允许地址重用。此错误通常在执行 bind
//                          时发生，但如果 bind 函数操作的是部分通配符地址（涉及 ADDR_ANY），并且需要在该函数执行时提交特定地址，
//                          则可能会延迟到此函数。
//      WSAEINTR            通过 WSACancelBlockingCall 取消了（阻塞）Windows 套接字 1.1 调用。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEALREADY         在指定的套接字上正在进行非阻塞连接或 WSAConnect 调用。
//      WSAEADDRNOTAVAIL    远程地址不是有效地址（例如 ADDR_ANY）。
//      WSAEAFNOSUPPORT     指定地址族的地址不能与该套接字一起使用。
//      WSAECONNREFUSED     连接尝试被拒绝。
//      WSAEFAULT           name 或 namelen 参数不是用户地址空间的有效部分，namelen 参数太小，lpCalleeData、lpSQOS 和 lpGQOS
//                          的缓冲区长度太小，或者 lpCallerData 的缓冲区长度太大。
//      WSAEINVAL           参数 s 是监听套接字，或者指定的目标地址与套接字所属的受限组不一致，或者 lpGQOS 参数不是 NULL。
//      WSAEISCONN          套接字已连接（仅适用于面向连接的套接字）。
//      WSAENETUNREACH      当前无法从该主机到达网络。
//      WSAEHOSTUNREACH     尝试对无法到达的主机执行套接字操作。
//      WSAENOBUFS          没有可用的缓冲区空间。套接字无法连接。
//      WSAENOTSOCK         描述符不是套接字。
//      WSAEOPNOTSUPP       lpSQOS 和 lpGQOS 中指定的 FLOWSPEC 结构无法满足。
//      WSAEPROTONOSUPPORT  服务提供程序不支持 lpCallerData 参数。
//      WSAETIMEDOUT        连接尝试超时而未建立连接。
//      WSAEWOULDBLOCK      套接字被标记为非阻塞，且连接无法立即完成。
//      WSAEACCES           尝试将数据报套接字连接到广播地址失败，因为未启用 setsockopt SO_BROADCAST。
//
// 参数 s 标识一个未连接的套接字的描述符。参数 name 指向 sockaddr 结构，该结构指定要
// 连接的地址。对于 IPv4，sockaddr 包含地址族的 AF_INET、目标 IPv4 地址和目标端口。
// 对于 IPv6，sockaddr 结构包含地址族的 AF_INET6、目标 IPv6 地址、目标端口，并可能包
// 含额外的流和作用域 ID 信息。参数 namelen 表示 name 参数所指向的 sockaddr 结构的长
// 度，以字节为单位。
//
// 参数 lpCallerData 指向要与连接请求一起发送的用户数据的指针（称为连接数据）。这是附
// 加数据，不在正常的网络数据流中，而是与建立连接的网络请求一起发送。此选项用于遗留协议，
// 如 DECNet、OSI TP4 等。
//
// 参数 lpCalleeData 指向从另一个套接字返回的用户数据，作为连接建立的一部分。lpCalleeData
// 参数指向的 WSABUF 结构的 len 成员最初包含应用程序为 WSABUF 结构的 buf 成员分配的
// 缓冲区的长度。如果未返回用户数据，则 lpCalleeData 参数指向的 WSABUF 结构的 len 成
// 员将被设置为零。lpCalleeData 信息在连接操作完成时有效。对于阻塞套接字，当 WSAConnect
// 函数返回时，连接操作完成。对于非阻塞套接字，完成将在 FD_CONNECT 通知发生后。如果 lpCalleeData
// 为 NULL，则不返回用户数据。用户数据的确切格式特定于套接字所属的地址族。
//
// 参数 lpSQOS 指向套接字 s 的 FLOWSPEC 结构，每个方向一个，后跟任何额外的提供程序特定
// 参数。如果与套接字关联的传输提供程序或特定类型的套接字无法满足 QoS 请求，则会返回错
// 误。对于单向套接字，将分别忽略发送或接收流规范值。如果未指定提供程序特定参数，则 lpCalleeData
// 参数指向的 WSABUF 结构的 buf 和 len 成员应分别设置为 NULL 和零。lpSQOS 参数的 NULL
// 值表示没有应用程序提供的服务质量。
//
// 参数 lpGQOS 保留供未来与套接字组一起使用。lpGQOS 指定套接字组的 FLOWSPEC 结构（如
// 果适用），每个方向一个，后跟任何额外的提供程序特定参数。如果未指定提供程序特定参数，
// 则 lpCalleeData 参数指向的 WSABUF 结构的 buf 和 len 成员应分别设置为 NULL 和零。
// lpGQOS 的 NULL 值表示没有应用程序提供的组服务质量。如果 s 不是套接字组的创建者，则
// 忽略此参数。
//
// WSAConnect 函数用于创建与指定目标的连接，并在连接时执行一些其他辅助操作。如果套接字    *** 如果套接字未绑定系统将自动绑定本地地址
// s 未绑定，系统将为本地关联分配唯一值，并将套接字标记为已绑定。
//
// 对于面向 Windows Vista 及更高版本的应用程序，建议使用 WSAConnectByList 或 WSAConnectByName
// 函数，这些函数大大简化了客户端应用程序的设计。
//
// 对于面向连接的套接字（例如 SOCK_STREAM），将使用 name（套接字命名空间中的地址；有关
// 详细描述，请参阅 bind）主动建立与远程主机的连接。当此调用成功完成时，套接字已准备好
// 发送/接收数据。如果 name 结构的地址参数全为零，WSAConnect 将返回 WSAEADDRNOTAVAIL
// 错误。任何尝试重新连接活动连接的操作都将因 WSAEISCONN 错误代码而失败。注意，如果打开
// 套接字，调用 setsockopt，然后调用 sendto，则 Windows 套接字将执行隐式 bind 函数调
// 用。
//
// 对于面向连接的非阻塞套接字，通常无法立即完成连接。在这种情况下，该函数返回 WSAEWOULDBLOCK
// 错误代码。然而，操作仍在进行中。当成功或失败的结果已知时，可以通过几种方式报告，具体
// 取决于客户端如何注册通知。如果客户端使用 select，则在 writefds 集合中报告成功，在
// exceptfds 集合中报告失败。如果客户端使用 WSAAsyncSelect 或 WSAEventSelect，则通过
// FD_CONNECT 通知宣布通知，FD_CONNECT 关联的错误代码表示成功或失败的具体原因。
//
// 对于无连接的套接字（例如 SOCK_DGRAM），WSAConnect 执行的操作仅仅是建立一个默认目标
// 地址，以便后续可以在连接的 send 和 receive 操作（send、WSASend、recv 和 WSARecv）
// 中使用该套接字。从除目标地址之外的地址接收到的任何数据报将被丢弃。如果整个 name 结构   *** 如果用全零 sockaddr 结构进行调用将清除默认远程地址
// 全为零（不仅仅是 name 结构的地址参数），则套接字将被断开连接。然后，默认远程地址将不
// 确定，因此 send、WSASend、recv 和 WSARecv 调用将返回 WSAENOTCONN 错误代码。然而，
// sendto、WSASendTo、recvfrom 和 WSARecvFrom 仍然可以使用。默认目标可以通过简单地再   *** 对于无连接套接字可以多次调用更改默认远程地址
// 次调用 WSAConnect 来更改，即使套接字已经连接。如果 name 与之前的 WSAConnect 不同，   *** 但是更改目标地址之后，之前正在等待接收的数据包将被丢弃
// 则丢弃为接收排队的任何数据报。
//
// 对于无连接的套接字，name 可以指示任何有效地址，包括广播地址。然而，要连接到广播地址，
// 套接字必须启用 setsockopt SO_BROADCAST。否则，WSAConnect 将因 WSAEACCES 错误代码
// 而失败。在无连接的套接字上，无法交换用户到用户数据，相应的参数将被静默忽略。
//
// 应用程序负责为其指定的任何参数直接或间接指向的内存空间分配内存。lpCallerData 参数包
// 含指向任何用户数据的指针，这些数据将与连接请求一起发送（称为连接数据）。这是附加数据，
// 不在正常的网络数据流中，而是与建立连接的网络请求一起发送。此选项由 DECNet、OSI TP4
// 等旧协议使用。注意 Windows 中的 TCP/IP 协议不支持连接数据。连接数据仅在原始套接字上   *** TCP/IP 不支持连接数据
// 的 ATM（RAWWAN）上受支持。
//
// 如果 lpCallerData 为 NULL，则不会有用户数据传递给对等方。lpCalleeData 是一个结果
// 参数，将包含从其他套接字作为连接建立的一部分传递回来的任何用户数据，位于 WSABUF 结构
// 中。lpCalleeData 参数指向的 WSABUF 结构的 len 成员最初包含应用程序为 WSABUF 结构的
// buf 成员分配的缓冲区的长度。如果未传递回用户数据，则 lpCalleeData 参数指向的 WSABUF
// 结构的 len 成员将被设置为零。lpCalleeData 信息在连接操作完成时有效。对于阻塞套接字，
// 当 WSAConnect 函数返回时，连接操作完成。对于非阻塞套接字，完成将在 FD_CONNECT 通知
// 发生后。如果 lpCalleeData 为 NULL，则不会传递回用户数据。用户数据的确切格式特定于套
// 接字所属的地址族。
//
// 在连接时，应用程序可以使用 lpSQOS 和 lpGQOS 参数来覆盖之前通过 WSAIoctl 与 SIO_SET_QOS
// 或 SIO_SET_GROUP_QOS 操作码为套接字进行的任何服务质量规范。
//
// lpSQOS 参数指定套接字 s 的 FLOWSPEC 结构，每个方向一个，后跟任何额外的提供程序特定
// 参数。如果关联的传输提供程序或特定类型的套接字无法满足服务质量请求，则会返回错误。对
// 于任何单向套接字，将分别忽略发送或接收流规范值。如果未指定提供程序特定参数，则 lpCalleeData
// 参数指向的 WSABUF 结构的 buf 和 len 成员应分别设置为 NULL 和零。lpSQOS 参数的 NULL
// 值表示没有应用程序提供的服务质量。
//
// lpGQOS 保留供未来与套接字组一起使用，指定套接字组（如果适用）的 FLOWSPEC 结构，每个
// 方向一个，后跟任何额外的提供程序特定参数。如果未指定提供程序特定参数，则 lpCalleeData
// 参数指向的 WSABUF 结构的 buf 和 len 成员应分别设置为 NULL 和零。lpGQOS 的 NULL 值
// 表示没有应用程序提供的组服务质量。如果 s 不是套接字组的创建者，则忽略此参数。
//
// 当连接的套接字因任何原因关闭时，应丢弃并重新创建。最安全的假设是，当连接的套接字因任    *** 当已连接的套接字因任何原因出现问题时应丢弃并重新创建所需的套接字用于连接
// 何原因出现问题时，应用程序必须丢弃并重新创建所需的套接字，以便返回到稳定状态。         *** 但对于因 WSAECONNREFUSED WSAENETUNREACH WSAETIMEDOUT 失败的未连接套接字可以用来重连
//
// 注意，当发出阻塞的 Winsock 调用（如 WSAConnect）时，Winsock 可能需要等待网络事件才
// 能完成调用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排的异步过
// 程调用（APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发出另一个
// 阻塞 Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。
//
// BOOL WSAConnectByList(
//      [in]      SOCKET               s,
//      [in]      PSOCKET_ADDRESS_LIST SocketAddress,
//      [in, out] LPDWORD              LocalAddressLength,
//      [out]     LPSOCKADDR           LocalAddress,
//      [in, out] LPDWORD              RemoteAddressLength,
//      [out]     LPSOCKADDR           RemoteAddress,
//      [in]      const timeval        *timeout,
//      [in]      LPWSAOVERLAPPED      Reserved
// );
//
// typedef struct _SOCKET_ADDRESS {
//      LPSOCKADDR lpSockaddr;
//      INT        iSockaddrLength;
// } SOCKET_ADDRESS, *PSOCKET_ADDRESS, *LPSOCKET_ADDRESS;
//
// typedef struct _SOCKET_ADDRESS_LIST {
//      INT            iAddressCount;
//      SOCKET_ADDRESS Address[1];
// } SOCKET_ADDRESS_LIST, *PSOCKET_ADDRESS_LIST, FAR *LPSOCKET_ADDRESS_LIST;
//
// WSAConnectByList 函数用于建立与一组可能目标地址（主机名和端口）中的一个连接。该函数
// 接受所有传递的目标地址以及本地所有源地址，并尝试使用所有可能的地址组合进行连接，直到
// 放弃为止。该函数支持 IPv4 和 IPv6 地址。如果建立连接，WSAConnectByList 返回 TRUE，
// 并且如果调用方提供了缓冲区，将填充 LocalAddress 和 RemoteAddress 参数。如果调用失
// 败，返回 FALSE。然后可以调用 WSAGetLastError 以获取扩展错误信息。
//      WSAEHOSTUNREACH     作为 nodename 参数传递的主机无法到达。
//      WSAEINVAL           向函数传递了无效参数。Reserved 参数必须为 NULL。
//      WSAENOBUFS          无法分配足够的内存。
//      WSAENOTSOCK         向函数传递了无效套接字。s 参数不能是 INVALID_SOCKET 或 NULL。
//      WSAETIMEDOUT        在 timeout 参数指定的时间内未收到远程应用的响应。
//
// 参数 s 标识一个未绑定且未连接的套接字的描述符。注意，与其他用于建立连接的 Winsock      *** 需要一个未绑定且未连接的套接字
// 调用（例如 WSAConnect）不同，WSAConnectByList 函数需要一个未绑定的套接字。
//
// 参数 SocketAddress 指向 SOCKET_ADDRESS_LIST 结构，该结构表示要连接到对等方的可能
// 目标地址和端口的一个列表。
//
// 参数 LocalAddressLength，在输入时，指向由调用方提供的 LocalAddress 缓冲区大小（以
// 字节为单位）的指针。在输出时，指向由系统在调用成功完成时填充的 LocalAddress 缓冲区
// 中存储的本地地址的 SOCKADDR 大小（以字节为单位）的指针。参数 LocalAddress 指向 SOCKADDR
// 结构，该结构接收连接的本地地址。该参数的大小正好是 LocalAddressLength 中返回的大小。
// 这是 getsockname 函数将返回的相同信息。如果该参数为 NULL，则忽略 LocalAddressLength
// 参数。
//
// 参数 RemoteAddressLength，在输入时，指向由调用方提供的 RemoteAddress 缓冲区大小
// （以字节为单位）的指针。在输出时，指向由系统在调用成功完成时填充的 RemoteAddress 缓
// 冲区中存储的远程地址的 SOCKADDR 大小（以字节为单位）的指针。参数 RemoteAddress 指
// 向 SOCKADDR 结构，该结构接收连接的远程地址。这是 getpeername 函数将返回的相同信息。
// 如果该参数为 NULL，则忽略 RemoteAddressLength 参数。
//
// 参数 timeout 等待远程应用响应的时间（以毫秒为单位），在放弃调用之前。如果该参数为
// NULL，则 WSAConnectByList 将在成功建立连接或尝试所有连接失败后返回。
//
// 参数 Reserved 为未来实现保留。此参数必须设置为 NULL。
//
// WSAConnectByList 与 WSAConnectByName 函数类似。与接受单个主机名和服务名（端口）不
// 同，WSAConnectByList 接受一组地址（主机地址和端口），并连接到其中一个地址。WSAConnectByList
// 函数旨在支持点对点（peer-to-peer）协作场景，其中应用程序需要连接到潜在节点列表中的任
// 何可用节点。WSAConnectByList 兼容 IPv6 和 IPv4 版本。
//
// 由调用方提供可能目标的集合，该集合由地址列表表示。WSAConnectByList 不仅仅尝试连接到
// 许多可能的目标地址中的一个。具体来说，该函数接受调用方传递的所有远程地址、所有本地地
// 址，然后首先尝试使用最有可能成功的地址对进行连接。因此，WSAConnectByList 不仅确保如
// 果可能的话将建立连接，还最小化了建立连接所需的时间。
//
// 调用方可以指定 LocalAddress 和 RemoteAddress 缓冲区及其长度，以确定成功建立连接的
// 本地和远程地址。
//
// timeout 参数允许调用方限制函数在建立连接上花费的时间。在内部，WSAConnectByList 执
// 行多个操作（连接尝试）。在每次操作之间，检查 timeout 参数以查看是否超出了超时时间，
// 如果是，则中止调用。注意，一旦超出了超时时间，单个操作（连接）不会被中断，因此 WSAConnectByList
// 调用的实际超时时间可能比 timeout 参数中指定的值更长。
//
// WSAConnectByList 有以下限制：它仅适用于面向连接的套接字，例如 SOCK_STREAM 类型的
// 套接字。该函数不支持重叠 I/O 或非阻塞行为。即使套接字处于非阻塞模式，WSAConnectByList   *** 该函数不支持重叠 I/O 或非阻塞行为
// 也会阻塞。WSAConnectByList 将依次尝试连接到调用方提供的各种地址。每个连接尝试都可能
// 以不同的错误代码失败。由于只能返回一个错误代码，因此返回的值是最后一次连接尝试的错误
// 代码。
//
// 为了使 IPv6 和 IPv4 地址都能在函数接受的单一地址列表中传递，必须在调用函数之前执行
// 以下步骤：
//  1.  必须在为 AF_INET6 地址族创建的套接字上调用 setsockopt 函数，以在调用 WSAConnectByList
//      之前禁用 IPV6_V6ONLY 套接字选项。这是通过将 setsockopt 函数的 level 参数设置
//      为 IPPROTO_IPV6（参见 IPPROTO_IPV6 套接字选项），optname 参数设置为 IPV6_V6ONLY，
//      以及 optvalue 参数值设置为零来完成的。
//  2.  任何 IPv4 地址都必须以 IPv4 映射的 IPv6 地址格式表示，这使得仅有 IPv6 的应用
//      程序能够与 IPv4 节点通信。IPv4 映射的 IPv6 地址格式允许将 IPv4 节点的 IPv4
//      地址表示为 IPv6 地址。IPv4 地址被编码到 IPv6 地址的低 32 位中，高 96 位持有
//      固定的前缀 0:0:0:0:0:FFFF。IPv4 映射的 IPv6 地址格式在 RFC 4291 中指定。有
//      关更多信息，请参见 www.ietf.org/rfc/rfc4291.txt。Mstcpip.h 中的 IN6ADDR_SETV4MAPPED
//      宏可用于将 IPv4 地址转换为所需的 IPv4 映射的 IPv6 地址格式。
//
// 传递给 SocketAddressList 参数的指针数组指向一个通用数据类型的 SOCKET_ADDRESS 结构
// 数组。RemoteAddress 和 LocalAddress 参数也指向 SOCKADDR 结构。当调用 WSAConnectByList
// 时，期望在这些参数中实际传递特定于正在使用的网络协议或地址族的套接字地址类型。因此，
// 对于 IPv4 地址，当作为参数传递时，sockaddr_in 结构的指针将被强制转换为 SOCKADDR 的
// 指针。对于 IPv6 地址，当作为参数传递时，sockaddr_in6 结构的指针将被强制转换为 SOCKADDR
// 的指针。SocketAddressList 参数可以包含指向 IPv4 和 IPv6 地址的混合指针。因此，一些
// SOCKET_ADDRESS 指针可以指向 sockaddr_in 结构，而其他指针可以指向 sockaddr_in6 结构。
// 如果期望可以使用 IPv6 地址，则 RemoteAddress 和 LocalAddress 参数应该指向 sockaddr_in6
// 结构，并被强制转换为 SOCKADDR 结构。RemoteAddressLength 和 LocalAddressLength 参
// 数必须表示这些较大结构的长度。
//
// 当 WSAConnectByList 函数返回 TRUE 时，套接字 s 处于已连接套接字的默认状态。直到在
// 套接字上设置 SO_UPDATE_CONNECT_CONTEXT 选项后，套接字 s 才启用之前设置的属性或选项。
// 使用 setsockopt 函数设置 SO_UPDATE_CONNECT_CONTEXT 选项。
//      //Need to #include <mswsock.h> for SO_UPDATE_CONNECT_CONTEXT
//      int iResult = 0;
//      iResult = setsockopt(s, SOL_SOCKET, SO_UPDATE_CONNECT_CONTEXT, NULL, 0);
//
// 注意 当使用 WSAConnectByList 发出阻塞的 Winsock 调用且 timeout 参数设置为 NULL
// 时，Winsock 可能需要等待网络事件才能完成调用。在这种情况下，Winsock 会执行可警报等
// 待，这可能会被同一线程上安排的异步过程调用（APC）中断。在中断了同一线程上正在进行的
// 阻塞 Winsock 调用的 APC 中发出另一个阻塞 Winsock 调用，将导致未定义行为，Winsock
// 客户端绝对不应尝试此操作。
//
// BOOL WSAConnectByNameA(
//      [in]      SOCKET          s,
//      [in]      LPCSTR          nodename,
//      [in]      LPCSTR          servicename,
//      [in, out] LPDWORD         LocalAddressLength,
//      [out]     LPSOCKADDR      LocalAddress,
//      [in, out] LPDWORD         RemoteAddressLength,
//      [out]     LPSOCKADDR      RemoteAddress,
//      [in]      const timeval   *timeout,
//                LPWSAOVERLAPPED Reserved
// );
//
// WSAConnectByName 函数用于建立与指定主机和端口的连接。该函数提供了一种快速连接到网络
// 端点的方法，只需提供主机名和端口即可。该函数支持 IPv4 和 IPv6 地址。如果建立连接，
// WSAConnectByName 返回 TRUE，并且如果调用方提供了缓冲区，则填充 LocalAddress 和
// RemoteAddress 参数。如果调用失败，返回 FALSE。然后可以调用 WSAGetLastError 以获取
// 扩展错误信息。
//      WSAEHOSTUNREACH 作为 nodename 参数传递的主机无法到达。
//      WSAEINVAL       向函数传递了无效参数。nodename 或 servicename 参数不能为 NULL。Reserved 参数必须为 NULL。
//      WSAENOBUFS      无法分配足够的内存。
//      WSAENOTSOCK     向函数传递了无效套接字。s 参数不能是 INVALID_SOCKET 或 NULL。
//      WSAETIMEDOUT    在 timeout 参数指定的时间内未收到远程应用的响应。
//
// 参数 s 标识一个未连接的套接字的描述符。注意，在 Windows 7、Windows Server 2008 R2
// 及更早版本中，WSAConnectByName 函数需要一个未绑定且未连接的套接字。这与其他用于建立   *** 需指定一个未绑定且未连接的套接字
// 连接的 Winsock 调用（例如 WSAConnect）不同。
//
// 参数 nodename 一个以 NULL 结尾的字符串，包含要连接的主机的名称或 IPv4/IPv6 地址。
//
// 参数 servicename 一个以 NULL 结尾的字符串，包含要连接的主机的服务名或目标端口。服务
// 名是端口号的字符串别名。例如，“http” 是由互联网工程任务组（IETF）定义的端口 80 的别
// 名，用于 HTTP 协议的默认端口。参数 servicename 的可能值列在以下文件中：
//      %WINDIR%\system32\drivers\etc\services
//
// 参数 LocalAddressLength，在输入时，指向由调用方提供的 LocalAddress 缓冲区大小（以
// 字节为单位）的指针。在输出时，指向由系统在调用成功完成时填充的 LocalAddress 缓冲区
// 中存储的本地地址的 SOCKADDR 大小（以字节为单位）的指针。参数 LocalAddress 指向 SOCKADDR
// 结构，该结构接收连接的本地地址。该参数的大小正好是 LocalAddressLength 中返回的大小。
// 这是 getsockname 函数将返回的相同信息。如果该参数为 NULL，则忽略 LocalAddressLength
// 参数。
//
// 参数 RemoteAddressLength，在输入时，指向由调用方提供的 RemoteAddress 缓冲区大小
// （以字节为单位）的指针。在输出时，指向由系统在调用成功完成时填充的 RemoteAddress 缓
// 冲区中存储的远程地址的 SOCKADDR 大小（以字节为单位）的指针。参数 RemoteAddress 指
// 向 SOCKADDR 结构，该结构接收连接的远程地址。这是 getpeername 函数将返回的相同信息。
// 如果该参数为 NULL，则忽略 RemoteAddressLength 参数。
//
// 参数 timeout 等待远程应用响应的时间（以毫秒为单位），在放弃调用之前。
//
// 参数 Reserved 为未来实现保留。此参数必须设置为 NULL。
//
// WSAConnectByName 提供了一种快速透明地连接到特定端口上的远程主机的方法。它兼容 IPv6
// 和 IPv4 版本。为了启用 IPv6 和 IPv4 通信，请使用以下方法：
//  1.  必须在为 AF_INET6 地址族创建的套接字上调用 setsockopt 函数，以在调用 WSAConnectByName
//      之前禁用 IPV6_V6ONLY 套接字选项。这是通过将 setsockopt 函数的 level 参数设置
//      为 IPPROTO_IPV6（参见 IPPROTO_IPV6 套接字选项），optname 参数设置为 IPV6_V6ONLY，
//      以及 optvalue 参数值设置为零来完成的。
//
// WSAConnectByName 有以下限制：它仅适用于面向连接的套接字，例如 SOCK_STREAM 类型的套   *** 该函数仅适用于面向连接的套接字
// 接字。该函数不支持重叠 I/O 或非阻塞行为。即使套接字处于非阻塞模式，WSAConnectByName   *** 该函数不支持重叠 I/O 或非阻塞行为
// 也会阻塞。
//
// WSAConnectByName 不支持在建立连接期间提供用户数据。此调用也不支持 FLOWSPEC 结构。
// 在需要这些功能的情况下，必须使用 WSAConnect。
//
// 在 Windows 10 之前的版本中，如果应用程序需要绑定到特定的本地地址或端口，则不能使用     *** Windows 10 之前不能绑定到特定的本地地址或端口
// WSAConnectByName，因为传递给 WSAConnectByName 的套接字参数必须是未绑定的套接字。
// 此限制在 Windows 10 中被移除。
//
// RemoteAddress 和 LocalAddress 参数指向一个通用数据类型的 SOCKADDR 结构。当调用
// WSAConnectByName 时，期望在这些参数中实际传递特定于正在使用的网络协议或地址族的套接
// 字地址类型。因此，对于 IPv4 地址，sockaddr_in 结构的指针将被强制转换为 SOCKADDR 的
// 指针，作为 RemoteAddress 和 LocalAddress 参数。对于 IPv6 地址，sockaddr_in6 结构
// 的指针将被强制转换为 SOCKADDR 的指针，作为 RemoteAddress 和 LocalAddress 参数。
//
// 当 WSAConnectByName 函数返回 TRUE 时，套接字 s 处于已连接套接字的默认状态。直到在
// 套接字上设置 SO_UPDATE_CONNECT_CONTEXT 选项后，套接字 s 才启用之前设置的属性或选
// 项。使用 setsockopt 函数设置 SO_UPDATE_CONNECT_CONTEXT 选项。
//      //Need to #include <mswsock.h> for SO_UPDATE_CONNECT_CONTEXT
//      int iResult = 0;
//      iResult = setsockopt(s, SOL_SOCKET, SO_UPDATE_CONNECT_CONTEXT, NULL, 0);
//
// 注意 当使用 WSAConnectByName 发出阻塞的 Winsock 调用且 timeout 参数设置为 NULL
// 时，Winsock 可能需要等待网络事件才能完成调用。在这种情况下，Winsock 会执行可警报等
// 待，这可能会被同一线程上安排的异步过程调用（APC）中断。在中断了同一线程上正在进行的
// 阻塞 Winsock 调用的 APC 中发出另一个阻塞 Winsock 调用，将导致未定义行为，Winsock
// 客户端绝对不应尝试此操作。
//
// BOOL ConnectEx(
//      [in]           SOCKET s,
//      [in]           const sockaddr *name,
//      [in]           int namelen,
//      [in, optional] PVOID lpSendBuffer,
//      [in]           DWORD dwSendDataLength,
//      [out]          LPDWORD lpdwBytesSent,
//      [in]           LPOVERLAPPED lpOverlapped
// );
//
// ConnectEx 函数建立与指定套接字的连接，并可选地在建立连接后发送数据。该函数仅支持面向   *** 该函数仅支持面向连接的套接字
// 连接的套接字。注意 该函数是 Microsoft 对 Windows 套接字规范的特定扩展。成功时，ConnectEx
// 函数返回 TRUE。失败时，函数返回 FALSE。使用 WSAGetLastError 函数获取扩展错误信息。
// 如果 WSAGetLastError 函数返回的错误码为 ERROR_IO_PENDING，则表示操作已成功启动且
// 正在进行。在这种情况下，调用可能在重叠操作完成时仍然失败。如果返回的错误码是
// WSAECONNREFUSED、WSAENETUNREACH 或 WSAETIMEDOUT，应用程序可以在同一个套接字上调用   *** 对于因 WSAECONNREFUSED WSAENETUNREACH WSAETIMEDOUT 错误而失败的未连接套接字可以用来重连
// ConnectEx、WSAConnect 或 connect。
//      WSANOTINITIALISED   在调用 ConnectEx 之前，必须先成功调用 WSAStartup 函数。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEADDRINUSE       套接字的本地地址已在使用中，且套接字未使用 SO_REUSEADDR 标记为允许地址重用。此
//                          错误通常在绑定操作期间发生，但如果 bind 函数使用通配符地址（INADDR_ANY 或 in6addr_any）
//                          指定了本地 IP 地址，则错误可能会延迟到 ConnectEx 函数调用。ConnectEx 函数需要
//                          隐式绑定到特定的 IP 地址。
//      WSAEALREADY         在指定的套接字上正在进行非阻塞的 connect、WSAConnect 或 ConnectEx 函数调用。
//      WSAEADDRNOTAVAIL    远程地址不是有效地址，例如 ADDR_ANY（ConnectEx 函数仅支持面向连接的套接字）。
//      WSAEAFNOSUPPORT     指定地址族的地址不能与该套接字一起使用。
//      WSAECONNREFUSED     连接尝试被拒绝。
//      WSAEFAULT           name、lpSendBuffer 或 lpOverlapped 参数不是用户地址空间的有效部分，或者 namelen
//                          太小。
//      WSAEINVAL           参数 s 是未绑定的或监听套接字。
//      WSAEISCONN          套接字已连接。
//      WSAENETUNREACH      当前无法从该主机到达网络。
//      WSAEHOSTUNREACH     尝试对无法到达的主机执行套接字操作。
//      WSAENOBUFS          没有可用的缓冲区空间；套接字无法连接。
//      WSAENOTSOCK         描述符不是套接字。
//      WSAETIMEDOUT        连接尝试超时而未建立连接。
//
// 参数 s 标识一个未连接的、之前已绑定的套接字的描述符。参数 name 指向 sockaddr 结构，   *** 提供一个未连接之前已绑定的套接字描述符
// 该结构指定要连接的地址。对于 IPv4，sockaddr 包含地址族的 AF_INET、目标 IPv4 地址和
// 目标端口。对于 IPv6，sockaddr 结构包含地址族的 AF_INET6、目标 IPv6 地址、目标端口，
// 并可能包含额外的 IPv6 流和作用域 ID 信息。参数 namelen 表示 name 参数所指向的 sockaddr
// 结构的长度，以字节为单位。
//
// 参数 lpSendBuffer 指向在建立连接后要传输的缓冲区的指针。此参数是可选的。如果在调用
// ConnectEx 之前在 s 上启用了 TCP_FASTOPEN 选项，则在建立连接期间可能会发送这些数据
// 的一部分。参数 dwSendDataLength 表示 lpSendBuffer 参数所指向的数据的长度，以字节
// 为单位。如果 lpSendBuffer 参数为 NULL，则忽略此参数。
//
// 参数 lpdwBytesSent 在成功返回时，此参数指向一个 DWORD 值，该值指示在建立连接后发送
// 的字节数。发送的字节来自 lpSendBuffer 参数所指向的缓冲区。如果 lpSendBuffer 参数为
// NULL，则忽略此参数。
//
// 参数 lpOverlapped 用于处理请求的 OVERLAPPED 结构。必须指定 lpOverlapped 参数，它
// 不能为 NULL。
//
// ConnectEx 函数将多个套接字函数合并为一个 API或内核切换。当 ConnectEx 函数调用成功
// 完成时，执行以下操作：
//  1.  建立新的连接。
//  2.  在建立连接后发送可选的数据块。
//
// 对于面向 Windows Vista 及更高版本的应用程序，建议使用 WSAConnectByList 或 WSAConnectByName
// 函数，这些函数大大简化了客户端应用程序的设计。
//
// ConnectEx 函数只能与面向连接的套接字一起使用。在 s 参数中传递的套接字必须使用 SOCK_STREAM、
// SOCK_RDM 或 SOCK_SEQPACKET 类型创建。lpSendBuffer 参数指向在建立连接后要发送的数
// 据缓冲区。dwSendDataLength 参数指定要发送的数据长度（以字节为单位）。应用程序可以使
// 用 ConnectEx 请求发送较大的数据缓冲区，就像使用 send 和 WSASend 函数一样。但强烈建
// 议不要使用 ConnectEx 在单次调用中发送巨大的缓冲区，因为此操作会占用大量系统内存资源，
// 直到整个缓冲区发送完成。
//
// 如果 ConnectEx 函数成功，表示已建立连接，并且 lpSendBuffer 参数所指向的所有数据都
// 已发送到 name 参数所指向的 sockaddr 结构中指定的地址。
//
// ConnectEx 函数使用重叠 I/O。因此，ConnectEx 函数使应用程序能够使用相对较少的线程来
// 服务大量客户端。相比之下，不使用重叠 I/O 的 WSAConnect 函数通常需要一个单独的线程来
// 处理每个连接请求，当同时收到多个请求时。注意，当给定线程退出时，该线程启动的所有 I/O
// 都将被取消。对于重叠套接字，如果在线程关闭之前操作未完成，则挂起的异步操作可能会失败。
// 有关更多信息，请参阅 ExitThread。
//
// 面向连接的套接字通常无法立即完成连接，因此操作被启动，函数立即返回 ERROR_IO_PENDING
// 或 WSA_IO_PENDING 错误。当连接操作完成并且成功或失败时，状态将通过 lpOverlapped 中
// 指示的完成通知机制报告。与所有重叠函数调用一样，可以使用事件或完成端口作为完成通知机
// 制。GetQueuedCompletionStatus、GetOverlappedResult 或 WSAGetOverlappedResult
// 函数的 lpNumberOfBytesTransferred 参数指示请求中发送的字节数。
//
// 当 ConnectEx 函数成功完成时，套接字句柄 s 可以传递给以下函数：
//  - ReadFile
//  - WriteFile
//  - send 或 WSASend
//  - recv 或 WSARecv
//  - TransmitFile
//  - closesocket
//
// 如果在已连接的套接字上调用 TransmitFile 函数，并使用 TF_DISCONNECT 和 TF_REUSE_SOCKET
// 标志，则指定的套接字将返回到未连接但已绑定的状态。在这种情况下，可以将套接字的句柄传
// 递给 ConnectEx 函数的 s 参数，但不能在 AcceptEx 函数调用中重用该套接字。同样，使用
// TransmitFile 函数重用的已接受套接字（accepted socket）不能用于 ConnectEx 函数调用。
// 注意，对于重用的套接字，ConnectEx 受底层传输行为的影响。例如，TCP 套接字可能会受到     *** 注意在重用时 ConnectEx 可能由于 TIME_WAIT 状态影响而延迟
// TCP TIME_WAIT 状态的影响，导致 ConnectEx 调用被延迟。
//
// 当 ConnectEx 函数返回 TRUE 时，套接字 s 处于已连接套接字的默认状态。直到在套接字上
// 设置 SO_UPDATE_CONNECT_CONTEXT 选项后，套接字 s 才启用之前设置的属性或选项。使用
// setsockopt 函数设置 SO_UPDATE_CONNECT_CONTEXT 选项。
//      // Need to #include <mswsock.h> for SO_UPDATE_CONNECT_CONTEXT
//      int iResult = 0;
//      iResult = setsockopt(s, SOL_SOCKET, SO_UPDATE_CONNECT_CONTEXT, NULL, 0);
//
// 可以使用 getsockopt 函数和 SO_CONNECT_TIME 套接字选项，在 ConnectEx 进行中时检查
// 是否已建立连接。如果已建立连接，传递给 getsockopt 函数的 optval 参数返回的值是套接
// 字已连接的秒数。如果套接字未连接，则返回的 optval 参数包含 0xFFFFFFFF。以这种方式检
// 查连接是必要的，以确定连接是否已建立一段时间而未发送任何数据；在这种情况下，建议终止
// 此类连接。
//      // Need to #include <mswsock.h> for SO_CONNECT_TIME
//      int seconds;
//      int bytes = sizeof(seconds);
//      int iResult = 0;
//      iResult = getsockopt(s, SOL_SOCKET, SO_CONNECT_TIME, (char *)&seconds, (PINT)&bytes);
//      if (iResult != NO_ERROR) {
//          printf("getsockopt(SO_CONNECT_TIME) failed with error: %u\n", WSAGetLastError());
//      } else {
//          if (seconds == 0xFFFFFFFF)
//              printf("Connection not established yet\n");
//          else
//              printf("Connection has been established %ld seconds\n", seconds);
//      }
//
// 注意，如果打开套接字，调用 setsockopt，然后调用 sendto，则 Windows 套接字将执行隐式
// bind 函数调用。
//
// 如果 sockaddr 结构中 name 参数指向的地址参数全为零，则 ConnectEx 返回 WSAEADDRNOTAVAIL
// 错误。任何尝试重新连接活动连接的操作都将因 WSAEISCONN 错误代码而失败。
//
// 当因任何原因关闭已连接的套接字时，建议丢弃该套接字并创建一个新的套接字。这样做的原因
// 是，假设当已连接的套接字因任何原因出现问题时，应用程序必须丢弃该套接字并重新创建所需    *** 当已连接的套接字因任何原因出现问题时，应用程序应该丢弃该套接字并重新创建所需的套接字用于连接
// 的套接字，以便恢复到稳定状态。
//
// 如果调用 DisconnectEx 函数并使用 TF_REUSE_SOCKET 标志，则指定的套接字将返回到未连    *** 调用 DisconnectEx 重用套接字，套接字回到已绑定未连接状态
// 接但已绑定的状态。在这种情况下，可以将套接字的句柄传递给 ConnectEx 函数的 s 参数。
//
// TCP 在释放已关闭连接并重用其资源之前必须经过的时间间隔称为 TIME_WAIT 状态或 2MSL      *** 在 TIME_WAIT 期间重新打开连接的成本远低于建立新连接
// 状态。在此期间，重新打开连接的成本远低于建立新连接。在 TIME_WAIT 结束之前，如果再次
// 收到远端发过来的同一四元组 SYN（即对端试图重建同一条逻辑连接），内核可以直接用还在
// TIME_WAIT 槽里的连接控制块（TCB），省掉一次完整的端口查找、TCB 分配和初始序列号验证，
// 所以处理成本比 “全新连接” 略低。应用程序看到的依旧是一条全新的 socket，旧连接不会
// “复活” 继续传数据。SO_REUSEADDR 让内核提前回收或忽略 TIME_WAIT，允许监听套接字立即
// 绑定到刚才处于 TIME_WAIT 的本地端口，只要远端地址不同即可成功。但仍然不能让同一个四
// 元组的两条连接同时存在，它只是把 “端口仍被占用” 的检查放宽。
//
// 客户端 “立刻重连”怎么办？客户端主动关闭后也会进入 TIME_WAIT。最简单的是使用随机源端    *** 不管是服务端还是客户端，主动关闭连接的一方都会进入 TIME_WAIT 状态
// 口 bind(0)，几乎不会撞车。必须固定端口时，同样给客户端 SO_REUSEADDR，然后 bind 同
// 一个 (addr,port) 再 connect，只要远端端口与旧连接不同，就能成功，当然完全相同的四元
// 组仍会被内核拒绝（WSAEADDRINUSE）。
//
// TIME_WAIT 行为在 RFC 793 中指定，要求 TCP 在关闭连接后至少维持一个间隔，该间隔等于
// 网络最大报文段生命周期（MSL）的两倍。当连接被释放时，其套接字对和用于套接字的内部资源
// 可以用于支持另一个连接。
//
// Windows TCP 在关闭连接后进入 TIME_WAIT 状态。在 TIME_WAIT 状态下，套接字对不能被
// 重用。可以通过修改以下 DWORD 注册表设置来配置 TIME_WAIT 间隔，该设置表示 TIME_WAIT
// 间隔（以秒为单位）。HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\TCPIP\
// Parameters\TcpTimedWaitDelay
//
// 默认情况下，MSL 定义为 120 秒。TcpTimedWaitDelay 注册表设置默认为 240 秒的值，这表    *** 默认情况下，TIME_WAIT 的结束将需要 4 分钟
// 示 120 秒的最大报文段生命周期的两倍，即 4 分钟。然而，可以使用此条目自定义间隔。降低
// 此条目的值可以让 TCP 更快地释放已关闭的连接，从而为新连接提供更多资源。然而，如果值过
// 低，TCP 可能在连接完成之前释放连接资源，导致服务器需要使用额外的资源重新建立连接。此
// 注册值可设置的范围从 0 到 300 秒。

void prh_impl_iocp_connect_continue(void *post_req) {
    struct tcp_socket *tcp = (struct tcp_socket *)post_req;
    prh_u32 error_code = (prh_u32)tcp->open_close_tx_node.Internal;
    if (error_code) { // 不管成功还是失败，上层在 continue_routine 中调用完 prh_iocp_connect_result 之后 prh_iocp_connect 就可以重用
        // 注意，connect_socket 任然注册在 PRH_IMPL_IOCP 中，直到上层调用 prh_iocp_close_connect_socket 主动关闭
        // 对于因 WSAECONNREFUSED WSAENETUNREACH WSAETIMEDOUT 错误而失败的未连接套接字可以用来重连
        // PRH_ECONN_UNREACH
        //      WSAENETUNREACH      当前无法从该主机到达网络。
        //      WSAEHOSTUNREACH     尝试对无法到达的主机执行套接字操作。
        // PRH_ECONN_TIMEOUT
        //      WSAETIMEDOUT        连接尝试超时而未建立连接。
        // PRH_ECONN_REFUSED
        //      WSAECONNREFUSED     连接尝试被拒绝。
        // PRH_ECONN_INVALID
        //      WSAEADDRNOTAVAIL    远程地址不是有效地址，例如 ADDR_ANY（ConnectEx 函数仅支持面向连接的套接字）。
        //      WSAEAFNOSUPPORT     指定地址族的地址不能与该套接字一起使用。
        //      WSAEFAULT           name、lpSendBuffer 或 lpOverlapped 参数不是用户地址空间的有效部分，或者 namelen 太小。
        //      WSAEINVAL           参数 s 是未绑定的或监听套接字。
        //      WSAENOTSOCK         描述符不是套接字。
        // PRH_ECONN_FAILURE
        //      WSANOTINITIALISED   在调用 ConnectEx 之前，必须先成功调用 WSAStartup 函数。
        //      WSAENETDOWN         网络子系统已失败。
        //      WSAENOBUFS          没有可用的缓冲区空间；套接字无法连接。
        //      WSAEADDRINUSE       套接字的本地地址已在使用中，且套接字未使用 SO_REUSEADDR 标记为允许地址重用。此错误通常在绑
        //                          定操作期间发生，但如果 bind 函数使用通配符地址（INADDR_ANY 或 in6addr_any）指定了本地 IP
        //                          地址，则错误可能会延迟到 ConnectEx 函数调用。ConnectEx 函数需要隐式绑定到特定的 IP 地址。
        //      WSAEALREADY         在指定的套接字上正在进行非阻塞的 connect、WSAConnect 或 ConnectEx 函数调用。
        //      WSAEISCONN          套接字已连接。
        if (error_code == WSAENETUNREACH || error_code == WSAEHOSTUNREACH) {
            error_code = PRH_ECONN_UNREACH;
        } else if (error_code == WSAETIMEDOUT) {
            error_code = PRH_ECONN_TIMEOUT;
        } else if (error_code == WSAECONNREFUSED) {
            error_code = PRH_ECONN_REFUSED;
        } else if (error_code == WSAEADDRNOTAVAIL || error_code == WSAEAFNOSUPPORT || error_code == WSAEFAULT || error_code == WSAEINVAL || error_code == WSAENOTSOCK) {
            error_code = PRH_ECONN_INVALID;
        } else {
            error_code = PRH_ECONN_FAILURE;
        }
    } else { // 当已连接的套接字因任何原因出现问题时，应用程序应该丢弃该套接字并重新创建所需的套接字用于连接
        prh_handle connect_socket = tcp->socket; // 注意，connect_socket 任然注册在 PRH_IMPL_IOCP 中，直到套接字断连关闭
        prh_setsockopt_update_connect_context(connect_socket);
        struct sockaddr_in6 in6_local;
        in6_local.sin6_family = (tcp->family == PRH_AF_IPV6) ? AF_INET6 : AF_INET;
        prh_sock_local_addr(connect_socket, &in6_local);
        prh_impl_recv_sockaddr((struct sockaddr_in *)&in6_local, &tcp->address.l_port, &tcp->address.l_addr);
        tcp->flags.opened = true;
    }
    tcp->callback->conn_rsp(tcp->context, error_code, tcp);
}

void prh_impl_iocp_connect_immediately_complete(struct tcp_socket *tcp, prh_u32 error_code) {
    assert(error_code != 0);
    tcp->open_close_tx_node.Internal = error_code;
    prh_iocp_thrd_post(&tcp->open_close_tx_node, prh_impl_iocp_connect_continue);
}

void prh_impl_iocp_connect_completed_from_port(void *overlapped) {
    prh_impl_iocp_sched_thrd_post(overlapped, prh_impl_iocp_connect_continue);
}

void prh_impl_iocp_connect_req(struct tcp_socket *tcp) {
    struct sockaddr_in6 in6_remote = {0};
    int family = (tcp->family == PRH_AF_IPV6) ? AF_INET6 : AF_INET;
    int namelen = prh_impl_init_sockaddr(&in6_remote, family, tcp->address.r_port, &tcp->address.r_addr);
    if (tcp->socket == PRH_INVASOCK) {
        prh_impl_iocp_create_socket(req, family);
    }
    OVERLAPPED *overlapped = &tcp->open_close_tx_node;
    overlapped->hEvent = prh_null; // 确保完成操作被投递到完成端口
    BOOL b = PRH_IMPL_CONNECTEX(
        /* [in]           SOCKET s                  */ tcp->socket,
        /* [in]           const sockaddr *name      */ (struct sockaddr *)&in6_remote;
        /* [in]           int namelen               */ namelen,
        /* [in, optional] PVOID lpSendBuffer        */ prh_null,
        /* [in]           DWORD dwSendDataLength    */ 0,
        /* [out]          LPDWORD lpdwBytesSent     */ prh_null,
        /* [in]           LPOVERLAPPED lpOverlapped */ overlapped,
        );
    // 如果一个句柄与完成端口关联，即使异步请求以同步方式完成，其结果仍然会被添加到完成端口队列中
    // 代码都走 “发起→挂起→完成” 流程，可以统一使用重叠模型编写，无需关注操作同步完成的分支
    DWORD error_code;
    if (b || (error_code = WSAGetLastError()) == WSA_IO_PENDING) {
        prh_impl_iocp_set_continue_routine(overlapped, prh_impl_iocp_connect_completed_from_port);
        return; // 请求立即完成或已经成功投递
    }
    prh_prerr(error_code);
    prh_impl_iocp_connect_immediately_complete(tcp, error_code);
}

struct tcp_socket *prh_iocp_tcp_client(void *address, struct tcp_callback *callback, void *context) {
    struct tcp_socket *tcp = (struct tcp_socket *)address;
    assert(address != prh_null && callback != prh_null);
    memset(tcp, 0, sizeof(struct tcp_socket));
    tcp->callback = callback;
    tcp->context = context;
    tcp->socket = PRH_INVASOCK;
}

void prh_iocp_tcp_connect_req(struct tcp_socket *tcp, const char *host, int flags_port) {
    assert(host != prh_addr_any && host != prh_ipv6_addr_any);
    assert((flags_port & 0xffff) != prh_port_any);
    if (tcp->flags.client_connect || tcp->flags.server_accept || tcp->flags.opened) {
        prh_prerr(*(prh_byte *)(&tcp->flags));
        return;
    }
    tcp->flags.client_connect = true;
    prh_impl_parse_address(host, flags_port, &tcp->family, &tcp->address.r_port, &tcp->address.r_addr);
    prh_impl_iocp_connect_req(tcp);
}

// BOOL TransmitFile(
//      SOCKET                  hSocket,
//      HANDLE                  hFile,
//      DWORD                   nNumberOfBytesToWrite,
//      DWORD                   nNumberOfBytesPerSend,
//      LPOVERLAPPED            lpOverlapped,
//      LPTRANSMIT_FILE_BUFFERS lpTransmitBuffers,
//      DWORD                   dwReserved
// );
//
// BOOL Transmitpackets(
//      SOCKET hSocket,
//      LPTRANSMIT_PACKETS_ELEMENT lpPacketArray,
//      DWORD nElementCount,
//      DWORD nSendSize,
//      LPOVERLAPPED lpOverlapped,
//      DWORD dwFlags
// );
//
// int sendto(SOCKET s, const char *buf, int len, int flags, const struct sockaddr *to, int tolen);
// int WSAAPI WSASendTo(
//      [in]  SOCKET                             s,
//      [in]  LPWSABUF                           lpBuffers,
//      [in]  DWORD                              dwBufferCount,
//      [out] LPDWORD                            lpNumberOfBytesSent,
//      [in]  DWORD                              dwFlags,
//      [in]  const sockaddr                     *lpTo,
//      [in]  int                                iTolen,
//      [in]  LPWSAOVERLAPPED                    lpOverlapped,
//      [in]  LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionRoutine
// );
//
// int send(SOCKET s, const char *buf, int len, int flags);
// int WSAAPI WSASend(
//      [in]  SOCKET                             s,
//      [in]  LPWSABUF                           lpBuffers,
//      [in]  DWORD                              dwBufferCount,
//      [out] LPDWORD                            lpNumberOfBytesSent,
//      [in]  DWORD                              dwFlags,
//      [in]  LPWSAOVERLAPPED                    lpOverlapped,
//      [in]  LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionRoutine
// );
// typedef struct _WSABUF {
//      ULONG len;
//      CHAR  *buf;
// } WSABUF, *LPWSABUF;
//
// WSASend 函数在已连接的套接字上发送数据。如果没有错误发生且发送操作已立即完成，WSASend
// 返回零。在这种情况下，完成例程将被安排在调用线程处于可警报状态时调用一次。否则返回值
// SOCKET_ERROR，可以通过调用 WSAGetLastError 获取特定的错误代码。错误代码 WSA_IO_PENDING
// 表示重叠操作已成功启动，完成将在稍后时间指示。任何其他错误代码表示重叠操作未成功启动，
// 不会发生完成指示。
//      WSAECONNABORTED           虚拟电路因超时或其他故障而终止。
//      WSAECONNRESET             对于流式套接字，虚拟电路被远程方重置。应用程序应关闭套接字，因为它已不再可用。对于 UDP 数据报
//                                套接字，此错误表示之前的发送操作导致了 ICMP“端口不可达”消息。
//      WSAEFAULT                 lpBuffers、lpNumberOfBytesSent、lpOverlapped 或 lpCompletionRoutine 参数未完全包含在用户
//                                地址空间的有效部分。
//      WSAEINTR                  通过 WSACancelBlockingCall 取消了阻塞的 Windows 套接字 1.1 调用。
//      WSAEINPROGRESS            一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINVAL                 套接字未使用 bind 绑定，或者套接字未使用重叠标志创建。
//      WSAEMSGSIZE               套接字是面向消息的，且消息大于底层传输支持的最大值。
//      WSAENETDOWN               网络子系统已失败。
//      WSAENETRESET              对于流式套接字，由于在操作进行中检测到故障而通过保持活动操作断开了连接。对于数据报套接字，此错
//                                误表示生存时间已到期。
//      WSAENOBUFS                Windows 套接字提供程序报告缓冲区死锁。
//      WSAENOTCONN               套接字未连接。
//      WSAENOTSOCK               描述符不是套接字。
//      WSAEOPNOTSUPP             指定了 MSG_OOB，但套接字不是流式套接字（如 SOCK_STREAM），OOB 数据在与该套接字关联的通信域中
//                                不支持，MSG_PARTIAL 不受支持，或者套接字是单向的且仅支持接收操作。
//      WSAESHUTDOWN              套接字已关闭；在调用 shutdown 后，无法在套接字上使用 WSASend，其中 how 设置为 SD_SEND 或
//                                SD_BOTH。
//      WSAEWOULDBLOCK            Windows NT：重叠套接字：存在过多的未完成重叠 I/O 请求。非重叠套接字：套接字被标记为非阻塞，且
//                                发送操作无法立即完成。
//      WSANOTINITIALISED         在调用此函数之前，必须先成功调用 WSAStartup。
//      WSA_IO_PENDING            重叠操作已成功启动，完成将在稍后时间指示。
//      WSA_OPERATION_ABORTED     由于套接字关闭、在 WSAIoctl 中执行“SIO_FLUSH”命令或启动重叠请求的线程在操作完成前退出，重叠
//                                操作已被取消。有关详细信息，请参阅备注部分。
//
// 参数 s 标识已连接套接字的描述符。参数 lpBuffers 指向 WSABUF 结构数组的指针。每个
// WSABUF 结构包含指向缓冲区的指针以及缓冲区的长度（以字节为单位）。对于 Winsock 应用
// 程序，一旦调用 WSASend 函数，系统将拥有这些缓冲区，应用程序不得访问它们。此数组在发
// 送操作期间必须有效。参数 dwBufferCount 表示 lpBuffers 数组中的 WSABUF 结构数量。
//
// 参数 lpNumberOfBytesSent 如果 I/O 操作立即完成，此参数指向本次调用发送的字节数。如
// 果 lpOverlapped 参数不为 NULL，为了避免可能出现的错误结果，应将此参数设置为 NULL。
// 仅当 lpOverlapped 参数不为 NULL 时，此参数可以为 NULL。
//
// 参数 dwFlags 用于修改 WSASend 函数调用行为。参数 lpOverlapped 指向 WSAOVERLAPPED
// 结构的指针。对于非重叠套接字，此参数将被忽略。参数 lpCompletionRoutine 指向完成例程
// 的指针，当发送操作完成时调用。对于非重叠套接字，此参数将被忽略。
//
// WSASend 函数在两个重要方面提供了超出标准 send 函数的功能：
//  1.  它可以与重叠套接字一起使用以执行重叠发送操作。
//  2.  它允许指定多个发送缓冲区，使其适用于分散/聚集类型的 I/O。
//
// WSASend 函数用于在由 s 指定的面向连接的套接字上从一个或多个缓冲区写入传出数据。它也
// 可以用于通过 connect 或 WSAConnect 函数建立默认对等地址的无连接套接字。
//
// 通过 socket 函数创建的套接字将以重叠属性作为默认值。通过 WSASocket 函数创建的套接字，
// 如果在传递给 WSASocket 的 dwFlags 参数中设置了 WSA_FLAG_OVERLAPPED 位，则将具有重
// 叠属性。对于具有重叠属性的套接字，除非 lpOverlapped 和 lpCompletionRoutine 参数均
// 为 NULL，否则 WSASend 使用重叠 I/O。在这种情况下，套接字被视为非重叠套接字。当缓冲区
// 被传输消耗时，将发生完成指示，调用完成例程或设置事件对象。如果操作未立即完成，则通过
// 完成例程或 WSAGetOverlappedResult 获取最终完成状态。
//
// 如果 lpOverlapped 和 lpCompletionRoutine 均为 NULL，则此函数中的套接字将被视为非
// 重叠套接字。对于非重叠套接字，最后两个参数（lpOverlapped、lpCompletionRoutine）将
// 被忽略，WSASend 采用与 send 相同的阻塞语义。数据从缓冲区复制到传输的缓冲区。如果套
// 接字是非阻塞且面向流的，并且传输的缓冲区中没有足够的空间，WSASend 将仅返回部分已消耗
// 缓冲区大小。在相同的缓冲区情况下，对于阻塞套接字，WSASend 将阻塞，直到应用程序缓冲区
// 内容都被消耗。注意，套接字选项 SO_RCVTIMEO 和 SO_SNDTIMEO 仅适用于阻塞套接字。
//
// 如果以重叠方式完成此函数，则 Winsock 服务提供程序负责在返回之前捕获 WSABUF 结构。这
// 使应用程序可以构建基于堆栈的 WSABUF 数组。对于面向消息的套接字，不要超出底层提供程序
// 的最大消息大小，该大小可以通过获取套接字选项 SO_MAX_MSG_SIZE 的值来获得。如果数据太
// 长，无法通过底层协议原子地传递，则返回错误 WSAEMSGSIZE，并且不传输任何数据。Windows
// Me/98/95：WSASend 函数不支持超过 16 个缓冲区。注意，WSASend 的成功完成并不表示数据
// 已成功传递。
//
// 参数 dwFlags 可用于在关联套接字指定的选项之外影响函数调用的行为。也就是说，该函数的
// 语义由套接字选项和 dwFlags 参数决定。后者是通过使用按位 OR 运算符与以下表中列出的值
// 组合而成。
//      MSG_DONTROUTE   指定数据不应受路由影响。Windows 套接字服务提供程序可以选择忽略此标志。
//      MSG_OOB         仅在流式套接字（如 SOCK_STREAM）上发送 OOB 数据。
//      MSG_PARTIAL     仅适用于面向消息的套接字，指定 lpBuffers 仅包含部分消息。请注意，如果协议不支持部分
//                      消息传输，将返回错误代码 WSAEOPNOTSUPP。
//
// 注意，当使用 WSASend 发出阻塞的 Winsock 调用且 lpOverlapped 参数设置为 NULL 时，
// Winsock 可能需要等待网络事件才能完成调用。在这种情况下，Winsock 会执行可警报等待，
// 这可能会被同一线程上安排的异步过程调用（APC）中断。在中断了同一线程上正在进行的阻塞
// Winsock 调用的 APC 中发出另一个阻塞 Winsock 调用，将导致未定义行为，Winsock 客户
// 端绝对不应尝试此操作。
//
// 重叠套接字 I/O，如果重叠操作立即完成，WSASend 返回零值，并且 lpNumberOfBytesSent
// 参数将被更新为发送的字节数。如果重叠操作已成功启动且稍后完成，WSASend 返回 SOCKET_ERROR
// 和错误代码 WSA_IO_PENDING。在这种情况下，lpNumberOfBytesSent 不会被更新。当重叠操
// 作完成时，通过完成例程中的 cbTransferred 参数（如果已指定）或 WSAGetOverlappedResult
// 中的 lpcbTransfer 参数指示传输的数据量。
//
// 注意，当给定线程退出时，该线程启动的所有 I/O 都将被取消。对于重叠套接字，如果在线程
// 关闭之前操作未完成，则挂起的异步操作可能会失败。有关更多信息，请参阅 ExitThread。
//
// 可以使用重叠 I/O 的 WSASend 函数在 WSARecv、WSARecvFrom、WSASend 或 WSASendTo
// 函数的完成例程中调用。这使得时间敏感的数据传输可以发生在抢占式上下文中。
//
// lpOverlapped 参数必须在整个重叠操作期间有效。如果同时有多个 I/O 操作挂起，则每个操
// 作都必须引用一个单独的 WSAOVERLAPPED 结构。
//
// 如果 lpCompletionRoutine 参数为 NULL，则当重叠操作完成且 lpOverlapped 中包含有效
// 的事件对象句柄时，lpOverlapped 的 hEvent 参数将被触发。应用程序可以使用 WSAWaitForMultipleEvents
// 或 WSAGetOverlappedResult 在事件对象上等待或轮询。
//
// 如果 lpCompletionRoutine 不为 NULL，则忽略 hEvent 参数，应用程序可以使用它将上下
// 文信息传递给完成例程。传递非 NULL lpCompletionRoutine 的调用者稍后为相同的重叠 I/O
// 请求调用 WSAGetOverlappedResult 时，不得将该调用的 fWait 参数设置为 TRUE。在这种
// 情况下，hEvent 参数的使用是未定义的，尝试等待 hEvent 参数将产生不可预测的结果。
//
// 完成例程遵循 Windows 文件 I/O 完成例程规定的相同规则。完成例程将在线程处于可警报等
// 待状态时被调用，例如在调用函数 WSAWaitForMultipleEvents 且 fAlertable 参数设置为
// TRUE 时。
//
// 传输提供程序允许应用程序从套接字 I/O 完成例程的上下文中调用发送和接收操作，并保证对
// 于给定套接字，I/O 完成例程不会嵌套。这允许时间敏感的数据传输完全在抢占式上下文中发生。
// 以下是完成例程的原型。
//      void CALLBACK CompletionRoutine(
//          IN DWORD dwError,
//          IN DWORD cbTransferred,
//          IN LPWSAOVERLAPPED lpOverlapped,
//          IN DWORD dwFlags
//      );
//
// CompletionRoutine 函数是应用程序定义或库定义的函数名称的占位符。dwError 参数指定由
// lpOverlapped 指示的重叠操作的完成状态。cbTransferred 指定发送的字节数。目前没有定
// 义标志 dwFlags 值，将为零。此函数不返回值。
//
// 从这个函数返回允许为该套接字调用另一个挂起的完成例程。所有等待的完成例程将在警报线程
// 的等待中以 WSA_IO_COMPLETION 返回码满足之前被调用。完成例程可以以任何顺序被调用，不
// 一定是重叠操作完成的相同顺序。但是，发送的缓冲区保证按照它们指定的顺序发送。
//
// 对 WSASend 的调用顺序也是将缓冲区传输到传输层的顺序。不应从不同线程并发地在同一个面
// 向流的套接字上调用 WSASend，因为某些 Winsock 提供程序可能会将较大的发送请求拆分为多
// 次传输，这可能导致来自多个并发发送请求的同一面向流的套接字上的数据意外交织。
//
// int WSAAPI WSASendDisconnect(
//      [in] SOCKET   s,
//      [in] LPWSABUF lpOutboundDisconnectData
// );
//
// WSASendDisconnect 函数用于启动套接字连接的终止，并发送断开连接数据。如果没有错误发
// 生，WSASendDisconnect 返回零。否则，返回值为 SOCKET_ERROR，可以通过调用 WSAGetLastError
// 获取特定的错误代码。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAENOPROTOOPT      lpOutboundDisconnectData 参数不为 NULL，且服务提供程序不支持断开连接数据。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAENOTCONN         套接字未连接（仅适用于面向连接的套接字）。
//      WSAENOTSOCK         描述符不是套接字。
//      WSAEFAULT           lpOutboundDisconnectData 参数未完全包含在有效的用户地址空间中。
//
// 参数 s 标识套接字的描述符。参数 lpOutboundDisconnectData 指向外出的（outgoing）断
// 开数据。
//
// WSASendDisconnect 函数用于面向连接的套接字，以禁用传输并启动连接的终止，同时发送断
// 开连接数据（如果支持）。这相当于调用 shutdown (SD_SEND)，但 WSASendDisconnect 还    *** WSASendDisconnect 相当于 shutdonw(SD_SEND) + 发送断开连接数据
// 允许发送断开连接数据（在支持该功能的协议中）。成功调用此函数后，后续的发送操作将被禁    *** 此函数调用成功后，后续的发送操作将被禁止
// 止。
//
// 如果 lpOutboundDisconnectData 不为 NULL，则指向一个包含要发送给远方的数据的缓冲区，
// 远方可以使用 WSARecvDisconnect 检索这些数据。注意，Windows 上的原生 TCP/IP 实现不    *** Windows 上的原生 TCP/IP 实现不支持断开连接数据
// 支持断开连接数据。断开连接数据仅在具有 XP1_DISCONNECT_DATA 标志的 Windows 套接字提
// 供程序的 WSAPROTOCOL_INFO 结构中受支持。可以使用 WSAEnumProtocols 函数获取所有已
// 安装提供程序的 WSAPROTOCOL_INFO 结构。
//
// WSASendDisconnect 函数不会关闭套接字，与套接字关联的资源直到调用 closesocket 时才
// 会被释放。无论套接字上的 SO_LINGER 设置如何，WSASendDisconnect 函数都不会阻塞。应
// 用程序不应依赖在调用 WSASendDisconnect 后重用套接字。特别是，Windows 套接字提供程
// 序不要求支持在这样的套接字上使用 connect/WSAConnect。
//
// 注意 当发出阻塞的 Winsock 调用（如 WSASendDisconnect）时，Winsock 可能需要等待网
// 络事件才能完成调用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排
// 的异步过程调用（APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发
// 出另一个阻塞 Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。
//
// int WSAAPI WSASendMsg(
//      [in]  SOCKET                             Handle,
//      [in]  LPWSAMSG                           lpMsg,
//      [in]  DWORD                              dwFlags,
//      [out] LPDWORD                            lpNumberOfBytesSent,
//      [in]  LPWSAOVERLAPPED                    lpOverlapped,
//      [in]  LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionRoutine
// );
//
//      typedef struct _WSAMSG {
//          LPSOCKADDR     name;
//          INT            namelen;
//          LPWSABUF       lpBuffers;
//          ULONG/DWROD    dwBufferCount;
//          WSABUF         Control;
//          ULONG/DWROD    dwFlags;
//      } WSAMSG, *PWSAMSG, *LPWSAMSG;
//
// WSASendMsg 函数从已连接和未连接的套接字发送数据和可选的控制信息。注意，该函数是 Microsoft
// 对 Windows 套接字规范的特定扩展。成功且立即完成时返回零。当返回零时，指定的完成例程
// 将在调用线程处于可警报状态时被调用。返回值为 SOCKET_ERROR，且后续调用 WSAGetLastError
// 返回 WSA_IO_PENDING，表示重叠操作已成功启动；完成将通过其他方式（如事件或完成端口）
// 指示。失败时返回 SOCKET_ERROR，且后续调用 WSAGetLastError 返回的值不是 WSA_IO_PENDING。
// 以下列出了错误代码。
//      WSAEACCES               请求的地址是广播地址，但未设置适当的标志。
//      WSAECONNRESET           对于 UDP 数据报套接字，此错误表示之前的发送操作导致了 ICMP “端口不可达” 消息。
//      WSAEFAULT               lpMsg、lpNumberOfBytesSent、lpOverlapped 或 lpCompletionRoutine 参数未完全包含在有效的用户
//                              地址空间中。如果 WSAMSG 结构中 lpMsg 参数指向的 name 成员是 NULL 指针，且 WSAMSG 结构的 namelen
//                              成员未设置为零，也会返回此错误。如果 WSAMSG 结构中 lpMsg 参数指向的 Control.buf 成员是 NULL
//                              指针，且 WSAMSG 结构的 Control.len 成员未设置为零，也会返回此错误。
//      WSAEINPROGRESS          一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINTR                通过 WSACancelBlockingCall 取消了阻塞的 Windows 套接字 1.1 调用。
//      WSAEINVAL               套接字未使用 bind 绑定，或者套接字未使用重叠标志创建。
//      WSAEMSGSIZE             套接字是面向消息的，且消息大于底层传输支持的最大值。
//      WSAENETDOWN             网络子系统已失败。
//      WSAENETRESET            对于数据报套接字，此错误表示生存时间已到期。
//      WSAENETUNREACH          网络不可达。
//      WSAENOBUFS              Windows 套接字提供程序报告缓冲区死锁。
//      WSAENOTCONN             套接字未连接。
//      WSAENOTSOCK             描述符不是套接字。
//      WSAEOPNOTSUPP           套接字操作不受支持。如果 lpMsg 参数指向的 WSAMSG 结构的 dwFlags 成员包含对 WSASendMsg 无效的
//                              任何控制标志，则返回此错误。
//      WSAESHUTDOWN            套接字已关闭；在调用 shutdown 后，无法在套接字上使用 WSASendMsg，其中 how 设置为 SD_SEND 或
//                              SD_BOTH。
//      WSAETIMEDOUT            套接字超时。如果套接字使用 SO_SNDTIMEO 套接字选项指定了等待超时，并且超时已超过，则返回此错误。
//      WSAEWOULDBLOCK          重叠套接字：存在过多的未完成重叠 I/O 请求。非重叠套接字：套接字被标记为非阻塞，且发送操作无法立
//                              即完成。
//      WSANOTINITIALISED       在调用此函数之前，必须先成功调用 WSAStartup。
//      WSA_IO_PENDING          重叠操作已成功启动，完成将在稍后时间指示。
//      WSA_OPERATION_ABORTED   由于套接字关闭或在 WSAIoctl 中执行 SIO_FLUSH 命令，重叠操作已被取消。
//
// 参数 Handle 标识套接字的描述符。参数 lpMsg 存储 Posix.1g msghdr 结构的 WSAMSG 结
// 构。参数 dwFlags 用于修改 WSASendMsg 函数调用行为的标志。参数 dwFlags 参数只能包含
// 以下控制标志的组合：MSG_DONTROUTE、MSG_PARTIAL 和 MSG_OOB。lpMsg 参数指向的 WSAMSG
// 结构的 dwFlags 成员在输入时被忽略，在输出时也不使用。参数 dwFlags 输入参数可用于在
// 关联套接字指定的选项之外影响函数调用的行为。也就是说，该函数的语义由套接字选项和
// dwFlags 参数决定。后者是通过使用按位 OR 运算符与以下值中的任何一个组合而成的。
//      MSG_DONTROUTE   指定数据不应受路由影响。Windows 套接字服务提供程序可以选择忽略此标志。
//      MSG_PARTIAL     指定 lpMsg->lpBuffers 仅包含部分消息。注意，不支持部分消息传输的传输将返回错误代码 WSAEOPNOTSUPP。
//
// 参数 lpNumberOfBytesSent，如果 I/O 操作立即完成，此参数指向本次调用发送的字节数。
// 如果 lpOverlapped 参数不为 NULL，为了避免可能出现的错误结果，应将此参数设置为 NULL。
// 仅当 lpOverlapped 参数不为 NULL 时，此参数可以为 NULL。
//
// 参数 lpOverlapped 指向 WSAOVERLAPPED 结构的指针。对于非重叠套接字，此参数将被忽略。
// 参数 lpCompletionRoutine 指向完成例程的指针，当发送操作完成时调用。对于非重叠套接字，
// 此参数将被忽略。
//
// WSASendMsg 函数可以替代 WSASend 和 WSASendTo 函数。WSASendMsg 函数只能用于数据报
// 和原始套接字。s 参数中的套接字描述符必须以 SOCK_DGRAM 或 SOCK_RAW 类型打开。
//
// 注意，必须在运行时通过调用 WSAIoctl 函数并指定 SIO_GET_EXTENSION_FUNCTION_POINTER
// 操作码来获取 WSASendMsg 函数的函数指针。传递给 WSAIoctl 函数的输入缓冲区必须包含
// WSAID_WSASENDMSG，这是一个全局唯一标识符（GUID），其值标识 WSASendMsg 扩展函数。
// 成功时，WSAIoctl 函数返回的输出包含指向 WSASendMsg 函数的指针。WSAID_WSASENDMSG
// GUID 在 Mswsock.h 头文件中定义。
//
// 通过设置 WSA_FLAG_OVERLAPPED 标志的 WSASocket 函数调用创建重叠套接字。对于重叠套
// 接字，除非 lpOverlapped 和 lpCompletionRoutine 均为 NULL，否则发送信息使用重叠
// I/O；当 lpOverlapped 和 lpCompletionRoutine 均为 NULL 时，套接字被视为非重叠套
// 接字。对于重叠套接字，会发生完成指示；一旦缓冲区被传输消耗，将触发完成例程或设置事件
// 对象。如果操作未立即完成，则通过完成例程或调用 WSAGetOverlappedResult 函数获取最终
// 完成状态。
//
// 对于非重叠套接字，lpOverlapped 和 lpCompletionRoutine 参数将被忽略，WSASendMsg
// 采用与 send 函数相同的阻塞语义：数据从缓冲区复制到传输的缓冲区。如果套接字是非阻塞且
// 面向流的，并且传输的缓冲区中没有足够的空间，WSASendMsg 将仅返回部分已被消耗的缓冲区
// 大小。相比之下，对于阻塞套接字，这种缓冲区情况会导致 WSASendMsg 阻塞，直到应用程序
// 缓冲区内容都被消耗。
//
// 如果以重叠方式完成此函数，则 Winsock 服务提供程序负责在返回之前捕获此 WSABUF 结构。
// 这使应用程序可以构建由 lpMsg 参数指向的 WSAMSG 结构的 lpBuffers 成员指向基于堆栈
// 的 WSABUF 数组。
//
// 对于面向消息的套接字，必须小心不要超出底层提供程序的最大消息大小，该大小可以通过获取
// 套接字选项 SO_MAX_MSG_SIZE 的值来获得。如果数据太长，无法通过底层协议原子地传递，则
// 返回错误 WSAEMSGSIZE，并且不传输任何数据。
//
// 在类型为 SOCK_DGRAM 或 SOCK_RAW 的 IPv4 套接字上，应用程序可以使用 WSASendMsg 函
// 数指定用于发送的本地 IPv4 源地址。在 WSASendMsg 函数的 WSAMSG 结构中传递的控制数据
// 对象之一可能包含一个 in_pktinfo 结构，用于指定发送的本地 IPv4 源地址。
//
// 在类型为 SOCK_DGRAM 或 SOCK_RAW 的 IPv6 套接字上，应用程序可以使用 WSASendMsg 函
// 数指定用于发送的本地 IPv6 源地址。在 WSASendMsg 函数的 WSAMSG 结构中传递的控制数据
// 对象之一可能包含一个 in6_pktinfo 结构，用于指定发送的本地 IPv6 源地址。
//
// 对于双栈套接字，当使用 WSASendMsg 函数发送数据报并且应用程序想要指定要使用的特定本
// 地 IP 源地址时，处理方法取决于目标 IP 地址。当发送到 IPv4 目标地址或 IPv4 映射的
// IPv6 目标地址时，lpMsg 参数指向的 WSAMSG 结构中传递的控制数据对象之一应包含一个
// in_pktinfo 结构，其中包含用于发送的本地 IPv4 源地址。当发送到不是 IPv4 映射的 IPv6
// 目标地址时，lpMsg 参数指向的 WSAMSG 结构中传递的控制数据对象之一应包含一个 in6_pktinfo
// 结构，其中包含用于发送的本地 IPv6 源地址。
//
// 注意，套接字选项 SO_SNDTIMEO 仅适用于阻塞套接字。WSASendMsg 的成功完成并不表示数据
// 已成功传递。当使用 WSASendMsg 发出阻塞的 Winsock 调用且 lpOverlapped 参数设置为
// NULL 时，Winsock 可能需要等待网络事件才能完成调用。在这种情况下，Winsock 会执行可
// 警报等待，这可能会被同一线程上安排的异步过程调用（APC）中断。在中断了同一线程上正在
// 进行的阻塞 Winsock 调用的 APC 中发出另一个阻塞 Winsock 调用，将导致未定义行为，
// Winsock 客户端绝对不应尝试此操作。
//
// 重叠套接字 I/O，如果重叠操作立即完成，WSASendMsg 返回零值，并且 lpNumberOfBytesSent
// 参数将被更新为发送的字节数。如果重叠操作已成功启动且稍后完成，WSASendMsg 返回 SOCKET_ERROR
// 并指示错误代码 WSA_IO_PENDING。在这种情况下，lpNumberOfBytesSent 不会被更新。当重
// 叠操作完成时，通过完成例程中的 cbTransferred 参数（如果已指定）或 WSAGetOverlappedResult
// 中的 lpcbTransfer 参数指示传输的数据量。
//
// 注意，当给定线程退出时，该线程启动的所有 I/O 都将被取消。对于重叠套接字，如果在线程
// 关闭之前操作未完成，则挂起的异步操作可能会失败。有关更多信息，请参阅 ExitThread。
//
// 可以使用重叠 I/O 的 WSASendMsg 函数在 WSARecv、WSARecvFrom、WSARecvMsg、WSASend、
// WSASendMsg 或 WSASendTo 函数的完成例程中调用。这使得时间敏感的数据传输可以完全发生
// 在抢占式上下文中。
//
// lpOverlapped 参数必须在整个重叠操作期间有效。如果同时有多个 I/O 操作挂起，则每个操
// 作都必须引用一个单独的 WSAOVERLAPPED 结构。
//
// 如果 lpCompletionRoutine 参数为 NULL，则当重叠操作完成且 lpOverlapped 中包含有效
// 的事件对象句柄时，lpOverlapped 的 hEvent 参数将被触发。应用程序可以使用 WSAWaitForMultipleEvents
// 或 WSAGetOverlappedResult 在事件对象上等待或轮询。
//
// 如果 lpCompletionRoutine 不为 NULL，则忽略 hEvent 参数，应用程序可以使用它将上下
// 文信息传递给完成例程。传递非 NULL lpCompletionRoutine 的调用者稍后为相同的重叠 I/O
// 请求调用 WSAGetOverlappedResult 时，不得将该调用的 fWait 参数设置为 TRUE。在这种
// 情况下，hEvent 参数的使用是未定义的，尝试等待 hEvent 参数将产生不可预测的结果。
//
// 完成例程遵循 Windows 文件 I/O 完成例程规定的相同规则。完成例程将在线程处于可警报等
// 待状态时被调用，例如在调用函数 WSAWaitForMultipleEvents 且 fAlertable 参数设置为
// TRUE 时。传输提供程序允许应用程序从套接字 I/O 完成例程的上下文中调用发送和接收操作，
// 并保证对于给定套接字，I/O 完成例程不会嵌套。这允许时间敏感的数据传输完全在抢占式上下
// 文中发生。完成例程的原型如下。
//      void CALLBACK CompletionRoutine(
//          IN DWORD dwError,
//          IN DWORD cbTransferred,
//          IN LPWSAOVERLAPPED lpOverlapped,
//          IN DWORD dwFlags
//      );
//
// CompletionRoutine 函数是应用程序定义或库定义的函数名称的占位符。dwError 参数指定由
// lpOverlapped 参数指示的重叠操作的完成状态。cbTransferred 参数指示发送的字节数。目
// 前没有定义 dwFlags 标志值，参数将为零。CompletionRoutine 函数不返回值。
//
// 从这个函数返回允许为该套接字调用另一个挂起的完成例程。所有等待的完成例程将在警报线程
// 的等待以 WSA_IO_COMPLETION 返回码满足之前被调用。完成例程可以以任何顺序被调用，不一
// 定是重叠操作完成的相同顺序。但是，发送的缓冲区保证按照它们指定的顺序发送。

void prh_impl_iocp_wsasend_continue(void *overlapped) {
    struct tcp_socket *tcp = (struct tcp_socket *)overlapped;
    prh_u32 error_code = (prh_u32)(((OVERLAPPED *)overlapped)->Internal);
    prh_u32 bytes_transferred = (prh_u32)(((OVERLAPPED *)overlapped)->InternalHigh);
    if (error_code) {
        // 错误代码 WSA_IO_PENDING 表示重叠操作已成功启动，操作将在稍后完成。任何其他
        // 错误代码表示重叠操作未成功启动，不会产生操作完成通知。
        // PRH_ESEND_TXCLOSE
        //      WSAESHUTDOWN            套接字已关闭；在调用 shutdown 后，无法在套接字上使用 WSASend，其中 how 设置为 SD_SEND
        //                              或 SD_BOTH。
        // PRH_ESEND_DISCONN
        //      WSAETIMEDOUT            连接已经丢失（dropped），由于网络故障或对端系统无征兆崩溃。
        //      WSAECONNABORTED         连接被本地主机软件中止，可能由虚拟电路数据传输超时或其他如协议错误的故障造成。
        //      WSAECONNRESET           对于流式套接字，虚拟电路被远程方重置。应用程序应关闭套接字，因为它已不再可用。对于 UDP
        //                              数据报套接字，此错误表示之前的发送操作导致了 ICMP“端口不可达”消息。
        //      WSAENETRESET            对于流式套接字，由于在操作进行中检测到故障而通过保持活动操作断开了连接。对于数据报套接字，
        //                              此错误表示生存时间已到期。
        // PRH_ESEND_INVALID
        //      WSAEFAULT               lpBuffers、lpNumberOfBytesSent、lpOverlapped 或 lpCompletionRoutine 参数未完全包含
        //                              在用户地址空间的有效部分。
        //      WSAEINVAL               套接字未使用 bind 绑定，或者套接字未使用重叠标志创建。
        //      WSAEMSGSIZE             套接字是面向消息的，且消息大于底层传输支持的最大值。
        //      WSAENOTSOCK             描述符不是套接字。
        //      WSAEOPNOTSUPP           指定了 MSG_OOB，但套接字不是流式套接字（如 SOCK_STREAM），OOB 数据在与该套接字关联的通
        //                              信域中不支持，MSG_PARTIAL 不受支持，或者套接字是单向的且仅支持接收操作。
        // PRH_ESEND_FAILURE
        //      WSAEINTR                通过 WSACancelBlockingCall 取消了阻塞的 Windows 套接字 1.1 调用。
        //      WSAEINPROGRESS          一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
        //      WSAENETDOWN             网络子系统已失败。
        //      WSAENOTCONN             套接字未连接。
        //      WSAENOBUFS              Windows 套接字提供程序报告缓冲区死锁。
        //      WSAEWOULDBLOCK          Windows NT：重叠套接字：存在过多的未完成重叠 I/O 请求。非重叠套接字：套接字被标记为非阻
        //                              塞，且发送操作无法立即完成。
        //      WSANOTINITIALISED       在调用此函数之前，必须先成功调用 WSAStartup。
        //      WSA_OPERATION_ABORTED   由于套接字关闭、在 WSAIoctl 中执行“SIO_FLUSH”命令或启动重叠请求的线程在操作完成前退出，
        //                              重叠操作已被取消。
        if (error_code == WSANO_DATA) {
            error_code = 0;
        } else if (error_code == WSAESHUTDOWN) {
            error_code = PRH_ESEND_TXCLOSE;
            tcp->flags.l_hup = true;
        } else if (error_code == WSAETIMEDOUT || error_code == WSAECONNABORTED || error_code == WSAECONNRESET || error_code == WSAENETRESET) {
            error_code = PRH_ESEND_DISCONN;
            tcp->flags.conn_closed = true;
            tcp->flags.l_hup = tcp->flags.r_hup = true;
        } else if (error_code == WSAEFAULT || error_code == WSAEINVAL || error_code == WSAEMSGSIZE || error_code == WSAENOTSOCK || error_code == WSAEOPNOTSUPP) {
            error_code = PRH_ESEND_INVALID;
        } else {
            error_code = PRH_ESEND_FAILURE;
        }
    }
    tcp->flags.tx_pending = false;
    tcp->callback->send_rsp(tcp->context, error_code, bytes_transferred);
}

void prh_impl_iocp_wsasend_immediately_complete(struct tcp_socket *tcp, prh_u32 error_code) {
    assert(error_code != 0);
    OVERLAPPED *overlapped = &tcp->open_close_tx_node;
    overlapped->Internal = error_code;
    overlapped->InternalHigh = 0;
    prh_iocp_thrd_post(overlapped, prh_impl_iocp_wsasend_continue);
}

void prh_impl_iocp_wsasend_completed_from_port(void *overlapped) {
    prh_impl_iocp_sched_thrd_post(overlapped, prh_impl_iocp_wsasend_continue);
}

void prh_impl_iocp_wsasend_req(struct tcp_socket *tcp, const prh_byte *buffer, int length) {
    assert(length > 0 && length < PRH_IMPL_TXRX_BYTES);
    // 如果以重叠方式完成此函数，Winsock 服务提供程序负责在返回之前捕获 WSABUF 结构。
    // 这使得应用程序可以构建基于堆栈的 WSABUF 数组。Windows Me/98/95：WSASend 函数
    // 不支持超过 16 个缓冲区。
    WSABUF send_buffer = {(ULONG)length, (CHAR *)buffer};
    // 如果传输缓冲区没有足够的空间，WSASend 将仅返回部分已消耗缓冲区大小。在相同的情况
    // 下，对于阻塞套接字，WSASend 将阻塞直到应用程序缓冲区内容都被消耗。不应从不同线程
    // 并发地在同一个面向流的套接字上调用 WSASend，因为某些 Winsock 提供程序可能会将较
    // 大的发送请求拆分为多次传输，这可能导致来自多个并发发送请求的同一面向流的套接字上
    // 的数据意外交织。
    OVERLAPPED *overlapped = &tcp->open_close_tx_node;
    overlapped->hEvent = prh_null; // 确保完成操作被投递到完成端口
    assert(tcp->socket != PRH_INVASOCK);
    int n = WSASend(
        /* [in]  SOCKET             s                   */ (SOCKET)tcp->socket,
        /* [in]  LPWSABUF           lpBuffers           */ &send_buffer, // 一旦调用 WSASend 函数，系统将拥有这些缓冲区，此数组在发送操作期间必须有效
        /* [in]  DWORD              dwBufferCount       */ 1, // 传入的 WSABUF 个数
        /* [out] LPDWORD            lpNumberOfBytesSent */ prh_null, // 仅当 lpOverlapped 参数不为 NULL 时，此参数可以为 NULL
        /* [in]  DWORD              dwFlags             */ 0,
        /* [in]  LPWSAOVERLAPPED    lpOverlapped        */ overlapped,
        /* [in]  LPWSAOVERLAPPED_COMPLETION_ROUTINE     */ prh_null,
        );
    // 如果一个句柄与完成端口关联，即使异步请求以同步方式完成，其结果仍然会被添加到完成端口队列中
    // 代码都走 “发起→挂起→完成” 流程，可以统一使用重叠模型编写，无需关注操作同步完成的分支
    DWORD error_code;
    if (b || (error_code = WSAGetLastError()) == WSA_IO_PENDING) { // 请求立即完成或已经成功投递
        prh_impl_iocp_set_continue_routine(overlapped, prh_impl_iocp_wsasend_completed_from_port);
    } else {
        prh_prerr(error_code);
        prh_impl_iocp_wsasend_immediately_complete(tcp, error_code);
    }
}

void prh_iocp_tcp_send_req(struct tcp_socket *tcp, const prh_byte *buffer, int length) {
    prh_u32 error_code; assert(tcp != prh_null);
    if (!tcp->flags.opened || tcp->flags.l_closing || tcp->flags.l_hup) {
        prh_prerr(*(prh_byte *)(&tcp->flags));
        error_code = WSAENOTCONN;
        goto label_complete;
    }
    if (tcp->socket == PRH_INVASOCK) {
        error_code = WSAEINVAL;
        goto label_complete;
    }
    if (tcp->flags.tx_pending) {
        error_code = WSAEALREADY;
label_complete: prh_prerr(error_code);
        return;
    }
    tcp->flags.tx_pending = true;
    if (buffer == prh_null || length <= 0) {
        prh_impl_iocp_wsasend_immediately_complete(tcp, WSANO_DATA);
    } else {
        prh_impl_iocp_wsasend_req(tcp, buffer, length);
    }
}

// int recvfrom(SOCKET s, char *buf, int len, int flags, struct sockaddr *from, int *fromlen);
// int WSAAPI WSARecvFrom(
//      [in]      SOCKET                             s,
//      [in, out] LPWSABUF                           lpBuffers,
//      [in]      DWORD                              dwBufferCount,
//      [out]     LPDWORD                            lpNumberOfBytesRecvd,
//      [in, out] LPDWORD                            lpFlags,
//      [out]     sockaddr                           *lpFrom,
//      [in, out] LPINT                              lpFromlen,
//      [in]      LPWSAOVERLAPPED                    lpOverlapped,
//      [in]      LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionRoutine
// );
// INT WSARecvMsg(
//      SOCKET s,
//      LPWSAMSG lpMsg,
//      LPDWORD lpdwNumberOfBytesRecvd,
//      LPWSAOVERLAPPED lpOverlapped,
//      LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionRoutine
// );
//
// int WSARecvEx(
//   [in]      SOCKET s,
//   [out]     char   *buf,
//   [in]      int    len,
//   [in, out] int    *flags
// );
//
// int recv(SOCKET s, char *buf, int len, int flags);
// int WSAAPI WSARecv(
//      [in]      SOCKET                             s,
//      [in, out] LPWSABUF                           lpBuffers,
//      [in]      DWORD                              dwBufferCount,
//      [out]     LPDWORD                            lpNumberOfBytesRecvd,
//      [in, out] LPDWORD                            lpFlags,
//      [in]      LPWSAOVERLAPPED                    lpOverlapped,
//      [in]      LPWSAOVERLAPPED_COMPLETION_ROUTINE lpCompletionRoutine
// );
//
// WSARecv 函数从已连接的套接字或已绑定的无连接套接字接收数据。如果没有错误发生且接收操
// 作已立即完成，WSARecv 返回零。在这种情况下，完成例程将被安排在调用线程处于可警报状态
// 时调用一次。否则，返回值为 SOCKET_ERROR，可以通过调用 WSAGetLastError 获取特定的错
// 误代码。错误代码 WSA_IO_PENDING 表示重叠操作已成功启动，完成将在稍后时间指示。任何
// 其他错误代码表示重叠操作未成功启动，不会发生完成指示。
//      WSAECONNABORTED         虚拟电路因超时或其他故障而终止。
//      WSAECONNRESET           对于流式套接字，虚拟电路被远程方重置。应用程序应关闭套接字，因为它已不再可用。对于 UDP 数据报套
//                              接字，此错误表示之前的发送操作导致了 ICMP“端口不可达”消息。
//      WSAEDISCON              套接字 s 是面向消息的，且虚拟电路已被远程方优雅关闭。
//      WSAEFAULT               lpBuffers 参数未完全包含在用户地址空间的有效部分。
//      WSAEINPROGRESS          一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAEINTR                通过 WSACancelBlockingCall 函数取消了（阻塞）调用。
//      WSAEINVAL               套接字未绑定（例如，未使用 bind）。
//      WSAEMSGSIZE             消息太大，无法放入指定的缓冲区，并且（仅适用于不可靠协议）消息中未放入缓冲区的尾部部分已被丢弃。
//      WSAENETDOWN             网络子系统已失败。
//      WSAENETRESET            对于面向连接的套接字，此错误表示由于在操作进行中检测到故障而通过保持活动操作断开了连接。对于数据
//                              报套接字，此错误表示生存时间已到期。
//      WSAENOTCONN             套接字未连接。
//      WSAENOTSOCK             描述符不是套接字。
//      WSAEOPNOTSUPP           指定了 MSG_OOB，但套接字不是流式套接字（如 SOCK_STREAM），OOB 数据在与该套接字关联的通信域中不
//                              支持，或者套接字是单向的且仅支持发送操作。
//      WSAESHUTDOWN            套接字已关闭；在调用 shutdown 后，无法在套接字上使用 WSARecv，其中 how 设置为 SD_RECEIVE 或
//                              SD_BOTH。
//      WSAETIMEDOUT            由于网络故障或对等系统未响应，连接已断开。
//      WSAEWOULDBLOCK          Windows NT：重叠套接字：存在过多的未完成重叠 I/O 请求。非重叠套接字：套接字被标记为非阻塞，且接
//                              收操作无法立即完成。
//      WSANOTINITIALISED       在调用此函数之前，必须先成功调用 WSAStartup。
//      WSA_IO_PENDING          重叠操作已成功启动，完成将在稍后时间指示。
//      WSA_OPERATION_ABORTED   由于套接字关闭，重叠操作已被取消。
//
// 参数 s 标识已连接套接字的描述符。参数 lpBuffers 指向 WSABUF 结构数组的指针。每个
// WSABUF 结构包含指向缓冲区的指针以及缓冲区的长度（以字节为单位）。参数 dwBufferCount
// 表示 lpBuffers 数组中 WSABUF 结构的数量。
//
// 参数 lpNumberOfBytesRecvd，如果接收操作立即完成，此参数指向本次调用接收的字节数。
// 如果 lpOverlapped 参数不为 NULL，为了避免可能出现的错误结果，应将此参数设置为 NULL。
// 仅当 lpOverlapped 参数不为 NULL 时，此参数可以为 NULL。
//
// 参数 lpFlags 指向用于修改 WSARecv 函数调用行为的标志的指针。参数 lpOverlapped 指向
// WSAOVERLAPPED 结构（对于非重叠套接字将被忽略）。参数 lpCompletionRoutine 指向完成
// 例程，当接收操作完成时调用（对于非重叠套接字将被忽略）。
//
// 与标准 recv 函数相比，WSARecv 函数在三个重要方面提供了一些额外功能：
//  1.  它可以与重叠套接字一起使用以执行重叠接收操作。
//  2.  它允许指定多个接收缓冲区，使其适用于分散/聚集类型的 I/O。
//  3.  lpFlags 参数既用于输入，也在输出时返回，允许应用程序感知 MSG_PARTIAL 标志位的
//      输出状态。然而，并非所有协议都支持 MSG_PARTIAL 标志位。
//
// WSARecv 函数用于由 s 参数指定的已连接套接字或已绑定的无连接套接字，用于读取传入数据。
// 套接字的本地地址必须已知。对于服务器应用程序，这通常是通过 bind 显式完成的，或者通过   *** 套接字的本地地址必须已知
// accept 或 WSAAccept 隐式完成。不建议客户端应用程序显式绑定。对于客户端应用程序，套
// 接字可以通过 connect、WSAConnect、sendto、WSASendTo 或 WSAJoinLeaf 隐式绑定到本
// 地地址。
//
// 对于已连接的无连接套接字，此函数限制了接受来源消息的地址。该函数仅返回连接中指定的远
// 程地址的消息。来自其他地址的消息将被（静默地）丢弃。
//
// 对于重叠套接字，WSARecv 用于发布一个或多个缓冲区，当数据可用时，传入数据将被放入这些
// 缓冲区，之后将发生应用程序指定的完成指示（调用完成例程或设置事件对象）。如果操作未立
// 即完成，则通过完成例程或 WSAGetOverlappedResult 获取最终完成状态。
//
// 注意，当给定线程退出时，该线程启动的所有 I/O 都将被取消。对于重叠套接字，如果在线程
// 关闭之前操作未完成，则挂起的异步操作可能会失败。有关更多信息，请参阅 ExitThread。
//
// 如果 lpOverlapped 和 lpCompletionRoutine 均为 NULL，则此函数中的套接字将被视为非
// 重叠套接字。对于非重叠套接字，阻塞语义与标准 recv 函数完全相同，lpOverlapped 和
// lpCompletionRoutine 参数将被忽略。任何已被传输接收并缓冲的数据将被复制到指定的用户
// 缓冲区。在阻塞套接字当前未接收并缓冲任何数据的情况下，调用将阻塞，直到接收到数据。Windows
// 套接字版本 2 不为此函数定义任何标准的阻塞超时机制。对于作为字节流协议运行的协议，协议
// 栈会尝试返回尽可能多的数据，具体取决于可用的缓冲区空间和已接收的数据量。然而，接收单
// 个字节就足以解除调用者的阻塞。不能保证返回的字节数会超过一个。对于作为面向消息的协议
// 运行的协议，需要一个完整的消息才能解除调用者的阻塞。注意，套接字选项 SO_RCVTIMEO 和
// SO_SNDTIMEO 仅适用于阻塞套接字。
//
// 协议是否作为字节流运行取决于其 WSAPROTOCOL_INFO 结构中 XP1_MESSAGE_ORIENTED 和
// XP1_PSEUDO_STREAM 的设置，以及传递给此函数的 MSG_PARTIAL 标志（对于支持该标志的协
// 议）。下表列出了相关的组合，星号 (*) 表示在此情况下该位的设置无关紧要。
//      XP1_MESSAGE_ORIENTED    XP1_PSEUDO_STREAM   MSG_PARTIAL     行为
//      未设置                   *                   *              字节流
//      *                       设置                 *              字节流
//      设置                    未设置              设置            字节流
//      设置                    未设置              未设置          面向消息
//
// 缓冲区按 lpBuffers 参数指向的数组中出现的顺序填充，并且缓冲区被紧凑打包（the buffers
// are packed），以便不创建空洞。如果以重叠方式完成此函数，则 Winsock 服务提供程序负责
// 在从该调用返回之前捕获 WSABUF 结构。这使应用程序可以构建由 lpBuffers 参数指向的基于
// 堆栈的 WSABUF 数组。
//
// 对于字节流式套接字（例如，类型为 SOCK_STREAM），传入数据将被放入缓冲区，直到缓冲区
// 被填满、连接关闭或内部缓冲的数据耗尽。无论传入数据是否填满所有缓冲区，对于重叠套接字
// 都会发生完成指示。
//
// 对于面向消息的套接字（例如，类型为 SOCK_DGRAM），传入消息将被放入缓冲区，直到达到缓
// 冲区的总大小，并且对于重叠套接字会发生完成指示。如果消息大于缓冲区，缓冲区将被填入消
// 息的第一部分。如果底层服务提供程序支持 MSG_PARTIAL 特性，则在 lpFlags 中设置 MSG_PARTIAL
// 标志，后续接收操作将检索消息的其余部分。如果 MSG_PARTIAL 不受支持但协议是可靠的，
// WSARecv 会生成 WSAEMSGSIZE 错误，后续接收操作可以使用更大的缓冲区来检索整个消息。
// 否则（即协议不可靠且不支持 MSG_PARTIAL），多余的数据将丢失，WSARecv 会生成 WSAEMSGSIZE
// 错误。
//
// 对于面向连接的套接字，WSARecv 可以通过两种方式之一指示虚拟电路的优雅终止，这取决于
// 套接字是字节流还是面向消息。对于字节流，读取零字节（通过返回值指示成功，且 lpNumberOfBytesRecvd
// 值为零）表示优雅关闭，且不会再读取任何字节。对于面向消息的套接字，零字节消息通常是允
// 许的，因此使用 WSAEDISCON 错误代码的失败表示优雅关闭。在任何情况下，返回错误代码
// WSAECONNRESET 表示发生了强制关闭。
//
// lpFlags 参数可用于在关联套接字指定的选项之外影响函数调用的行为。也就是说，该函数的
// 语义由套接字选项和 lpFlags 参数决定。后者是通过使用按位 OR 运算符与以下表中列出的值
// 中的任何一个组合而成的。
//      MSG_PEEK            查看传入数据。数据被复制到缓冲区，但不会从输入队列中移除。此标志仅适用于非重叠套接字。
//      MSG_OOB             处理带外数据。
//      MSG_PARTIAL         仅适用于面向消息的套接字。在输出时，此标志表示指定的数据是发送方传输的消息的一部分。消息的剩余部分将
//                          在后续接收操作中指定。作为输入参数时，此标志表示即使仅接收到了消息的一部分，接收操作也应完成。
//      MSG_PUSH_IMMEDIATE  仅适用于面向流的套接字。此标志允许使用流式套接字的应用程序告诉传输提供程序不要延迟挂起的（pending）
//                          部分填充接收请求的完成。这是提示传输提供程序，表示应用程序愿意尽快接收任何传入数据，而不必等待可能仍
//                          在传输中的其余数据。什么是部分填充的挂起接收请求是传输特定的。
//                          在 TCP 的情况下，这指的是传入的 TCP 数据段被放入接收请求数据缓冲区，但没有任何 TCP 数据段指示 PUSH
//                          位值为 1。在这种情况下，TCP 可能会稍微延迟部分填充的接收请求，以便让其余数据与设置了 PUSH 位的 TCP
//                          数据段一起到达。此标志告诉 TCP 不要延迟接收请求，而是立即完成它。
//                          不建议在大块传输中使用此标志，因为处理部分数据块通常不是最优的。此标志仅适用于接收和处理部分数据可以
//                          立即帮助减少处理延迟的情况。此标志是一个提示，而不是实际的保证。此标志在 Windows 8.1、Windows Server
//                          2012 R2 及更高版本中受支持。
//      MSG_WAITALL         接收请求仅在以下事件之一发生时完成：
//                              * 调用方提供的缓冲区完全填满。
//                              * 连接已关闭。
//                              * 请求被取消或发生错误。
//                          请注意，如果底层传输提供程序不支持 MSG_WAITALL，或者套接字处于非阻塞模式，则此调用将因 WSAEOPNOTSUPP
//                          错误而失败。此外，如果 MSG_WAITALL 与 MSG_OOB、MSG_PEEK 或 MSG_PARTIAL 一起指定，则此调用将因
//                          WSAEOPNOTSUPP 错误而失败。
//                          此标志不适用于数据报套接字或面向消息的套接字。
//
// 对于面向消息的套接字，如果收到部分消息，则在 lpFlags 参数中设置 MSG_PARTIAL 位。如
// 果收到完整消息，则在 lpFlags 中清除 MSG_PARTIAL。在延迟完成的情况下，lpFlags 指向
// 的值不会被更新。完成指示后，应用程序应调用 WSAGetOverlappedResult 并检查 lpdwFlags
// 参数指示的标志。
//
// 注意，当使用 WSARecv 发出阻塞的 Winsock 调用且 lpOverlapped 参数设置为 NULL 时，
// Winsock 可能需要等待网络事件才能完成调用。在这种情况下，Winsock 会执行可警报等待，
// 这可能会被同一线程上安排的异步过程调用（APC）中断。在中断了同一线程上正在进行的阻塞
// Winsock 调用的 APC 中发出另一个阻塞 Winsock 调用，将导致未定义行为，Winsock 客户
// 端绝对不应尝试此操作。
//
// 重叠套接字 I/O，如果重叠操作立即完成，WSARecv 返回零值，并且 lpNumberOfBytesRecvd
// 参数将被更新为接收的字节数，lpFlags 参数指示的标志位也将被更新。如果重叠操作已成功启
// 动且稍后完成，WSARecv 返回 SOCKET_ERROR 并指示错误代码 WSA_IO_PENDING。在这种情况
// 下，lpNumberOfBytesRecvd 和 lpFlags 不会被更新。当重叠操作完成时，通过完成例程中的
// cbTransferred 参数（如果已指定）或 WSAGetOverlappedResult 中的 lpcbTransfer 参数
// 指示传输的数据量。通过检查 WSAGetOverlappedResult 的 lpdwFlags 参数获取标志值。
//
// 使用重叠 I/O 的 WSARecv 函数可以在 WSARecv、WSARecvFrom、WSASend 或 WSASendTo
// 函数的完成例程中调用。对于给定的套接字，I/O 完成例程不会嵌套。这允许时间敏感的数据传
// 输完全在抢占式上下文中发生。
//
// lpOverlapped 参数必须在整个重叠操作期间有效。如果同时有多个 I/O 操作挂起，则每个操
// 作都必须引用一个单独的 WSAOVERLAPPED 结构。
//
// 如果 lpCompletionRoutine 参数为 NULL，则当重叠操作完成且 lpOverlapped 中包含有效
// 的事件对象句柄时，lpOverlapped 的 hEvent 参数将被触发。应用程序可以使用 WSAWaitForMultipleEvents
// 或 WSAGetOverlappedResult 在事件对象上等待或轮询。
//
// 如果 lpCompletionRoutine 不为 NULL，则忽略 hEvent 参数，应用程序可以使用它将上下
// 文信息传递给完成例程。传递非 NULL lpCompletionRoutine 的调用者稍后为相同的重叠 I/O
// 请求调用 WSAGetOverlappedResult 时，不得将该调用的 fWait 参数设置为 TRUE。在这种
// 情况下，hEvent 参数的使用是未定义的，尝试等待 hEvent 参数将产生不可预测的结果。
//
// 完成例程遵循 Windows 文件 I/O 完成例程规定的相同规则。完成例程将在线程处于可警报等
// 待状态时被调用，例如在调用函数 WSAWaitForMultipleEvents 且 fAlertable 参数设置为
// TRUE 时。完成例程的原型如下：
//      void CALLBACK CompletionRoutine(
//          IN DWORD dwError,
//          IN DWORD cbTransferred,
//          IN LPWSAOVERLAPPED lpOverlapped,
//          IN DWORD dwFlags
//      );
//
// CompletionRoutine 是应用程序定义或库定义的函数名称的占位符。dwError 参数指定由
// lpOverlapped 参数指示的重叠操作的完成状态。cbTransferred 参数指定接收的字节数。
// dwFlags 参数包含如果接收操作立即完成将在 lpFlags 中出现的信息。此函数不返回值。
//
// 从这个函数返回允许为该套接字调用另一个挂起的完成例程。当使用 WSAWaitForMultipleEvents
// 时，所有等待的完成例程将在警报线程的等待以 WSA_IO_COMPLETION 返回码满足之前被调用。
// 完成例程可以以任何顺序被调用，不一定是重叠操作完成的相同顺序。但是，发送的缓冲区保证
// 按照它们指定的顺序填充。如果使用的是 I/O 完成端口，请注意，对 WSARecv 的调用顺序也
// 是缓冲区被填充的顺序。不应从不同线程并发地在同一个套接字上调用 WSARecv，因为这可能
// 导致不可预测的缓冲区顺序。
//
// int WSAAPI WSARecvDisconnect(
//      [in]  SOCKET   s,
//      [out] LPWSABUF lpInboundDisconnectData
// );
//
// WSARecvDisconnect 函数用于终止套接字上的接收，并在套接字是面向连接的情况下检索断开
// 连接数据。如果没有错误发生，WSARecvDisconnect 返回零。否则返回 SOCKET_ERROR，可以
// 通过调用 WSAGetLastError 获取特定的错误代码。
//      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
//      WSAENETDOWN         网络子系统已失败。
//      WSAEFAULT           lpInboundDisconnectData 参数引用的缓冲区太小。
//      WSAENOPROTOOPT      指定的协议族不支持断开连接数据。注意，不支持断开连接数据的 TCP/IP 实现不要求返回 WSAENOPROTOOPT 错
//                          误代码。有关 Microsoft 实现的 TCP/IP 的信息，请参阅备注部分。
//      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
//      WSAENOTCONN         套接字未连接（仅适用于面向连接的套接字）。
//      WSAENOTSOCK         描述符不是套接字。
//
// 参数 s 标识套接字的描述符。参数 lpInboundDisconnectData 指向传入的断开连接数据。
//
// WSARecvDisconnect 函数用于面向连接的套接字，以禁用接收并从远方检索任何传入的断开连
// 接数据。这相当于调用 shutdown (SD_RECEIVE)，但 WSARecvDisconnect 还允许接收断开
// 连接数据（在支持该功能的协议中）。
//
// 成功调用此函数后，后续对该套接字的接收操作将被禁止。调用 WSARecvDisconnect 对底层
// 协议层没有影响。对于 TCP 套接字，如果套接字上仍有排队等待接收的数据，或者后续有数据
// 到达，连接将被重置，因为数据无法传递给用户。对于 UDP，传入的数据报将被接受并排队。在
// 任何情况下，都不会生成 ICMP 错误数据包。
//
// 注意，Windows 上的原生 TCP/IP 实现不支持断开连接数据。断开连接数据仅在具有 XP1_DISCONNECT_DATA
// 标志的 Windows 套接字提供程序的 WSAPROTOCOL_INFO 结构中受支持。可以使用 WSAEnumProtocols
// 函数获取所有已安装提供程序的 WSAPROTOCOL_INFO 结构。
//
// 为了成功接收传入的断开连接数据，应用程序必须使用其他机制来确定电路已关闭。例如，应用
// 程序需要接收 FD_CLOSE 通知、接收零返回值，或者从 recv/WSARecv 接收 WSAEDISCON 或
// WSAECONNRESET 错误代码。
//
// WSARecvDisconnect 函数不会关闭套接字，与套接字关联的资源直到调用 closesocket 时才
// 会被释放。无论套接字上的 SO_LINGER 设置如何，WSARecvDisconnect 函数都不会阻塞。
//
// 应用程序不应依赖在使用 WSARecvDisconnect 断开连接后重用套接字。特别是，Windows 套
// 接字提供程序不要求支持在这样的套接字上使用 connect 或 WSAConnect。
//
// 注意，当发出阻塞的 Winsock 调用（如 WSARecvDisconnect）时，Winsock 可能需要等待网
// 络事件才能完成调用。在这种情况下，Winsock 会执行可警报等待，这可能会被同一线程上安排
// 的异步过程调用（APC）中断。在中断了同一线程上正在进行的阻塞 Winsock 调用的 APC 中发
// 出另一个阻塞 Winsock 调用，将导致未定义行为，Winsock 客户端绝对不应尝试此操作。

void prh_impl_iocp_wsarecv_continue(void *overlapped) {
    struct tcp_socket *tcp = prh_impl_tcp_socket_from_rx_node(overlapped);
    prh_u32 error_code = (prh_u32)(((OVERLAPPED *)overlapped)->Internal);
    prh_u32 bytes_transferred = (prh_u32)(((OVERLAPPED *)overlapped)->InternalHigh);
    if (error_code) {
        // 错误代码 WSA_IO_PENDING 表示重叠操作已成功启动，操作将在稍后完成。任何其他
        // 错误代码表示重叠操作未成功启动，不会产生操作完成通知。
        // PRH_ERECV_RXCLOSE
        //      WSAESHUTDOWN        套接字已关闭；在调用 shutdown 后，无法在套接字上使用 WSARecv，其中 how 设置为 SD_RECEIVE
        //                          或 SD_BOTH。
        //      WSAEDISCON          套接字 s 是面向消息的，且虚拟电路已被远程方优雅关闭。
        // PRH_ESEND_DISCONN
        //      WSAETIMEDOUT        由于网络故障或对等系统未响应，连接已断开。
        //      WSAECONNABORTED     虚拟电路因超时或其他故障而终止。
        //      WSAECONNRESET       对于流式套接字，虚拟电路被远程方重置。应用程序应关闭套接字，因为它已不再可用。对于 UDP 数据
        //                          报套接字，此错误表示之前的发送操作导致了 ICMP“端口不可达”消息。
        //      WSAENETRESET        对于面向连接的套接字，此错误表示由于在操作进行中检测到故障而通过保持活动操作断开了连接。对于
        //                          数报套接字，此错误表示生存时间已到期。
        // PRH_ESEND_INVALID
        //      WSAEFAULT           lpBuffers 参数未完全包含在用户地址空间的有效部分。
        //      WSAEINVAL           套接字未绑定（例如，未使用 bind）。
        //      WSAEMSGSIZE         消息太大无法放入指定的缓冲区，并且（仅适用于不可靠协议）消息中未放入缓冲区的尾部部分已被丢弃
        //      WSAENOTSOCK         描述符不是套接字。
        //      WSAEOPNOTSUPP       指定了 MSG_OOB，但套接字不是流式套接字（如 SOCK_STREAM），OOB 数据在与该套接字关联的通信域
        //                          中不支持，或者套接字是单向的且仅支持发送操作。
        // PRH_ESEND_FAILURE
        //      WSAEINTR            通过 WSACancelBlockingCall 函数取消了（阻塞）调用。
        //      WSAEINPROGRESS      一个阻塞的 Windows 套接字 1.1 调用正在进行中，或者服务提供程序仍在处理回调函数。
        //      WSAENETDOWN         网络子系统已失败。
        //      WSAENOTCONN         套接字未连接。
        //      WSAEWOULDBLOCK      Windows NT：重叠套接字：存在过多的未完成重叠 I/O 请求。非重叠套接字：套接字被标记为非阻塞，
        //                          且接收操作无法立即完成。
        //      WSANOTINITIALISED   在调用此函数之前，必须先成功调用 WSAStartup。
        //      WSA_OPERATION_ABORTED 由于套接字关闭，重叠操作已被取消。
        if (error_code == WSAESHUTDOWN || error_code == WSAEDISCON) {
            error_code = PRH_ERECV_RXCLOSE;
            tcp->flags.r_hup = true;
        } else if (error_code == WSAETIMEDOUT || error_code == WSAECONNABORTED || error_code == WSAECONNRESET || error_code == WSAENETRESET) {
            error_code = PRH_ERECV_DISCONN;
            tcp->flags.conn_closed = true;
            tcp->flags.l_hup = tcp->flags.r_hup = true;
        } else if (error_code == WSAEFAULT || error_code == WSAEINVAL || error_code == WSAEMSGSIZE || error_code == WSAENOTSOCK || error_code == WSAEOPNOTSUPP) {
            error_code = PRH_ERECV_INVALID;
        } else {
            error_code = PRH_ERECV_FAILURE;
        }
    }
    tcp->flags.rx_pending = false;
    tcp->callback->recv_rsp(tcp->context, error_code, bytes_transferred);
}

void prh_impl_iocp_wsarecv_immediately_complete(struct tcp_socket *tcp, prh_u32 error_code) {
    assert(error_code != 0);
    OVERLAPPED *overlapped = &tcp->rx_node;
    overlapped->Internal = error_code;
    overlapped->InternalHigh = 0;
    prh_iocp_thrd_post(overlapped, prh_impl_iocp_wsarecv_continue);
}

void prh_impl_iocp_wsarecv_completed_from_port(void *overlapped) {
    prh_impl_iocp_sched_thrd_post(overlapped, prh_impl_iocp_wsarecv_continue);
}

void prh_impl_iocp_wsarecv_req(struct tcp_socket *tcp, prh_byte *buffer, int length) {
    assert(length > 0 && length < PRH_IMPL_TXRX_BYTES);
    // 如果以重叠方式调用此函数，Winsock 服务提供程序负责在返回之前捕获 WSABUF 结构，
    // 这使得应用程序可以构建基于堆栈的 WSABUF 数组。
    WSABUF recv_buffer = {(ULONG)length, (CHAR *)buffer};
    // 标志 MSG_PARTIAL 仅适用于面向消息的套接字，当 lpFlags 作为输入参数时，如果指定
    // 了 MSG_PARTIAL，表示即使收到消息的一部分，接收操作也应完成。当 lpFlags 作为输出
    // 参数时，如果包含了 MSG_PARTIAL 标志，则表示指定的数据是发送方传输的消息的一部分，
    // 消息的剩余部分将在后续接收操作中指定。
    // 对于面向消息的套接字，如果收到部分消息，则在 lpFlags 参数中设置 MSG_PARTIAL 位。
    // 如果收到完整消息，则在 lpFlags 中清除 MSG_PARTIAL。在延迟完成的情况下，lpFlags
    // 指向的值不会被更新。完成指示后，应用程序应调用 WSAGetOverlappedResult 并检查
    // lpdwFlags 参数指示的标志。
    DWORD recv_flags = 0;
    // 套接字的本地地址必须已知。对于服务器应用程序，这通常是通过 bind 显式完成的，或者
    // 通过 accept 或 WSAAccept 隐式完成。不建议客户端应用程序显式绑定。对于客户端应用
    // 程序，套接字可以通过 connect、WSAConnect、sendto、WSASendTo 或 WSAJoinLeaf
    // 隐式绑定到本地地址。
    // 阻塞套接字，对于作为字节流协议运行的协议，协议栈会尝试返回尽可能多的数据，具体取
    // 决于可用的缓冲区空间和已接收的数据量。然而，接收单个字节就足以解除调用者的阻塞，
    // 不能保证返回的字节数会超过一个。对于作为面向消息的协议运行的协议，需要一个完整的
    // 消息才能解除调用者的阻塞。注意，套接字选项 SO_RCVTIMEO 和 SO_SNDTIMEO 仅适用于
    // 阻塞套接字。
    // 当对同一个套接字同时调用多次 WSARecv 函数时，如果使用的是 I/O 完成端口，对 WSARecv
    // 的调用顺序也是缓冲区被填充的顺序。不应从不同线程并发地在同一个套接字上调用 WSARecv，
    // 因为这可能导致不可预测的缓冲区顺序。
    OVERLAPPED *overlapped = &tcp->rx_node;
    overlapped->hEvent = prh_null; // 确保完成操作被投递到完成端口
    assert(tcp->socket != PRH_INVASOCK);
    int n = WSARecv(
        /* [in]      SOCKET             s                    */ (SOCKET)tcp->socket,
        /* [in, out] LPWSABUF           lpBuffers            */ &recv_buffer,
        /* [in]      DWORD              dwBufferCount        */ 1, // 传入的 WSABUF 个数
        /* [out]     LPDWORD            lpNumberOfBytesRecvd */ prh_null, // 仅当 lpOverlapped 参数不为 NULL 时，此参数可以为 NULL
        /* [in, out] LPDWORD            lpFlags              */ &recv_flags,
        /* [in]      LPWSAOVERLAPPED    lpOverlapped         */ overlapped,
        /* [in]      LPWSAOVERLAPPED_COMPLETION_ROUTINE      */ prh_null
        );
    // 如果一个句柄与完成端口关联，即使异步请求以同步方式完成，其结果仍然会被添加到完成端口队列中
    // 代码都走 “发起→挂起→完成” 流程，可以统一使用重叠模型编写，无需关注操作同步完成的分支
    DWORD error_code;
    if (b || (error_code = WSAGetLastError()) == WSA_IO_PENDING) { // 请求立即完成或已经成功投递
        prh_impl_iocp_set_continue_routine(overlapped, prh_impl_iocp_wsarecv_completed_from_port);
    } else {
        prh_prerr(error_code);
        prh_impl_iocp_wsarecv_immediately_complete(tcp, error_code);
    }
}

// 在资源充足的机器上，Winsock 服务器处理数千个并发连接应该没有任何问题。然而，随着服务
// 器处理的并发连接数量不断增加，最终会遇到资源限制。最有可能遇到的两个限制是锁定页面的数
// 量和非分页池（non-paged pool）的使用。锁定页面的限制比耗尽非分页池要不那么严重，也更
// 容易避免。
//
// 每次进行重叠的发送或接收操作时，提交的数据缓冲区很可能被锁定。当内存被锁定时，它不能被
// 换出物理内存。操作系统对可以锁定的内存量设定了一个限制。当达到这个限制时，重叠操作将因
// WSAENOBUFS 错误而失败。如果服务器在每个连接上发布了许多重叠的接收操作，随着连接数量的
// 增加，这个限制将被达到。如果服务器预计会处理大量并发客户端，服务器可以在每个连接上发布
// 一个零字节的接收操作。由于接收操作没有关联的缓冲区，因此不需要锁定任何内存。采用这种方
// 法时，应保留每个套接字的接收缓冲区，因为一旦零字节接收操作完成，服务器就可以简单地执行
// 非阻塞接收，以检索套接字接收缓冲区中缓冲的所有数据。当非阻塞接收因 WSAEWOULDBLOCK 错
// 误失败时，表示没有更多的待处理数据。这种设计适用于需要尽可能多的并发连接，同时牺牲每个
// 连接的数据吞吐量的服务器。
//
// 当然，你越了解客户端将如何与服务器交互，就越好。在前面的例子中，一旦零字节接收完成，就
// 会执行一次非阻塞接收以检索缓冲的数据。如果服务器知道客户端以突发方式发送数据，那么一旦
// 零字节接收完成，它可能会发布一个或多个重叠的接收操作，以防客户端发送大量数据（大于每个
// 套接字默认的 8 KB 的接收缓冲区）。
//
// 另一个重要的考虑因素是服务器运行架构的页面大小。当系统锁定传递给重叠操作的内存时，它是
// 按页面边界锁定的。在 x86 架构上，页面以 4 KB 的倍数锁定。如果一个操作发布了一个 1 KB
// 的缓冲区，那么系统实际上锁定了一块 4 KB 的内存。为了避免这种浪费，重叠的发送和接收缓
// 冲区应该是页面大小的倍数。
//
// 达到非分页池限制是一个更严重的错误，很难从中恢复。非分页池是始终驻留在物理内存中且永远
// 不会被换出的内存部分。内核模式操作系统组件（如驱动程序）通常使用非分页池，包括 Winsock
// 和协议驱动程序（如 tcpip.sys）。每个创建的套接字都会消耗一小部分非分页池，用于维护套
// 接字状态信息。当套接字绑定到地址时，TCP/IP 堆栈会为本地地址信息分配额外的非分页池。当
// 套接字连接后，TCP/IP 堆栈还会分配一个远程地址结构。总的来说，一个已连接的套接字大约消
// 耗 2 KB 的非分页池，而从 accept 或 AcceptEx 返回的套接字大约使用 1.5 KB 的非分页池
// （因为一个已接受的套接字只需要存储远程地址）。此外，每个在套接字上发出的重叠操作都需要
// 分配一个 I/O 请求包，大约使用 500 字节的非分页池。
//
// 正如你所看到的，每个连接使用的非分页池量并不大；然而，随着连接的客户端数量增加，服务器
// 使用的非分页池量可能会很可观。例如，考虑一台运行 Windows 2000（或更高版本）且具有 1GB
// 物理内存的服务器。对于这么多内存，将有 256 MB 用于非分页池。一般来说，分配的非分页池
// 量是物理内存量的四分之一，在 Windows 2000 及更高版本上有限制为 256 MB，在 Windows NT
// 4.0 上有限制为 128 MB。有了 256 MB 的非分页池，有可能处理 50,000 个或更多的连接，但
// 必须小心限制排队等待接受新连接以及在现有连接上发送和接收的重叠操作的数量。在这个例子中，
// 仅连接的套接字就消耗了 75 MB 的非分页池（假设每个套接字使用 1.5 KB 的非分页池，如上
// 所述）。因此，如果使用零字节重叠接收策略，那么每个连接将分配一个 IRP，这将再使用 25 MB
// 的非分页池。
//
// 如果系统确实耗尽了非分页池，有两种可能性。在最好的情况下，Winsock 调用将因 WSAENOBUFS
// 错误而失败。最坏的情况是系统因终端错误而崩溃。这通常发生在内核模式组件（如第三方驱动程
// 序）没有正确处理失败的内存分配时。因此，没有一种确定的方法可以从耗尽非分页池中恢复，并
// 且，也没有一种可靠的方法来监控可用的非分页池量，因为任何内核模式组件都可能消耗非分页池。
// 这次讨论的主要观点是，没有一种神奇的或编程方法可以确定可以接受的并发连接和重叠操作的数
// 量。此外，几乎不可能确定系统是耗尽了非分页池还是超过了锁定页面计数，因为两者都会导致
// Winsock 调用因 WSAENOBUFS 错误而失败。必须在服务器上进行测试。由于这些因素，开发人员
// 必须用不同数量的并发连接和重叠操作来测试服务器的性能，以找到一个平衡点。如果通过编程限
// 制来防止服务器耗尽非分页池，那么你会知道任何 WSAENOBUFS 失败通常是由于超过了锁定页面
// 限制，这可以通过编程以优雅的方式处理，例如进一步限制未完成操作的数量或关闭一些连接。
//
// 在本节中，我们将探讨几种根据服务器的性质处理资源的策略。此外，你对客户端和服务器设计的
// 控制越多，就可以相应地设计它们，以避免前面讨论的限制和瓶颈。同样，没有一种万无一失的方
// 法可以在所有情况下 100% 奏效。服务器大致可以分为两类：高吞吐量和高连接数。高吞吐量服
// 务器更关注在少量连接上推送数据。当然，“少量连接” 这一说法是相对于服务器上可用资源的数
// 量而言的。高连接数服务器则更关注处理大量连接，而不是试图推送大量数据。

void prh_iocp_tcp_recv_req(struct tcp_socket *tcp, prh_byte *buffer, int length) {
    prh_u32 error_code; assert(tcp != prh_null);
    if (!tcp->opened || tcp->r_hup) {
        prh_prerr(*(prh_byte *)(&tcp->flags));
        error_code = WSAENOTCONN;
        goto label_complete;
    }
    if (buffer == prh_null || length <= 0 || tcp->socket == PRH_INVASOCK) {
        error_code = WSAEINVAL;
        goto label_complete;
    }
    if (tcp->flags.rx_pending) {
        error_code = WSAEALREADY;
label_complete: prh_prerr(error_code);
        return;
    }
    tcp->flags.rx_pending = true;
    prh_impl_iocp_wsarecv_req(tcp, buffer, length);
}

// BOOL RIOSend(
//      RIO_RQ SocketQueue,
//      PRIO_BUF pData,
//      ULONG DataBufferCount,
//      DWORD Flags,
//      PVOID RequestContext
// );
//
// RIOSend 函数用于在已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套接字上发送网络数据。
// 如果没有错误发生，RIOSend 函数返回 TRUE。在这种情况下，发送操作已成功启动，操作的完
// 成通知已经排队，或将在稍后时间触发。否则返回 FALSE，操作未成功启动，不会有操作完成
// 通知。可以通过调用 WSAGetLastError 函数获取特定的错误代码。
//      WSAEFAULT       系统在尝试使用指针参数时检测到无效的指针地址。如果在操作排队或调用之前，为参数传递的任何 RIO_BUF 结构注销
//                      了缓冲区标识符或释放了缓冲区，则返回此错误。
//      WSAEINVAL       向函数传递了无效参数。如果 SocketQueue 参数无效，Flags 参数包含对发送操作无效的值，或者完成队列的完整性
//                      受到损害，则返回此错误。此错误也可能因其他参数问题而返回。
//      WSAENOBUFS      无法分配足够的内存。如果与 SocketQueue 参数关联的 I/O 完成队列已满，或者 I/O 完成队列是用零发送条目创建
//                      的，则返回此错误。
//      WSA_IO_PENDING  操作已成功启动，完成将在稍后时间排队。
//
// 参数 SocketQueue 标识已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套接字。
//
// 参数 pData 对注册缓冲区中要发送数据的部分区域的描述。如果应用程序不需要在 UDP 数据报
// 中发送数据负载，则对于已绑定的 RIO UDP 套接字，此参数可以为 NULL。参数 DataBufferCount
// 表示是否需要发送 pData 缓冲区中的数据。如果 pData 为 NULL，则此参数应设置为零。否则，
// 此参数应设置为 1。
//
// 参数 Flags 一组标志，用于修改 RIOSend 函数的行为。Flags 参数可以包含以下选项的组合，
// 这些选项在 mswsockdef.h 头文件中定义：
//      RIO_MSG_COMMIT_ONLY     之前使用 RIO_MSG_DEFER 标志添加的请求将被提交。当设置 RIO_MSG_COMMIT_ONLY 标志时，不能指定其
//                              他标志。当设置 RIO_MSG_COMMIT_ONLY 标志时，pData 和 RequestContext 参数必须为 NULL，DataBufferCount
//                              参数必须为零。
//                              通常在使用 RIO_MSG_DEFER 标志发出多个请求后，偶尔使用此标志。这避免了在使用 RIO_MSG_DEFER 标志
//                              时需要发出最后一个没有 RIO_MSG_DEFER 标志的请求，这会导致最后一个请求比其他请求慢得多。
//                              与其他 RIOSend 函数调用不同，当设置 RIO_MSG_COMMIT_ONLY 标志时，对 RIOSend 函数的调用不需要序
//                              列化。对于单个 RIO_RQ，可以在一个线程上使用 RIO_MSG_COMMIT_ONLY 调用 RIOSend 函数，同时在另一
//                              个线程上调用 RIOSend 函数。
//      RIO_MSG_DONT_NOTIFY     请求完成在插入完成队列时不应触发 RIONotify 函数。
//      RIO_MSG_DEFER           请求不需要立即执行。这将把请求插入请求队列，但可能会也可能不会触发请求的执行。
//                              发送数据可能会延迟，直到在 SocketQueue 参数传递的 RIO_RQ 上发出没有设置 RIO_MSG_DEFER 标志的
//                              发送请求。要触发发送队列中所有发送的执行，请调用 RIOSend 或 RIOSendEx 函数，且不设置 RIO_MSG_DEFER
//                              标志。
//                              注意，无论是否设置了 RIO_MSG_DEFER，发送请求都会占用 SocketQueue 参数传递的 RIO_RQ 上的未完成
//                              I/O 容量。
//
// 应用程序可以使用 RIOSend 函数从完全包含在单个注册缓冲区内的任何缓冲区发送网络数据。
// pData 参数指向的 RIO_BUF 结构的 Offset 和 Length 成员确定从缓冲区发送的网络数据。
//
// 发送操作关联的缓冲区不应与另一个发送或接收操作同时使用。缓冲区以及缓冲区注册必须在整
// 个发送操作期间保持有效。这意味着不应在已经有挂起的 RIOSend(Ex) 请求时，将相同的 PRIO_BUF
// 传递给 RIOSend(Ex) 请求。只有当请求中的 RIOSend(Ex) 操作完成后，才应重用相同的
// PRIO_BUF（不管是使用相同的偏移还是使用不同的偏移和长度）。此外，当发送数据引用一个注
// 册缓冲区（无论是部分还是整个缓冲区）时，在发送完成之前，不应使用整个注册缓冲区。这包
// 括使用注册缓冲区的一部分进行接收操作或另一个发送操作。
//
//      为什么文档会写成 "entire registered buffer"？
//      保守措辞：早期版本实现曾采用 整页锁 或 区间合并锁，为防未来实现变严格，文档干脆把范围说大；
//      简化示例：官方示例通常一张缓冲区只切一个 RIO_BUF 循环使用，于是 "整段 buffer" 在示例里确实要等完成；
//      避免误用：如果允许任意细粒度重叠，实现要做 区间树/红黑树 来跟踪飞行区，文档索性一句话 "别碰" 最省心。
//      实测与社区结论
//      Boost.ASIO、libuv、dpdk-rio 等生产代码都把同一 RIO_BUFFERID 切成多块并发投递，从未出现数据损坏或
//      返回错误；Windows 8/10/11 当前实现 采用 "区间锁"（粒度 64 B ~ 4 kB），不重叠即可并行；微软内部论坛
//      曾回复："The restriction applies only to the byte-range referenced by the RIO_BUF.
//      Non-overlapping ranges within the same registration are safe to use concurrently."
//      文档的 "entire registered buffer" 应读作 "本次发送所引用的那段连续区间"；
//      只要新请求与正在飞的区间不重叠，你就可以安全地并发使用同一个 RIO_BUFFERID ——
//      这是当前实现的事实行为，也是高性能 RIO 代码的通用做法。
//
// Flags 参数可用于在关联套接字指定的选项之外影响 RIOSend 函数的行为。该函数的行为由关
// 联套接字上设置的任何套接字选项与 Flags 参数中指定的值的组合决定。
//
// BOOL RIOSendEx(
//      RIO_RQ SocketQueue,
//      PRIO_BUF pData,
//      ULONG DataBufferCount,
//      PRIO_BUF pLocalAddress,
//      PRIO_BUF pRemoteAddress,
//      PRIO_BUF pControlContext,
//      PRIO_BUF pFlags,
//      DWORD Flags,
//      PVOID RequestContext
// );
//
// RIOSendEx 函数用于在已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套接字上发送网络数据，
// 并提供额外选项。如果没有错误发生，RIOSendEx 函数返回 TRUE。在这种情况下，发送操作已
// 成功启动，操作完成通知已经排队，或将在稍后排队。返回值为 FALSE 表示函数失败，操作未
// 成功启动，且不会排队完成通知。可以通过调用 WSAGetLastError 函数获取特定的错误代码。
//      WSAEFAULT       系统在尝试使用指针参数调用时检测到无效的指针地址。如果在操作排队或调用之前，传递给参数的任何 RIO_BUF 结构
//                      的缓冲区标识符被注销或缓冲区被释放，则返回此错误。
//      WSAEINVAL       传递给函数的参数无效。如果 SocketQueue 参数无效，Flags 参数包含对发送操作无效的值，或者完成队列的完整性
//                      受到损害，则返回此错误。此错误也可能因其他参数问题而返回。
//      WSAENOBUFS      无法分配足够的内存。如果与 SocketQueue 参数关联的 I/O 完成队列已满，或者 I/O 完成队列是用零发送条目创建
//                      的，则返回此错误。
//      WSA_IO_PENDING  操作已成功启动，完成将在稍后排队。
//
// 参数 SocketQueue 标识已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套接字。
//
// 参数 pData 从注册缓冲区中发送数据的缓冲区段。此参数指向的 RIO_BUF 结构可以表示注册
// 缓冲区的一部分或完整的注册缓冲区。如果应用程序不需要在 UDP 数据报中发送数据负载，则
// 对于已绑定的 RIO UDP 套接字，此参数可以为 NULL。参数 DataBufferCount 表示是否要发
// 送 pData 缓冲区中的数据。如果 pData 为 NULL，则此参数应设置为零。否则，此参数应设置
// 为 1。
//
// 参数 pLocalAddress 此参数保留，必须为 NULL。参数 pRemoteAddress 指定网络数据发送
// 的远程地址。如果套接字已连接，则此参数可以为 NULL。
//
// 参数 pControlContext 在完成时将包含有关发送操作的附加控制信息。如果应用程序不需要接
// 收附加控制信息，则此参数可以为 NULL。参数 pFlags 在完成时将包含有关发送操作的附加标
// 志信息。如果应用程序不需要接收附加标志信息，则此参数可以为 NULL。
//
// 参数 Flags 一组修改 RIOSendEx 函数行为的标志。Flags 参数可以包含以下选项的组合，这
// 些选项在 Mswsockdef.h 头文件中定义：
//      RIO_MSG_COMMIT_ONLY     之前使用 RIO_MSG_DEFER 标志添加的请求将被提交。当设置了 RIO_MSG_COMMIT_ONLY 标志时，不得指定
//                              其他标志。当设置了 RIO_MSG_COMMIT_ONLY 标志时，pData、pLocalAddress、pRemoteAddress、pControlContext、
//                              pFlags 和 RequestContext 参数必须为 NULL，DataBufferCount 参数必须为零。
//                              通常情况下，此标志会在使用 RIO_MSG_DEFER 标志发出多个请求后偶尔使用。这消除了在使用 RIO_MSG_DEFER
//                              标志时需要发出最后一个没有 RIO_MSG_DEFER 标志的请求的需求，否则最后一个请求的完成速度会比其他请
//                              求慢得多。
//                              与其他对 RIOSendEx 函数的调用不同，当设置了 RIO_MSG_COMMIT_ONLY 标志时，对 RIOSendEx 函数的调
//                              用不需要序列化。对于单个 RIO_RQ，可以在一个线程上调用带有 RIO_MSG_COMMIT_ONLY 的 RIOSendEx 函
//                              数，同时在另一个线程上调用 RIOSendEx 函数。
//      RIO_MSG_DONT_NOTIFY     当请求完成被插入到其完成队列中时，不应触发 RIONotify 函数。
//      RIO_MSG_DEFER           请求不需要立即执行。这会将请求插入到请求队列中，但可能会也可能不会触发请求的执行。
//                              发送数据可能会延迟，直到在 SocketQueue 参数中传递的 RIO_RQ 上发出一个没有设置 RIO_MSG_DEFER
//                              标志的发送请求。要触发发送队列中所有发送的执行，请调用没有设置 RIO_MSG_DEFER 标志的 RIOSend 或
//                              RIOSendEx 函数。
//                              注意，无论是否设置了 RIO_MSG_DEFER，发送请求都会占用 SocketQueue 参数中传递的 RIO_RQ 上的未完
//                              成 I/O 容量。
//
// 参数 RequestContext 与此次发送操作关联的请求上下文。
//
// 应用程序可以使用 RIOSendEx 函数从完全包含在单个注册缓冲区内的任何缓冲区发送网络数据。
// pData 参数指向的 RIO_BUF 结构的 Offset 和 Length 成员决定了从缓冲区发送的网络数据。
//
// 与发送操作关联的缓冲区不能与另一个发送或接收操作同时使用。缓冲区和缓冲区注册必须在整
// 个发送操作期间保持有效。这意味着您不应在已经有一个待处理的 RIOSend(Ex) 请求时，将相
// 同的 PRIO_BUF 传递给 RIOSend(Ex) 请求。只有在请求中的 RIOSend(Ex) 操作完成后，才
// 能重新使用相同的 PRIO_BUF（无论是使用相同的偏移量还是使用不同的偏移量和长度）。此外，
// 当发送数据引用注册缓冲区（无论是部分还是整个缓冲区）时，在发送完成之前，不得使用整个
// 注册缓冲区。这包括使用注册缓冲区的一部分进行接收操作或另一个发送操作。
//
// 下表是与 pControlContext 相关的控制信息：
//  协议    cmsg_level      cmsg_type       描述
//  IPv4    IPPROTO_IP      IP_PKTINFO      指定/接收数据包信息。有关更多信息，请参阅 IP_PKTINFO 套接字选项。
//  IPv6    IPPROTO_IPV6    IPV6_DSTOPTS    指定/接收目标选项。
//  IPv6    IPPROTO_IPV6    IPV6_HOPLIMIT   指定/接收跳数限制。有关更多信息，请参阅 IPV6_HOPLIMIT 套接字选项。
//  IPv6    IPPROTO_IPV6    IPV6_HOPOPTS    指定/接收逐跳选项。
//  IPv6    IPPROTO_IPV6    IPV6_NEXTHOP    指定下一跳地址。
//  IPv6    IPPROTO_IPV6    IPV6_PKTINFO    指定/接收数据包信息。有关更多信息，请参阅 IPV6_PKTINFO 套接字选项。
//  IPv6    IPPROTO_IPV6    IPV6_RTHDR      指定/接收路由头。
//
// 控制数据由一个或多个控制数据对象组成，每个对象都以 WSACMSGHDR 结构开头，定义如下：
//      typedef struct WSACMSGHDR_t {
//          int cmsg_len;    // 从 WSACMSGHDR 开始到数据末尾的字节数（不包括可能跟随数据的填充字节）
//          int cmsg_level;  // 产生控制信息的协议
//          int cmsg_type;   // 协议特定的控制信息类型
//      } WSACMSGHDR;
//
// Flags 参数可用于影响 RIOSendEx 函数的行为，此函数的行为由与 SocketQueue 关联套接字
// 选项以及在 Flags 参数中指定的值的组合决定。

DWORD prh_impl_rio_send(prh_rio_rqueue *rqueue, RIO_BUF *buffer, DWORD flags, void *request_context) {
    BOOL b = PRH_IMPL_RIO.RIOSend(
        /* RIO_RQ SocketQueue       */ (RIO_RQ)rqueue,
        /* PRIO_BUF pData           */ buffer,
        /* ULONG DataBufferCount    */ 1,
        /* DWORD Flags              */ flags,
        /* PVOID RequestContext     */ (PVOID)request_context
        );
    return b == TRUE ? 0 : WSAGetLastError();
}

int prh_iocp_riosend_alloc_size(void) {
    return prh_impl_iocp_trxreq_alloc_size();
}

void prh_iocp_riosend_init(prh_iocp_riosend *req, prh_rio_socket rio_socket, prh_continue_routine routine, void *context) {
    prh_impl_iocp_trxreq_init(req, (prh_handle)rio_socket, routine, context);
}

void prh_impl_iocp_riosend_req(prh_iocp_riosend *req, const prh_byte *buffer, int length, prh_u32 flags) {
    assert(buffer >= PRH_IMPL_RIO_BUFBEG && buffer < PRH_IMPL_RIO_BUFEND && (buffer % PRH_CACHE_LINE_SIZE) == 0);
    assert(length > 0 && length < PRH_IMPL_TXRX_BYTES && buffer + length < PRH_IMPL_RIO_BUFEND);
    RIO_BUF rio_buf = {.BufferId = (RIO_BUFFERID)PRH_IMPL_RIO_BUFFER, .Offset = (ULONG)(buffer - PRH_IMPL_RIO_BUFBEG), .Length = (ULONG)length};
    DWORD error_code = prh_impl_rio_send((prh_rio_socket)req->socket, &rio_buf, flags, &req->overlapped);
    if (error_code == 0 || error_code == WSA_IO_PENDING) {
        req->post.continue_routine = prh_impl_iocp_wsasend_completed_from_port; // 严格来说，是通过查询完成队列来完成操作
        return; // 请求立即完成或已经成功投递
    }
    prh_prerr(error_code);
    prh_impl_iocp_error_occurred(&req->post, error_code);
    prh_impl_iocp_wsasend_complete(&req->post);
}

void prh_iocp_riosend_req(prh_iocp_riosend *req, const prh_byte *buffer, int length) {
    prh_impl_iocp_riosend_req(req, buffer, length, 0);
}

void prh_iocp_riosend_dont_notify_req(prh_iocp_riosend *req, const prh_byte *buffer, int length) {
    // 设置了 RIO_MSG_DONT_NOTIFY 的操作，请求完成之后会插入 RIO_CQ 完成队列，但是不会通知关联的完成端口
    prh_impl_iocp_riosend_req(req, buffer, length, RIO_MSG_DONT_NOTIFY);
}

// BOOL RIOReceive(
//      RIO_RQ SocketQueue,
//      PRIO_BUF pData,
//      ULONG DataBufferCount,
//      DWORD Flags,
//      PVOID RequestContext
// );
//
// RIOReceive 函数用于在已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套接字上接收网络数
// 据。如果没有错误发生，RIOReceive 函数返回 TRUE。在这种情况下，接收操作已成功启动，
// 完成已经排队，或完成将在稍后排队。返回值为 FALSE 表示函数失败，操作未成功启动，且不
// 会排队完成通知。可以通过调用 WSAGetLastError 函数获取特定的错误代码。
//      WSAEFAULT               系统在尝试使用指针参数调用时检测到无效的指针地址。如果在操作排队或调用之前，传递给参数的任何 RIO_BUF
//                              结构的缓冲区标识符被注销或缓冲区被释放，则返回此错误。
//      WSAEINVAL               传递给函数的参数无效。如果 SocketQueue 参数无效，Flags 参数包含对接收操作无效的值，或者完成队列
//                              的完整性受到损害，则返回此错误。此错误也可能因其他参数问题而返回。
//      WSAENOBUFS              无法分配足够的内存。如果与 SocketQueue 参数关联的 I/O 完成队列已满，或者 I/O 完成队列是用零接收
//                              条目创建的，则返回此错误。
//      WSA_OPERATION_ABORTED   在接收操作挂起时，操作已被取消。如果套接字被本地或远程关闭，或者在此套接字上执行了 WSAIoctl 的
//                              SIO_FLUSH 命令，则返回此错误。
//
// 参数 SocketQueue 一个描述符，用于标识已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套
// 接字。参数 pData 对注册缓冲区中用于接收数据的部分的描述。如果应用程序不需要接收 UDP
// 数据报中的数据负载，则对于已绑定的 RIO UDP 套接字，此参数可以为 NULL。参数 DataBufferCount
// 表示是否要在 pData 参数指向的缓冲区中接收数据。如果 pData 为 NULL，则此参数应设置为
// 零。否则，此参数应设置为 1。
//
// 参数 Flags 一组修改 RIOReceive 函数行为的标志。Flags 参数可以包含以下选项的组合，
// 这些选项在 Mswsockdef.h 头文件中定义：
//      RIO_MSG_COMMIT_ONLY     之前使用 RIO_MSG_DEFER 标志添加的请求将被提交。当设置了 RIO_MSG_COMMIT_ONLY 标志时，不得指定
//                              其他标志。当设置了 RIO_MSG_COMMIT_ONLY 标志时，pData 和 RequestContext 参数必须为 NULL，
//                              DataBufferCount 参数必须为零。
//                              通常情况下，此标志会在使用 RIO_MSG_DEFER 标志发出多个请求后偶尔使用。这消除了在使用 RIO_MSG_DEFER
//                              标志时需要发出最后一个没有 RIO_MSG_DEFER 标志的请求的需求，否则最后一个请求的完成速度会比其他请
//                              求慢得多。
//                              与其他对 RIOReceive 函数的调用不同，当设置了 RIO_MSG_COMMIT_ONLY 标志时，对 RIOReceive 函数的
//                              调用不需要序列化。对于单个 RIO_RQ，可以在一个线程上调用带有 RIO_MSG_COMMIT_ONLY 的 RIOReceive
//                              函数，同时在另一个线程上调用 RIOReceive 函数。
//      RIO_MSG_DONT_NOTIFY     当请求完成被插入到其完成队列中时，不应触发 RIONotify 函数。
//      RIO_MSG_DEFER           请求不需要立即执行。这会将请求插入到请求队列中，但可能会也可能不会触发请求的执行。数据接收可能会
//                              延迟，直到在 SocketQueue 参数中传递的 RIO_RQ 上发出一个没有设置 RIO_MSG_DEFER 标志的接收请求。
//                              要触发请求队列中所有接收的执行，请调用没有设置 RIO_MSG_DEFER 标志的 RIOReceive 或 RIOReceiveEx
//                              函数。
//                              注意，无论是否设置了 RIO_MSG_DEFER，接收请求都会占用 SocketQueue 参数中传递的 RIO_RQ 上的未完
//                              成 I/O 容量。
//      RIO_MSG_WAITALL         RIOReceive 函数不会完成，直到以下事件之一发生。此标志不支持 UDP 套接字。
//                              * 调用者在 pData 参数中提供的缓冲区段完全填满。
//                              * 连接已关闭。
//                              * 请求被取消或发生错误。
//
//  参数 RequestContext 与此次接收操作关联的请求上下文。
//
// 应用程序可以使用 RIOReceive 函数将网络数据接收进完全包含在单个注册缓冲区内的任何缓
// 冲区。pData 参数指向的 RIO_BUF 结构的 Offset 和 Length 成员决定了网络数据在缓冲区
// 中的接收位置。
//
// 一旦调用了 RIOReceive 函数，pData 参数中传递的缓冲区，包括 RIO_BUF 结构的 BufferId
// 成员中的 RIO_BUFFERID，必须在整个接收操作期间保持有效。
//
// 为了避免竞争条件，与接收请求关联的缓冲区在请求完成之前不应被读取或写入。这包括将缓冲
// 区用作发送请求的源或另一个接收请求的目的地。未与任何接收请求关联的注册缓冲区的部分不
// 受此限制。
//
// Flags 参数可用于影响 RIOReceive 函数调用的行为，此函数的行为由与 SocketQueue 关联
// 的套接字选项以及在 Flags 参数中指定的值组合决定。
//
// int RIOReceiveEx(
//      RIO_RQ SocketQueue,
//      PRIO_BUF pData,
//      ULONG DataBufferCount,
//      PRIO_BUF pLocalAddress,
//      PRIO_BUF pRemoteAddress,
//      PRIO_BUF pControlContext,
//      PRIO_BUF pFlags,
//      DWORD Flags,
//      PVOID RequestContext
// );
//
// typedef union _SOCKADDR_INET {
//      SOCKADDR_IN    Ipv4;
//      SOCKADDR_IN6   Ipv6;
//      ADDRESS_FAMILY si_family;
// } SOCKADDR_INET, *PSOCKADDR_INET;
//
// RIOSendEx 函数用于在已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套接字上发送网络数据，
// 并提供了与 Winsock RIO 扩展一起使用的附加选项。如果没有错误发生，RIOSendEx 函数返回
// TRUE。在这种情况下，接收操作已成功启动，完成已经排队，或完成将在稍后时间排队。FALSE
// 表示函数失败，操作未成功启动，完成通知不会排队。可以通过调用 WSAGetLastError 函数获
// 取特定的错误代码。
//      WSAEFAULT               系统在尝试使用指针参数时检测到无效的指针地址。如果在操作排队或调用之前，为参数传递的任何 RIO_BUF
//                              结构注销了缓冲区标识符或释放了缓冲区，则返回此错误。
//      WSAEINVAL               向函数传递了无效参数。如果 SocketQueue 参数无效，dwFlags 参数包含对发送操作无效的值，或者完成队
//                              列的完整性受到损害，则返回此错误。此错误也可能因其他参数问题而返回。
//      WSAENOBUFS              无法分配足够的内存。如果与 SocketQueue 参数关联的 I/O 完成队列已满，或者 I/O 完成队列是用零发送
//                              条目创建的，则返回此错误。
//      WSA_IO_PENDING          操作已成功启动，完成将在稍后时间排队。
//      WSA_OPERATION_ABORTED   操作已被取消，而接收操作仍在挂起。如果套接字在本地或远程关闭，或者执行了 WSAIoctl 中的 SIO_FLUSH
//                              命令，则返回此错误。
//
// 参数 SocketQueue 标识已连接的 RIO TCP 套接字或已绑定的 RIO UDP 套接字的描述符。
//
// 参数 pData 用于接收数据的缓冲区区域。如果应用程序不需要在 UDP 数据报中接收数据负载，
// 则对于已绑定的 RIO UDP 套接字，此参数可以为 NULL。参数 DataBufferCount 表示是否要
// 使用 pData 参数指向的缓冲区接收数据。如果 pData 为 NULL，则此参数应设置为零。否则，
// 此参数应设置为 1。
//
// 参数 pLocalAddress 一个缓冲区段，完成时将包含接收网络数据的本地地址。如果应用程序不
// 想接收本地地址，则此参数可以为 NULL。如果此参数不为 NULL，则缓冲区段的大小必须至少为
// SOCKADDR_INET 结构的大小。
//
// 参数 pRemoteAddress 一个缓冲区段，完成时将包含接收网络数据的远程地址。如果应用程序
// 不想接收远程地址，则此参数可以为 NULL。如果此参数不为 NULL，则缓冲区段的大小必须至少
// 为 SOCKADDR_INET 结构的大小。
//
// 参数 pControlContext 一个缓冲区切片，完成时将包含有关接收操作的额外控制信息。如果应
// 用程序不想接收额外的控制信息，则此参数可以为 NULL。参数 pFlags 在完成时将包含有关接
// 收操作的附加标志信息。如果应用程序不需要接收附加标志信息，则此参数可以为 NULL。
//
// 参数 Flags 一组标志，用于修改 RIOReceiveEx 函数的行为。Flags 参数可以包含以下选项
// 的组合，这些选项在 Mswsockdef.h 头文件中定义：
//      RIO_MSG_COMMIT_ONLY     之前使用 RIO_MSG_DEFER 标志添加的请求将被提交。当设置 RIO_MSG_COMMIT_ONLY 标志时，不能指定其
//                              他标志。当设置 RIO_MSG_COMMIT_ONLY 标志时，pData、pLocalAddress、pRemoteAddress、pControlContext、
//                              pFlags 和 RequestContext 参数必须为 NULL，DataBufferCount 参数必须为零。
//                              通常在使用 RIO_MSG_DEFER 标志发出多个请求后，偶尔使用此标志。这避免了在使用 RIO_MSG_DEFER 标志
//                              时需要发出最后一个没有 RIO_MSG_DEFER 标志的请求，这会导致最后一个请求比其他请求慢得多。
//                              与其他 RIOReceiveEx 函数调用不同，当设置 RIO_MSG_COMMIT_ONLY 标志时，对 RIOReceiveEx 函数的
//                              调用不需要序列化。对于单个 RIO_RQ，可以在一个线程上使用 RIO_MSG_COMMIT_ONLY 调用 RIOReceiveEx
//                              函数，同时在另一个线程上调用 RIOReceiveEx 函数。
//      RIO_MSG_DONT_NOTIFY     请求完成在插入完成队列中时不应触发 RIONotify 函数。
//      RIO_MSG_DEFER           请求不需要立即执行。这将把请求插入请求队列，但可能会也可能不会触发请求的执行。
//                              数据接收可能会延迟，直到在 SocketQueue 参数传递的 RIO_RQ 上发出没有设置 RIO_MSG_DEFER 标志的
//                              接收请求。要触发请求队列中所有接收的执行，请调用 RIOReceive 或 RIOReceiveEx 函数，且不设置
//                              RIO_MSG_DEFER 标志。
//                              注意：无论是否设置了 RIO_MSG_DEFER，接收请求都会占用 SocketQueue 参数传递的 RIO_RQ 上的未完成
//                              I/O 容量。
//      RIO_MSG_WAITALL         RIOSendEx 函数不会完成，直到发生以下事件之一。此标志不支持数据报套接字或面向消息的无连接套接字。
//                              * 调用方在 pData 参数中提供的缓冲区切片完全填满。
//                              * 连接已关闭。
//                              * 请求被取消或发生错误。
//
// 参数 RequestContext 与此次接收操作关联的请求上下文。
//
// 应用程序可以使用 RIOSendEx 函数将网络数据接收进完全包含在单个注册缓冲区内的任何缓冲
// 区。pData 参数指向的 RIO_BUF 结构的 Offset 和 Length 成员确定网络数据在缓冲区中的
// 接收位置。
//
// 调用 RIOSendEx 函数后，pData 参数传递的缓冲区，包括 RIO_BUF 结构的 BufferId 成员中
// 的 RIO_BUFFERID，必须在整个接收操作期间保持有效。
//
// 为了避免竞争条件，与接收请求关联的缓冲区在请求完成之前不应被读取或写入。这包括将缓冲
// 区用作发送请求的源或另一个接收请求的目的地。未与任何接收请求关联的注册缓冲区的部分不
// 受此限制。
//
// pLocalAddress 参数可用于检索数据接收的本地地址。pRemoteAddress 参数可用于检索数据
// 发送的远程地址。本地和远程地址以 SOCKADDR_INET 结构的形式返回。因此，pLocalAddress
// 或 pRemoteAddress 参数指向的 RIO_BUF 的 Length 成员应等于或大于 SOCKADDR_INET 结
// 构的大小。
//
// 以下是与 pControlContext 相关的控制信息：
//  协议    cmsg_level      cmsg_type               描述
//  IPv4    IPPROTO_IP      IP_ORIGINAL_ARRIVAL_IF  接收数据报套接字接收数据包的原始 IPv4 到达接口。此控制数据用于防火墙，当使用 Teredo、6to4 或 ISATAP 隧道进行 IPv4 NAT 穿越时。
//  IPv4    IPPROTO_IP      IP_PKTINFO              指定/接收数据包信息。
//  IPv6    IPPROTO_IPV6    IPV6_DSTOPTS            指定/接收目标选项。
//  IPv6    IPPROTO_IPV6    IPV6_HOPLIMIT           指定/接收跳数限制。
//  IPv6    IPPROTO_IPV6    IPV6_HOPOPTS            指定/接收逐跳选项。
//  IPv6    IPPROTO_IPV6    IPV6_NEXTHOP            指定下一跳地址。
//  IPv6    IPPROTO_IPV6    IPV6_PKTINFO            指定/接收数据包信息。
//  IPv6    IPPROTO_IPV6    IPV6_RTHDR              指定/接收路由头。
//
// 控制数据由一个或多个控制数据对象组成，每个对象都以 WSACMSGHDR 结构开始，定义如下：
//      typedef struct WSACMSGHDR_t {
//          int cmsg_len;    // 从 WSACMSGHDR 开始到数据末尾的字节数（不包括可能跟随数据的填充字节）
//          int cmsg_level;  // 产生控制信息的协议
//          int cmsg_type;   // 协议特定的控制信息类型
//      } WSACMSGHDR;
//
// Flags 参数可用于在关联套接字指定的选项之外影响 RIOSendEx 函数调用的行为。该函数的行
// 为由关联套接字上设置的任何套接字选项与 Flags 参数中指定的值的组合决定。

DWORD prh_impl_rio_recv(prh_rio_rqueue *rqueue, RIO_BUF *buffer, DWORD flags, void *request_context) {
    BOOL b = PRH_IMPL_RIO.RIORecv(
        /* RIO_RQ SocketQueue       */ (RIO_RQ)rqueue,
        /* PRIO_BUF pData           */ buffer,
        /* ULONG DataBufferCount    */ 1,
        /* DWORD Flags              */ flags,
        /* PVOID RequestContext     */ (PVOID)request_context
        );
    return b == TRUE ? 0 : WSAGetLastError();
}

int prh_iocp_riorecv_alloc_size(void) {
    return prh_impl_iocp_trxreq_alloc_size();
}

void prh_iocp_riorecv_init(prh_iocp_riorecv *req, prh_rio_socket rio_socket, prh_continue_routine routine, void *context) {
    prh_impl_iocp_trxreq_init(req, (prh_handle)rio_socket, routine, context);
}

void prh_impl_iocp_riorecv_req(prh_iocp_riorecv *req, prh_byte *buffer, int length, prh_u32 flags) {
    assert(buffer >= PRH_IMPL_RIO_BUFBEG && buffer < PRH_IMPL_RIO_BUFEND && (buffer % PRH_CACHE_LINE_SIZE) == 0);
    assert(length > 0 && length < PRH_IMPL_TXRX_BYTES && buffer + length < PRH_IMPL_RIO_BUFEND);
    RIO_BUF rio_buf = {.BufferId = (RIO_BUFFERID)PRH_IMPL_RIO_BUFFER, .Offset = (ULONG)(buffer - PRH_IMPL_RIO_BUFBEG), .Length = (ULONG)length};
    DWORD error_code = prh_impl_rio_recv((prh_rio_socket)req->socket, &rio_buf, flags, &req->overlapped);
    if (error_code == 0 || error_code == WSA_IO_PENDING) {
        req->post.continue_routine = prh_impl_iocp_wsarecv_completed_from_port; // 严格来说，是通过查询完成队列来完成操作
        return; // 请求立即完成或已经成功投递
    }
    prh_prerr(error_code);
    prh_impl_iocp_error_occurred(&req->post, error_code);
    prh_impl_iocp_wsarecv_complete(&req->post);
}

void prh_iocp_riorecv_req(prh_iocp_riorecv *req, const prh_byte *buffer, int length) {
    prh_impl_iocp_riorecv_req(req, buffer, length, 0);
}

void prh_iocp_riorecv_dont_notify_req(prh_iocp_riorecv *req, const prh_byte *buffer, int length) {
    // 设置了 RIO_MSG_DONT_NOTIFY 的操作，请求完成之后会插入 RIO_CQ 完成队列，但是不会通知关联的完成端口
    prh_impl_iocp_riorecv_req(req, buffer, length, RIO_MSG_DONT_NOTIFY);
}

#ifdef PRH_TEST_IMPLEMENTATION
void prh_impl_sock_test(void) {
    printf("SOCKET %d-byte\n", (int)sizeof(SOCKET));
    printf("INVALID_SOCKET %d\n", INVALID_SOCKET);
    printf("struct sockaddr_in %d-byte\n", (int)sizeof(struct sockaddr_in));
    printf("struct sockaddr_in6 %d-byte\n", (int)sizeof(struct sockaddr_in6));
    printf("RIO_MAX_CQ_SIZE %d (%08x)\n", RIO_MAX_CQ_SIZE, RIO_MAX_CQ_SIZE);
}
#endif // PRH_TEST_IMPLEMENTATION
#else // POSIX begin
// RFC 791 - Internet Protocol, J. Postel (ed.), 1981
// RFC 950 - Internet Standard Subnetting Procedure, J. Mogul J. Postel, 1985
// RFC 793 - Transmission Control Protocol, J. Postel (ed.), 1981
// RFC 768 - User Datagram Protocol, J. Postel (ed.), 1980
// RFC 1122 - Requirements for Internet Hosts Communication Layers, R. Braden (ed.), 1989 对早期 TCP/IP 的扩展和修正
// RFC 1323 - TCP Extensions for High Performance, 1992
// RFC 2018 - TCP Selective Acknowledgment Options, 1996
// RFC 2581 - TCP Congestion Control, 1999
// RFC 2861 - TCP Congestion Window Validation, 2000
// RFC 2883 - An Extension to the Selective Acknowledgement (SACK) Option, 2000
// RFC 2988 - Computing TCP's Retransmission Timer, 2000
// RFC 3168 - The Addition of Explicit Congestion Notification (ECN) to IP, 2001
// RFC 3390 - Increasing TCP's Initial Window, 2002
//
// 流式套接字（SOCK_STREAM）提供可靠双向的字节流通信信道，字节流表示与管道一样不存在消息
// 边界的概念。流式套接字通常被称为面向连接的，术语对等套接字指连接另一端的套接字，对等
// 地址表示对端地址。数据包套接字（SOCK_DGRAM）运行数据以数据报的消息的形式进行交换，在
// 数据报套接字中，消息边界得到了保留，但数据传输是不可靠的。消息的到达可能是无序的、重复
// 的或者根本就无法到达。数据报套接字是更一般的无连接套接字，与流式套接字不同，一个数据报
// 套接字在使用时无需与另一个套接字连接。数据包套接字可以与另一个套接字进行连接，但其语义
// 与连接的流式套接字不同。在 internet domain 中，数据包套接字使用了用户数据报协议（UDP），
// 而流式套接字则通常使用传输控制协议（TCP），一般来讲在称呼这两种套接字时更偏向于使用术语
// UDP 套接字和 TCP 套接字。
//
// 套接字 I/O 操作可以使用传统的 read() 和 write() 系统调用，或者使用一组套接字特有的
// 系统调用，如 send() recv() sendto() recvfrom() 来完成。在默认情况下，这些系统调用
// 在 I/O 操作无法被立即完成时会阻塞。通过使用 fcntl() F_SETFL 操作启用 O_NONBLOCK
// 打开文件状态标记可以执行非阻塞 I/O。
//
// UDP 协议格式：
//      [源IP地址 4B|目的IP地址 4B|0 1B|17 1B|UDP长度 2B]      伪首部
//      [源端口 2B|目的端口 2B|整体长度 2B|校验和 2B][数据部分]  UDP数据报
//
// UDP 用户数据报头部中校验和的计算方法有些特殊，在计算校验和时，要在UDP用户数据报之前
// 增加12个字节的伪首部，伪首部仅仅为了计算校验和而用。UDP 和 TCP 使用的校验和的长度只有
// 16位，并且只是简单的“总结性”校验和，因此无法检测出特定的错误，其结果是无法提供较强的
// 错误检测机制。繁忙的互联网服务器通常只能每隔几天看一下未检测出的传输错误的平均情况。需
// 要更多确保数据完整性的应用程序可以使用安全套接字层（Secure Sockets Layer, SSL），它
// 不仅仅提供了安全的通信，而且还提供更加严格的错误检测过程。或者应用程序也可以实现自己的
// 错误控制机制。
//
// 鉴于 TCP 可提供可靠的数据传送而 UDP 无法保证这一点，那么为何还要有 UDP 呢？这里是我们
// 选择 UDP 的原因：（一）UDP 服务器能从多个客户端接收数据报并可以向它们发送回复，而不必
// 为每个客户端创建和终止连接。（二）对于简单的请求响应通信，UDP 的速度比 TCP 更快，因为
// UDP 不需要建立连接和终止连接。在最好的情况下使用 TCP 需要的时间是 2 * RTT + SPT，其
// 中 RTT 表示往返时间，发送一个请求并接收响应所需要的时间，而 SPT 表示服务器端处理请求
// 所用的时间。对于 UDP 来说，最好情况下单个请求响应通信所用的时间为 RTT + SPT。DNS 就
// 是应用 UDP 绝好的例子，采用 UDP 使得域名查找操作只需要在服务器间双向各发送一个数据报
// 即可。（三）UDP 套接字上可以进行广播和组播处理，广播允许发送端发送的数据报能在接入到
// 该网络的所有主机的相同端口收到。组播也类似，只是组播只允许数据报发送到指定的一组主机
// 上。（四）某些特定的应用，例如视频流和音频流，不需要 TCP 提供可靠性也能在可接受范围内
// 工作。换句话说，当报文在传输过程中丢失，TCP 尝试重传所造成的延时可能是无法接受的，在
// 视频流中出现延时可能比简单的丢包更严重。因而，这样的应用更倾向于使用 UDP，并在应用程序
// 中采用特定的恢复策略来应对偶尔会出现的丢包现象。
//
// 使用 UDP 但又需要可靠性保证的应用程序必须自行实现可靠性保障功能，通常这至少需要序号、
// 确认机制、丢包重传以及重复报文检测。但是，如果还需要更高级的功能如流量控制和拥塞控制的
// 话，那么最好还是直接使用 TCP。在 UDP 之上实现所有这些功能是非常复杂的，就算真的实现得
// 很好，结果也很可能达不到 TCP 的性能。
//
// https://www.man7.org/linux/man-pages/man7/tcp.7.html
//
// TCP 协议格式：前20个字节固定，后面有4n字节根据需要增加选项
//      [源端口 2B][目的端口 2B]
//      [序号 4B]                              TCP是面向字节流的，在TCP连接中传送的每个字节都按顺序编号，字节流的起始序号在连接建立时设置，序号字段表示的是第一个字节的序号
//      [确认号 4B]                            期望收到对方下一个报文段的第一个数据字节的序号
//      [数据偏移|保留 1B]                      数据偏移字段（4-bit）表示数据部分距离头部起始位置有多远，以4字节为单位，最大可以表示15*4=60字节，这也是TCP首部的最大长度
//      [CWR|ECE|URG|ACK|PSH|RST|SYN|FIN 1B]   CWR（congestion window reduced flag）拥塞窗口减小标记；ECE（explicit congestion notification echo flag）显式拥塞通知回显标记
//      [窗口 2B]                              发送本报文段的一方的接收窗口大小，窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前可以接收的数据量
//      [校验和 2B]                            TCP校验和不只包含TCP首部以及数据部分，还包括称为伪首部的12个字节，[源地址 4B|目的地址 4B|0 1B|6 1B|TCP长度 2B]
//      [紧急指针 2B]                          紧急指针仅在 URG=1 时才有意义，指出本报文段中紧急数据的字节数，其加上序号指向非紧急数据的第一个字节，紧急数据结束后才是普通数据，注意即使窗口为零也可发送紧急数据
//      [可选选项|填充]                         可选字段最长40个字节
//      [数据部分 0B ~ nB]
//      CWR 和 ECE 标记用在 TCP/IP 的显式拥塞通知（ECN）算法中，ECN 加入进来的时间相对较新（RFC 3168），Linux 2.4 实现了 ENC，设置 /proc/sys/net/ipv4/tcp_ecn 非零值开启这个功能
//      紧急 URG=1 表示紧急指针字段有效，它告诉系统此报文段中有紧急数据，应尽快传送（相当于高优先级数据），而不要按原来的排队顺序传送
//      确认 ACK=1 表示确认号字段有效，TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置为 1
//      推送 PSH=1 当两应用交互时，有时希望键入命令后立即就能收到对方的响应，此时TCP可以使用推送操作，把PSH置1并立即创建一个报文发送出去，接收方也会尽快交付不等缓存满，虽然程序可以选择推送操作但还很少使用
//      复位 RST=1 表示TCP连接出现了严重差错，如主机崩溃或其他原因，必须释放连接，然后再重新建立连接，复位还用来拒绝一个非法的报文段或拒绝打开一个连接
//      同步 SYN=1 在连接建立时用来同步序号，当SYN=1而ACK=0时表明这是一个连接请求报文，对方若同意建立连接则应响应SYN=1和ACK=1，在连接建立的过程的同时交换了初始字节序号
//      终止 FIN=1 用来释放连接表示发送端提示已经完成了发送任务，当FIN=1时表示此报文段的发送方的数据已发送完毕，并要求释放连接
//      窗口字段明确指出现在允许发送方可以发送的数据量，窗口值是经常在动态变化的值。
//      紧急指针字段：RFC 793 第17页描述紧急指针指向非紧急数据的第一个字节；RFC 1011 勘误，紧急指针指向紧急数据的最后一个字节；而 RFC 9293 又将紧急指针定义为指向非紧急数据的第一个字节。
//      可选选项最初只有最大报文段长度 MSS（Max Segment Size），即 TCP 数据报数据字段的最大长度；后面增加了窗口扩大选项、时间戳选项、选择确认（SACK）选项等等。
//      窗口扩大选项是为了扩大窗口，原始窗口大小最大 64KB 字节，虽然对早期的网络是足够的，但对于包含卫星信道的网络，传播时延和带宽都很大，要获得高吞吐率需要更大的窗口大小。
//      时间戳选项占10字节，其中最主要的字段时间戳值（4字节）和时间戳回送回答（4字节），用来计算往返时间 RTT，以及处理 TCP 序号超过 32-bit 的情况，又称为防止序号绕回 PAWS。
//
// 确认、重传、超时：当一个 TCP 段无错地到达目的地时，接收 TCP 会向发送者发送一个确认，
// 通知它数据接收成功。如果一个段在到达时存在错误，那么这个段会被丢弃，确认也不会被发送。
// 为了处理段永远不能到达或被丢弃的情况，发送者在发送每一个段时会开启一个定时器。如果在
// 定时器超时之前没有收到确认，那么就会重传这个段。由于所使用的网络以及当前的流量负载会
// 影响传输一个段和接收其确认所需的时间，因此 TCP 采用了一个算法来动态地调整重传超时时间
// （RTO）的大小。接收 TCP 可能不会立即发送确认，而是会等待即毫秒来观察一下是否可以将确
// 认塞进接收者返回给发送者的响应中。这项被称为延迟 ACK 的技术的目的时能少发一个 TCP
// 段，从而降低网络中包的数量以及降低发送和接收主机的负载。
//
// MSS 并不是考虑接收方应用层的接收缓存可能放不下 TCP 报文段中的数据，实际上 MSS 与接收
// 窗口值没有关系，它考虑的时网络底层的数据传送能力。我们知道 TCP 报文段的数据部分，至少
// 要加上 40 字节的头部（包括TCP头部和IP头部）才能组装成一个IP数据报，若选择较小的 MSS
// 网络利用率就较低。但反过来，若TCP报文段非常长，那么在 IP 层传输时就可能要分解成多个短
// 数据片，在终点要把收到的各个短数据分片装配成原来的TCP报文段。当传输出错时还要进行重传，
// 这些也都会使开销增大。因此，MSS 应尽可能大些，只要在 IP 层传输时不需要再分片就行。由于
// IP 数据报所经历的路径时动态变化的，因此在这条路径上确定的不需要分片的 MSS，如果改走另
// 一条路径就可能需要进行分片，因此最佳的 MSS 是很难确定的。在连接建立的过程中，双方都把
// 字节能够支持的 MSS 写入这一字段，以后就按照这个数值传送数据，两个传送方向可以有不同的
// MSS 值。RFC 879 指出，流行的一种说法是在 TCP 连接建立阶段双方协商 MSS 值，但这是错误
// 的，因为这里并不存在任何的协商，而只是一方把 MSS 值设定好以后通知另一方而已。若主机未
// 填写这一项，则 MSS 的默认值是 536 字节，因此所有在因特网上的主机都应能接受的数据报长度
// 为 536 + 20（TCP固定首部）+ 20（IP固定首部）= 576 字节。
//
// 拥塞控制：慢启动和拥塞避免算法。TCP 的拥塞控制算法被设计用来防止快速的发送者压垮整个
// 网络。如果发送 TCP 的速度要快于一个中间路由器转发的速度，那么该路由器就会开始丢弃包。
// 这将会导致较高的包丢失率，其结果是如果 TCP 保持以相同的速度发送这些被丢弃的段就会极大
// 地降低网络性能。TCP 的拥塞控制算法在以下两个场景中比较重要：（一）在连接建立后或空闲
// 一段时间后继续发送，发送者可以立即向网络中注入尽可能多的分段，只要接收者报告的窗口大小
// 允许即可。这里的问题在于如果网络无法处理这种分段洪泛，那么发送者会存在立即压垮整个网络
// 的风险。（二）当拥塞被检测到时，如果发送 TCP 检测到发生了拥塞，那么它就必须降低其传输
// 速率，TCP 根据分段丢失来检测是否发生了拥塞，因为传输错误率时非常低的，即如果一个包丢
// 失了就认为发生了拥塞。
//
// TCP 的拥塞控制策略组合采用了两种算法：慢启动和拥塞避免。慢启动算法会使发送 TCP 在一开
// 始的时候以低速传输分段，但同时允许它以指数级的速度提高其速率，只要这些分段都得到接收
// TCP 的确认。慢启动能够防止一个快速的 TCP 发送者压垮整个网络。但如果不加限制的话，慢
// 启动在传输速率上的指数级增长意味着发送者在短时间内就会压垮整个网络。TCP 的拥塞控制避免
// 算法用来防止这种情况的发生，它为速率的增长安排了一个管理实体。有了拥塞避免之后，在连接
// 刚建立时，发送 TCP 会使用一个较小的拥塞窗口，它会限制所能传输的未确认的数据数量。当发
// 送者从对等 TCP 处收到确认时，拥塞窗口在一开始时会呈现指数级增长。但一旦拥塞窗口增长到
// 一个被认为是接近网络传输容量的阈值时，其增长速度就会编程线性，而不是指数级的。对网络
// 容量的估算时根据检测到拥塞时的传输速率来计算得出的，或者在一开始建立连接时设定为一个
// 固定值。在任何时刻，发送 TCP 传输的数据数量还会受到接收 TCP 的接收窗口和本地的 TCP
// 发送缓冲器大小的限制。慢启动和拥塞避免算法组合起来使得发送者可以快速地将传输速度提升
// 至网络的可用容量，并且不会超出该容量。这些算法的作用时允许数据传输快速地到达一个平衡
// 状态，即发送者传输包的速率与它从接收者处接收确认的速率一致。
//
// 带外数据（紧急数据）是流式套接字的一种特性，允许发送端将传送的数据标记为高优先级。也就
// 是说，接收端不需要读取字节流中所有的中间数据就能获得有可用的带外数据的通知。这个特性在
// 许多程序中都有用到，比如 talnet、rlogin、ftp，它们利用该特性来终止之前传送的命令。带
// 外数据的发送和接收需要在 send() recv() 中指定 MSG_OOB 标记。当一个套接字接收到带外
// 数据可用的通知时，内核为该套接字，通常是使用该套接字的进程，生成 SIGURG 信号，如同
// fcntl() 的 F_SETOWN 操作一样。如果在接收端处理完前一个带外数据字节之前，发送端发送了
// 额外的带外数据，那么新数据将会丢失。即如果用户处于“紧急模式”时又有紧急指针更新，更新的
// 紧急数据将对用户不可见。
//
// 当采用 TCP 套接字时，任意时刻最多只能有 1 字节数据可被标记为带外数据。TCP 将带外数据
// 限制为一个字节，这实际上是在套接字 API 的通用型带外模型和采用 TCP 紧急模式的具体实现
// 之间的不匹配造成的，因为几乎所有实现都采用带外模型并只提供一个字节的带外数据缓冲区。
//
// 在某些 UNIX 实现中，UNIX 域流式套接字是支持带外数据的，而 Linux 不支持。现在不提倡使
// 用带外数据，在某些情况下它可能是不可靠的。另外一种方法是维护两个流式套接字用作通信，其
// 中一个用来做普通的通信，而另一个用来做高优先级通信。这种方法允许让多个字节优先级数据得
// 到传送，还可用在任何通信域的流式套接字中，比如 UNIX 域套接字。
//
// TCP 连接的建立：
//      主机（A）                               主机（B）
//  CLOSED                                  CLOSED（LISTEN）
//      SYN=1 seq=x ACK=0 ---------------------->           （1）
//  SYN-SENT                                SYN-RCVD
//      <-------------- SYN=1 seq=y ACK=1 ack=x+1           （2）如果不想接受连接，不予理睬或发送RST
//  ESTABLISHED
//      SYN=0 seq=x+1 ACK=1 ack=y+1 ------------>           （3）第一个数据包
//                                          ESTABLISHED
//
// TCP 规定 SYN=1 的报文段不能携带数据，但要消耗掉一个字节序号，请求端和接收端都要选择一
// 个自己的起始序号。TCP 规定 ACK=1 的报文段可以携带数据，但如果不携带数据则不消耗序号。
// 例如第（3）步中如果不携带数据，下一个数据报文段的序号仍是 seq=x+1。三次握手，请求端
// 为什么要再次发送一次确认呢？这主要是为了防止已经失效的连接请求报文突然又被传送到接收端
// 而引起错误。
//
// 所谓的“已失效的连接请求报文”是这样产生的，考虑一种正常情况，A 发送连接请求，但因连接
// 报文丢失而未收到确认，于是 A 再重传一次连接请求。后来收到了确认，建立了连接，这里 A
// 共发了两个连接请求报文，其中第一个丢失，第二个到达了 B。现在假设出现一种异常情况，即
// A 发送出去的第一个连接请求并没有丢失，而是在某些网络节点长时间滞留了，以致延误到连接
// 释放以后的某个时间才到达 B，本来这是一个早已失效的报文。但 B 收到后误认为 A 又发出了
// 一次连接请求，于是就像 A 发出确认同一建立连接。由于现在 A 并没有发出建立连接的请求，
// 因此不会理睬 B，但 B 却以为新的连接已经建立了，并一直等待 A 发送数据，这样 B 的许多
// 资源就白白浪费了。而三次握手需要 A 的确认 B 才能认为连接建立成功，即使第一个丢失的请
// 求在连接释放后再次到达 B，B 发送了确认，但没有 A 的确认 B 不会认为连接建立成功。
//
// TCP 连接的释放：数据传输结束后，通信的双方都可以释放连接，u 等于前面已经传送过的数据的最后一个字节的序号加1
//      主机（A）                               主机（B）
//  ESTABLISHED                             ESTABLISHED
//      =============== 数据传输完毕 ============>
//      FIN=1 seq=u ACK=1 ack=v ---------------->           （1）接收端通知应用程序，等待应用程序发送被动关闭
//  FIN-WAIT-1                              CLOSE-WAIT
//      <-------------- FIN=0 seq=v ACK=1 ack=u+1           （2）
//  FIN-WAIT-2                              CLOSE-WAIT
//      <============== 数据传输完毕 =============
//      <-------------- FIN=1 seq=w ACK=1 ack=u+1           （3）接收端应用程序最终决定关闭
//  TIME-WAIT                               LAST-ACK
//      FIN=0 seq=u+1 ACK=1 ack=w+1 ------------>           （4）
//  TIME-WAIT                               CLOSED
//  等待 2MSL
//  CLOSED
//
// TCP 规定，FIN=1 报文即使不携带数据，也要消耗掉一个序号。TCP 连接的释放分为两个方向，
// 两个方向都释放才完成。第（2）之后，一个方向的连接就释放了，此时 TCP 连接处于半关闭
// （half-close）状态，即 A 已经没有数据要发送了，但 B 若发送数据，A 仍然要接收。也就
// 是说，从 B 到 A 这个方向的连接并未关闭，这个状态可能会持续一些时间。若 B 也已经没有
// 要向 A 发送的数据，其应用程序就通知 TCP 释放连接，这时 B 发送释放请求，等待释放的最
// 后确认（LAST-ACK），B 只要收到最后确认就认为连接成功释放了。
//
// 但在 A 发送最后确认之后，需要等待 TIME-WAIT 计时器设置的时间 2MSL 之后，A 才进入释放
// 状态。时间 MSL 是最长报文段寿命（Max Segment Lifetime），RFC 793 建议设置为 2 分钟。
// 但这完全是从工程上来考虑，对于现在的网络，MSL=2分钟可能太长了一些，因此 TCP 允许不同
// 的实现可根据具体情况使用更小的 MSL 值。也因此，A 在 TIME-WAIT 之后需要经过 4 分钟后
// 才进入释放状态，才能开始建立下一个新的连接。为什么必须等待 2MSL 时间呢，有两个理由：
// （一）为了保证 A 发送的最后确认报文段能够到达 B，即实现可靠的连接终止，这个确认报文段
// 有可能丢失，B 收不到最后的确认会超时重传断连请求，这时 A 就能在 2MSL 时间内收到这个重
// 传请求接着重发一次确认，再重新启动 2MSL 计时器。这也解释了为何 TIME_WAIT 需要等待
// 2MSL，因为一个 MSL 时间留给最后的确认报文传送给 B，另一个 MSL 时间留给 B 可能重发断
// 连请求到达 A。如果 A 一方已经不存在了，那么它不再持有有关连接的任何状态信息，TCP 将
// 针对对端重发的 FIN 发送一个 RST 作为响应，而这个 RST 会被解释为一个错误。
// （二）防止上文提到的“已失效的连接请求”出现在本连接中，A 在发送完最后一个确认报文后，再
// 经过 2MSL 时间，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以
// 使下一个新的连接中不会出现这种旧的连接请求报文段。我们必须记住 TCP 协议采用重传算法意
// 味着可能会生成重复的报文，并且根据路由的选择，这些重复的报文可能会在连接已经终止后才到
// 达。而在这时，一条相同地址的新的连接可能又建立了起来。这种情况下，TCP 必须确保上一次
// 连接中的重复报文不会再新连接中被当成合法数据接收。而当 TCP 处于 TIME_WAIT 状态时是
// 无法通过相同的地址创建新连接的，这也就阻止了新连接的建立。
//
// 在网络论坛中常会看到一个问题是如何关闭 TIME_WAIT 状态，因为当重新启动的服务器进程尝试
// 将套接字绑定到处于 TIME_WAIT 状态的地址上时，会导致出现 EADDRINUSE 错误。尽管的确有
// 办法可以关闭 TIME_WAIT 状态，并且页有办法可以让 TCP 从 TIME_WAIT 状态中过早地终止，
// 但还是应该避免这么做，因为这么做会阻碍 TIME_WAIT 状态所提供的可靠性保证。可以使用套接
// 字选项 SO_REUSEADDR 避免 EADDRINUSE 错误，同时仍然允许 TIME_WAIT 状态提供其可靠性
// 保障。
//
// TIME_WAIT 状态的存在注意基于两个目的：实现可靠的连接终止；让老的重复的报文段在网络中
// 过期消失，避免新连接收到。其等待时间 2MSL 中的 MSL（报文最大生成时间）是 TCP 报文在
// 网络中的最大生存时间。IP 首部中有一个 8 位生存时间字段（TTL），如果报文从源主机到目的
// 主机间传递时，在规定的跳数（经过的路由器）内没有达到目的地，那么该报文就会被丢弃。MSL
// 是 IP 报文在超过 TTL 限制前可在网络中生存的最大估计时间。由于 TTL 只有 8 位，因此允
// 许最大跳数为 255 跳。通常 IP 报文在完成整个转发过程中需要的跳数比这个最大值要小很多，
// 当路由器出现几种特定类型的异常时（例如路由器错误配置），导致报文在网络中循环直到超过了
// TTL 限制，此时 IP 报文会遇到这个极限值。BSD 套接字实现假设 MSL 为 30 秒，而 Linux
// 遵循了 BSD 规范，因而 Linux 上的 TIME_WAIT 状态将持续 60 秒。但是，RFC 1122 建议
// MSL 的值为 2 分钟，因此在遵循该建议的实现中，TIME_WAIT 状态将持续 4 分钟。
//
// 另外，TCP 还设有一个保活计时器（keeplive timer），设想这样的情况，客户已主动与服务器
// 建立了 TCP 连接，但后来客户端主机突然出故障。显然服务器以后就不能再收到客户发来的数据，
// 因此应当有措施使服务器不要再白白等待下去。这就是使用保活计时器，服务器每收到一次客户的
// 数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器
// 就发送一个探测报文段，以后则每隔75分钟发送一次，若一连发送10个探测报文后仍无客户的响应，
// 服务器就认为客户端出了故障，接着就关闭这个连接。
//
// https://www.cl.cam.ac.uk/~pes20/Netsem/poster.pdf
// TCP 连接的状态迁移：
//
// 客户端角色：关闭状态（CLOSED）                                                 0. 服务端角色：监听状态（LISTEN）
// 1. 发送连接请求，连接已发送状态（SYN_SENT）                                     2. 接收连接请求，连接已接收状态（SYN_RECV），发送服务端连接确认
// 3. 接收连接确认，连接建立状态（ESTABLISHED），发送客户端连接确认                  4. 接收连接确认，连接建立状态（ESTABLISHED）
//
// 状态（0）如果关闭，进入关闭状态（CLOSED）；
// 状态（1）如果关闭或超时，进入关闭状态；
// 状态（2）如果关闭或超时，进入关闭状态；
//
// 主动关闭一方的状态：状态为本地视角，两边可能都认为自己主动，但通常客户端主动关闭     被动关闭一方的状态，
// 5. 发送断连请求，等待断连确认（FIN_WAIT1），也可以接收断连请求                    6. 收到断连请求，发送断连确认，对端已关闭，等待本端关闭（CLOSE_WAIT）
// 7. FIN_WAIT1 收到断连请求，发送断连确认，进入正在关闭状态（CLOSING）              8. 数据发送完毕后，本端进行断连，进入最后确认状态（LAST_ACK）
// 9. FIN_WAIT1 收到断连确认，等待对方断连（FIN_WAIT2）                            10 收到断连确认，连接关闭（CLOSED），因此被动的一方释放得很快
// 11 FIN_WAIT1 收到对方断连和断连确认，发送断连确认，进入最后等待状态（TIME_WAIT）
// 13 CLOSING   收到断连确认，进入最后等待状态（TIMIE_WAIT）
// 15 FIN_WAIT2 收到对方断连，发送断连确认，进入最后等待状态（TIME_WAIT）
// 17 TIME_WAIT 计时器 2MSL 超时之后，连接关闭（CLOSED）
//
// 本地关闭，对端连接：本地数据发送完毕，send() EPIPE，recv() 正常
// 本地连接，对端关闭：对端数据发送完毕，send() 正常， recv() 遇到文件尾，读取0字节
// 本地关闭，对端关闭：两边数据发送完毕，send() EPIPE，recv() 遇到文件尾，读取0字节
//
// 对 TCP 调用 SHUT_RD 没有实际意义，因为大多数 TCP 协议的实现中都没有为 SHUT_RD 提供
// 所期望的行为，而且 SHUT_RD 产生的效果在不同的实现中各由不同。在 Linux 以及其他一些
// 实现中，在执行 SHUT_RD 操作后，read() 将返回文件尾。但是，如果对端应用程序稍后在该
// 套接字上继续 数据，那么仍然可以在本地套接字上读取到数据。在其他实现中（例如BSD），
// SHUT_RD 确实会导致后续的 read() 总是返回 0。但是，在那些实现中，如果对端继续通过
// write() 向套接字写入数据，呢吗数据通道最终会被填满，直到对端 write() 被阻塞（阻塞
// 式）。在 UNIX 域流式套接字中，如果本地套接字上执行 SHUT_RD 操作后，如果对端继续写
// 入数据，那么对端将收到 SIGPIPE，且写入操作会返回 EPIPE。总的来说，对于可移植的 TCP
// 应用程序，应该避免使用 SHUT_RD 操作。
//
// 使用 tcpdump 来监视 TCP 流量。tcpdump 是一个很有用的调试工具，可以让超级用户监视网络
// 中的实时流量，实时生成文本信息，其实 tcpdump 实际可显示所有类型的 TCP/IP 数据包流量，
// 例如 TCP 报文、UDP 数据报、ICMP 报文等等。对于每个网络报文，tcpdump 都会显示出时间
// 戳、源地址、目的地址、以及更多的协议特有的细节信息。wireshark 程序可以完成同 tcpdump
// 类似的认为，但流量信息是通过图形界面来显示的。对于每个 TCP 报文，tcpdump 都会按照如下
// 方式显示：src > dst: flags data-seqno ack window urg <options>。其中 flags 表示
// TCP 控制位，即 S（SYN）、F（FIN）、P（PSH）、R（RST）、E（ECE）、C（CWR）。
//
// 顺序数据包套接字（Sequenced packet socket）SOCK_SEQPACKET 结合了流式套接字和数据报
// 套接字的功能。同流式套接字一样，顺序数据包套接字也是面向连接的，建立连接的方式和流式套
// 接字一样。同数据报套接字一样，顺序数据包套接字也是保留消息边界的。在顺序数据包套接字
// 上调用 read() 只会返回由对端写入的一条消息，如果消息比调用者提供的缓冲区还要长，那么
// 剩余字节会被丢弃。与流式套接字一样，而不同于数据报套接字的是：顺序数据包套接字之间的
// 通信是可靠的，消息会以无错误、按顺序、不重复的方式传递到对端应用程序上，且可以保证消息
// 会到达对端（假设没有出现系统或应用程序崩溃或网络过载的现象）。Linux 2.6.4 内核开始，
// Linux 在 UNIX 域套接字上支持了 SOCK_SEQPACKET。在 Internet 域上，UDP 和 TCP 协议
// 都不支持 SOCK_SEQPACKET，但是 SCTP 协议是支持的。
//
// SCTP 和 DCCP 是两个新的传输层协议。流控制传输协议（SCTP）同 TCP 一样提供了可靠、双
// 向、面向连接的传输。与 TCP 不同的是，SCTP 预留了消息边界。SCTP 的特点是支持多条数据
// 流，这也就允许多个逻辑上的数据流通过一条单独的连接来传递。有关 SCTP 的描述可以 RFC
// 4960、3257、3286 中找到。Linux 2.6 也开始支持 SCTP，更多关于该特性的实现信息可在
// https://github.com/sctp/lksctp-tools/wiki 上找到。SCTP 提供了一种可选的协议来实现
// 流式套接字：socket(AF_INET，SOCK_STREAM, IPPROTO_SCTP)。
//
// 从 2.6.14 内核开始，Linux 支持了一种新的数据报协议，即数据报拥塞控制协议（DCCP）。同
// TCP 一样，DCCP 也提供拥塞控制能力，应用层就没必要实现拥塞控制了，防止由于数据报的快速
// 传递而使网络过载。但是，与 TCP 不同的是，类似于 UDP，DCCP 对于可靠性或按序传递并不做
// 任何保证，因而可以让不需要用到这些特性的应用程序避免承担所经历的延时。关于 DCCP 的信息
// 可在 RFC 4336 以及 4340 中找到。
//
// IP 协议格式：前20个字节固定，后面4n字节可选
//      [版本|首部长度 1B][区分服务 1B][总长度 2B]      区分服务（DS）实际上一直没有被用过
//      [标识 2B]                                    对每一个用户数据报标识都会加一，如果由于超过MTU而需要分片，分片的IP数据包中的标识都相同
//      [标志|片偏移 2B]                              标志：MF=1 还有分片 MF=0 最后一个分片 DF=1 不能分片 DF=0 可以分片；片偏移（13-bit）：分片在原片中的偏移，以8字节为单位
//      [生存时间 1B]                                 TTL（Time To Live）：数据报在网络中的寿命，定义为被路由器转发的跳数限制，而设置为1则只能在本局域网中传送
//      [协议 1B][首部检验和 2B]                      协议：ICMP 1 IGMP 2 IP 4 TCP 6 EGP 8 IGP 9 UDP 17 IPv6 41 ESP 50 OSPF 89
//      [源地址 4B][目的地址 4B]
//      [可选字段|填充]
//      [数据部分]
//
// IP 层之下的每一种数据链路层协议都规定了一个数据帧中的数据字段的最大长度，称为最大传送
// 单元 MTU （Max Transfer Unit）。当一个IP数据报封装成链路层帧时，此数据报的总长度，即
// IP 首部加上数据部分一定不能超过下面的数据链路层所规定的MTU值。例如，最常用的以太网就
// 规定器 MTU 值是 1500 字节。若所传送的数据报长度超过数据链路层的MTU值，就必须把过长的
// 数据报进行分片处理。虽然使用尽可能长的IP数据报会使传送效率提高（因为头部长度占比就会
// 变小），但数据报短些也有好处。每一个IP数据报越短，路由器转发的速度就越快。为此 IP 协议
// 规定，在因特网中所有的主机和路由器，必须能够接受长度不超过 576 字节的数据报。这是假定
// 上层交下来的数据长度有 512 字节（合理的长度），加上最长的IP首部 60 字节，再加上 4 字
// 节的富裕量，就得到 576 字节。当主机需要发送长度超过 576 字节的数据报时，应当先了解一
// 下，目的主机能否接受所要发送的数据报长度，否则就要进行分片。
//
// IP 是一种无连接不可靠协议，它尽最大可能将数据报从发送者传输给接收者，但并不保证包到达
// 的顺序会与它们被传输的顺序一致，也不保证包是否重复，甚至都不保证包是否到达接收者。IP
// 也没有提高错误恢复，头信息错误的包会被静默地丢弃。可靠性是通过使用一个可靠的传输层协议
// 例如TCP或应用程序本身来保证的。
//
// IP 数据报分片的发生对于高层协议是透明的，但一般来讲并不希望分片的发生。这里的问题在于
// IP 并不进行重传并且只有在所有分片都到达目的地之后才能对数据报进行组装，因此如果其中一
// 些分片丢失或包含传输错误的话，会导致整个数据报不可用。在一些情况下，这会导致极高的数据
// 丢失率或降低传输速率。现代 TCP 实现采用了一些算法（路径MTU发现）来确定主机之间的一条
// 路径的 MTU，并根据该值对传递给 IP 的数据进行分解，这样 IP 就不会碰到需要传输大小超过
// MTU 的数据报的情况了。UDP 并没有提供这种机制，基于 UDP 的应用程序通常不会知道源主机
// 和目的主机之间路径的 MTU。一般来讲，基于 UDP 的应用程序会采用保守的方法来避免 IP 分片，
// 即确保传输的 IP 数据报的大小小于 IPv4 的组装缓冲区大小的最小值 576 字节。
//
// 众所周知的端口 [0, 1023] 已经永久地分配给特定的应用程序，它是由中央授权机构互联网号码
// 分配局（IANA）来分配的。IANA 还记录着注册端口，对这些端口的分配就不那么严格了，这也意
// 味着一个实现无需保证这些端口是否真正用于它们注册时申请的用途。IANA 注册端口范围是
// [1024, 41951]，不是所有位于这个范围内的端口都被注册了。IANA 众所周知端口和注册端口分
// 配情况可查看：http://www.iana.org/assignments/port-numbers 。在大多数 TCP/IP 实现
// 中，包括 Linux，范围在 0 到 1023 间的端口号也是特权端口，这意味着只有特权 CAP_NET_BIND_SERVICE
// 进程可以绑定到这些端口上，从而防止普通用户通过实现恶意程序，如伪造 ssh，来获取密码。有
// 些时候，特权端口也被称为保留端口。
//
// 尽管端口号相同的 TCP 和 UDP 端口是不同的实体，但同一个众所周知的端口号通常会同时被分配
// 给基于 TCP 和 UDP 的服务，即使该服务通常只提供其中一种协议服务。这种惯例避免了端口号
// 在两个协议中产生混淆的情况。
//
// 如果一个应用程序没有选择一个特定的端口，即没有调用 bind() 将套接字绑定到一个特定的端口
// 上，那么 TCP 和 UDP 会为该套接字分配一个唯一的临时端口（即存活时间较短）。在这种情况
// 下，应用程序，通常是一个客户端，并不关心它所使用的端口号。TCP 和 UDP 在将套接字绑定到
// 端口 0 也会分配一个临时端口号。IANA 将位于 [49152, 65535] 之间的端口称为动态或私有
// 端口，这表示这些端口可供本地应用程序使用或作为临时端口分配。然后不同的实现可能会在不同
// 的范围内分配临时端口。在 Linux 上，这个范围是有包含在以下文件中的两个数值来定义的：
// cat /proc/sys/net/ipv4/ip_local_port_range
//
// https://www.man7.org/linux/man-pages/man2/socket.2.html
//
// #include <sys/socket.h>
// int socket(int domain, int type, int protocol);
//      domain - 指定套接字通信域，AF_UNIX AF_LOCAL sockaddr_un，AF_INET sockaddr_in，AF_INET6 sockaddr_in6
//      type - 流式套接字 SOCK_STREAM，数据报套接字 SOCK_DGRAM，裸套接字 SOCK_RAW。
//          从内核 2.6.27 开始，Linux 为 type 参数提供了第二种用途，允许两个非标准的标
//          记 SOCK_CLOEXEC SOCK_NONBLOCK，第一个标记参见 open() O_CLOEXEC，第二个
//          标记可以让内核在创建套接字文件描述符后直接设置好 O_NONBLOCK 标记，从而无需
//          再通过 fcntl() 来设置。
//      protocol - 一般总是指定为 0，但在裸套接字中（SOCK_RAW）会指定为 IPPROTO_RAW
// int bind(int sofd, const struct sockaddr *addr, socklen_t addrlen);
//      将套接字绑定到一个本地地址上，一般来讲，会将一个服务器的套接字绑定到一个众所周知
//      的地址上，即一个固定的与服务器进行通信的客户端应用程序提前知道的地址。除此之外还
//      有其他做法，例如对于一个 internet domain 套接字来说，服务器可以不调用 bind()
//      而直接调用 listen()，这将会导致内核为该套接字选择一个临时端口，之后服务器可以
//      使用 getsockname() 来获取套接字的地址。在这种场景中，服务器必须要发布其地址使得
//      客户端能够知道如何定位到服务器的套接字。这种发布可以通过向一个中心目录服务应用程
//      序注册服务器的地址来完成，之后客户端可以通过这个服务来获取服务器的地址。当然，目录
//      服务应用程序的套接字必须要位于一个众所周知的地址上。
//      #include <netinet/in.h>
//      struct sockaddr {
//          sa_family_t sa_family;
//          char sa_data[14];
//      };
//      struct sockaddr_in {            // 'in' is for internet
//          sa_family_t    sin_family;  // address family: AF_INET
//          in_port_t      sin_port;    // port in network byte-order 端口和地址必须是网络字节序
//          struct in_addr sin_addr;    // internet address in network byte-order: struct in_addr { uint32_t s_addr; } INADDR_ANY INADDR_LOOPBACK
//          unsigned char __pad[X];     // pad to size of sockaddr (16-byte)
//      };
//      struct sockaddr_in6 {
//          sa_family_t     sin6_family;   // AF_INET6
//          in_port_t       sin6_port;     // port number
//          uint32_t        sin6_flowinfo; // IPv6 flow information
//          struct in6_addr sin6_addr;     // IPv6 address: struct in6_addr { unsigned char s6_addr[16]; } IN6ADDR_ANY_INIT
//          uint32_t        sin6_scope_id; // Scope ID (new in kernel 2.4)
//      };
//      struct sockaddr_storage { // IPv6 套接字 API 中引入了一个通用的 sockaddr_storage 结构，提供的空间足以存储任意类型的套接字地址
//          sa_family_t ss_family;
//          __ss_aligntype __ss_align;
//          char __ss_padding[SS_PADSIZE];
//      };
// int listen(int sofd, int backlog);
//      将流式套接字标记为被动，这个套接字后面会被动接受来自于其他套接字的连接。无法在一
//      个已连接的套接字（即已经成功执行 connect 的套接字或由 accept 调用返回的套接字）
//      上执行 listen()。监听套接字会保持打开状态，并且可以持续接受后续的连接请求。
//      参数 backlog，要理解 backlog 的用途首先需要注意客户端可能会在服务器调用 accept
//      之前调用 connect，这种情况是有可能发生的，如服务器可能正忙于处理其他客户端。这将
//      产生一个未决的连接。内核必须要记录所有未决的连接请求的相关信息，这样后续 accept
//      就能够处理这些请求。backlog 参数指定这种未决连接的最大数量，在这个限制之内的连接
//      请求会立即成功，之外的连接请求就会阻塞直到一个未决的连接请求被 accept 调用接受，
//      并从未决连接队列删除为止。SUSv3 允许实现为 backlog 的可取值规定一个上限并允许一
//      个实现静默地将 backlog 值向下舍入到这个限制值。SUSv3 规定实现应该通过在定义
//      SOMAXCONN 常量来发布这个限制，在 Linux 上这个常量的值被定义程了 128。但从内核
//      2.4.25 起，Linux 允许在运行时通过 Linux 特有的 /proc/sys/net/core/somaxconn
//      文件来调整这个限制。在最初的 BSD 套接字实现中，backlog 的上限是 5，并且在较早
//      的代码中可以看到这个数值。所有现代实现允许为 backlog 指定更高的值，这对于使用
//      TCP 套接字实现大量客户的网络服务器来讲是有必要的。
//      cat /proc/sys/net/core/somaxconn
//      4096
// int accept(int sofd, struct sockaddr *addr, socklen_t *addrlen);
//      接受监听流套接字上的一个接入连接，如果不存在未决的连接，那么调用 accept 就会阻塞
//      直到有连接请求到达为止。理解 accept() 的关键点是它会创建一个新 socket，并且正是
//      这个新套接字会与执行 connect() 的对等套接字进行连接。accept() 调用的返回结果是
//      已连接的套接字文件描述符。
//      addrlen 是一个 in-out 参数，执行之前必须将它初始化为 addr 指向的缓冲区的大小，
//      这样内核就知道有多少空间可用于返回套接字地址了。当 accept 返回后，这个值会被设置
//      程实际被复制进缓冲区的数据的字节数。如果不关心对等套接字的地址，可以将 addr 和
//      addrlen 设置为 NULL 和 0。这样可以在后面某个时刻使用 getpeername() 系统调用来
//      获取对端的地址。
//      从内核 2.6.28 开始，Linux 支持一个新的非标准系统调用 accept4()，这个系统调用
//      执行的任务与 accept() 相同，但支持一个额外的参数 flags，可以设置 SOCK_CLOEXEC
//      和 SOCK_NONBLOCK 两个标志。
//      由于 accept() 在一些老式实现版本中并不是一个原子化的系统调用，因此可能需要通过一
//      些互斥技术，以确保每次只有一个进程/线程可以执行 accept() 调用。
// int connect(int sofd, const struct sockaddr *addr, socklen_t addrlen);
//      如果 connect 失败并且希望重新进行连接，那么 SUSv3 规定完成这个任务的可移植的方
//      法是关闭这个套接字，创建一个新套接字，在该新套接字上重新进行连接。
//
// 流套接字就像是打电话进行通信，而数据包套接字就像是邮政系统，socket() 的调用等价于创建
// 一个邮箱，与邮政系统一样，当从一个地址向另一个地址发送多个数据包（信）时无法保证它们
// 按照被发送的顺序到达，甚至无法保证它们都能够到达。数据包还新增了邮政系统所不具备的一个
// 特定，由于底层网络协议有时候会重新传输一个数据包，因此同样的数据包可能会多次到达。
// 在 Linux 上可以使用 sendto() 发送长度为 0 的数据报，但不是所有的 UNIX 实现都允许这样
// 做。SUSv3 在解除对等关系方面的论断是比较模糊的，它只是声称通过调用一个指定了“空地址”
// 的 connect() 调用可以重置一个连接。SUSv4 则明确规定了需要使用 AF_UNSPEC。在一些 TCP/IP
// 实践中，将一个数据报连接到一个对等套接字能够带来性能上的提升。在 Linux 上连接一个数据
// 报套接字能对性能产生些许差异。设置一个对等套接字主要对那些需要向单个对等套接字（通常是
// 某种数据报客户端）发送多个数据报的应用程序是比较有用的。
//
// 尽管数据报套接字是无连接的，但在数据报套接字上应用 connect() 系统调用仍然起作用。在
// 数据报套接字上调用 connect() 会导致内核记录这个套接字的对等地址。此后发送数据就不要
// 带目的地址的参数了，数据报的发送可以使用 write() 或 send() 来完成，与 sendto() 一样，
// 每个 write() 调用会发送一个独立的数据报。另外这个套接字上只能读取对等套接字发送的数据
// 报。通过再调用一次 connect() 可以修改已经绑定的目的套接字地址，此外通过指定一个地址族
// 为 AF_UNSPEC 的地址结构还可以解除地址绑定，但注意的是，其他很多 UNIX 实现并不支持将
// AF_UNSPEC 用于这个用途。
//
// #include <sys/socket.h>
// int shutdown(int sockfd, int how);
// shutdown() 调用会关闭与 sockfd 关联的套接字上的全双工连接的全部或部分。SHUT_RD 之后
// 不允许继续读，SHUT_WR 之后不允许继续写，SHUT_RDWR 之后不允许继续读写。
// EBADF - sockfd 是非法文件描述符。EINVAL - how 是非法值。ENOTCONN - 指定的套接字没
// 有连接。ENOTSOCK - sockfd 不是套接字文件描述符。

void prh_sock_shut_read(int sofd) {
    // 关闭连接的读取端，之后的读操作将返回文件尾。数据仍然可以写入到套接字上，在 UNIX
    // 域（UNIX domain）流式套接字上执行 SHUT_RD 操作后，对端应用程序将接收到 SIGPIPE
    // 信号，如果继续尝试在对端套接字上做写操作将产生 EPIPE 错误。SHUT_RD 对于 TCP 套
    // 接字来说没有什么意义。
    int n = shutdown(sofd, SHUT_RD);
    prh_preno_if(n != 0);
}

void prh_sock_shut_write(int sofd) {
    // 关闭连接的写入端，后续对本地套接字的写操作将产生 SIGPIPE 信号以及 EPIPE 错误，而
    // 由对端写入的数据仍然可以在套接字上传送。换句话说，这个操作允许我们仍然能读取对端
    // 发来的数据的同时，通知对方自己的写入端已经关闭，对方可以通过读取到文件尾来完成所有
    // 的文件读取。在 shutdown() 中最常用到的操作就是 SHUT_WR，有时候也被称为半关闭套
    // 接字。
    int n = shutdown(sofd, SHUT_WR);
    prh_preno_if(n != 0);
}

void prh_sock_shut_read_write(int sofd) {
    // 将连接的读取端和写入端都关闭，这等用于先执行 SHUT_RD 跟着再执行 SHUT_WR 操作。
    // 除了 how 参数的语义外，shutdown() 同 close() 之间的另一个重要区别是：无论套接字
    // 上是否还关联其他的文件描述符，shutdown() 都会关闭套接字通道。换句话说，shutdown
    // 是根据打开的文件描述（open file description）来执行操作，而与文件描述符无法。
    // 例如 fd2 = dup(sockfd); close(sockfd); 连接仍然会保证打开状态，我们仍然可以通
    // 过文件描述符 fd2 在该连接上执行 I/O 操作。但是 shutdown(sockfd, SHUT_RDWR) 后
    // 那么该连接的双向通道都会关闭，通过 fd2 也无法再执行 I/O 操作了。如果套接字文件描
    // 述符在 fork() 时被复制，那么此时也会出现相似的场景。如果在 fork() 调用之后，一个
    // 进程在描述符的副本上执行一次 SHUT_RDWR 操作，那么其他进程就无法再再这个文件描述符
    // 执行 I/O 操作了。**需要注意的是**，shutdown() 并不会关闭文件描述符，就是参数指定
    // 为 SHUT_RDWR 时也一样，要关闭文件标书费，我们必须另外调用 close()。
    int n = shutdown(sofd, SHUT_RDWR);
    prh_preno_if(n != 0);
}

// #include <unistd.h>
// int close(int fd);
//
// close() 关闭一个文件描述符，使其不再指向任何文件，并可被重用。该描述符关联的文件上由
// 本进程持有的所有记录锁（参见 fcntl(2)）都会被移除，无论当初是通过哪个文件描述符获得的
// 锁。这会带来一些不幸的后果，因此在使用建议性记录锁（advisory record lock）时应格外小
// 心。有关风险与后果的讨论，以及（可能更推荐的）open file description locks，请参见
// fcntl(2)。如果 fd 是底层打开文件描述（参见 open(2)）的最后一个引用，则与该打开文件
// 描述相关的资源将被释放；如果该文件描述符是对一个已通过 unlink(2) 删除的文件的最后一个
// 引用，则该文件会被删除。
//
// 成功返回0，错误返回-1，errno记录对应的错误。EBADF 非法文件描述符。EINTR 被信号中断。
// EIO 发生I/O错误。ENOSPC EDQUOT 在 NFS 上，该错误通常不会在对首次超出可用存储空间的
// write() 调用中立即返回，而是在随后的 write(2)、fsync(2) 或 close() 中才报告。
// close() 在出错后不应该重试。
//
// 一次成功的 close 并不保证数据已真正写回磁盘，因为内核利用缓冲区缓存来延迟写操作。通常，
// 文件系统在文件关闭时不会刷新缓冲区。如果你必须确认数据已物理写入底层磁盘，请使用
// fsync(2)，此时还取决于磁盘硬件本身。close-on-exec 文件描述符标志可确保在成功执行
// execve(2) 时自动关闭该描述符；详见 fcntl(2)。
//
// 多线程进程与 close()：在同一进程的其他线程可能正在使用该文件描述符进行系统调用时关闭
// 它，可能并不明智。由于文件描述符可能被重用，存在一些隐蔽的竞争条件，可能导致意想不到的
// 副作用。进一步考虑以下场景：两个线程对同一文件描述符进行操作：(1) 一个线程在该描述符上
// 的 I/O 系统调用中阻塞。例如，它正尝试 write(2) 到一个已满的管道，或尝试 read(2) 一个
// 当前没有可用数据的数据流套接字。(2) 另一个线程关闭了该文件描述符。此情况下的行为因系统
// 而异。在某些系统上，当文件描述符被关闭时，阻塞的系统调用会立即返回并报告错误。在 Linux
// （可能还有其他一些系统）上，行为不同：阻塞的 I/O 系统调用持有对底层打开文件描述的引用，
// 该引用会在 I/O 系统调用完成前保持描述符打开，参见 open(2) 中关于打开文件描述的讨论。
// 因此，第一个线程中的阻塞系统调用可能在第二个线程执行 close() 后仍然成功完成。
//
// 处理 close() 的错误返回值：谨慎的程序员会检查 close() 的返回值，因为先前 write(2)
// 操作的错误可能仅在最终释放打开文件描述的 close() 时才报告。关闭文件时不检查返回值可能
// 导致数据静默丢失。这种情况在使用 NFS 和磁盘配额（disk quota）时尤为明显。然而请注意，
// 失败返回仅应用于诊断目的（即向应用程序警告可能仍有 I/O 未完成或曾发生失败的 I/O）或补
// 救目的（例如，再次写入文件或创建备份）。在 close() 返回失败后重试 close() 是错误的，
// 因为这可能导致关闭另一个线程已重用的文件描述符。这是因为 Linux 内核总是在关闭操作早期
// 就释放文件描述符，使其可被重用；而可能返回错误的步骤（如将数据刷新到文件系统或设备）发
// 生在关闭操作的后期。许多其他实现同样总是关闭文件描述符（EBADF 情况除外，表示文件描述符
// 无效），即使随后从 close() 返回时报告错误。POSIX.1 目前对此未作规定，但计划在下一次
// 主要标准修订中强制这一行为。
//
// 希望了解 I/O 错误的谨慎程序员可在 close() 之前调用 fsync(2)。EINTR 错误是一种较为特
// 殊的情况。关于 EINTR 错误，POSIX.1-2008 规定：如果 close() 被要捕获的信号中断，它将
// 返回 -1 并将 errno 设为 EINTR，此时 fildes 的状态未定义。这允许发生在 Linux 和许多
// 其他实现上的行为：如同 close() 可能报告的其他错误一样，文件描述符保证已被关闭。然而，
// 它也允许另一种可能：实现返回 EINTR 错误并保持文件描述符打开。根据其文档，HP-UX 的
// close() 就是这样。调用者必须再次使用 close() 关闭该文件描述符，以避免文件描述符泄漏。
// 实现行为上的这种差异为可移植应用程序带来了难题，因为在许多实现上，EINTR 错误后绝不能
// 再次调用 close()，而在至少一种实现上必须再次调用。POSIX.1 下一次主要发布计划解决这一
// 困境。

prh_inline void prh_impl_close_handle(prh_handle fd) {
    prh_preno_if(close((int)fd));
}

prh_inline void prh_impl_close_socket(prh_handle sock) {
    prh_preno_if(close((int)sock));
}

// 域名系统（DNS）维护域名和IP地址之间的映射关系，在 DNS 出现以前，主机名和IP地址之间的
// 映射关系是在一个手工维护的本地文件 /etc/hosts 中进行定义的：
//      127.0.0.1       localhost
//      127.0.1.1       home.localdomain home
//      ::1             ip6-localhost ip6-loopback
//      fe00::0         ip6-localnet
// 函数 getaddrinfo() 通过搜索这个文件并找出与规范主机名，或其中一个别名（可选的以空格
// 分隔），匹配的记录来获取对应的 IP 地址。然而，/etc/hosts 模式的扩展性较差，并且随着
// 网络主机数量的增长（如因特网中存在者数以亿记的主机），这种方式已经变得不太可行。
//
// DNS 被设计用来解决这个问题，DNS 将主机名组织在一个层级名空间中，DNS 层级中的每个节点
// 都有一个名字，该名字最多可包含63个字符。层级的根是一个无名字的节点，即“匿名节点”。一个
// 节点的域名由该节点到根节点的路径中所有节点的名字连接而成，例如节点 baidu 对应的域名为
// baidu.com。完全限定域名（FQDN fully qualified domain name），如 www.baidu.com.，
// 标识处了层级中的一台主机。区分一个完全限定域名的方法是看名字是否已点结尾，但在很多情况
// 下这个点会省略。
//      [匿名根]
//      [顶级域名] 通用域名 com edu net org 国家域名 cn de eu us
//      [二级域名] baidu kernel gnu
//                www ftp
// 没有一个组织或系统会管理整个层级，相反，存在一个 DNS 服务器层级，每台服务器管理树的一
// 个分支（一个区域）。通常，每个区域都有一个主要域名服务器，此外还包含一个或多个从域名服
// 务器，它们在主要域名服务器崩溃时提供备份。区域本身可以被划分成一个个单独管理的更小的区
// 域。当一台主机被添加到一个区域中，或主机名到IP地址之间的映射关系发生变化时，管理员负责
// 更新本地域名服务器上域名数据中对应的名字，无需手动更改层级中其他域名服务器数据库。当一
// 个程序调用 getaddrinfo() 获取主机名对应的IP地址时，它会与本地DNS服务器通信，如果这个
// 服务器无法提供所需的信息，那么它就会与位于层级中的其他DNS服务器进行通信以便获取信息。
// 有时候，这个解析过程可能会花费很多时间，DNS服务器采用缓存技术来避免在查询常见域名时所
// 发生的不必要的通信。使用这种方法使得DNS能够处理大规模的名字空间，同时无需对域名进行集
// 中管理。
//
// DNS 解析请求可以分为两类，递归和迭代。在一个递归请求中，请求者要求服务器处理整个解析任
// 务，包括在必要时与其他DNS服务器进行通信。当位于本地主机上的一个应用程序调用getaddrinfo()
// 时，该函数会向本地DNS服务器发起一个递归请求。如果本地 DNS 服务器自己并没有相关信息来
// 完成解析，那么它就会迭代地解析这个域名。下面通过一个例子来解释迭代域名。假设本地 DNS
// 服务器需要解析 www.otago.ac.nz，要完成这个任务，它首先与每个 DNS 服务器都知道的一组
// 根域名服务器中的一个进行通信。给定 www.otago.ac.nz 根域名服务器会告诉本地 DNS 服务器
// 到其中一台 nz 服务器上查询，然后本地服务器会在 nz 服务器上查询，并收到 ac.nz 服务器
// 信息，之后继续在 ac.nz 服务器上查询得到 otago.ac.nz 服务器信息，最后本地 DNS 服务器
// 会在 otago.ac.nz 域名服务器上查询到 www.otago.ac.nz 并获取到所需的 IP 地址。如果
// 向 getaddrinfo() 传递了一个不完整域名，那么解析器在解析之前会尝试补全。域名补全规则
// 是在 /etc/resolv.conf 中定义的，参见 resolv.conf(5) 手册。在默认情况下，解析器至少
// 会使用本机的域名来补全。
//
// 众所周知的端口，与对应的服务协议名称，之间的映射。由于服务名称是集中管理并且不会像IP
// 那样频繁变化，因此没必要采用DNS服务器来管理它们。相反，端口号和服务名称会记录在文件
// /etc/services 中。函数 getaddrinfo() 和 getnameinfo() 会使用这个文件中的信息在
// 服务名称和端口号之间进行转换。
//      tcpmux          1/tcp                           # TCP port service multiplexer
//      echo            7/tcp
//      echo            7/udp
//      systat          11/tcp          users
//      daytime         13/tcp
//      daytime         13/udp
//      netstat         15/tcp
//      ssh             22/tcp                          # SSH Remote Login Protocol
//      telnet          23/tcp
//      smtp            25/tcp          mail （别名）
//      time            37/tcp          timserver
//      time            37/udp          timserver
//      whois           43/tcp          nicname
//      domain          53/tcp                          # Domain Name Server
//      domain          53/udp
//      http            80/tcp          www             # WorldWideWeb HTTP
//      pop3            110/tcp         pop-3           # POP version 3
//      ntp             123/udp                         # Network Time Protocol
//      https           443/tcp                         # http protocol over TLS/SSL
//
// TCP 和 UDP 的端口号是相互独立的，相同的端口号可以同时分配给 TCP 和 UDP 用，且可以表
// 示不同发服务。但 IANA 的策略是将两个端口都分配给同一个服务，即使服务只使用了其中一种
// 协议，例如 telnet ssh http smtp 都只使用了 TCP，但对应的 UDP 端口也被分配给了这些
// 服务。响应的 ntp 只使用 udp 但 TCP 端口 123 也分配给了 ntp。在一些情况下，一个服务
// 既会使用 TCP 也会使用 UDP，例如 DNS 和 echo。最后，还有极少出现的情况将数值相同的
// UDP 和 TCP 端口分配给了不同的服务，如 rsh 使用 TCP 端口 514，而 syslog daemon 使用
// DUP 端口 514，这是因为这些端口在采用现行的 IANA 策略之前就分配出去了。
//
// 对于使用套接字的网络服务器程序，有两种常见的设计方式。迭代型：服务器每次只处理一个客户
// 请求，只有当完全处理完一个客户端的请求后才去处理下一个客户端。并发型：可以同时处理多个
// 客户请求。迭代型服务器通常只适用于能够快速处理客户请求的场景，因为每个客户都必须等待前
// 面的客户请求完成。迭代型服务器的典型场景是当客户端和服务器之间交换单个请求和响应时。
//
// 并发服务器的其他解决方案，采用服务器集群（server farm）。构建服务器集群最简单的一种方
// 法是 DNS 轮转负载共享（DNS round-robin load sharing）或称为负载分发（load distribution），
// 一个地区的域名权威服务器将同一个域名映射到多个IP地址上，即多台服务器共享同一个域名。
// 后续对 DNS 服务器的域名解析请求将以循环轮转的方式以不同的顺序返回这些 IP 地址。DNS 循
// 环轮转的优势是成本低，而且容易实施。但是，它也存在一些问题。其中一个问题是远端DNS服务
// 器上所执行的缓存操作，这意味着今后位于某个特定主机（或一组主机）上的客户端发出的请求会
// 绕过循环轮转DNS服务器，并总是由同一个服务器来负责处理。此外，循环轮转DNS并没有任何内建
// 的用来确保达到良好负责均衡（不同客户端在服务上产生的负载不同）或者是确保高可用性的机制
// （如果其中一台服务器宕机或者运行的服务器程序崩溃了怎么办）。在许多采用多台服务器设备的
// 设计中，另一个我们需要考虑的因素是服务器的亲和性（server affinity）。这就是说，确保
// 来自同一个客户端的请求序列能够全部定向到同一台服务器上，这样由服务器维护的任何有关客户
// 端状态的信息都能保持准确，这里涉及保存的客户注册信息在多个服务器之间的同步问题。
//
// 一个更灵活但也更复杂的解决方案是服务器负载均衡（server load balancing）。在这种场景
// 下，由一台负载均衡服务器将客户端请求路由到服务器集群中的其中一个成员上。为了确保高可用
// 性，可能还会有一台备用的服务器，一旦负载均衡主服务器崩溃，备用服务器就立刻接管主服务器
// 的任务。这消除了由远端DNS缓存所引起的问题，因为服务器集群只对外提供一个单独的IP地址，
// 也就是负载均衡服务器的IP地址。负载均衡服务器结合一些算法来衡量或计算服务器负载，可能是
// 服务器集群的成员所提供的量值，并智能化地将负载分发到集群中的各个成员之上。负载均衡服务
// 器也会自动检测集群中失效的成员，如果需要还会自动检测新增加的服务器成员。最后，负载均衡
// 服务器可能还会提供对服务器亲和力的支持。
//
// 如果我们查看一下 /etc/services 的内容，可以看到列出了数百个不同的服务项目，这意味着
// 一个系统理论上可以运行数量庞大的服务器进程。但是大部分服务器进程通常只是等待着偶尔发送
// 过来的连接请求或数据报，除此之外它们什么都不做。所有这些服务器进程依然会占用内核进程表
// 中的资源，而且也会占用一些内存和交换空间，因而对系统产生负载。守护进程 inetd 被设计用
// 来消除运行大量非常用服务器进程的需要。inetd 可提供两个主要好处：与其为每个服务器运行一
// 个单独的守护进程，现在只需用一个进程（inetd）就可以监视一组指定的套接字端口，并按照需
// 要启动其他的服务。因此可以降低系统上运行的进程数量。inetd 简化了启动其他服务的编程工
// 作，因为由 inetd 执行的一些步骤通常在所有的网络服务启动时都会用到。由于inetd监管着一
// 系列的服务，可按照需要启动其他的服务，因此 inetd 有时候也被称为 Internet超 级服务器。
// 在一些 Linux 发行版本中提供有 inetd 的扩展版本 xinetd，关于 xinetd 的 相关信息可参
// 考 www.xinetd.org。
//
// inetd 守护进程通常在系统启动时运行，在称为守护进程后，inetd 执行如下步骤：
//      1. 对于 /etc/inetd.conf 中配置的每一项服务，inetd 都会创建一个恰当类型的套接字
//      （即流式套接字或数据报套接字），然后绑定到指定的端口上。此外，每个TCP套接字都会
//      通过 listen() 调用运行客户端发来连接。
//      2. 通过 select() 调用，inetd 对前一步中创建的所有套接字进行监控，看是否有数据
//      报或请求连接发送过来。
//      3. select() 调用进入阻塞状态，直到一个UDP套接字上有数据报可读或者TCP套接字上收
//      到连接请求。在TCP连接中，inetd 在进入下一个步骤之前纤维连接执行 accept() 调用。
//      4. 要启动这个套接字上指定的服务，inetd 调用 fork() 创建一个新的进程，然后通过
//      exec() 启动服务器程序。在执行exec()前，子进程执行如下的步骤：除了用于 UDP 数据
//      报和接收TCP连接的文件描述符外，将其他所有从父进程继承而来的文件描述符都关闭；在
//      文件描述符0、1、2上复制套接字文件描述符，并关闭套接字文件描述符本身，因为已经不再
//      需要它们了，完成这一步之后，启动的服务器进程就能通过这三个标准文件描述符同套接字
//      通信了；之后这一步是可选的，为启动的服务器进程设定用户和组ID，设定的值需要配置在
//      /etc/inetd.conf 中的相应条目中。
//      5. 第3步骤中，如果在TCP套接字上接收了一个连接，inetd 就关闭这个连接套接字，因为
//      这个套接字只会在稍后启动的服务器进行中使用。
//      6. inetd 服务跳转回第2步进行执行。
// 配置文件 /etc/inetd.conf 中的每一行都描述了一种由 inetd 处理的服务：
//      # echo stream tcp nowait root internal
//      # echo dgram  udp wait   root internal
//      ftp    stream tcp nowait root /usr/sbin/tcpd in.ftpd
//      talnet stream tcp nowait root /usr/sbin/tcpd in.telnetd
//      login  stream tcp nowait root /usr/sbin/tcpd in.rlogind
//
// 第一列是服务名称，结合第三列协议字段，可以通过 /etc/services 确定服务的端口号。第三
// 列指定了套接字所使用的协议，/etc/protocols 中列出了所有的 Internet 协议，但大多数服
// 务使用的都是TCP或UDP。第五列登录名，确定运行的服务器程序的用户ID和组ID，由于inetd以
// root方式运行，它的子进程也同样是特权级的，因而可以在有需要的时候通过 setuid() 以及
// setgid() 来修改进程的凭据。第六列服务器程序，该字段指定了被执行的服务器程序的路径名。
// 第七列服务器程序参数，该字段指定一个或多个参数，参数之间有空格分隔。一些内置服务，例如
// UDP 和 TCP 的 echo 服务，是由 inetd 服务本身实现的，对于这样的服务，服务器程序字段
// 应该是 internal，而服务器程序参数字段将被忽略。要启动 echo 服务，将上面 echo 开头的
// 注释 # 去掉即可。当我们修改了 /etc/inetd.conf 文件后，需要发送一个 SIGHUP 信号给
// inetd，请求它重新读取配置文件：killall -HUP inetd。
//
// 通过 inetd 调用的流式套接字（TCP）服务器通常都被设计为只处理一个单独的客户端连接，处
// 理完后就终止，把监听其他连接的任务留给 inetd。对于这样的服务，第四列的参数应该设置为
// nowait。相反如果是有被执行的服务进程来接受连接的话，那么该字段就应该设置为 wait，此时
// inetd 不会去接受连接，而是将监听套接字的文件描述符当作描述符0传递给被执行的服务进程。
// 对于大部分的UDP服务器，该字段应该设为 wait。由 inetd 调用的 UDP 服务器通常被设计为读
// 取并处理所有套接字上未完成的数据报，然后终止。从套接字中读取数据报时，通常需要一些超时
// 机制，这样在指定的时间间隔内如果没有新的数据报到来，服务进程就会终止。通过指定为 wait，
// 我们可以阻止 inetd 在套接字上同时尝试做 select() 操作，因为 inetd 可能会在检查数据
// 报的时候同 UDP 服务之间产生竞争条件，从事如果 inetd 赢了它还会启动另一个 UDP 服务进
// 程实例。由于 inetd 操作以及它的配置文件的格式并没有在 SUSv3 中指定，因此在配置文件
// /etc/inetd.conf 中指定的值可能会有一些变动。
//
// 守护进程（daemon）是一种具备下列特征的进程：它的声明周期很长，通常一个守护进程会在系统
// 启动的时候被创建并一直运行直至系统被关闭；它在后台运行并且不拥有控制终端，控制终端的缺
// 失确保内核永远不会为守护进程自动生成任何任务控制信号以及终端相关的信号，例如 SIGINT、
// SIGTSTP、SIGHUP。很多标准 daemon 会作为特权进行运行（即有效用户ID为0），因此在编写
// 守护进程时应该遵循特别的安全规范。特权程序能够访问普通用户无法访问的特性和资源，一个程
// 序可以下面两种方式已特权方式运行：程序在一个特权用户ID下启动，很多守护进程和网络服务器
// 通常以 root 身份运行，它们就属于这种类别；另外程序设置了 set-user-Id 或 set-group-ID
// 权限位，当一个 set-user-ID（set-group-ID）程序被执行之后，它会将进程的有效用户（组）
// ID修改为与程序文件的所有者（组）一样的ID。如果一个特权程序包含 bug 或可以被恶意用户破
// 坏，那么系统或应用程序的安全性就会受到影响。从安全的角度来讲，在编写程序的时候应该将系
// 统受到安全威胁的可能性以及受到安全威胁时产生的损失降到最小。
//
// 通常会将守护进程程序的名称以字母d结尾，但并不是所有人都遵循这个惯例。在 Linux 上，特定
// 的守护进程会作为内核线程运行。实现此类 daemon 的代码时内核的一部分，它们通常在系统启动
// 的时候被创建。当使用 ps(1) 列出线程时，这些守护进程的名称会用方括号[]括起来。要创建一
// 个守护进程，需要：
// （一）执行一个 fork() 之后父进程退出，子进程继续执行，结果时守护进程称为 init 进程的
// 子进程。之所以要做这一步是因为下面两个原因：假设守护进程是从命令行启动的，父进程的终止
// 会被 shell 发现，shell 在发现之后会显示出另一个 shell 提示符并让子进程继续在后台运行；
// 子进程被确保不会成为一个进程组首进程，因为它从其父进程那里继承了进程组ID并且拥有了自己
// 的唯一的进程ID，而这个进程ID与继承而来的进程组ID是不同的，这样才能够成功地执行下面的
// 一个步骤。
// （二）子进程调用 setsid() 开启一个新会话，并释放它与控制终端之间的所有关联关系。
// （三）如果守护进程从来没有打开过终端设备，那么就无需担心守护进程会重新请求一个控制终端
// 了。如果守护进程后面可能会打开一个终端设备，那么必须要采取措施来确保这个设备不会成为
// 控制终端。这可以通过下面两种方式实现：在所有可能应用到一个终端设备上的 open() 调用中
// 指定 O_NOCTTY 标记；或者更简单的说，在 setsid() 调用之后执行第二个 fork()，然后再次
// 让父进程退出并让孙子进程继续执行。这样就确保了子进程不会成为会话组长，因此根据 System
// V 中获取终端的规则（Linux 也遵循这个规则），进程永远不会重新请求一个控制终端。在遵循
// BSD 规则的实现中，一个进程只能通过一个显式的 ioctl() TIOCSCTTY 操作来获取一个控制
// 终端，因此第二个 fork() 调用对控制终端的获取并没有任何影响，但多一个 fork() 调用不会
// 带来任何坏处。
// （四）清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限。
// （五）修改进程的当前工作目录，同辉改为根目录，这样做是有必要的，因为守护进程通常会一直
// 运行直至系统关闭为止。如果守护进程的当前工作目路是不包含/的文件系统，那么就无法卸载该
// 文件系统。或者守护进程可以将工作目录改为完成任务时所在的目录或在配置文件中定义的一个目
// 录，只要包含这个目录的文件系统永远不会被卸载即可。如 cron 会将自身放在 /var/spool/cron
// 目录下。
// （六）关闭守护进程从其父进程继承而来的所有打开这的文件描述符，守护进程可能需要保持继承
// 而来的文件描述的打开状态，因此这一步时可选的。之所以需要这样做的原因有很多，由于守护
// 进程失去了控制终端并且是在后台运行的，因此让守护进程保持文件描述符 0 1 2 的打开状态毫
// 无意义，因为它们指向的就是控制终端。此外，无法卸载长时间运行的守护进程打开的文件所在的
// 文件系统，因此通常的做法时关闭所有无用的打开着的文件描述符，因为文件描述符时一种有限的
// 资源。一些 UNIX 实现提供了一个名为 closefrom(n) 或类似名称的函数，它关闭嗦鱼大于或
// 等于 n 的文件描述符。Linux 上并不存在这个函数。
// （七）在关闭了文件描述符 0 1 2 之后，守护进程通常会打开 /dev/null 并使用 dup2() 或
// 类似的函数，使所有这些描述符指向这个设备。之所以要这样做时因为：它确保了当守护进程调用
// 了在这些描述符上执行 I/O 的库函数时不会出乎意外地失败；它防止了守护进程后面使用描述符
// 1 或 2 打开一个文件的情况，因为库函数会将这些描述符当作标准输出和标准错误来写入数据。
// /dev/null 是一个虚拟设备，它总会将写入的数据丢弃。当需要删除一个 shell 命令的标准输
// 出和错误时可以将它们重定向到这个文件。从这个设备中读取数据总是会返回文件结束的错误。
//
// 一个守护进程通常只有在系统关闭的时候才会终止。很多标准的守护进程通过在系统关闭时执行
// 特定于应用程序的脚本来停止。而那些不以这种方式终止的守护进程会收到一个 SIGTERM 信号，
// 因为在系统关闭的时候 init 进程会向所有其子进程发送这个信号。在默认情况下，SIGTERM
// 信号会终止一个进程。如果守护进程在终止之前需要做些清理工作，那么就需要为这个信号建立
// 一个处理函数。这个处理函数必须能快速的完成清理工作，因为 init 在发完 SIGTERM 信号 5
// 秒之后会发送一个 SIGKILL 信号。这并不意味着这个守护进程能够执行 5 秒的 CPU 时间，因
// 为 init 会同时向系统中的所有进程发送信号，而它们可能都试图在 5 秒内完成清理工作。由于
// 守护进程是长时间运行的，因此要特别小心潜在的内存泄露问题和文件描述符泄露。很多守护进程
// 需要确保同一时刻只有一个进程实例处于活跃状态。
//
// 由于很多守护进程需要持续执行，因此在设计守护进程时需要克服一些障碍：通常守护进程会在启
// 动时从相关的配置文件中读取操作参数，但有时候需要在不重启守护进程的情况下快速修改这些参
// 数；一些守护进程会产生日志文件，如果守护进程永远不关闭日志文件的话，那么日志文件就会无
// 限制地增长，最终会阻塞文件系统。即使删除了一个文件的文件名，只要有进程还打开着这个文件，
// 那么这个文件就会一直存在下去。这里需要有一种机制来告诉守护进程关闭其日志文件并打开一个
// 新文件，这样就能够在需要的时候旋转日志文件了。解决这两个问题的方案时让守护进程为 SIGHUP
// 建立一个处理函数，并在收到这个信号时采取所需的措施。当控制进程与控制终端断开连接之后就
// 会生成 SIGHUP 信号。由于守护进程没有控制终端，因此内核永远不会向守护进程发送这个信号，
// 这样守护进程就可以使用 SIGHUP 信号来达到这个目的。logrotate 程序可以自动旋转守护进程
// 的日志文件，具体参考 logrotate(8) 手册。一些守护进程在收到 SIGHUP 信号时会使用其他方
// 法来重新初始化自身：它们会关闭所有文件，然后使用 exec() 重新启动自身。
//
// 在编写守护进程时碰到的一个问题时如何显式错误消息，由于守护进程是后台运行的，因此通常无
// 法像其他消息输出到关联终端上。这个问题的一种解决方式是将消息写入到一个特定于应用程序的
// 日志文件中。这种方式存在的一个主要问题是让系统管理员管理多个应用程序日志文件和监控其中
// 是否存在错误比较困难，syslog 工具就用于解决这个问题。syslog 工具提供了一个集中式日志
// 工具，系统中的所有应用程序都可以使用这个工具来记录日志消息。
//
// 如果套接字上可用的数据比在 read() 中请求的数据要少，那就可能会出现部分读的现象，在这种
// 情况下，read() 简单地返回可用的字节数。如果没有足够的缓冲空间来传输所有请求字节，并满
// 足以下条件之一，可能会出现部分写的现象：在 write() 调用过程中传输了部分请求后被信号处
// 理函数中断；套接字工作在非阻塞模式下，可能当前只能传输一部分请求的字节；在部分请求的字
// 节已经完成传输后出现了一个异步错误，异步错误例如由于 TCP 连接出现问题，可能会使对端的
// 应用程序崩溃。如果出现了部分 I/O 现象，那么有时候需要重新调用系统调用来完成全部数据的
// 传输。
//
// #include "rdwrn.h"
// ssize_t readn(int fd, void *buffer, size_t count); 返回读取的字节数，文件尾返回0，错误返回-1
// ssize_t writen(int fd, const void *buffer, size_t count); 返回写入的字节数，错误返回-1
//
// 函数 readn() 和 writen() 的参数与 read() 和 write() 相同，但是这两个函数使用循环
// 重新启用这些系统调用，因此确保请求的字节数总是能够全部得到传输，除非出现错误或者read()
// 检测到文件结束符。
//
// #include <sys/types.h>
// #include <unistd.h>
// ssize_t read(int fd, void buf[.count], size_t count); 返回读取的字节数，文件尾返回0，错误返回-1
// ssize_t pread(int fd, void *buf, size_t count, off_t offset); 不会修改文件偏移，文件必须支持 seeking
//
// 如果 count 为零，read() 可用来检测下面的错误，如果没有错误或者 read() 不检测错误，
// read() 会简单的返回0，不会有其他效果。根据 POSIX.1 如果 count 大于 SSIZE_MAX，其
// 行为是具体实现定义的。在 Linux 上，read() 和类似的系统调用最多传输 0x7fff_f000 个
// 字节（21_4747_9552），返回实际传输的字节数，在 32-bit 和 64-bit 系统上都成立。
//
// 在 NFS 文件系统上，读取少量数据时，时间戳仅在第一次读取时更新，后续调用可能不会更新。
// 这是由于客户端属性缓存导致的，因为大多数（如果不是全部）NFS 客户端将 st_atime（最后
// 文件访问时间）的更新留给服务器处理，而客户端缓存满足的读取不会导致服务器上的 st_atime
// 更新，因为服务器端没有发生读取操作。可以通过禁用客户端属性缓存来获得 UNIX 语义，但在
// 大多数情况下，这会显著增加服务器负载并降低性能。第一次读取：客户端从服务器读取数据时，
// 会更新 st_atime，并将新值缓存。后续读取：如果数据在客户端缓存中，客户端直接从缓存读取，
// 不会再次访问服务器，因此不会更新 st_atime。
//
// 根据 POSIX.1-2008/SUSv4 第 XSI 2.9.7 节（“线程与常规文件操作的交互”）：以下所有函
// 数在 POSIX.1-2008 指定的效果方面，当它们对常规文件或符号链接进行操作时，彼此之间的操
// 作都应该是原子的：…… 随后列出的 API 包括 read() 和 readv(2)。而在线程（和进程）之间
// 应该是原子的效果中，包括文件偏移量的更新。然而，在 Linux 3.14 之前，情况并非如此：如
// 果两个共享打开文件描述，参见 open(2)，的进程同时执行 read() 或 readv(2)，那么 I/O
// 操作在更新文件偏移量方面不是原子的，结果可能导致两个进程的读取操作（错误地）在它们获取
// 的数据块上发生重叠。这个问题在 Linux 3.14 中得到了修复。
//
// 可能返回的错误：
//      EAGAIN - 非套接字文件描述符，设置成了非阻塞，该错误表示已经没有可读的内容，稍后尝试。
//      EAGAIN 或 EWOULDBLOCK - 非阻塞套接字文件描述符，该错误表示稍后尝试，POSIX.1-2002 允许返回这两个值中
//          的任意一个，且没有要求这两个值必须是相同的，因此可移植程序应该同时检查这两个值。
//      EBADF - fd 非法文件描述符，或者这个文件打开的目的不是用于读取的。
//      EFAULT - buf 地址非法。
//      EINTR - 在没有读取任何数据之前，被信号中断。
//      EINVAL - fd 对应的对象不适合读取，或者文件使用 O_DIRECT 打开并且buf/count/文件偏移没有适当对齐。
//          文件描述符是通过 timerfd_create(2) 创建的，但是 read() 提供了错误大小的缓存空间。
//      EISDIR - fd 对应的是一个文件目录。
//      EIO - 表示发生了输入/输出错误。例如后台进程组读取控制终端，进程处于后台进程组，尝试从控制终端读取数据，
//          进程忽略或阻塞 SIGTTIN 信号，或进程组是孤儿进程组，此时 read() 返回 EIO，表示不允许后台进程读取
//          控制终端。或者从磁盘或磁带读取数据时发生低级 I/O 错误。还如在网络文件系统（如 NFS）上，如果对文件
//          描述符持有的建议锁（advisory lock）丢失，read() 可能返回 EIO。建议锁用于协调多个进程对文件的访
//          问，锁丢失可能导致数据不一致。参考：详见 fcntl(2) 的“丢失的锁”部分。
//      根据fd关联的对象，可能发生其他错误
//          例如：如果 fd 指向一个套接字，read() 可能返回 ECONNRESET（连接被重置）或 ENOTCONN（套接字未连
//          接）。如果 fd 指向一个管道，read() 可能返回 EPIPE（管道破裂）。
//
// 系统调用 pread() 和 pwrite() 在多线程程序中特别有用，它允许多线程在同一个文件上执行
// I/O 操作，而不受其他线程修改文件偏移的影响。POSIX 规定：用 O_APPEND 标志打开文件时，
// pwrite() 的写入位置不应受该标志影响；也就是说，即使文件以追加方式打开，pwrite() 仍应
// 严格按照调用者给出的 offset 参数在指定偏移处写入数据。然而，在 Linux 上，如果文件以
// O_APPEND 方式打开，pwrite() 会忽略 offset 参数，始终将数据追加到文件末尾。
//
// #include <unistd.h>
// ssize_t write(int fd, const void buf[.count], size_t count); 返回写入的字节数，错误返回-1
// ssize_t pwrite(int fd, const void buf[.count], size_t count, off_t offset); 不会更新文件偏移
//
// write() 将缓冲区 buf 起始处最多 count 字节的数据写入文件描述符 fd 所指向的文件。实际
// 写入的字节数可能小于 count，例如：底层物理介质空间不足；遇到 RLIMIT_FSIZE 资源限制
// （参见 setrlimit(2)）；在写入所有数据之前被信号处理程序中断；非阻塞描述符暂时无法写入
// 更多数据。
//
// 对于位置可以偏移的文件（即可对其使用 lseek(2) 的文件，例如普通文件）：写入发生在当前
// 文件偏移量处，写入完成后偏移量增加实际写入字节数。若文件以 O_APPEND 打开，则先原子性
// 将偏移量设为文件末尾，再执行写入。偏移量调整与写入操作视为原子步骤。
//
// POSIX 要求：任何可证明在 write() 返回之后发生的 read(2) 必须返回新数据。注意，并非
// 所有文件系统都符合 POSIX。根据 POSIX.1，若 count 大于 SSIZE_MAX，结果由实现定义。
// 在 Linux 上，write()（以及类似的系统调用）一次最多传输 0x7ffff000（2,147,479,552）
// 字节，并返回实际传输的字节数。这在 32 位和 64 位系统上都成立。
//
// 成功时返回实际写入的字节数。出错时返回 -1，并设置 errno 指示错误。注意：成功写入的字
// 节数可能小于 count（部分写入）。部分写入原因包括：磁盘空间不足、阻塞写入被信号中断等。
// 调用者可再次调用 write() 传输剩余字节，后续调用可能继续传输或返回错误（如磁盘已满）。
// 若 count 为 0 且 fd 指向普通文件：若检测到错误则返回失败状态；若未检测到错误，返回 0
// 且不产生其他效果。若 count 为 0 且 fd 指向非普通文件，结果未定义。
//
// write() 的成功返回并不保证数据已提交到磁盘。在某些文件系统（包括 NFS）上，它甚至不保
// 证已为数据成功预留空间。在这种情况下，某些错误可能会延迟到后续的 write()、fsync(2)
// 或甚至 close(2) 才出现。唯一确保的方法是，在完成所有数据写入后调用 fsync(2)。
//
// 标准 POSIX.1-2008，历史 Svr4, 4.3BSD, POSIX.1-2001。在 SVr4 之前，write 可能在任
// 意时刻被中断并返回 EINTR，而不仅仅是在尚未写入任何数据之前。当前标准，如果 write()
// 在尚未写入任何字节时被信号处理程序中断，则调用失败并返回错误 EINTR；如果在已写入至少
// 一个字节后被中断，则调用成功，并返回已写入的字节数。
//
// 在使用直接 I/O 执行 write() 时，返回错误并不意味着整个写入失败。可能已写入部分数据，
// 此时应认为 write() 所尝试的文件偏移处的数据是不一致的。
//
// 可能返回的错误：
//      EAGAIN - 非套接字文件描述符，设置成了非阻塞，该错误表示已经没有可读的内容，稍后尝试。
//      EAGAIN 或 EWOULDBLOCK - 非阻塞套接字文件描述符，该错误表示稍后尝试，POSIX.1-2002 允许返回这两个值中
//          的任意一个，且没有要求这两个值必须是相同的，因此可移植程序应该同时检查这两个值。
//      EBADF - fd 非法文件描述符，或者这个文件打开的目的不是用于写入的。
//      EDESTADDRREQ - fd 对应数据报套接字，目的地址没有通过 connect(2) 设置。
//      EDQUOT - 用户在该文件所在文件系统上的磁盘块配额已用尽。
//      EFBIG - 试图写入的文件大小超过了实现定义的最大文件尺寸，或超出了进程的文件大小限制，或写入位置超过了允许的最大偏移量。
//      EFAULT - buf 地址非法。
//      EINTR - 在没有读取任何数据之前，被信号中断。
//      EINVAL - fd 对应的对象不适合写入，或者文件使用 O_DIRECT 打开并且buf/count/文件偏移没有适当对齐。
//          文件描述符是通过 timerfd_create(2) 创建的，但是 read() 提供了错误大小的缓存空间。
//      EIO - 在修改 inode 时发生了底层 I/O 错误。该错误可能与之前某次 write() 写入的数据回写有关，而那次
//          write() 可能使用了同一文件的不同文件描述符。自 Linux 4.13 起，回写产生的错误保证：后续 write()
//          请求可能会再次报告该错误；后续 fsync(2) 一定会报告该错误，无论 write() 是否已报告。在网络文件系
//          统上，另一个导致 EIO 的原因是：文件描述符上曾持有的建议锁已丢失。详见 fcntl(2) 的 “Lost locks”
//          部分。
//      ENOSPC - 包含该文件的设备已无剩余空间存放数据。
//      EPERM - 操作被文件 seal 阻止；参见 fcntl(2)。
//      EPIPE - fd 连接到一个管道或套接字，其读端已关闭，此时写进程还会收到 SIGPIPE 信号。因此只有在程序捕获、
//          阻塞或忽略该信号时，才能看到 write 的返回值。
//      根据fd关联的对象，可能发生其他错误
//
// #include <sys/uio.h> // 成功返回读取或写入的字节数，失败返回-1和errno
// ssize_t readv(int fd, const struct iovec *iov, int iovcnt);
// ssize_t writev(int fd, const struct iovec *iov, int iovcnt);
// struct iovec {
//      void *iov_base; /* Starting address */
//      size_t iov_len; /* Size of the memory pointed to by iov_base. */
// };
//
// iov 结构体数组的最大数量为 IOV_MAX（定义在 limits.h），或者通过 sysconf(_SC_IOV_MAX)
// 访问对应的值。readv() writev() 返回的错误跟 read(2) write(2) 相同，另外额外定义了
// 以下错误：EINVAL iov_len 的总和超过 ssize_t 的值，或者 iovcnt 小于零或大于允许的最
// 大值。
//
// readv() 系统调用从与文件描述符 fd 关联的文件中读取到 iovcnt 个 iov 描述的缓冲区，称
// 为分散输入（scatter input）。writev() 系统调用将 iov 描述的 iovcnt 个数据缓冲区写
// 入与文件描述符 fd 关联的文件中，称为聚集输出（gather output）。readv() 系统调用的工
// 作方式与 read(2) 类似，只是它会填充多个缓冲区。writev() 系统调用的工作方式与 write(2)
// 类似，只是它会写入多个缓冲区。缓冲区是按数组顺序处理的。这意味着 readv() 会先完全填满
// iov[0]，然后再处理 iov[1]，依此类推，如果数据不足，则 iov 指向的并非所有缓冲区都可能
// 被填满。同样地，writev() 会先写完 iov[0] 的全部内容，然后才处理 iov[1]，依此类推。
// readv() 和 writev() 执行的数据传输是原子性的：writev() 写入的数据作为一个单独的块写
// 入，不会与其他进程的写操作输出混杂；类似地，readv() 保证从文件中读取一个连续的数据块，
// 无论其他线程或进程（它们的文件描述符引用了相同的打开文件描述）执行了何种读操作，参见
// open(2)。
//
// 历史C库/内核差异：为了应对早期 Linux 版本中 IOV_MAX 值过低的问题，如果底层内核系统
// 调用因超出此限制而失败，glibc 的 readv() 和 writev() 包装函数会做一些额外的工作。在
// readv() 的情况下，包装函数会分配一个足够大以容纳 iov 指定的所有项目的临时缓冲区，通过
// 调用 read(2) 将该缓冲区传递，将数据从缓冲区复制到 iov 元素的 iov_base 字段指定的位
// 置，然后释放缓冲区。writev() 的包装函数则使用临时缓冲区和对 write(2) 的调用执行类似
// 的任务。随着 Linux 2.2 及更高版本的出现，glibc 包装函数中这种额外的努力变得不再必要。
// 然而，直到 glibc 2.10，glibc 仍然提供这种行为。从 glibc 2.9 开始，只有当库检测到系
// 统运行的 Linux 内核版本早于 Linux 2.6.18（一个随意选择的内核版本）时，包装函数才会
// 提供这种行为。并且，由于 glibc 2.20（它要求最低为 Linux 2.6.32），glibc 包装函数始
// 终直接调用系统调用。在现代 Linux 系统中，IOV_MAX 的值为 1024，而在 Linux 2.0 时代，
// 这个值是 16。
//
// #include <sys/socket.h>
// ssize_t recv(int sockfd, void *buf, size_t size, int flags);
// ssize_t recvfrom(int sockfd, void *buf, size_t size, int flags, struct sockaddr *_Nullable src_addr, socklen_t *_Nullable addrlen);
//
// recv() 和 send() 系统调用可在已连接的套接字上执行I/O操作，它们提供了专属于套接字的功
// 能，而这些功能在传统的 read() 和 write() 系统调用上是没有的。recv() 和 send() 的返
// 回值和前三个参数同 read() 和 write() 一样。最后一个参数 flags 是一个位掩码，用来修改
// I/O 操作的行为。
//
// 这三个调用成功时都会返回消息的大小。如果消息太长，无法完全放入提供的缓冲区中，根据消息
// 来源的套接字类型，多余的字节可能会被丢弃。如果在套接字上没有可用的消息，接收调用会等待
// 消息到达，除非套接字是非阻塞的，这种情况下会返回值 -1 并将 errno 设置为 EAGAIN 或
// EWOULDBLOCK。接收调用通常会返回任何可用的数据，最多是请求的数量，而不是等待接收完整数
// 量的消息。
//
// 这些调用返回接收到的字节数，如果发生错误则返回 -1 设置 errno。当流式套接字的对端执行
// 有序关闭（orderly shutdown）时，返回值将是 0（传统的“文件结束”返回值）。数据报套接字
// （包括UNIX 域和 Internet 域）允许零大小的数据报，当接收到这样的数据报时，返回值是 0。
// 如果调用 recv() 时指定的接收字节数为 0，也会返回 0。
//
// 如果 recv() 提供的 flags 为零，基本上功能与 read() 一样。唯一不同的是，如果零字节长
// 度用户数据报正等待处理时，read() 不产生任何效果，数据报仍然在等待，但是 recv() 会消耗
// 掉这个数据报。
//
// 而 recv() 与 recvfrom()，系统调用 recv（sockfd, buf, size, flags) 通常用于已经连
// 接的套接字，它等价于 recvfrom(sockfd, buf, size, falgs, NULL, NULL)。recvfrom()
// 将接收到的消息放入缓冲区 buf 中，如果 src_addr 不为 NULL，并且底层协议提供了消息的源
// 地址，则该源地址将被放置在 src_addr 指向的缓冲区中。在这种情况下，addrlen 是一个
// in-out 参数。在调用之前，应将其初始化为与 src_addr 相关联的缓冲区的大小。返回时，
// addrlen 会被更新为包含源地址的实际大小。如果提供的缓冲区太小，返回的地址将被截断；在
// 这种情况下，addrlen 将返回一个大于调用时提供的值。如果调用者对源地址不感兴趣，则应将
// src_addr 和 addrlen 指定为 NULL。
//
// 标准 POSIX. 1-2008，历史 POSIX.1-2001, 4.4BSD (第一次出现在 4.2BSD)，POSIX.1 仅
// 描述了 MSG_OOB、MSG_PEEK、MSG_WAITALL 这三个标志。
//
// MSG_OOB - 此标志请求接收不会在正常数据流中接收的带外数据。某些协议将加急数据放在正常
//      数据队列的前面，因此不能与这些协议一起使用此标志。
// MSG_PEEK - 此标志导致接收操作从接收队列的开头返回数据，但不从队列中移除这些数据。因此，
//      后续的接收调用将返回相同的数据。
// MSG_WAITALL Linux 2.2 - 此标志请求操作阻塞，直到满足完整请求为止。然而，如果捕获到
//      信号、发生错误或连接断开，或者要接收的下一条数据与返回的数据类型不同，调用仍可能
//      返回少于请求的数据。此标志对数据报套接字无效。
// MSG_TRUNC Linux 2.2 - 对于原始（AF_PACKET）、网络数据报（Linux 2.4.27/2.6.8）、
//      netlink（Linux 2.6.22）、UNIX 数据报包括有序数据包（sequenced-packet）（Linux 3.4）
//      套接字：会返回数据包（packet）或数据报（datagram）的真实大小，即使它比传递的缓
//      存大小要长。对于该标志对流式套接字的作用，参考 tcp(7)。
// MSG_DONTWAIT Linux 2.2 - 启用非阻塞操作；如果操作会阻塞，则调用失败并返回错误 EAGAIN
//      或 EWOULDBLOCK。这与通过 fcntl(2) 的 F_SETFL 操作设置 O_NONBLOCK 标志类似，
//      但有所不同：MSG_DONTWAIT 是每次调用的选项，而 O_NONBLOCK 是打开的文件描述符上
//      的设置（参见 open(2)），它会影响调用进程中的所有线程以及其他持有相同打开文件描述
//      符的进程。
// MSG_CMSG_CLOEXEC （仅限 recvmsg()；Linux 2.6.23） - 为通过 UNIX 域文件描述符使用
//      SCM_RIGHTS 操作，参考 unix(7)，接收的文件描述符设置 close-on-exec 标志。此标
//      志的作用与 open(2) 中的 O_CLOEXEC 标志相同。
// MSG_ERRQUEUE Linux 2.2 - 此标志指定应从套接字错误队列中接收排队的错误。错误通过附属
//      数据传递（ancillary data），数据类型取决于协议（对于 IPv4 是 IP_RECVERR）。
//      用户应提供足够大的缓冲区，请参见 cmsg(3) 和 ip(7)。导致错误的原始数据包的负载
//      （payload）作为普通数据通过 msg_iov 传递。导致错误的数据报的原始目标地址通过
//      msg_name 提供。错误通过 sock_extended_err 结构传递：
//      #define SO_EE_ORIGIN_NONE    0
//      #define SO_EE_ORIGIN_LOCAL   1
//      #define SO_EE_ORIGIN_ICMP    2
//      #define SO_EE_ORIGIN_ICMP6   3
//      struct sock_extended_err {
//          uint32_t ee_errno;   /* Error number */ 错误码
//          uint8_t  ee_origin;  /* Where the error originated */ 错误来源的来源
//          uint8_t  ee_type;    /* Type */ 其他字段是协议特定的
//          uint8_t  ee_code;    /* Code */
//          uint8_t  ee_pad;     /* Padding */
//          uint32_t ee_info;    /* Additional information */
//          uint32_t ee_data;    /* Other data */
//          /* More data may follow */ };
//      struct sockaddr *SO_EE_OFFENDER(struct sock_extended_err *); 犯错误的人
//      宏 SO_EE_OFFENDER 根据附属数据的指针返回导致错误的网络对象的地址指针。如果该地
//      址未知，则 sockaddr 的 sa_family 成员包含 AF_UNSPEC，sockaddr 的其他字段未
//      定义。导致错误的数据包的负载（payload）会作为普通数据传递。
//      对于本地错误，不传递地址（可以通过 cmsghdr 的 cmsg_len 成员检查）。对于错误接
//      收，msghdr 中设置了 MSG_ERRQUEUE 标志。传递错误后，会根据下一个排队的错误重新
//      生成挂起的套接字错误，并在下一次套接字操作中传递。
//
// ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);
// struct msghdr {
//      void         *msg_name;       /* Optional address */ 由调用者分配
//      socklen_t     msg_namelen;    /* Size of address */
//      struct iovec *msg_iov;        /* Scatter/gather array */ 可将单个数据报分散到多个用户空间缓冲区中
//      size_t        msg_iovlen;     /* # elements in msg_iov，根据 POSIX.1 类型应该是 int */
//      void         *msg_control;    /* ancillary data, see below */ 附属数据，实际的缓存由调用者提供
//      size_t        msg_controllen; /* ancillary data buffer size, 根据 POSIX.1 类型应该是 socklen_t */
//      int           msg_flags;      /* Flags on received message */ }; 接收到的消息拥有的标志
// struct cmsghdr {
//      size_t cmsg_len;    /* Data byte count, including header (type is socklen_t in POSIX) */
//      int    cmsg_level;  /* Originating protocol */ 来源协议
//      int    cmsg_type;   /* Protocol-specific type */ 协议特定类型
//      /* followed by unsigned char cmsg_data[]; */ };
//
// 另外，Linux 提供 recvmmsg(2) 可用来通过一个系统调用接收多个数据报。recvmsg() 使用
// msghdr 结构来减少直接传递的参数数量。recvmsg() 可以提供 readv() 一样的执行分散-聚合
// I/O 功能，还可以接收包含特定于域的附属数据（也称为控制信息），附属数据可以通过流式和数
// 据报套接字来传递。
//
// msg_name 指向一个由调用者分配的缓冲区，用于返回源地址（如果套接字未连接），调用者在调
// 用前应将 msg_namelen 设置为该缓冲区的大小，成功调用后，msg_namelen 将包含返回地址的
// 大小。如果应用程序不需要知道源地址，可以将 msg_name 指定为 NULL。msg_iov 和 msg_iovlen
// 字段描述了分散/聚集位置，类似于 readv(2) 中讨论的内容，它们用于指定多个缓冲区，数据将
// 被分散到这些缓冲区中。msg_control 指向一个缓冲区，用于存储协议控制相关的消息或其他附
// 属数据，调用 recvmsg() 时，msg_controllen 应包含 msg_control 缓冲区的大小，成功调
// 用后它将包含控制消息序列的大小。在 recvmsg() 返回时，msghdr 中的 msg_flags 字段会被
// 设置，可能包含以下标志：MSG_EOR - 表示记录结束，返回的数据结束一个记录，通常用于
// SOCK_SEQPACKET 类型的套接字。MSG_TRUNC - 表示数据报的尾部被丢弃，因为数据报大于提供
// 的缓冲区。MSG_CTRUNC - 表示由于附属数据缓冲区空间不足，某些控制数据被丢弃。MSG_OOB
// 表示接收到加急或带外数据。MSG_ERRQUEUE - 表示没有接收到数据，但有一个来自套接字错误
// 队列的扩展错误。MSG_CMSG_CLOEXEC Linux 2.6.23 表示在 recvmsg() 的 flags 参数中指
// 定了 MSG_CMSG_CLOEXEC。
//
// 附属数据以 cmsghdr 结构的形式出现，附属数据应仅通过 cmsg(3) 中定义的宏来访问。例如
// Linux 使用这种附属数据机制来传递扩展错误、IP 选项或通过 UNIX 域套接字传递文件描述符。
// 关于在各种套接字域中使用附属数据的更多信息，请参见 unix(7) 和 ip(7)。
//
// recv() recvfrom() recvmsg() 可能返回的错误：
//      以下是由套接字层产生的一些标准错误，底层协议模块可能会产生并返回其他错误，请参考
//      协议手册。
//      EAGAIN 或 EWOULDBLOCK - 套接字被标记为非阻塞，且接收操作会阻塞，或者设置了接收
//          超时，而在接收到数据之前已经超时。
//      EBADF - 参数 sockfd 是一个无效的文件描述符。
//      ECONNREFUSED - 远程主机拒绝接受网络连接（通常是因为它没有运行请求的服务）。
//      EFAULT - 接收缓冲区指针指向进程地址空间之外。
//      EINTR - 在任何数据可用之前，接收操作被信号中断；请参阅 signal(7)。
//      EINVAL - 传递了无效的参数。
//      ENOMEM - 无法为 recvmsg() 分配内存。
//      ENOTCONN - 套接字与面向连接的协议相关但尚未连接，参考 connect(2) accept(2)。
//      ENOTSOCK - 文件描述符 sockfd 不指向套接字。
//
// #include <sys/socket.h>
// ssize_t send(int sockfd, const void *buf, size_t size, int flags);
// ssize_t sendto(int sockfd, const void *buf, size_t size, int flags, const struct sockaddr *dest_addr, socklen_t addrlen);
// ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
//
// 系统调用 send()、sendto() 和 sendmsg() 用于将消息发送到另一个套接字。send() 调用仅
// 在套接字处于连接状态时（即已知目标接收者）才可用。send() 和 write(2) 之间的唯一区别
// 在于 flags 参数的存在。如果 flags 参数为零，则 send() 等同于 write(2)。另外
// send(sockfd, buf, size, flags) 等价于 sendto(sockfd,buf,size,flags,NULL,0)。
//
// 如果在面向连接的套接字（SOCK_STREAM、SOCK_SEQPACKET）上使用 sendto()，则会忽略参数
// dest_addr 和 addrlen（如果它们不是 NULL 和 0，则可能返回错误 EISCONN），并且如果套
// 接字实际上未连接，则返回错误 ENOTCONN。否则，目标地址由 dest_addr 给出，addrlen 指
// 定其大小。对于 sendmsg()，目标地址由 msg.msg_name 给出，msg.msg_namelen 指定其大小。
//
// 对于 send() 和 sendto()，消息存储在 buf 中，大小为 size。对于 sendmsg()，消息由数
// 组 msg.msg_iov 的元素指向。sendmsg() 调用还允许发送附属数据（也称为控制信息）。如果
// 消息太长，无法通过底层协议原子性地传递，则返回错误 EMSGSIZE，并且消息不会被传输。
// send() 操作本身并不隐含发送失败的指示。本地检测到的错误通过返回值 -1 表示。当消息无法
// 放入套接字的发送缓冲区时，send() 通常会阻塞，除非套接字已置于非阻塞 I/O 模式。在这种
// 情况下，如果处于非阻塞模式，则会以错误 EAGAIN 或 EWOULDBLOCK 失败。可以使用
// select(2) 调用来确定何时可以发送更多数据。
//
// sendmsg() 使用 msghdr 结构来减少直接传递的参数数量。另外，Linux 特有的 sendmmsg(2)
// 可用一个系统调用发送多个数据报。sendmsg() 可以提供 writev() 一样的执行分散-聚合I/O
// 功能，还可以传送包含特定于域的附属数据（也称为控制信息），附属数据可以通过流式和数据报
// 套接字来传递。
//
// msg_name msg_namelen - 在未连接的套接字上用于指定数据报的目标地址，它指向一个包含地
//      址的缓冲区；msg_namelen 字段应设置为地址的大小；对于已连接的套接字，这些字段应
//      分别指定为 NULL 和 0。
// msg_iov msg_iovlen - 这些字段指定分散/聚集位置，类似于 writev(2)。
// msg_control msg_controllen - 指定发送控制信息（或称为附属数据），内核可以处理的附属
//      数据缓冲区的最大大小由 /proc/sys/net/core/optmem_max 中的值限制；更多信息请参
//      见 socket(7)。关于在各种套接字域中使用附属数据的进一步信息，请参见 unix(7) 和
//      ip(7)。
// msg_flags - 该字段被忽略。
//
// 标准 POSIX.1-2008 MSG_CONFIRM 是一个 Linux 扩展标志。历史 4.4BSD, SVr4,
// POSIX.1-2001，第一次出现在 4.2BSD。POSIX.1-2001 仅定义了 MSG_OOB 和 MSG_EOR
// 标志。POSIX.1-2008 增加了对 MSG_NOSIGNAL 标志的定义。
//
// MSG_OOB - 在支持这一概念的套接字（如 SOCK_STREAM 类型）上发送带外数据；底层协议也必
//      须支持带外数据。
// MSG_EOR Linux 2.2 - 终止一条记录（在支持这一概念的情况下，例如对于 SOCK_SEQPACKET
//      类型的套接字）。
// MSG_NOSIGNAL Linux 2.2 - 如果面向流的套接字的对端已关闭连接，则不会生成 SIGPIPE
//      信号，但仍会返回 EPIPE 错误。这与使用 sigaction(2) 忽略 SIGPIPE 行为类似，但
//      不同的是：MSG_NOSIGNAL 是每次调用的特性，而忽略 SIGPIPE 则设置了一个影响进程
//      内所有线程的进程属性。
// MSG_DONTROUTE - 发送数据包时不使用网关，仅向直接连接的网络上的主机发送。通常仅由诊断
//      或路由程序使用。仅针对会进行路由的协议族定义；数据包套接字（packet socket）不适
//      用。
// MSG_DONTWAIT Linux 2.2 - 启用非阻塞操作；如果操作会阻塞，则返回 EAGAIN 或 EWOULDBLOCK。
//      这与通过 fcntl(2) 的 F_SETFL 操作设置 O_NONBLOCK 标志类似，但有所不同：MSG_DONTWAIT
//      是每次调用的选项，而 O_NONBLOCK 是打开文件描述符上的设置（参见 open(2)），它会
//      影响调用进程中的所有线程以及其他持有相同打开文件描述符的进程。
// MSG_MORE Linux 2.4.4 - 调用者还有更多数据要发送。此标志用于 TCP 套接字，以实现与
//      TCP_CORK 套接字选项（参见 tcp(7)）相同的效果，不同之处在于，此标志可以在每次调
//      用的基础上设置。自 Linux 2.6 起，此标志也适用于 UDP 套接字，并告知内核将所有设
//      置了此标志的调用中发送的数据打包到一个数据报中，仅在未设置此标志的调用执行时才发
//      送该数据报，参考 udp(7) 中描述的 UDP_CORK 套接字选项。
// MSG_FASTOPEN Linux 3.7 - 尝试 TCP 快速打开（RFC7413），像 connect(2) 和 write(2)
//      的组合一样，在 SYN 中发送数据，通过执行隐式的 connect(2) 操作来实现。它会阻塞，
//      直到数据被缓冲并且握手完成。对于非阻塞套接字，它会返回在 SYN 数据包中缓冲并发送
//      的字节数。如果本地没有可用的 cookie，则返回 EINPROGRESS，并自动发送一个带有
//      Fast Open cookie 请求的 SYN。当套接字连接成功后，调用者需要重新写入数据。如果
//      握手失败，它会设置与 connect(2) 相同的 errno。此标志需要在 sysctl net.ipv4.tcp_fastopen
//      中启用 TCP Fast Open 客户端支持。请参考 tcp(7) 中的 TCP_FASTOPEN_CONNECT 套
//      接字选项，了解另一种方法。
// MSG_CONFIRM Linux 2.3.15 - 是 Linux 系统的扩展标志，告知链路层已取得进展：你从对端
//      收到了成功的回复。如果链路层没有收到这个信号，它会定期重新探测邻居（例如，通过单
//      播 ARP）。仅在 SOCK_DGRAM 和 SOCK_RAW 套接字上有效，目前仅针对 IPv4 和 IPv6
//      实现。详情请参见 arp(7)。
//
// 可能的错误：以下是由套接字层产生的一些标准错误。底层协议模块可能会产生并返回其他错误；
// 请参阅它们各自的手册页。
// EACCES -（对于通过路径名标识的 UNIX 域套接字）对目标套接字文件的写权限被拒绝，或者路
//      径前缀中的某个目录的搜索权限被拒绝，参见 path_resolution(7)。（对于UDP套接字）
//      像给单播地址发送数据一样给网络/广播地址发送数据。
// EAGAIN EWOULDBLOCK - 套接字被标记为非阻塞，且请求的操作会阻塞。POSIX.1-2001 允许对
//      这种情况返回任一错误，并且不要求这些常量具有相同的值，因此可移植的应用程序应检查
//      这两种可能性。
// EAGAIN -（Internet 域数据报套接字）由 sockfd 指向的套接字之前未绑定到地址，并且在尝
//      试将其绑定到一个临时端口时，发现临时端口范围内的所有端口号当前都在使用。请参见
//      ip(7) 中关于 /proc/sys/net/ipv4/ip_local_port_range 的讨论。
// EALREADY - 另一个快速打开操作正在进行。
// EBADF - sockfd 不是一个有效的打开文件描述符。
// ECONNRESET - 连接被对端重置。
// EDESTADDRREQ - 套接字不是面向连接的，并且未设置对端地址。
// EFAULT - 指定了无效的用户空间地址作为参数。
// EINTR - 在传输任何数据之前被信号中断；请参见 signal(7)。
// EINVAL - 传递了无效的参数。
// EISCONN - 面向连接的套接字已经连接，但指定了一个接收者。现在要么返回此错误，要么忽略
//      接收者指定。
// EMSGSIZE - 套接字类型要求消息以原子方式发送，但要发送的消息大小使得这不可能。
// ENOBUFS - 网络接口的输出队列已满。这通常表明接口已停止发送，但可能是由瞬态拥塞引起的。
//      通常在 Linux 中不会出现这种情况。当设备队列溢出时，数据包会被静默丢弃。
// ENOMEM - 没有可用内存。
// ENOTCONN - 套接字未连接，并且未指定目标。Linux 上可能返回 EPIPE 而不是 ENOTCONN。
// ENOTSOCK - 文件描述符 sockfd 不指向套接字。
// EOPNOTSUPP - flags 参数中的某些位对于套接字类型不适合。
// EPIPE - 在面向连接的套接字上，本地端已经关闭。在这种情况下，除非设置了 MSG_NOSIGNAL，
//      否则进程还会收到 SIGPIPE。
//
// #include <sys/sendfile.h> 返回传输的字节数，或返回-1和errno。
// ssize_t sendfile(int out_fd, int in_fd, off_t *_Nullable offset, size_t count);
//
// 像 Web 服务器和文件服务器这样的应用程序，常常需要将磁盘上的文件内容不做修改地通过已连
// 接套接字传输出去。一种方法是通过循环按照以下方式处理：
//      while ((n = read(diskfile, buf, BUZ_SIZE)) > 0)
//          write(sockfd, buf, n);
// 对于许多应用程序来说，这样的循环是完全可接受的。但是，如果我们需要通过套接字频繁地传输
// 大文件的话，这种技术就显得很不高效。为了传输文件，我们必须使用两个系统调用：一个用来将
// 文件内容从内核缓冲区拷贝到用户空间，另一个用来将用户空间缓冲区拷贝到内核空间。如果应用
// 程序在发起传输之前根本不对文件内容做任何处理的话，那么这种处理就是一种浪费。系统调用
// sendfile() 被设计用来消除这种低效性，文件内容会直接传送到套接字上，而不会经过用户空
// 间，这种技术被称为零拷贝传输（zero-copy transfer）。
//
// 文件描述符 out_fd 必须指向一个套接字，in_fd 指向的文件必须可以进行 mmap() 操作，在
// 实践中，这通常表示一个普通文件。这些局限限制了 sendfile() 的使用，我们可以使用它将数
// 据从文件传递到套接字上，但反过来就不行。另外，我们也不能通过 sendfile() 在两个套接字
// 之间直接传送数据。如果 offset 不是 NULL，表示指定了文件的起始偏移量，它是一个 in-out
// 参数，sendfile() 返回后的文件偏移通过该 offset 传出，sendfile() 不会修改 in_fd 文
// 件的文件偏移。但如果 offset 为 NULL，sendfile() 会从文件当前偏移开始发送数据，并在
// 传输后 sendfile() 会修改文件偏移。参数 count 指定了请求传输的字节数，如果在 count
// 字节之前就遇到了文件结尾，那么只有文件结尾之前的那些字节能传输，调用成功后返回实际传输
// 的字节数。SUSv3 中并没有指定 sendfile()，还有几种不同版本的 sendfile() 在其他 UNIX
// 实现中也存在，其参数可能与 Linux 下的 sendfile() 不同。
//
// 要进一步提供 TCP 应用使用 sendfile() 时的性能，采用 Linux 专有的套接字选项 TCP_CORK
// 常常很有用。当在 TCP 套接字上启用了 TCP_CORK 选项后，之后所有的输出都会缓冲到一个单
// 独的 TCP 报文段中，指定满足以下条件为止：已达到报文段的大小上限、取消了 TCP_CORK 选
// 项、套接字被关闭、或者当启用 TCP_CORK 后，从写入第一个字节开始已经经历了 200 毫秒。
// 如果应用程序忘记取消 TCP_CORK 选项，那么超时时间可确保被缓冲的数据能得以传输。
//      optval = 1;
//      setsockopt(sockfd, IPPROTO_TCP, TCP_CORK, &optval, sizeof(optval));
//      write(sockfd, ...); // write HTTP headers
//      sendfile(sockfd, ...); // send page data
//      optval = 0; // corked output is now transmitted in a single TCP segment
//      setsockopt(sockfd, IPPROTO_TCP, TCP_CORK, &optval, sizeof(optval));
// 另外 MSG_MORE write 标记提供了同 TCP_CORK 相似的功能，只是 MSG_MORE 是基于每次调用
// 的，而 TCP_CORK 是全局性的。FreeBSD 中的 TCP_NOPUSH 选项提供了类似于 TCP_CORK 的
// 功能。
//
// #include <fcntl.h>
// int fcntl(int fd, int op, ... /* arg */ );
//
// #include <sys/socket.h> 成功返回 0，失败返回 -1 和 errno
// int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen);
// int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen);
//
// 系统调用 setsockopt() 和 getsockopt() 用来设定和获取套接字选项：参数 level - 套接
// 字层级 SOL_SOCKET，其他协议层级包括 IPPROTO_IP、IPPROTO_IPV6、IPPROTO_ICMP、
// IPPROTO_RAW（Raw IP Packets Protocol）、IPPROTO_TCP、IPPROTO_UDP。参数 optname
// 标识希望设定或获取的套接字选项。参数 optval 是一个指向缓冲区指针，用来指定选项或返回
// 选项的值，根据选项的不同，这个参数可以是一个指向整数或结构体的指针。参数 optlen 指定
// 了 optval 指向的缓冲区的大小。对于 getsockopt()，在调用后，optlen 参数会被设为实际
// 写入到缓冲区的字节数。
//
// 套接字选项是与打开的文件描述关联的，因此通过 dup() 或 fork() 调用复制而来的文件描述符
// 副本同原始的文件描述符一起共享套接字选项集合。套接字选项 SO_TYPE 可用于读取套接字类型。
// 如果一个监听套接字上设定了一些标记和套接字选项，它们会通过由 accept() 返回的新套接字
// 所继承吗？在 Linux 上，如下这些属性不会被 accept() 返回的新文件描述符继承：
//      1. 同打开的文件描述相关的状态标记，即通过 fcntl() F_SETFL 修改的标记，这些标记包括 O_NONBLOCK 和 O_ASYNC；
//      2. 文件描述符标记，即可用通过 fcntl() F_SETFD 修改的标记，唯一一个这样的标记是志雄中关闭 FD_CLOEXEC；
//      3. 与信号驱动 IO 相关联的文件描述符属性，如 fcntl() F_SETOWN 属主进程ID、以及 F_SETSIG 生成信号操作；
// 换句话说，由 accept() 返回的新描述符继承了大部分套接字选项，这些选项可以通过 setsockopt()
// 来设定。有关 accept() 返回的新连接套接字的继承规则在不同的 UNIX 实现中也有所不同。最
// 需要注意的是，在一些 UNIX 规则中，如果打开的文件状态标记如 O_NONBLOCK 和 O_ASYNC 设
// 定在了监听套接字上，那么它们会被 accept() 返回的新套接字继承。为了满足可移植性，可能
// 需要显式地在 accept() 返回的新套接字上重新设定这些属性。
//
// 套接字选项 SO_REUSEADDR 有多种用途，其中最常见的一种是：避免当 TCP 服务器重启时，尝
// 试将套接字绑定到当前已经同 TCP 相关联的端口上时，出现 EADDRINUSE 错误。这个问题通常
// 会在下面两种情况中出现。（一）之前连接到客户端的服务器要么通过 close()，要么因为崩溃
// （如被信号杀死）而执行了一个主动关闭，这使得 TCP 处于 TIME_WAIT 状态，指定 2MSL 超
// 时过期为止。（二）之前服务器先创建了一个子进程来处理客户端的连接，稍后服务器终止，而
// 子进程继续执行服务客户端，因而使得维护的 TCP 仍在使用服务器的知名端口（well-known
// port）。
//
// 一个已连接的 TCP 套接字由一个4元组来唯一标识：{local-ip-address, local-port,
// foreign-ip-address, foreign-port}。TCP 规范要求每个这样的 4 元组都是唯一的，也就是
// 说只有一个对应的连接可以存在。问题时大多数实现，包括 Linux，都强制施加了一个更为严格
// 的约束：如果主机上有任何可匹配到本地端口的 TCP 连接，则本地端口不能被重用（即对 bind
// 的调用）。启用 SO_REUSEADDR 套接字选项可以解放这个限制，使得更接近 TCP 的需求。默认
// 情况下该选项的值为0，可以在绑定套接字之前为该选项设定一个非零值来启用它。
#include <sys/socket.h>
#include <fcntl.h>

bool prh_has_nonblock(int fd) {
    int flags = fcntl(fd, F_GETFL);
    assert(flags != -1);
    return (flags & O_NONBLOCK);
}

void prh_set_nonblock(int fd) {
    int flags = fcntl(fd, F_GETFL);
    assert(flags != -1);
    if (flags & O_NONBLOCK) return;
    flags |= O_NONBLOCK;
    prh_nnegret(fcntl(fd, F_SETFL, flags));
}

void prh_clr_nonblock(int fd) {
    int flags = fcntl(fd, F_GETFL);
    assert(flags != -1);
    if ((flags & O_NONBLOCK) == 0) return;
    flags &= ~O_NONBLOCK;
    prh_nnegret(fcntl(fd, F_SETFL, flags));
}

bool prh_has_cloexec(int fd) {
    int flags = fcntl(fd, F_GETFD);
    assert(flags != -1);
    return (flags & FD_CLOEXEC);
}

void prh_set_cloexec(int fd) {
    int flags = fcntl(fd, F_GETFD);
    assert(flags != -1);
    if (flags & FD_CLOEXEC) return;
    flags |= FD_CLOEXEC;
    prh_nnegret(fcntl(fd, F_SETFD, flags));
}

void prh_clr_cloexec(int fd) {
    int flags = fcntl(fd, F_GETFD);
    assert(flags != -1);
    if ((flags & FD_CLOEXEC) == 0) return;
    flags &= ~FD_CLOEXEC;
    prh_nnegret(fcntl(fd, F_SETFD, flags));
}

void prh_setsockopt_reuseaddr(prh_handle sock, int reuse) {
    prh_zeroret_or_errno(setsockopt((int)sock, SOL_SOCKET, SO_REUSEADDR, &reuse, (int)sizeof(int)));
}

// #include <sys/socket.h>
// int getsockname(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
// int getpeername(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
//
// getsockname() 可以获取映射绑定的套接字本地地址，包括ip和端口。内核会在出现如下情况时
// 执行一个隐式绑定：（1）已经在 TCP 套接字上执行了 connect() 或 listen() 调用，但之前
// 并没有调用 bind() 绑定到一个地址上。（2）当在 UDP 套接字上首次调用 sendto() 时，该
// 套接字还没有绑定到地址上。（3）调用 bind() 时将端口号设置为 0，这种情况下内核会选择一
// 个临时的端口号给该套接字使用。
//
// #include <arpa/inet.h>
// int inet_pton(int af, const char *src, void *dst); 返回1成功，0非法地址字符串，-1非法地址族
// const char *inet_ntop(int af, const void *src, char dst[.size], socklen_t size);
//
// #include <arpa/inet.h>
// uint32_t htonl(uint32_t hostlong);
// uint16_t htons(uint16_t hostshort);
// uint32_t ntohl(uint32_t netlong);
// uint16_t ntohs(uint16_t netshort);
//
//  struct sockaddr {
//      sa_family_t sa_family;
//      char sa_data[14];
//  };
//  struct sockaddr_in {            // 'in' is for internet
//      sa_family_t    sin_family;  // address family: AF_INET
//      in_port_t      sin_port;    // port in network byte-order 端口和地址必须是网络字节序
//      struct in_addr sin_addr;    // internet address in network byte-order: struct in_addr { uint32_t s_addr; } INADDR_ANY INADDR_LOOPBACK
//      unsigned char __pad[X];     // pad to size of sockaddr (16-byte)
//  };
//  struct sockaddr_in6 {
//      sa_family_t     sin6_family;   // AF_INET6
//      in_port_t       sin6_port;     // port number
//      uint32_t        sin6_flowinfo; // IPv6 flow information
//      struct in6_addr sin6_addr;     // IPv6 address: struct in6_addr { unsigned char s6_addr[16]; } IN6ADDR_ANY_INIT
//      uint32_t        sin6_scope_id; // Scope ID (new in kernel 2.4)
//  };

prh_inline struct sockaddr_in *prh_impl_sockaddr_in(struct sockaddr_in6 *p) {
    return (struct sockaddr_in *)p;
}

prh_u32 prh_sock_ipv4_address(const char *ip_string) {
    struct in_addr out = {0}; // ddd.ddd.ddd.ddd => u32 网络字节序，d 的范围 [0, 255]，每个字节最多3个d
    assert(ip_string != prh_null);
    prh_numbret(1, inet_pton(AF_INET, ip_string, &out));
    return out.s_addr;
}

void prh_sock_ipv6_address(const char *ip_string, prh_byte *ipv6_16_byte) {
    // xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx
    // xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:d.d.d.d (IPv4-mapped IPv6 address)
    // 0:0:0:0:0:0:0:1 => ::1
    // 0:0:0:0:0:0:0:0 => ::
    // ::FFFF:204.152.189.116
    assert(ip_string != prh_null);
    prh_numbret(1, inet_pton(AF_INET6, ip_string, ipv6_16_byte));
}

void prh_sock_ip_string(prh_u32 ip, char *str_16_byte) {
    assert(str_16_byte != prh_null); // src 指向网络字节序的 struct in_addr，
    assert(INET_ADDRSTRLEN <= 16); // size 至少为 INET_ADDRSTRLEN
    prh_boolret(inet_ntop(AF_INET, &ip, str_16_byte, INET_ADDRSTRLEN));
}

void prh_sock_ipv6_string(const char *ipv6_16_byte, char *str_48_byte) {
    assert(str_48_byte != prh_null); // src 指向网络字节序的 struct in6_addr，
    assert(INET6_ADDRSTRLEN <= 48); // size 至少为 INET6_ADDRSTRLEN
    prh_boolret(inet_ntop(AF_INET6, ipv6_16_byte, str_48_byte, INET6_ADDRSTRLEN));
}

void prh_sock_local_addr(prh_handle sock, void *addr, int addrlen) {
    // EBADF sockfd invalid, EFAULT addr invalid, EINVAL addrlen, ENOBUFS insufficient resources, ENOTSOCK sockfd
    prh_zeroret_or_errno(getsockname(sock, (struct sockaddr *)addr, &addrlen));
    assert(addrlen == sizeof(struct sockaddr_in) || addrlen == sizeof(struct sockaddr_in6));
}

void prh_sock_peer_addr(prh_handle sock, void *addr, int addrlen) {
    prh_zeroret_or_errno(getpeername(sock, (struct sockaddr *)addr, &addrlen)); // ENOTCONN socket is not connected
    assert(addrlen == sizeof(struct sockaddr_in) || addrlen == sizeof(struct sockaddr_in6));
}

prh_u16 prh_sock_local_port(prh_handle sock, int addrlen) {
    struct sockaddr_in6 in;
    prh_sock_local_addr(sock, &in, addrlen);
    return ntohs(prh_impl_sockaddr_in(&in)->sin_port);
}

void prh_impl_tcp_get_local_addr(prh_tcpsocket *tcp) {
    int sock = (int)tcp->sock;
    struct sockaddr_in6 in6;
    struct sockaddr_in *in = (struct sockaddr_in *)&in6;
    prh_sock_local_addr(sock, in, sizeof(struct sockaddr_in6));
    if (in6.sin6_family == AF_INET) {
        tcp->l_addr = in->sin_addr.s_addr;
    } else {
        memcpy(&tcp->l_addr, in6.sin6_addr.s6_addr, 16);
    }
    tcp->l_port = ntohs(in->sin_port);
}

prh_handle prh_impl_tcp_socket(int family) {
#if defined(prh_plat_linux) || (defined(SOCK_CLOEXEC) && defined(SOCK_NONBLOCK))
    int sock = socket((sa_family_t)family, SOCK_STREAM | SOCK_CLOEXEC | SOCK_NONBLOCK, 0);
    assert(sock >= 0);
#else
    int sock = socket((sa_family_t)family, SOCK_STREAM, 0);
    assert(sock >= 0);
    prh_set_cloexec(sock);
    prh_set_nonblock(sock);
#endif
    return (prh_handle)sock;
}

void prh_impl_tcp_bind(prh_handle sock, struct sockaddr_in *addr, int addrlen) {
    // 端口如果是 prh_port_any，内核在bind时选择一个可用的临时端口。服务器可以绑定通
    // 配地址（prh_addr_any），当一个连接到达时，服务器可以调用 getsockname 获取来自
    // 客户的目的IP地址，服务器然后根据这个客户连接所发往的IP地址来处理客户请求。也可
    // 以绑定本机特定地址，该IP地址必须属于所在主机的网络接口之一。
    // bind() 成功返回0，失败返回-1和errno。失败时可能的错误：
    //  EACCES - 地址受保护，用户不是超级用户。
    //  EADDRINUSE - 给定的地址正在使用。或者对于inet套接字，没有临时端口可用。
    //  EBADF - 套接字是非法文件描述符。
    //  EINVAL - 套接字已经绑定到一个地址。或者地址长度非法，或者地址非法。
    //  ENOTSOCK - 套接字文件描述符指向的不是一个套接字。
    //  EADDRNOTAVAIL - 本地没有对应地址的网络接口。
    // bind 返回的一个常见错误时 EADDRINUSE，这涉及 SO_REUSEADDR 和 SO_REUSEPORT
    // 这两个套接字选项。SO_REUSEADDR 有一个潜在的安全问题，假设存在一个绑定到通配地
    // 址和端口5555的套接字，如果指定SO_REUSEADDR，我们就可以把相同的端口绑定到不同
    // 的IP地址上，譬如说是所在主机的主IP地址。此后目的地为端口5555及新绑定IP地址的数
    // 据报将被递送到新的套接字，而不是递送到绑定了通配地址的已有套接字。这些数据报可
    // 以是TCP的SYN报文、SCTP的INIT块或UDP数据报。
    // 为了安全起见，有些操作系统不允许对已经绑定了通配地址的端口再绑定任何更为明确的
    // 地址，也就是说不论是否预先设置 SO_REUSEADDR，对应的bind调用都会失败。在这样的
    // 系统上，执行通配地址捆绑的服务器进程必须最后一个启动。这么做是为了防止把恶意的服
    // 务器绑定到某个系统服务正在使用的IP地址和端口上，造成合法请求被截取。
    prh_setsockopt_reuseaddr(sock, 1);
    prh_real_zeroret_or_errno(bind(sock, (struct sockaddr *)addr, addrlen));
}

void prh_impl_tcp_listen(prh_handle sock, int backlog) {
    // listen() 系统调用仅由TCP服务程序调用，它做两件事情。当socket函数创建一个套接
    // 字时，默认是主动套接字，即可以调用connect主动连接的套接字，而listen将一个未连
    // 接的套接字转换成一个被动套接字，指示内核应接受指向该套接字的连接请求。调用该函
    // 数导致套接字从CLOSED状态转换到LISTEN状态。该函数的第二个参数指定了内核应该为
    // 相应套接字排队的最大连接个数。成功返回0，失败返回-1和errno。
    prh_real_zeroret_or_errno(listen(sock, backlog));
}

int prh_impl_sock_accept(int sock, struct sockaddr *in, socklen_t *addrlen) {
    int conn_sock;
label_continue:
    errno = 0;
#if defined(prh_plat_linux) || (defined(SOCK_CLOEXEC) && defined(SOCK_NONBLOCK))
    conn_sock = accept4(sock, in, addrlen, SOCK_CLOEXEC | SOCK_NONBLOCK);
    if (errno == EINTR) goto label_continue;
#else
    conn_sock = accept(sock, in, addrlen);
    if (errno == EINTR) goto label_continue;
    if (conn_sock >= 0) {
        prh_set_cloexec(conn_sock);
        prh_set_nonblock(conn_sock);
    }
#endif
    return conn_sock;
}

// 返回 new_connection->sock != PRH_INVASOCK 表示成功接收到一个客户新连接，另外返回
// 值表示内核是否还有待处理的连接，返回true表示有。
bool prh_sock_tcp_accept(prh_tcplisten *listen, prh_tcpsocket *new_connection) {
    struct sockaddr_in6 in;
    socklen_t addrlen = listen->ipv6 ? sizeof(struct sockaddr_in6) : sizeof(struct sockaddr_in);
    int conn_sock = prh_impl_sock_accept((int)listen->sock, (struct sockaddr *)&in, &addrlen);
    assert(addrlen == sizeof(struct sockaddr_in) || addrlen == sizeof(struct sockaddr_in6));
    if (conn_sock >= 0) {
        if (errno) { // 新连接套接字出现网络错误
            prh_impl_close_socket(conn_sock);
            conn_sock = PRH_INVASOCK;
        } else {
            memset(new_connection, 0, sizeof(prh_tcpsocket));
            new_connection->ipv6 = listen->ipv6;
            new_connection->server_accepted_socket = true;
            new_connection->p_port = prh_impl_sockaddr_in(&in)->sin_port;
            new_connection->l_port = listen->port;
            if (listen->ipv6) {
                memcpy(&new_connection->p_addr, in.sin6_addr.s6_addr, 16);
                if (listen->addr_any) {
                    prh_sock_local_addr(conn_sock, &in, addrlen); // 获取当前连接的本地地址暂存到 in，原来存的是对方地址
                    memcpy(&new_connection->l_addr, in.sin6_addr.s6_addr, 16);
                } else {
                    memcpy(&new_connection->l_addr, &listen->addr, 16);
                }
            } else {
                new_connection->p_addr = prh_impl_sockaddr_in(&in)->sin_addr.s_addr;
                if (listen->addr_any) {
                    prh_sock_local_addr(conn_sock, &in, addrlen); // 获取当前连接的本地地址暂存到 in，原来存的是对方地址
                    new_connection->l_addr = prh_impl_sockaddr_in(&in)->sin_addr.s_addr;
                } else {
                    new_connection->l_addr = listen->addr;
                }
            }
        }
    } else {
        conn_sock = PRH_INVASOCK;
    }
    new_connection->sock = conn_sock;
    // 成功返回非负的已连接的套接字文件描述符，失败返回-1和errno并且addrlen没被修改。
    // Linux accept() 和 accept4() 会把已在新 socket 上挂起的网络层错误当作错误码
    // 直接返回。这种行为与多数 BSD 套接字实现不同。为了保证可靠运行，应用程序在
    // accept() 之后必须检测协议所定义的这类网络错误，并像对待 EAGAIN 那样重试。对于
    // TCP/IP，这些错误码包括：ENETDOWN、EPROTO、ENOPROTOOPT、EHOSTDOWN、ENONET、
    // EHOSTUNREACH、EOPNOTSUPP 和 ENETUNREACH。
    //
    // 可能的错误码：
    //      EAGAIN EWOULDBLOCK - 套接字被设为非阻塞（O_NONBLOCK）且当前没有待接受
    //          的连接。POSIX.1-2001 与 POSIX.1-2008 允许两者之一返回，并且不要求
    //          这两个宏值相同，故可移植代码应同时检查。
    //      EBADF - sockfd 不是有效的打开文件描述符。
    //      ECONNABORTED - 已建立的连接被对端或网络异常中止。
    //      EFAULT - addr 指向的内存不可写。
    //      EINTR - 系统调用在有效连接到达前被捕获的信号中断。
    //      EINVAL - 套接字未处于监听状态，或 addrlen 无效（如为负值）。accept4()
    //          flags 含非法位。
    //      EMFILE - 进程级文件描述符数量达到上限。
    //      ENFILE - 系统级文件描述符总量达到上限。
    //      ENOBUFS / ENOMEM - 内核套接字缓存区不足；通常受 socket buffer 限制，而
    //          非系统内存总量。
    //      ENOTSOCK - sockfd 并非套接字描述符。
    //      EOPNOTSUPP - 套接字类型不是 SOCK_STREAM。
    //      EPERM - 防火墙规则禁止连接。
    //      EPROTO - 协议层错误。
    //  此外，新套接字上已存在的网络错误（如 ENETDOWN、EHOSTUNREACH 等）也可能在
    //  accept() 时返回。不同 Linux 版本还可能返回 ENOSR、ESOCKTNOSUPPORT 等；追
    //  踪时可见 ERESTARTSYS。
    //
    // 版本差异。Linux 中，accept() 返回的新套接字不会继承监听套接字的 O_NONBLOCK、
    // O_ASYNC 等文件状态标志；这与 BSD 规范实现不同。可移植程序应显式设置所需标志。
    // 非阻塞注意事项。即使 SIGIO 或 select/poll/epoll 报告可读，也可能因异步网络错
    // 误或另一线程抢先 accept() 导致无连接可取。此时 accept() 将阻塞等待下一个连
    // 接。若要保证 accept() 永不阻塞，监听套接字必须设置 O_NONBLOCK。对于需要显式确
    // 认的协议（如 DECnet），accept() 只取出下一个连接请求而不表示确认；后续对新的
    // fd 进行普通读/写即视为确认，关闭新套接字则表示拒绝。目前 Linux 上仅 DECnet
    // 采用此语义。历史上 BSD 将 accept 的第三个参数声明为 int*；POSIX.1g 草案曾拟
    // 改为 size_t*，最终标准及 glibc 2.x 采用 socklen_t*。
    bool has_pending_connection;
#if EAGAIN == EWOULDBLOCK
    if (errno == EAGAIN) {
#else
    if (errno == EAGAIN || errno == EWOULDBLOCK) {
#endif
        has_pending_connection = false; // 内核已经没有待处理的连接
    } else {
        has_pending_connection = true;
        prh_prerr(errno);
    }
    return has_pending_connection;
}

void prh_sock_tcp_reset(prh_handle sockfd) {
    // 设置 SO_LINGER 超时为 0，告诉内核“不等缓冲区，立刻 RST”。把 SO_LINGER 设为 {1, 0} 再 close()，即可让内核发送 RST，强制终止 TCP 连接。
    struct linger l = { .l_onoff = 1, .l_linger = 0 };
    prh_zeroret_or_errno(setsockopt((int)sockfd, SOL_SOCKET, SO_LINGER, &l, sizeof(l)));
    prh_impl_close_socket(sockfd);
}

bool prh_impl_is_ipv4_str(const char *host) {
    char c;
    while ((c = *host++)) {
        if ((c < '0' || c > '9') && c != '.') {
            return false;
        }
    }
    return true;
}

void prh_impl_tcp_connect_error(prh_tcpsocket *tcp, int error) {
    int error_code = PRH_ERROR;
    if (error == ETIMEDOUT) error_code = PRH_ETIMEOUT;
    else if (error == EHOSTUNREACH || error == ENETUNREACH) error_code = PRH_EUNREACH;
    else if (error == ECONNREFUSED || error == ECONNRESET) error_code = PRH_EREFUSED;
    tcp->error_code = error_code;
}

bool prh_impl_tcp_connect_result(prh_tcpsocket *tcp) {
    int sock = (int)tcp->sock, error = -1;
    socklen_t optlen = sizeof(int);
    prh_zeroret_or_errno(getsockopt(sock, SOL_SOCKET, SO_ERROR, &error, &optlen));
    if (error == 0) {
        prh_impl_tcp_get_local_addr(tcp);
        return true;
    }
    prh_impl_tcp_connect_error(tcp, error);
    return false;
}

// tcp->error_code == 0 表示成功（tcp->sock != PRH_INVASOCK），tcp->conn_wait_open 表示需要等待连接打开
void prh_impl_tcp_connect(prh_tcpsocket *tcp, struct sockaddr_in *addr) {
    // int connect(int sofd, const struct sockaddr *addr, socklen_t addrlen);
    // 如果 connect 失败并且希望重新进行连接，那么 SUSv3 规定完成这个任务的可移植的方法是关
    // 闭这个套接字，创建一个新套接字，在该新套接字上重新进行连接。若 connect() 失败则该套接
    // 字不再可用，必须关闭，我们不能对这样的套接字再次调用 connect() 函数。每次 connect()
    // 都必须重新调用 socket() 创建套接字拿来使用。
    //
    // 套接字地址结构必须包含服务器的IP地址和端口号。客户在调用connect()前不必非得调用bind()，
    // 因为如果需要的话，内核会确定源IP地址，并选择一个临时端口作为源端口。部分协议套接字（例如
    // TCP 套接字，以及 UNIX 域和 Internet 域中的数据报套接字）可以通过“连接”到一个特殊地址
    // 来解除原有的连接关系：在该地址的 sockaddr 结构体中，把sa_family成员设为AF_UNSPEC；
    // 完成这一步后，该套接字就可以再次连接到其他地址（自 Linux 2.2 起支持 AF_UNSPEC）。
    //
    // 如果是TCP套接字，调用connect()会触发TCP的三路握手过程，而且仅在连接建立成功或出错时
    // 才返回。其中出错返回可能有以下几种情况：
    //  ETIMEDOUT - TCP客户端没有收到SYN的响应。例如内核发送一个SYN，若无响应则等待6s后再
    //      发送一个，若仍无响应则等待24s后再发送一个，若总共等了75s后仍未响应则返回该错误。
    //  ECONNREFUSED - 收到SYN的响应是RST，则表明该服务器在我们指定的端口上没有进程在等待
    //      与之连接，例如服务进程也许没有运行，这是一种硬错误（hard error），客户一接收到
    //      RST就马上返回ECONNREFUSED错误。产生RST响应的三个条件是：目的为某端口的SYN到
    //      达，然而该端口上没有正在监听的服务；TCP想取消一个已有连接；TCP接收到一个根本不存
    //      在的连接上的数据包。
    // EHOSTUNREACH ENETUNREACH - 若客户发出的SYN数据包在中间的某个路由上引发一个目的地
    //      不可达（destination unreachable）的ICMP错误，则认为是一种软错误（soft
    //      error）。客户主机内核保存该消息，并按第一种错误中所述的时间间隔继续发送SYN。若
    //      在某个规定的时间（BSD4.4规定75s）后仍未收到响应，则把保存的消息（即ICMP错误）
    //      作为EHOSTUNREACH或ENETUNREACH错误返回给进程。以下两种情况也是有可能的：一是
    //      按照本地系统的转发表，根本没有到达远程系统的路径；二是connect调用根本不等待就返
    //      回。许多早期系统（譬如BSD4.2）在收到“目的地不可达”ICMP错误时会不正确的放弃建立
    //      连接的尝试。这种做法不正确是因为ICMP错误可能指示某个暂时的状态，譬如说可能是一个
    //      可以修复的某个路由问题引起的。注意，即使ICMP错误指示目的网络不可达，但网络不可达
    //      这个错误被认为已过时，应用进程应该把ENETUNREACH和EHOSTUNREACH作为相同的错误
    //      对待。
    //
    // 若连接或绑定成功，则返回 0；若出错，则返回 -1，并设置 errno 以指明具体错误。以下列出
    // 的是通用的套接字错误；各协议族还可能有其特有的错误码。
    //
    //  EACCES -（针对通过路径名标识的 UNIX 域套接字）对套接字文件没有写权限，或对路径前缀中
    //      的某个目录没有搜索权限（另见 path_resolution(7)）。
    //  EACCES - 也可能因 SELinux 策略拒绝连接而返回（例如策略规定 HTTP 代理只能连接 HTTP
    //      服务器端口，而代理试图连接其他端口）。
    //  EACCES EPERM - 用户试图在未启用套接字广播标志的情况下连接到广播地址；或者因为本地防
    //      火墙规则导致连接请求失败。
    //  EADDRINUSE - 本地地址已被占用。
    //  EADDRNOTAVAIL -（Internet 域套接字）sockfd 指向的套接字此前未绑定地址，尝试将其
    //      绑定到临时端口时，发现临时端口范围内的所有端口号当前均已被占用。参见 ip(7) 中
    //      /proc/sys/net/ipv4/ip_local_port_range 的讨论。
    //  EAFNOSUPPORT - 传入地址的 sa_family 字段并非正确的地址族。
    //  EAGAIN - 对于非阻塞 UNIX 域套接字：套接字为非阻塞，且连接无法立即完成。对于其他套接
    //      字族：路由缓存中条目不足。
    //  EINPROGRESS - 套接字为非阻塞，且连接无法立即完成（UNIX 域套接字会返回 EAGAIN）。
    //      可通过 select(2) 或 poll(2) 监听套接字可写事件来等待完成。select(2) 指示可
    //      写后，使用 getsockopt(2) 读取 SOL_SOCKET 层的 SO_ERROR 选项，判断
    //      connect() 是否成功（SO_ERROR 为 0）或失败（SO_ERROR 为下文列出的某个常规错
    //      误码，解释失败原因）。
    //  EALREADY - 套接字为非阻塞，且先前的连接尝试尚未完成。
    //  EBADF - sockfd 不是有效的打开文件描述符。
    //  ECONNREFUSED - 在流式套接字上执行 connect() 时，远程地址无人监听。
    //  EFAULT - 套接字结构地址位于用户地址空间之外。
    //  EINTR - 系统调用被捕获的信号中断；参见 signal(7)。
    //  EISCONN - 套接字已连接。
    //  ENETUNREACH - 网络不可达。
    //  ENOTSOCK - 文件描述符 sockfd 并非套接字。
    //  EPROTOTYPE - 套接字类型不支持请求的通信协议。例如，试图将 UNIX 域数据报套接字连接
    //      到流式套接字时会发生此错误。
    //  ETIMEDOUT - 尝试连接时超时。服务器可能太忙，无法接受新连接。注意，对于 IP 套接字，
    //      若服务器启用了 SYN Cookie，则超时时间可能非常长。
    sa_family_t family = addr->sin_family;
    int sock = prh_impl_tcp_socket(family);
    socklen_t addrlen;
    if (family == AF_INET) {
        addrlen = sizeof(struct sockaddr_in);
        tcp->p_addr = addr->sin_addr.s_addr;
        tcp->ipv6 = false;
    } else {
        addrlen = sizeof(struct sockaddr_in6);
        struct sockaddr_in6 *in6 = (struct sockaddr_in6 *)addr;
        memcpy(&tcp->p_addr, in6->sin6_addr.s6_addr, 16);
        tcp->ipv6 = true;
    }
    tcp->p_port = ntohs(addr->sin_port);
    tcp->error_code = 0;
    tcp->conn_wait_open = 0;
label_continue:
    if (connect(sock, (struct sockaddr *)addr, addrlen) == 0) {
        tcp->sock = sock;
        prh_impl_tcp_get_local_addr(tcp);
        return;
    }
    if (errno == EINTR) {
        goto label_continue;
    }
    if (errno == EINPROGRESS) {
        tcp->sock = sock;
        tcp->conn_wait_open = 1;
    } else {
        tcp->sock = PRH_INVASOCK;
        prh_impl_tcp_connect_error(tcp, errno);
        prh_impl_close_socket(sock);
    }
}

void prh_sock_tcp_connect(prh_tcpsocket *tcp, const char *host, prh_u16 port) {
    assert(host != prh_addr_any && port != prh_port_any);
    struct sockaddr_in in = {0};
    in.sin_family = AF_INET;
    in.sin_port = htons(port);
    if (host == prh_loopback) {
        in.sin_addr.s_addr = htonl(INADDR_LOOPBACK);
        prh_impl_tcp_connect(tcp, &in);
        return;
    }
    if (prh_impl_is_ipv4_str(host)) {
        in.sin_addr.s_addr = prh_sock_ipv4_address(host);
        prh_impl_tcp_connect(tcp, &in);
        return;
    }
    // int getaddrinfo(const char *node, const char *service, const struct addrinfo *hints, struct addrinfo **res);
    // void freeaddrinfo(struct addrinfo *res); const char *gai_strerror(int errcode);
    // int getnameinfo(const struct sockaddr *addr, socklen_t addrlen, char *host, socklen_t hostlen, char *serv, socklen_t servlen, int flags);
    // getaddrinfo() 将域名和服务名称，转换成IP地址和端口号的一个链表，getnameinfo() 将IP地址和端口号，转换成域名和服务名称
    // NI_MAXHOST 1025 域名的最大长度 NI_MAXSERV 32 服务名称的最大长度。getnameinfo() 中的 host 和 serv 至少提供一个，flags 值如下:
    //  NI_DGRAM 默认返回流式套接字对应的地址字符串，指定该标志标识返回数据报套接字对应的地址字符串，通常这是无关紧要的因为，因为相同的端口对应的服务名通常相同。
    //  NI_NAMEREQD 默认情况下，如果无法解析获取到主机名，那么 host 中会返回数据地址字符串，如果制定了该标志，那么会返回错误 EAI_NONAME。
    //  NI_NOFQDN 默认情况下会返回主机的完全限定域名，指定该标志时如果主机位于局域网中只返回名字的第一部分（即主机名）。
    //  NI_NUMERICHOST 强制返回数值型地址字符串，禁止耗时的 DNS 查询；不指定该标志，仍然可能返回数值型地址，因为可能域名解析获取不到主机名。
    //  NI_NUMERICSERV 强制返回数值型服务名称，避免搜索 /etc/services，没有指定该标志也可能返回数值端口号字符串，因为一些端口号根本就不对应任何服务名。
    // struct addrinfo {
    //      int              ai_flags;
    //      int              ai_family; // AF_UNSPEC any family, AF_INET, AF_INET6
    //      int              ai_socktype; // SOCK_STREAM, SOCK_DGRAM, or 0
    //      int              ai_protocol; // 0
    //      socklen_t        ai_addrlen;
    //      struct sockaddr *ai_addr;
    //      char            *ai_canonname;
    //      struct addrinfo *ai_next; };
    // 其中 ai_flags 可能的值为：
    //  AI_NUMERICHOST 地址字符串必须是数值型字符串，设置这个标志可以避免昂贵的域名解析流程。数值型字符串可以是，十六
    //      进制和冒号的 IPv6 地址，十进制或者八进制（0）或十六进制（0x）和点号的 IPv4 地址（a.b.c.d a.b.u16
    //      a.u24 u32）。
    //  AI_PASSIVE 标志如果设置且 node 为 NULL（即只提供了端口号），则返回的套接字地址适用于 bind(2) 用来
    //      accept(2) 连接，这时返回的套接字地址是通配地址（wildcard address），INADDR_ANY 或
    //      IN6ADDR_ANY_INIT。通配地址常适用于服务器，它可以接收本地主机任意网络地址上的连接。如果 node 不为空，则
    //      AI_PASSIVE 标志会被忽略。如果没有 AI_PASSIVE 标志，则返回的套接字地址适用于 connect(2) sendto(2)
    //      sendmsg(2)，如果 node 为空返回的是回环地址（loopback address)，INADDR_LOOPBACK 或者
    //      IN6ADDR_LOOPBACK_INIT。
    //  AI_CANONNAME 标志如果指定，返回的第一个地址中的 ai_canonname 指向规范域名（official name
    //      of the host）。
    //  AI_ADDRCONFIG 标志如果指定，只有当本地系统配置了至少一个 IPv4 地址时才返回 IPv4 地址，只有当
    //      配置了至少一个 IPv6 地址时才返回 IPv6 地址。并且回环地址不被认为是一个有效的配置地址。例如在只配置有
    //      IPv4 的系统上，这个标志可以保证不返回 IPv6 套接字地址。
    //  AI_V4MAPPED 标志如果设定，并且 hints.ai_family 设定为 AF_INET6，并且没有找到匹配的 IPv6
    //      地址，那么 IPv4 映射的 IPv6 地址会被返回。如果同时指定了 AI_V4MAPPED 和 AI_ALL，IPv6 地址和映射的
    //      IPv4 地址都会返回。如果 AI_V4MAPPED 没有指定，那么 AI_ALL 会被忽略。
    // 将 hints 设置为空，等价于：ai_family AF_UNSPEC, ai_socktype ai_protocol 0, ai_flags AI_V4MAPPED|
    // AI_ADDRCONFIG。根据 POSIX.1 标准，如果将 hints 参数指定为 NULL，则应默认将 ai_flags 视为 0。然而，GNU
    // C 库（glibc）在这种情况下默认使用 (AI_V4MAPPED|AI_ADDRCONFIG) 的值，因为这一默认值被认为是对标准的一种改
    // 进。AI_V4MAPPED：允许 IPv6 地址映射为 IPv4，提高兼容性。AI_ADDRCONFIG：根据系统配置返回地址，避免返回不适
    // 用的地址（如在没有 IPv6 支持的系统上返回 IPv6 地址）。
    // 参数 node 和 service 其中一个可以为 NULL。如果 service 是服务名称，则会被转换成对应的端口号，如果是数值字符
    // 串则直接将字符串转换成整数。如果 service 为 NULL，返回的所有套接字地址中的端口都不进行初始化。如果设置了
    // AI_NUMERICSERV 标志，并且 service 不为空，那么 service 必须是数值字符串。
    struct addrinfo hints = {0}; // hints 只需设置前四个参数，其他字段必须为零
    hints.ai_flags = AI_ADDRCONFIG;
    hints.ai_family   = AF_UNSPEC;   // 允许 IPv4/IPv6
    hints.ai_socktype = SOCK_STREAM; // TCP
    struct addrinfo *res;
    // warning: Using 'getaddrinfo' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking.
    // 这条警告不是编译错误，而是 glibc 的设计限制：它依赖动态加载的 NSS（Name Service Switch）插件来实现
    // getaddrinfo、gethostbyname 等函数。这些插件无法静态链接，因此当你用 -static 时，glibc 只能把调用地
    // 址写进可执行文件，运行时仍需去文件系统里 dlopen 对应的共享库（如 libnss_dns.so、libnss_files.so）。
    // 如果目标系统没有这些库或 glibc 版本不同，解析就会失败。
    int n = getaddrinfo(host, prh_null, &hints, &res);
    // 成功返回0，否则返回以下错误：
    // EAI_ADDRFAMILY - 对应的网络主机（node）没有任何与指定的地址族匹配的网络地址。
    // EAI_AGAIN - 域名服务器返回一个临时失败条件，请稍后重试。
    // EAI_BADFLAGS - hints.ai_flags 包含非法标志，或者包含 AI_CANONNAME 但是 node 为空。
    // EAI_FAIL - 域名服务器返回一个永久失败条件，不可恢复的错误。
    // EAI_FAMILY - 指定的地址族不支持。
    // EAI_MEMORY - 内存耗尽。
    // EAI_NODATA - 存在指定的网络主机，但是该主机没有定义任何网络地址。
    // EAI_NONAME - node 或者 service 非法，或者都是 NULL，或者制定了 AI_NUMERICSERV 但 service 不是数值字符串。
    // EAI_SERVICE - 找不到指定类型（ai_socktype）的服务，例如指定了 SOCK_DGRAM 但只有流式套接字服务，例如设定了 service 但是 ai_socktype 是 SOCK_RAW。
    // EAI_SOCKTYPE - 指定的 ai_socktype 不支持，例如与指定的 ai_protocol 不匹配，例如 SOCK_DGRAM 和 IPPROTO_TCP。
    // EAI_SYSTEM - 其他系统错误，errno 返回错误码。
    tcp->sock = PRH_INVASOCK;
    tcp->error_code = PRH_ENAMERES;
    tcp->conn_wait_open = 0;
    if (n != 0) {
        prh_prerr(errno);
        return;
    }
    // 返回的套接字地址的排序规则定义在 RFC3484 中，在一些平台上可以编辑 /etc/gai.conf 配置其行为。域名和服务
    // 名称对，可以映射多个套接字地址的原因是，例如域名对应的网络主机配置了多个主机地址（the network host is
    // multihomed），例如既可以通过 IPv4 也可以通过 IPv6 地址访问，或者一个服务提供了多种套接字访问类型（例如
    // 返回的一个地址是 SOCK_STREAM 类型，另一个地址是 SOCK_DGRAM 类型）。正常情况下，应用程序应该按套接字地
    // 址的返回顺序优先使用靠前的地址。
    for (struct addrinfo *p = res; p; p = p->ai_next) {
        ((struct sockaddr_in *)(p->ai_addr))->sin_port = in.sin_port;
        prh_impl_tcp_connect(tcp, (struct sockaddr_in *)p->ai_addr);
        if (tcp->error_code == 0) {
            break;
        }
    }
    freeaddrinfo(res);
}

void prh_ipv6_sock_tcp_connect(prh_tcpsocket *tcp, const char *host, prh_u16 port) {
    assert(host != prh_addr_any && port != prh_port_any);
    struct sockaddr_in6 in6 = {0};
    in6.sin6_family = AF_INET6;
    in6.sin6_port = htons(port);
    if (host == prh_loopback) {
        in6.sin6_addr = in6addr_loopback;
    } else {
        prh_sock_ipv6_address(host, in6.sin6_addr.s6_addr);
    }
    prh_impl_tcp_connect(tcp, (struct sockaddr_in *)&in6);
}

// 返回true表示可以继续发送更多数据，否则必须等待写就绪事件再发
bool prh_sock_tcp_send(prh_tcpsocket *tcp) {
    prh_byte_arrfit *txbuf = &tcp->txbuf;
    ssize_t size = txbuf->size - tcp->txbuf_cur;
    assert(size > 0 && size < PRH_IMPL_TXRX_BYTES); // 若 count 为 0 且 fd 指向非普通文件，结果未定义
    bool can_send_more_data;
    ssize_t n;
label_continue:
    if ((n = send((int)tcp->sock, prh_arrfit_begin(txbuf) + tcp->txbuf_cur, size, 0)) >= 0) {
        if (n == size) {
            prh_arrfit_clear(txbuf);
            tcp->txbuf_cur = 0;
            tcp->tx_done = true;
        } else {
            tcp->txbuf_cur += n;
        }
        return true;
    }
    if (errno == EINTR) {
        goto label_continue;
    }
#if EAGAIN == EWOULDBLOCK
    if (errno == EAGAIN) {
#else
    if (errno == EAGAIN || errno == EWOULDBLOCK) {
#endif
        can_send_more_data = false;
    } else {
        can_send_more_data = true;
        prh_prerr(errno);
    }
    return can_send_more_data;
}

// 返回true表示可以继续接收更多数据，否则必须等待读就绪事件再收
bool prh_sock_tcp_recv(prh_tcpsocket *tcp) {
    prh_byte_arrfit *rxbuf = &tcp->rxbuf;
    ssize_t size = rxbuf->capacity;
    assert(size > 0 && size < PRH_IMPL_TXRX_BYTES);
    bool can_recv_more_data;
    ssize_t n;
label_continue:
    if ((n = recv((int)tcp->sock, prh_arrfit_begin(rxbuf), size, 0)) >= 0) {
        rxbuf->size = n;
        return true;
    }
    if (errno == EINTR) {
        goto label_continue;
    }
#if EAGAIN == EWOULDBLOCK
    if (errno == EAGAIN) {
#else
    if (errno == EAGAIN || errno == EWOULDBLOCK) {
#endif
        can_recv_more_data = false;
    } else {
        can_recv_more_data = true;
        prh_prerr(errno);
    }
    return can_recv_more_data;
}

#ifdef PRH_TEST_IMPLEMENTATION
#include <limits.h>
void prh_impl_sock_test(void) {
    prh_u32 ipv4_loopback = htonl(INADDR_LOOPBACK);
    prh_u32 ipv4_addr_any = htonl(INADDR_ANY);
    struct in6_addr ip6_loopback = in6addr_loopback;
    struct in6_addr ip6_addr_any = in6addr_any;
    prh_u16 *ipv6_loopback = (prh_u16 *)&ip6_loopback;
    prh_u16 *ipv6_addr_any = (prh_u16 *)&ip6_addr_any;
    printf("ipv4 loopback: %d.%d.%d.%d addr_any: %d.%d.%d.%d\n",
        (ipv4_loopback & 0xff), (ipv4_loopback >> 8) & 0xff, (ipv4_loopback >> 16) & 0xff, (ipv4_loopback >> 24) & 0xff,
        (ipv4_addr_any & 0xff), (ipv4_addr_any >> 8) & 0xff, (ipv4_addr_any >> 16) & 0xff, (ipv4_addr_any >> 24) & 0xff);
    printf("ipv6 loopback: %04x::%04x::%04x::%04x::%04x::%04x::%04x::%04x\n",
        ipv6_loopback[0], ipv6_loopback[1], ipv6_loopback[2], ipv6_loopback[3], ipv6_loopback[4], ipv6_loopback[5], ipv6_loopback[6], ipv6_loopback[7],
        ipv6_addr_any[0], ipv6_addr_any[1], ipv6_addr_any[2], ipv6_addr_any[3], ipv6_addr_any[4], ipv6_addr_any[5], ipv6_addr_any[6], ipv6_addr_any[7]);
    printf("sa_family_t %d-byte\n", sizeof(sa_family_t));
#ifdef INET_ADDRSTRLEN
    printf("INET_ADDRSTRLEN %d\n", INET_ADDRSTRLEN);
#endif
#ifdef INET6_ADDRSTRLEN
    printf("INET6_ADDRSTRLEN %d\n", INET6_ADDRSTRLEN);
#endif
#ifdef NI_MAXHOST
    printf("NI_MAXHOST %d\n", NI_MAXHOST); // 最大域名长度
#endif
#ifdef NI_MAXSERV
    printf("NI_MAXSERV %d\n", NI_MAXSERV); // 最大的端口服务名称长度
#endif
#ifdef IOV_MAX
    printf("IOV_MAX %d\n", IOV_MAX);
#endif
}
#endif // PRH_TEST_IMPLEMENTATION

// 处理同一个客户同时建立多个TCP连接的情况，TCP运行两个端口之间能建立多条连接吗？但是
// 一个客户账号可以用两台不同的机器来连接，这时就需要对客户账号进行唯一性验证。或者它在
// 同一个主机上使用不同的端口号进行连接呢，也是需要进行客户账号进行唯一性验证。
#endif // POSIX END

// https://www.man7.org/linux/man-pages/man7/packet.7.html
//
// libpcap 使用 socket(PF_PACKET, SOCK_RAW, htons(ETH_P_ALL)) 创建原始套接字，接收
// 所有链路层数据帧。其接收函数为 packet_rcv()，该函数将数据包放入对应 socket 的接收队
// 列中。BPF 是 libpcap 的核心过滤机制，它允许用户定义过滤规则（如只捕获 TCP 端口 80
// 的数据包），并在内核中执行过滤逻辑，减少不必要的数据拷贝。libpcap 的改进版本（如
// libpcap-mmap）使用 mmap 技术将内核缓冲区映射到用户空间，避免了额外的数据拷贝，提高了
// 性能。libpcap 在数据链路层插入一个“旁路”，不干扰系统正常协议栈处理。它通过创建 PF_PACKET
// 类型的原始套接字，直接从链路层驱动获取数据包，绕过 TCP/IP 协议栈，从而提高捕获效率。
// 当数据包到达网卡时，libpcap 通过以下路径捕获数据：
// 网卡接收数据包 → 触发中断 → 网卡驱动分配 sk_buff 并拷贝数据（第一次拷贝）；
// 根据是否启用 NAPI，调用 netif_rx() 或 netif_rx_schedule() 将数据包送入内核网络栈；
// 触发软中断 NET_RX_SOFTIRQ，执行 net_rx_action()；
// 调用 netif_receive_skb()，若有抓包程序，数据包进入 BPF 过滤器；
// 匹配成功的数据包被拷贝到内核缓冲区（第二次拷贝）；
// 用户空间通过 recvfrom() 系统调用将数据包从内核缓冲区拷贝到用户缓冲区（第三次拷贝）。

#endif // PRH_SOCK_IMPLEMENTATION
#endif // PRH_SOCK_INCLUDE

#ifdef PRH_SOCK_INCLUDE
#define PRH_MAX_SAME_TIME_POSTS_TCP_TO_UPPER 4 // 最多只能同时存在 RX_DATA RX_END TX_DONE CLOSED
typedef enum { // tcp layer => upper layer
    PRH_TCPE_OPEN_IND, // 连接请求到来
    PRH_TCPE_OPENED,   // 连接已经打开，主动连接需要检查tcp->error_code是否连接失败
    PRH_TCPE_TX_DONE,  // 数据发送完毕
    PRH_TCPE_RX_DATA,  // 有数据需要上层接收
    PRH_TCPE_RX_END,   // 远方数据发送完毕，上层可在传输完所有数据后进行 close_req
    PRH_TCPE_CLOSED,   // 连接已经关闭，上层之后需要调用 tcp_finish 释放资源
    PRH_TCPE_MAX_NUM,
} prh_tcp_event;

typedef struct {
    prh_cono_pdata head;
    prh_tcpsocket *tcp;
} prh_tcpe_open_ind;

typedef struct {
    prh_cono_pdata head;
    prh_tcpsocket *tcp;
    prh_byte *txbuf;
    prh_byte *rxbuf;
} prh_tcpe_opened;

void prh_tcp_open_accept(prh_tcpsocket *tcp, prh_u32 txbuf_size, prh_u32 rxbuf_size);
void prh_tcp_open_reject(prh_tcpsocket *tcp); // 拒绝之后不能再使用tcp
void prh_tcp_rx_done(prh_tcpsocket *tcp);
void prh_tcp_tx_data(prh_tcpsocket *tcp, prh_u32 size);
void prh_tcp_tx_end(prh_tcpsocket *tcp); // 上层需要在传输完所有数据之后，才能执行TX_END
void prh_tcp_finish(prh_tcpsocket *tcp); // finish之后不能再使用tcp，opened fail 和 closed 之后需要调用 finish

#ifdef PRH_SOCK_INCLUDE
#ifdef PRH_SOCK_IMPLEMENTATION
// 如果有人使用通配地址注册一个端口，那么该端口就不能再被其他人注册，之前有人注册过的
// 也会被强制断开。
typedef struct {
    bool addr_any;
    prh_u16 l_port;
    prh_u32 l_addr;
#if defined(prh_ipv6_enable)
    prh_u32 addr[3];
#endif
} prh_tcp_port_reg;

typedef struct {
    prh_tcp_port_reg *reg_arrfit_type;
} prh_tcp_global;

#define PRH_MAX_SAME_TIME_POSTS_UPPER_TO_TCP 4 // 最多只能同时存在 RX_DONE TX_DATA TX_END
typedef enum {
    PRH_IMPL_TCPQ_UPPER,
    PRH_IMPL_TCPQ_EPOLL,
    PRH_IMPL_TCPQ_NUM,
} prh_impl_tcp_subq;

typedef enum {
    // upper layer => tcp layer, TCP层需要主动执行操作
    PRH_TCPA_TX_DATA,       // 主动请求发送数据
    PRH_TCPA_TX_END,        // 本地数据发送完毕
    PRH_TCPA_RX_DONE,       // 本次数据接收完毕
    PRH_TCPA_FINISH,        // 最后释放和清理TCP连接
    PRH_TCPA_OPEN_REQ,      // 上层发起连接请求
    PRH_TCPA_OPEN_ACCEPT,   // 是否接受当前连接
} prh_tcp_action;

void prh_impl_process_tcpa_tx_data(prh_tcpsocket *tcp, prh_cono_pdata *pdata);
void prh_impl_process_tcpa_tx_end(prh_tcpsocket *tcp, prh_cono_pdata *pdata);
void prh_impl_process_tcpa_rx_done(prh_tcpsocket *tcp, prh_cono_pdata *pdata);

typedef void (*prh_impl_tcpa_process_func)(prh_tcpsocket *tcp, prh_cono_pdata *pdata);
static prh_impl_tcpa_process_func PRH_IMPL_TCPA_FROM_UPPER[PRH_TCPA_FINISH] = {
    prh_impl_process_tcpa_tx_data,
    prh_impl_process_tcpa_tx_end,
    prh_impl_process_tcpa_rx_done,
};

#define PRH_TCPA_INDEX_OPEN_ACCEPT  &port->action.head, 0
#define PRH_TCPA_INDEX_OPEN_REQ     &port->action.head, 1
#define PRH_TCPA_INDEX_TX_END       &port->action.head, 2
#define PRH_TCPA_INDEX_FINISH       &port->action.head, 3
#define PRH_TCPA_INDEX_TX_DATA      &port->tx_data_rx_done, 0
#define PRH_TCPA_INDEX_RX_DONE      &port->tx_data_rx_done, 1
#define PRH_TCPE_INDEX_OPEN_IND     &port->event.head, 0
#define PRH_TCPE_INDEX_OPENED       &port->event.head, 1
#define PRH_TCPE_INDEX_RX_END       &port->event.head, 2
#define PRH_TCPE_INDEX_CLOSED       &port->event.head, 3
#define PRH_TCPE_INDEX_TX_DONE      &port->tx_done_rx_data, 0
#define PRH_TCPE_INDEX_RX_DATA      &port->tx_done_rx_data, 1

typedef struct {
    prh_cono_pdata head;
    prh_u32 rxbuf_size;
    prh_u32 txbuf_size;
} prh_impl_tcpa_accept;

typedef struct {
    prh_impl_tcpa_accept action; // PRH_TCPA_OPEN_ACCEPT 0 PRH_TCPA_OPEN_REQ 1 PRH_TCPA_TX_END 2 PRH_TCPA_FINISH 3
    prh_cono_pdata tx_data_rx_done; // PRH_TCPA_TX_DATA 0 PRH_TCPA_RX_DONE 1
    prh_tcpe_opened event; // PRH_TCPE_OPEN_IND 0 PRH_TCPE_OPENED 1 PRH_TCPE_RX_END 2 PRH_TCPE_CLOSED 3
    prh_cono_pdata tx_done_rx_data; // PRH_TCPE_TX_DONE 0 PRH_TCPE_RX_DATA 1
} prh_impl_tcp_port;

prh_impl_tcp_port *prh_impl_get_tcp_port(prh_tcpsocket *tcp) {
    return (prh_impl_tcp_port *)(tcp + 1);
}

void prh_impl_tcp_port_init(prh_tcpsocket *tcp, prh_cono_subq *upper_subq, prh_cono_subq *self_subq) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    port->action.head.subq = self_subq;
    port->action.head.opcode[0] = PRH_TCPA_OPEN_ACCEPT;
    port->action.head.opcode[1] = PRH_TCPA_OPEN_REQ;
    port->action.head.opcode[2] = PRH_TCPA_TX_END;
    port->action.head.opcode[3] = PRH_TCPA_FINISH;
    port->tx_data_rx_done.subq = self_subq;
    port->tx_data_rx_done.opcode[0] = PRH_TCPA_TX_DATA;
    port->tx_data_rx_done.opcode[1] = PRH_TCPA_RX_DONE;
    port->event.head.subq = upper_subq;
    port->event.head.opcode[0] = PRH_TCPE_OPEN_IND;
    port->event.head.opcode[1] = PRH_TCPE_OPENED;
    port->event.head.opcode[2] = PRH_TCPE_RX_END;
    port->event.head.opcode[3] = PRH_TCPE_CLOSED;
    port->tx_done_rx_data.subq = upper_subq;
    port->tx_done_rx_data.opcode[0] = PRH_TCPE_TX_DONE;
    port->tx_done_rx_data.opcode[1] = PRH_TCPE_RX_DATA;
}

void prh_tcp_open_accept(prh_tcpsocket *tcp, prh_u32 txbuf_size, prh_u32 rxbuf_size) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_impl_tcpa_accept *pdata = &port->action;
    pdata->head.u.value = true;
    pdata->rxbuf_size = rxbuf_size;
    pdata->txbuf_size = txbuf_size;
    prh_cono_post(PRH_TCPA_INDEX_OPEN_ACCEPT);
}

void prh_tcp_open_reject(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    port->action.head.u.value = false;
    prh_cono_post(PRH_TCPA_INDEX_OPEN_ACCEPT);
}

void prh_tcp_tx_data(prh_tcpsocket *tcp, prh_u32 size) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    port->tx_data_rx_done.u.size = size;
    prh_cono_post(PRH_TCPA_INDEX_TX_DATA);
}

void prh_tcp_rx_done(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_cono_post(PRH_TCPA_INDEX_RX_DONE);
}

void prh_tcp_tx_end(prh_tcpsocket *tcp) { // 上层需要在传输完所有数据之后，才能执行 tx end
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_cono_post(PRH_TCPA_INDEX_TX_END);
}

void prh_tcp_finish(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_cono_post(PRH_TCPA_INDEX_FINISH);
}

void prh_impl_report_tcpe_opened(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_tcpe_opened *opened = &port->event;
    opened->tcp = tcp; // PRH_TCPE_OPEN_IND 和 PRH_TCPE_OPENED 是互斥的
    opened->txbuf = prh_arrfit_begin(&tcp->txbuf);
    opened->rxbuf = prh_arrfit_begin(&tcp->rxbuf);
    prh_cono_post(PRH_TCPE_INDEX_OPENED);
}

void prh_impl_report_tcpe_tx_done(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_cono_post(PRH_TCPE_INDEX_TX_DONE);
}

void prh_impl_report_tcpe_rx_data(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    port->tx_done_rx_data.u.size = tcp->rxbuf.size;
    prh_cono_post(PRH_TCPE_INDEX_RX_DATA);
}

void prh_impl_report_tcpe_rx_end(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_cono_post(PRH_TCPE_INDEX_RX_END);
}

void prh_impl_report_tcpe_closed(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    prh_cono_post(PRH_TCPE_INDEX_CLOSED);
    prh_epoll_del_and_close(tcp->epoll_port);
    tcp->closed = true;
}

void prh_impl_tcp_local_close(prh_tcpsocket *tcp) {
    if (tcp->txbuf.size > 0) {
        return; // 等待本地写缓冲发送完毕之后才能关闭
    }
    if (!tcp->local_closed) {
        prh_sock_shut_write((int)tcp->sock);
        tcp->local_closed = true;
    }
}

void prh_impl_tcp_send_data(prh_tcpsocket *tcp) { // 只在 TX_DATA 发送第一包，然后在 epoll_out 就绪发送剩余包
    if (!prh_sock_tcp_send(tcp)) {
        prh_epoll_wait_tx_data(tcp->epoll_port);
    } else if (tcp->tx_done) {
        tcp->tx_done = false;
        if (tcp->close_req) {
            prh_impl_tcp_local_close(tcp);
        } else {
            prh_impl_report_tcpe_tx_done(tcp); // 只在没有错误连接还在，上层可继续发包的情况下上报 TX_DONE
        }
    }
}

void prh_impl_tcp_recv_data(prh_tcpsocket *tcp) {
    if (tcp->epoll_rdhup || tcp->epoll_hup) {
        prh_sock_tcp_recv(tcp);
        if (tcp->rxbuf.size == 0) { // 本端已经将对方发送的所有数据消耗完毕
            tcp->drained = true;
            if (tcp->epoll_rdhup) {
                prh_impl_report_tcpe_rx_end(tcp); // 只要对端发来 FIN，内核就把该套接字标记为读端已关闭，不需要调用 shut_read
            }
            if (tcp->epoll_hup) {
                prh_impl_report_tcpe_closed(tcp);
            }
        } else {
            prh_impl_report_tcpe_rx_data(tcp);
        }
    } else {
        if (!prh_sock_tcp_recv(tcp)) {
            prh_epoll_wait_rx_data(tcp->epoll_port);
        } else if (tcp->rxbuf.size) {
            prh_impl_report_tcpe_rx_data(tcp);
        }
    }
}

void prh_impl_process_tcpa_tx_data(prh_tcpsocket *tcp, prh_cono_pdata *pdata) {
    assert(tcp->txbuf.size == 0); // 上层必须在 tx done 的情况下继续发送数据
    if (tcp->close_req || tcp->epoll_err || tcp->epoll_hup) return;
    tcp->txbuf.size = pdata->u.size;
    assert(tcp->txbuf.size > 0);
    prh_impl_tcp_send_data(tcp);
}

void prh_impl_process_tcpa_tx_end(prh_tcpsocket *tcp, prh_cono_pdata *pdata) {
    if (tcp->close_req || tcp->epoll_err || tcp->epoll_hup) return;
    tcp->close_req = true;
    prh_impl_tcp_local_close(tcp);
}

void prh_impl_process_tcpa_rx_done(prh_tcpsocket *tcp, prh_cono_pdata *pdata) {
    tcp->rxbuf.size = 0;
    if (tcp->drained || tcp->epoll_err) return; // 对端或双端关闭且读缓存读取完，或发生错误之后：不能继续读取
    prh_impl_tcp_recv_data(tcp);
}

// https://blog.netherlabs.nl/articles/2009/01/18/the-ultimate-so_linger-page-or-why-is-my-tcp-not-reliable
//
// Sending data over a TCP socket really does not offer the same ‘it hit the disk’ semantics as
// writing to a normal file does (if you remember to call fsync()). In fact, all a successful
// write() in the TCP world means is that the kernel has accepted your data, and will now try to
// transmit it in its own sweet time. Even when the kernel feels that the packets carrying your
// data have been sent, in reality, they’ve only been handed off to the network adapter, which
// might actually even send the packets when it feels like it. From that point on, the data will
// traverse many such adapters and queues over the network, until it arrives at the remote host.
// The kernel there will acknowledge the data on receipt, and if the process that owns the socket
// is actually paying attention and trying to read from it, the data will finally have arrived at
// the application, and in filesystem speak, ‘hit the disk’. Note that the acknowledgment sent out
// only means the kernel saw the data - it does not mean the application did!
//
// When we issue a close() on a TCP/IP socket, depending on the circumstances, the kernel may do
// exactly that: close down the socket, and with it the TCP/IP connection that goes with it. And
// this does in fact happen - even though some of your data was still waiting to be sent, or had
// been sent but not acknowledged: the kernel can close the whole connection. This issue has led
// to a large number of postings on mailing lists, Usenet and fora, and these all quickly zero in
// on the SO_LINGER socket option, which appears to have been written with just this issue in
// mind: “When enabled, a close(2) or shutdown(2) will not return until all queued messages for
// the socket have been successfully sent or the linger timeout has been reached. Otherwise, the
// call returns immediately and the closing is done in the background. When the socket is closed
// as part of exit(2), it always lingers in the background.”
//
// So, we set this option, rerun our program. And it still does not work, not all our million
// bytes arrive. It turns out that in this case, section 4.2.2.13 of RFC 1122 tells us that a
// close() with any pending readable data could lead to an immediate reset being sent. “A host
// MAY implement a ‘half-duplex’ TCP close sequence, so that an application that has called CLOSE
// cannot continue to read data from the connection. If such a host issues a CLOSE call while
// received data is still pending in TCP, or if new data is received after CLOSE is called, its
// TCP SHOULD send a RST to show that data was lost.” And in our case, we have such data pending:
// the “220 Welcome\r\n” we transmitted in program B, but never read in program A!
//
// So, if we read that data first, and LINGER, are we good to go? Not really. The close() call
// really does not convey what we are trying to tell the kernel: please close the connection after
// sending all the data I submitted through write(). Luckily, the system call shutdown() is
// available, which tells the kernel exactly this. However, it alone is not enough. When
// shutdown() returns, we still have no indication that everything was received by program B.
// What we can do however is issue a shutdown(), which will lead to a FIN packet being sent to
// program B. Program B in turn will close down its socket, and we can detect this from program A:
// a subsequent read() will return 0.
//
// Well.. If we look at the HTTP protocol, there data is usually sent with length information
// included, either at the beginning of an HTTP response, or in the course of transmitting
// information (so called ‘chunked’ mode). And they do this for a reason. Only in this way can
// the receiving end be sure it received all information that it was sent. Using the shutdown()
// technique above really only tells us that the remote closed the connection. It does not actually
// guarantee that all data was received correctly by program B. The best advice is to send length
// information, and to have the remote program actively acknowledge that all data was received.
//
// What else can be done? If you need to deliver streaming data to a ‘stupid TCP/IP hole in the
// wall’, as I’ve had to do a number of times, it may be impossible to follow the sage advice
// above about sending length information, and getting acknowledgments. In such cases, it may not
// be good enough to accept the closing of the receiving side of the socket as an indication that
// everything arrived. Luckily, it turns out that Linux keeps track of the amount of unacknowledged
// data, which can be queried using the SIOCOUTQ ioctl(). Once we see this number hit 0, we can be
// reasonably sure our data reached at least the remote operating system. Unlike the shutdown()
// technique described above, SIOCOUTQ appears to be Linux-specific. Updates for other operating
// systems are welcome.
//
// 在处理这种复杂情况时，最好不要同时使用SO_LINGER和非阻塞套接字。因为它们的组合可能会导致难以预料和调试的问题。建议
// 采用shutdown()函数关闭套接字的写端，然后通过读取操作来检测对方是否关闭了连接（当读取返回0时，表示对方已经关闭了连
// 接，也就是达到了EOF，即文件结束标志）。这是一种更可靠的方式来确保数据的发送和接收完成情况。
//
// A few words on the Linux sendfile() and splice() system calls. It should also be noted that
// the Linux system calls sendfile() and splice() hit a spot in between - these usually manage
// to deliver the contents of the file to be sent, even if you immediately call close() after
// they return. This has to do with the fact that splice() (on which sendfile() is based) can
// only safely return after all packets have hit the TCP stack since it is zero copy, and can’t
// very well change its behaviour if you modify a file after the call returns! Please note that
// the functions do not wait until all the data has been acknowledged, it only waits until it has
// been sent.
//
// sendfile()和splice()通常能够将要发送的文件内容成功地传递给TCP栈，即使在它们返回后立即调用close()。这是因为
// splice()（sendfile()基于它实现）是零拷贝的，它只能在所有数据包都进入TCP栈后才能安全地返回。如果在splice()返
// 回后修改文件，它也无法改变其行为。

void prh_impl_process_tcp_epoll_events(prh_tcpsocket *tcp) {
    prh_epoll_receive_events(tcp);
    // 在tcp断连的四次握手之后，内核会立即把 EPOLLHUP 放入就绪队列，与读缓冲区是否还
    // 有数据无关。如果此时仍有未读数据，epoll_wait 会同时返回 EPOLLIN + EPOLLHUP；
    // 如果没有数据，会只返回 EPOLLHUP。
    // EPOLLERR 表示内核已检测到不可恢复的套接字错误（通常是 RST、ICMP 不可达等），此
    // 时：套接字已处于错误状态；所有后续 send() 或 recv() 立即返回-1和 ECONNRESET|
    // ENETRESET|...；因此收到 EPOLLERR 后，直接 close(fd) 即可。
    if (tcp->epoll_err || (tcp->epoll_hup && !tcp->epoll_in)) {
        prh_impl_report_tcpe_closed(tcp);
        return;
    }
    if (tcp->epoll_in) { // 收到 EPOLLRDHUP/EPOLLHUP 时，如果读缓冲区有数据会同时设置 EPOLLIN
        if (tcp->rxbuf.size == 0) { // 如果 rxbuf.size 大于零，表示当前正在读取数据，上层还没有 RX_DONE，读取操作会自动在 RX_DONE 后继续
            prh_impl_tcp_recv_data(tcp); // 后面可以一直读取直到 EAGAIN 为止
        }
        tcp->epoll_in = 0;
        if (tcp->epoll_hup) { // EPOLLHUP 之后不能继续发送数据
            return;
        }
    }
    if (tcp->epoll_out) {
        if (tcp->txbuf.size > 0) { // 如果当前数据已经发送完毕，后续数据等 TX_DATA 时可继续发送
            prh_impl_tcp_send_data(tcp); // 后面可以一直写入直到 EAGAIN 为止
        }
        tcp->epoll_out = 0;
    }
}

void prh_impl_finish_tcp_connect(prh_tcpsocket *tcp) {
    prh_epoll_receive_events(tcp);
    if (tcp->epoll_out && prh_impl_tcp_connect_result(tcp)) {
        prh_epoll_mod_tcp_connect(tcp);
        return;
    }
    prh_epoll_del_and_close(tcp->epoll_port);
    tcp->closed = true;
}

void prh_impl_tcp_init_buffer(prh_tcpsocket *tcp, prh_u32 txbuf_size, prh_u32 rxbuf_size) {
    assert(txbuf_size > 0 && rxbuf_size > 0);
    prh_byte_arrfit *txbuf = &tcp->txbuf;
    prh_byte_arrfit *rxbuf = &tcp->rxbuf;
    prh_arrfit_init(txbuf, txbuf_size);
    prh_arrfit_init(rxbuf, rxbuf_size);
}

bool prh_impl_report_tcpe_open_ind(prh_tcpsocket *tcp) {
    prh_impl_tcp_port *port = prh_impl_get_tcp_port(tcp);
    port->event.tcp = tcp; // PRH_TCPE_OPEN_IND 和 PRH_TCPE_OPENED 是互斥的
    prh_cono_post(PRH_TCPE_INDEX_OPEN_IND);
    prh_pwait_data data = prh_cono_subq_pwait(PRH_IMPL_TCPQ_UPPER);
    prh_impl_tcpa_accept *accept = (prh_impl_tcpa_accept *)data.pdata;
    assert(data.opcode == PRH_TCPA_OPEN_ACCEPT);
    if (accept->head.u.value) {
        prh_impl_tcp_init_buffer(tcp, accept->txbuf_size, accept->rxbuf_size);
        return true;
    }
    return false;
}

void prh_impl_wait_tcp_finish(prh_tcpsocket *tcp) {
    prh_pwait_data data = prh_cono_subq_pwait(PRH_IMPL_TCPQ_UPPER);
    assert(data.opcode == PRH_TCPA_FINISH);
    prh_byte_arrfit *txbuf = &tcp->txbuf;
    prh_byte_arrfit *rxbuf = &tcp->rxbuf;
    prh_arrfit_free(txbuf);
    prh_arrfit_free(rxbuf);
}

#define PRH_TCP_SOCKET_STACK_SIZE 512

prh_cono_proc prh_impl_tcp_socket_procedure(void) {
    prh_tcpsocket *tcp = prh_cono_spwan_data();
    if (tcp->server_accepted_socket && !prh_impl_report_tcpe_open_ind(tcp)) {
        prh_sock_tcp_reset(tcp->sock); // 新连接被上层拒绝，关闭该连接
        return;
    }
    if (tcp->sock != PRH_INVASOCK) {
        if (tcp->conn_wait_open) {
            prh_epoll_add_tcp_connect(tcp, prh_cono_self_subq(PRH_IMPL_TCPQ_EPOLL));
            prh_epoll_wait_tx_data(tcp->epoll_port); // 监听套接字可写事件来等待连接完成
            prh_pwait_data data = prh_cono_subq_pwait(PRH_IMPL_TCPQ_EPOLL);
            assert(data.opcode == PRH_EPEV_READY);
            prh_impl_finish_tcp_connect(tcp);
        } else {
            prh_epoll_add_tcp_socket(tcp, prh_cono_self_subq(PRH_IMPL_TCPQ_EPOLL));
        }
    } else {
        tcp->closed = true;
    }
    prh_impl_report_tcpe_opened(tcp);
    while (!tcp->closed) {
        prh_pwait_data data = prh_cono_pwait();
        if (data.subq_i == PRH_IMPL_TCPQ_UPPER) {
            assert(data.opcode < PRH_TCPA_FINISH);
            PRH_IMPL_TCPA_FROM_UPPER[data.opcode](tcp, data.pdata);
        } else {
            assert(data.subq_i == PRH_IMPL_TCPQ_EPOLL);
            prh_impl_process_tcp_epoll_events(tcp);
        }
    }
    prh_impl_wait_tcp_finish(tcp);
}

prh_tcpsocket *prh_impl_create_tcp_socket_routine(prh_cono_subq *cono_subq) {
    int size = (int)sizeof(prh_tcpsocket) + (int)sizeof(prh_impl_tcp_port);
    int subq_total_posts = 8; // PRH_MAX_SAME_TIME_POSTS_UPPER_TO_TCP 4 PRH_MAX_SAME_TIME_POSTS_EPOLL_TO_EACH_FILE_DESCRIPTOR 2
    prh_tcpsocket *tcp = prh_cono_spawx_fixed_subq(prh_impl_tcp_socket_procedure, PRH_TCP_SOCKET_STACK_SIZE, size, PRH_IMPL_TCPQ_NUM, subq_total_posts);
    prh_impl_tcp_port_init(tcp, cono_subq, prh_cono_get_subq((prh_spawn_data *)tcp, PRH_IMPL_TCPQ_UPPER));
    return tcp;
}

void prh_impl_start_tcp_socket_procedure(prh_cono_subq *cono_subq, prh_tcpsocket *new_connection) {
    int size = (int)sizeof(prh_tcpsocket) + (int)sizeof(prh_impl_tcp_port);
    int subq_total_posts = 8; // PRH_MAX_SAME_TIME_POSTS_UPPER_TO_TCP 4 PRH_MAX_SAME_TIME_POSTS_EPOLL_TO_EACH_FILE_DESCRIPTOR 2
    prh_tcpsocket *tcp = prh_cono_spawx_fixed_subq(prh_impl_tcp_socket_procedure, PRH_TCP_SOCKET_STACK_SIZE, size, PRH_IMPL_TCPQ_NUM, subq_total_posts);
    *tcp = *new_connection;
    prh_impl_tcp_port_init(tcp, cono_subq, prh_cono_get_subq((prh_spawn_data *)tcp, PRH_IMPL_TCPQ_UPPER));
    prh_cono_start((prh_spawn_data *)tcp, false);
}

void prh_tcp_connect(prh_cono_subq *cono_subq, const char *host, prh_u16 port) {
    prh_tcpsocket new_connection = {0};
    prh_sock_tcp_connect(&new_connection, host, port);
    prh_impl_start_tcp_socket_procedure(cono_subq, &new_connection);
}

#define PRH_TCP_LISTEN_STACK_SIZE 256

prh_cono_proc prh_impl_tcp_listen_procedure(void) {
    prh_tcplisten *listen = prh_cono_spwan_data();
    prh_tcpsocket new_connection;
    prh_epoll_add_tcp_accept(listen, prh_cono_self_subq(0));
    while (!listen->quit) {
        if (!prh_sock_tcp_accept(listen, &new_connection)) { // 添加限流控制
            prh_epoll_wait_rx_data(listen->epoll_port);
            prh_cono_pwait();
        } else if (new_connection.sock != PRH_INVASOCK) {
            prh_impl_start_tcp_socket_procedure(listen->upper_subq, &new_connection);
        }
    }
    prh_epoll_del_and_close(listen->epoll_port);
}

// 如果有人使用通配地址注册一个端口，那么该端口就不能再被其他人注册，之前有人注册过的也会被强制断开。
void prh_tcp_listen(prh_cono_subq *cono_subq, const char *host, prh_u16 port, int backlog) {
    int subq_total_posts = 2; // PRH_MAX_SAME_TIME_POSTS_EPOLL_TO_EACH_FILE_DESCRIPTOR 2
    prh_tcplisten *listen = prh_cono_spawx_fixed_subq(prh_impl_tcp_listen_procedure, PRH_TCP_LISTEN_STACK_SIZE, sizeof(prh_tcplisten), 1, subq_total_posts);
    prh_sock_tcp_listen(listen, host, port, backlog);
    listen->upper_subq = cono_subq;
    prh_cono_start((prh_spawn_data *)listen, false);
}

void prh_ipv6_tcp_listen(prh_cono_subq *cono_subq, const char *host, prh_u16 port, int backlog) {
    int subq_total_posts = 2; // PRH_MAX_SAME_TIME_POSTS_EPOLL_TO_EACH_FILE_DESCRIPTOR 2
    prh_tcplisten *listen = prh_cono_spawx_fixed_subq(prh_impl_tcp_listen_procedure, PRH_TCP_LISTEN_STACK_SIZE, sizeof(prh_tcplisten), 1, subq_total_posts);
    prh_ipv6_sock_tcp_listen(listen, host, port, backlog);
    listen->upper_subq = cono_subq;
    prh_cono_start((prh_spawn_data *)listen, false);
}
#endif // PRH_SOCK_IMPLEMENTATION
#endif // PRH_SOCK_INCLUDE

#ifdef __cplusplus
}
#endif
#endif // PRH_IMPL_INCLUDE_H
/*
------------------------------------------------------------------------------
This software is available under 2 licenses -- choose whichever you prefer.
------------------------------------------------------------------------------
ALTERNATIVE A - MIT License
Copyright (c) 2025 swdayu <github.com/swdayu>
Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
------------------------------------------------------------------------------
ALTERNATIVE B - Public Domain (www.unlicense.org)
This is free and unencumbered software released into the public domain.
Anyone is free to copy, modify, publish, use, compile, sell, or distribute this
software, either in source code form or as a compiled binary, for any purpose,
commercial or non-commercial, and by any means.
In jurisdictions that recognize copyright laws, the author or authors of this
software dedicate any and all copyright interest in the software to the public
domain. We make this dedication for the benefit of the public at large and to
the detriment of our heirs and successors. We intend this dedication to be an
overt act of relinquishment in perpetuity of all present and future rights to
this software under copyright law.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
------------------------------------------------------------------------------
*/